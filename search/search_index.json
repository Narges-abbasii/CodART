{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CodART: Automated Source Code Refactoring Toolkit Morteza Zakeri \u2020 \u2020 Ph.D. Student, Iran University of Science and Technology, Tehran, Iran (m-zakeri@live.com). Version 0.2.2 (16 March 2021) \u251c Download PDF versions v0.1.0 , v0.2.0 Abstract\u2014 Software refactoring is performed by changing the software structure without modifying its external behavior. Many software quality attributes can be enhanced through the source code refactoring, such as reusability, flexibility, understandability, and testability. Refactoring engines are tools that automate the application of refactorings: first, the user chooses a refactoring to apply, then the engine checks if the transformation is safe, and if so, transforms the program. Refactoring engines are a key component of modern Integrated Development Environments (IDEs), and programmers rely on them to perform refactorings. In this project, an open-source software toolkit for refactoring Java source codes, namely CodART, will be developed. ANTLR parser generator is used to create and modify the program syntax-tree and produce the refactored version of the program. To the best of our knowledge, CodART is the first open-source refactoring toolkit based on ANTLR. Index Terms: Software refactoring, refactoring engine, search-based refactoring, ANTLR, Java. 1 Introduction R efactoring is a behavior-preserving program transformation that improves the design of a program. Refactoring engines are tools that automate the application of refactorings. The programmer need only select which refactoring to apply, and the engine will automatically check the preconditions and apply the transformations across the entire program if the preconditions are satisfied. Refactoring is gaining popularity, as evidenced by the inclusion of refactoring engines in modern IDEs such as IntelliJ IDEA , Eclipse , or NetBeans for Java. Considering the EncapsulateField refactoring as an illustrative example. This refactoring replaces all references to a field with accesses through setter and getter methods. The EncapsulateField refactoring takes as input the name of the field to encapsulate and the names of the new getter and setter methods. It performs the following transformations: Creates a public getter method that returns the field's value, Creates a public setter method that updates the field's value, to a given parameter's value, Replaces all field reads with calls to the getter method, Replaces all field writes with calls to the setter method, Changes the field's access modifier to private. The EncapsulateField refactoring checks several preconditions, including that the code does not already contain accessor methods and that these methods are applicable to the expressions in which the field appears. Figure 1 shows a sample program before and after encapsulating the field f into the getF and setF methods. Figure 1. Example EncapsulateField refactoring Refactoring engines must be reliable. A fault in a refactoring engine can silently introduce bugs in the refactored program and lead to challenging debugging sessions. If the original program compiles, but the refactored program does not, the refactoring is obviously incorrect and can be easily undone. However, if the refactoring engine erroneously produces a refactored program that compiles but does not preserve the semantics of the original program, this can have severe consequences. To perform refactoring correctly, the tool has to operate on the syntax tree of the code, not on the text. Manipulating the syntax tree is much more reliable to preserve what the code is doing. Refactoring is not just understanding and updating the syntax tree. The tool also needs to figure out how to rerender the code into text back in the editor view, called code transformation. All in all, implementing decent refactoring is a challenging programming exercise, required compiler knowledge. In this project, we develop CodART, a toolkit for applying a given refactoring on the source code and obtain the refactored code. To this aim, we will use ANTLR [1] to generate and modify the program syntax tree. CodART development consists of two phases: In the first phase, 47 common refactoring operations will be automated, and in the second phase, an algorithm to find the best sequence of refactorings to apply on a given software will be developed using many-objective search-based approaches. The rest of this white-paper is organized as follows. Section 2 describes the refactoring operations in detail. Section 3 explains code smells in detail. Section 4 briefly discusses the search-based refactoring techniques and many-objective evolutionary algorithms. Section 5 explains the implementation details of the current version of CodART. Section 6 lists the Java project used to evaluate CodART. Section 7 articulates the proposals that existed behind the CodART projects. Finally, the conclusion and future works are discussed in Section 8. 2 Refactoring operations This section explains the refactoring operations used in the project. A catalog of 72 refactoring operations has been proposed by Fowler [2]. We called this refactorings atomic refactoring operations. Each refactoring operation has a definition and is clearly specified by the entities in which it is involved and the role of each. Table 1 describes the desirable refactorings, which we aim to automate them. It worth noting that not all of these refactoring operations are introduced by Fowler [2]. A concrete example for most of the refactoring operations in the table is available at https://refactoring.com/catalog/ . Examples of other refactorings can be found at https://refactoring.guru/refactoring/techniques and https://sourcemaking.com/refactoring/refactorings . Table 1. Refactoring operations Refactoring Definition Entities Roles Move class Move a class from a package to another package class source package, target package moved class Move method Move a method from a class to another. class method source class, target class moved method Merge packages Merge the elements of a set of packages in one of them package source package, target package Extract/Split package Add a package to compose the elements of another package package source package, target package Extract class Create a new class and move fields and methods from the old class to the new one class method source class, new class moved methods Extract method Extract a code fragment into a method method statement source method, new method moved statements Inline class Move all features of a class in another one and remove it class source class, target class Move field Move a field from a class to another class field source class, target class field Push down field Move a field of a superclass to a subclass class field super class, sub classes move field Push down method Move a method of a superclass to a subclass class method super class, sub classes moved method Pull up field Move a field from subclasses to the superclass class field sub classes, super class moved field Pull up method Move a method from subclasses to the superclass class method sub classes, super class moved method Increase field visibility Increase the visibility of a field from public to protected, protected to package or package to private class field source class source filed Decrease field visibility Decrease the visibility of a field from private to package, package to protected or protected to public class field source class source filed Make field final Make a non-final field final class field source class source filed Make field non-final Make a final field non-final class field source class source filed Make field static Make a non-static field static class field source class source filed Make field non-static Make a static field non-static class field source class source filed Remove field Remove a field from a class class field source class source filed Increase method visibility Increase the visibility of a method from public to protected, protected to package or package to private class method source class source method Decrease method visibility Decrease the visibility of a method from private to package, package to protected or protected to public class method source class source method Make method final Make a non-final method final class method source class source method Make method non-final Make a final method non-final class method source class source method Make method static Make a non-static method static class method source class source method Make method non-static Make a static method non-static class method source class source method Remove method Remove a method from a class class method source class source method Make class-final Make a non-final class final class source class Make class non-final Make a final class non-final class source class Make class abstract Change a concrete class to abstract class source class Make class concrete Change an abstract class to concrete class source class Extract subclass Create a subclass for a set of features class method source class, new subclass moved methods Extract interface Extract methods of a class into an interface class method source class, new interface interface methods Inline method Move the body of a method into its callers and remove the method method source method, callers method Collapse hierarchy Merge a superclass and a subclass class superclass, subclass Remove control flag Replace control flag with a break class method source class source method Replace nested conditional with guard clauses Replace nested conditional with guard clauses class method source class source method Replace constructor with a factory function Replace constructor with a factory function class source class Replace exception with test Replace exception with precheck class method source class source method Rename field Rename a field class field source class source filed Rename method Rename a method class method source class source method Rename class Rename a class class source class Rename package Rename a package package source package Encapsulate field Create setter/mutator and getter/accessor methods for a private field class field source class source filed Replace parameter with query Replace parameter with query class method source class source method Pull up constructor body Move the constructor class method subclass class, superclass constructor Replace control flag with break Replace control flag with break class method source class source method Remove flag argument Remove flag argument class method source class source method Total 47 \u2014 \u2014 3 Code smells Deciding when and where to start refactoring\u2014and when and where to stop\u2014is just as important to refactoring as knowing how to operate its mechanics [2]. To answer this important question, we should know the refactoring activities. The refactoring process consists of six distinct activities [9]: Identify where the software should be refactored. Determine which refactoring(s) should be applied to the identified places. Guarantee that the applied refactoring preserves behavior. Apply the refactoring. Assess the effect of the refactoring on quality characteristics of the software (e.g., complexity, understandability, maintainability) or the process (e.g., productivity, cost, effort). Maintain the consistency between the refactored program code and other software artifacts (such as documentation, design documents, requirements specifications, tests, etc.). Table 2. Code smells Code smell Descriptions and other names God class The class defines many data members (fields) and methods and exhibits low cohesion. The god class smell occurs when a huge class surrounded by many data classes acts as a controller (i.e., takes most of the decisions and monopolizes the software's functionality). Other names: Blob, large class, brain class. Long method This smell occurs when a method is too long to understand and most presumably perform more than one responsibility. Other names: God method, brain method, large method. Feature envy This smell occurs when a method seems more interested in a class other than the one it actually is in. Data class This smell occurs when a class contains only fields and possibly getters/setters without any behavior (methods). Shotgun surgery This smell characterizes the situation when one kind of change leads to many changes to multiple different classes. When the changes are all over the place, they are hard to find, and it is easy to miss a necessary change. Refused bequest This smell occurs when a subclass rejects some of the methods or properties offered by its superclass. Functional decomposition This smell occurs when the experienced developers coming from procedural languages background write highly procedural and non-object-oriented code in an object-oriented language. Long parameter list This smell occurs when a method accepts a long list of parameters. Such lists are hard to understand and difficult to use. Promiscuous package A package can be considered promiscuous if it contains classes implementing too many features, making it too hard to understand and maintain. As for god class and long method, this smell arises when the package has low cohesion since it manages different responsibilities. Misplaced class A Misplaced Class smell suggests a class that is in a package that contains other classes not related to it. Switch statement This smell occurs when switch statements that switch on type codes are spread across the software system instead of exploiting polymorphism. Spaghetti code This smell refers to an unmaintainable, incomprehensible code without any structure. The smell does not exploit and prevents the use of object-orientation mechanisms and concepts. Divergent change Divergent change occurs when one class is commonly changed in different ways for different reasons. Other names: Multifaceted abstraction Deficient encapsulation This smell occurs when the declared accessibility of one or more members of abstraction is more permissive than actually required. Swiss army knife This smell arises when the designer attempts to provide all possible uses of the class and ends up in an excessively complex class interface. Lazy class Unnecessary abstraction Cyclically-dependent modularization This smell arises when two or more abstractions depend on each other directly or indirectly. Primitive obsession This smell occurs when primitive data types are used where an abstraction encapsulating the primitives could serve better. Speculative generality This smell occurs where abstraction is created based on speculated requirements. It is often unnecessary that makes things difficult to understand and maintain. Message chains A message chain occurs when a client requests another object, that object requests yet another one, and so on. These chains mean that the client is dependent on navigation along with the class structure. Any changes in these relationships require modifying the client. Total 20 4 Search-based refactoring After refactoring operations were automated, we must decide which refactorings souled be performed in order to elevate software quality. The concern about using refactoring operations in Table 1 is whether each one of them has a positive impact on the refactored code quality or not. Finding the right sequence of refactorings to be applied in a software artifact is considered a challenging task since there is a wide range of refactorings. The ideal sequence is, therefore, must correlate to different quality attributes to be improved as a result of applying refactorings. Finding the best refactoring sequence is an optimization problem that can be solved by search techniques in the field known as Search-Based Software Engineering (SBSE) [3]. In this approach, refactorings are applied stochastically to the original software solution, and then the software is measured using a fitness function consisting of one or more software metrics. There are various metric suites available to measure characteristics like cohesion and coupling, but different metrics measure the software in different ways, and thus how they are applied will have a different effect on the outcome. The second phase of this project is to use a many-objective search algorithm to find the best sequence of refactoring on a given project. Recently, many-objective SBSE approach for refactoring [3]\u2013[5] and remodularization, regrouping a set of classes C in terms of packages P, [6] has gained more attention due to its ability to find the best sequence of refactoring operations which is led to the improvement in software quality. Therefore, we first focus on implementing the proposed approach approaches in [3], [5], [6] as fundamental works in this area. Then, we will improve their approach. As a new contribution, we add new refactoring operations and new objective functions to improve the quality attribute of the software. We also evaluate our method on the new software projects which are not used in previous works. 5 Implementation This section describes implementation details of the CodART. It includes CodART architecture, high-level repository directories structure, refactoring automation with ANTLR parser generator, and refactoring recommendation through many-objective search-based software engineering techniques. 5.1 CodART architecture The high-level architecture of CodART is shown in Figure 2. The source code consists of several Python packages and directories. We briefly describe each component in CodART. Figure 2. CodART architecture I. grammars : This directory contains three ANTLR4 grammars for the Java programming language: Java9_v2.g4 : This grammar was used in the initial version of CodART. The main problem of this grammar is that parsing large source code files is performed very slow due to some decisions used in grammar design. We have switched to the fast grammar JavaParserLabled.g4 . JavaLexer.g4 : The lexer of Java fast grammar. This lexer is used for both fast parsers, i.e., JavaParser.g4 and JavaParserLabeled. JavaParser.g4 : The original parser of Java fast grammar. This parser is currently used in some refactoring. In the future release, this grammar will be replaced with JavaPaseredLabled.g4 . JavaParserLabeled.g4 : This file contains the same JavaParsar.g4 grammar. The only difference is that the rules with more than one extension are labled with a specific name. The ANTLR parser generator thus generates separate visitor and listener methods for each extension. This grammar facilitates the development of some refactoring. It is the preferred parser in CodART project. II. gen : The gen packages contain all generated source code for the parser, lexer, visitor, and listener for different grammars available in the grammars directory. To develop refactorings and code smells, gen.JavaLabled package, which contains JavaParserLabled.g4 generated source code, must be used. The content of this package is generated automatically , and therefore it should not be modified manually . Modules within this gen package are just for importing and using in other modules. III. speedy : The python implementation for ANTLR is less efficient than Java or C++ implementation. The speedy module implements a Java parser with a C++ back-end, improving the efficiency and speed of parsing. It uses speedy-antlr implementation with some minor changes. The current version of the speedy module use java9_v2.g4 grammar, which inherently slow as described. To switch to C++ back-end, first, the speedy module must be installed on the client system. It requires a C++ compiler. We recommended to CodART developers using the Python back-end as switching to C++ back-end would be done transparently in the future release. The Python back-end saves debugging and developing time. IV. refactorings : The refactorings package is the main package in the CodART project and contains numerous Python modules that form the kernel functionalities of CodART. Each module implements the automation of one refactoring operation according to standard practices. The modules may include several classes which inherit from ANTLR listeners. Sub-packages in this module contain refactorings, which are in an early step of development or deprecated version of an existing refactoring. This package is under active development and testing. The module in the root packages can be used for testing purposes. V. refactoring_design_patters : The refactoring_design_pattern packages contain modules that implement refactoring to a specific design pattern automatically. VI. smells : The smell package implements the automatic detection of software code and design smells relevant to the refactoring operation supported by CodART. Each smell corresponds to one or more refactoring in the refactoring package. VII. metrics : The metrics packages contain several modules that implement the computation of the most well-known source code metrics. These metrics used to detect code smells and measuring the quality of software in terms of quality attributed. VIII. tests : The test directory contains individual test data and test cases that are used for developing specific refactorings. Typically, each test case is a single Java file that contains one or more Java classes. IX. benchmark_projects : This directory contains several open-source Java projects formerly used in automated refactoring researches by many researchers. Once the implementation of refactoring is completed, it will be executed and tested on all projects in this benchmark to ensure the generalization of functionality proposed by the implementation. X. Other packages : The information of other packages will be announced in the future. 5.2 Refactoring automation Each refactoring operation in Table 1 is implemented as an API, with the refactoring name. The API receives the involved entities with their refactoring roles and other required data as inputs, checks the feasibility of the refactoring using refactoring preconditions described in [2], performs the refactoring if it is feasible, and returns the refactored code or return null if the refactoring is not feasible. The core of our refactoring engine is a syntax-tree modification algorithm. Fundamentally, ANTLR is used to generate and modify the syntax-tree of a given program. Each refactoring API is an ANTLR Listener or visitor class, which required argument by its constructor and preform refactoring when call by parse-tree walker object. The refactoring target and input parameters must read from a configuration file, which can be expressed in JSON, XML, or YAML formats. The key to use ANTLR for refactoring tasks is the TokenStreamRewriter object that knows how to give altered views of a token stream without actually modifying the stream. It treats all of the manipulation methods as \"instructions\" and queues them up for lazy execution when traversing the token stream to render it back as text. The rewriter executes those instructions every time we call getText() . This strategy is very effective for the general problem of source code instrumentation or refactoring. The TokenStreamRewriter is a powerful and extremely efficient means of manipulating a token stream. 5.3 Refactoring recommendation A solution consists of a sequence of n refactoring operations applied to different code elements in the source code to fix. In order to represent a candidate solution (individual/chromosome), we use a vector-based representation. Each vector\u2019s dimension represents a refactoring operation where the order of applying these refactoring operations corresponds to their positions in the vector. The initial population is generated by randomly assigning a sequence of refactorings to some code fragments. Each generated refactoring solution is executed on the software system S . Once all required data is computed, the solution is evaluated based on the quality of the resulting design. 6 Benchmark projects and testbed To ensure CodART works properly, we are running it on many real-life software projects. Refactorings are applied to the software systems listed in Table 3. Benchmark projects may update and extend in the future. For the time being, we use a set of well-known open-source Java projects that have been intensely studied in previous works. We have also added two new Java software programs, WEKA and ANTLR, to examine the versatility of CodART performance on real-life software projects. Table 3. Software systems refactored in this project System Release Previous releases Domain Reference Xerces-J v2.7.0 -- software packages for parsing XML [3], [6] Azureus v2.3.0.6 -- Java BitTorrent client for handling multiple torrents [3] ArgoUML v0.26 and v0.3 -- UML tool for object-oriented design [3] Apache Ant v1.5.0 and v1.7.0 -- Java build tool and library [3] GanttProject v1.10.2 and v1.11.1 -- project management [3], [6], [5] JHotDraw v6.1 and v6.0b1 and v5.3 -- graphics tool [6], [5], [4] JFreeChart v1.0.9 -- chart tool [6] Beaver v0.9.11 and v0.9.8 -- parser generator [5], [4] Apache XML-RPC v3.1.1 -- B2B communications [5], [4] JRDF v0.3.4.3 -- semantic web (resource management) [5] XOM v1.2.1 -- XML tool [5] JSON v1.1 -- software packages for parsing JSON [4] JFlex v1.4.1 -- lexical analyzer generator [4] Mango v2.0.1 -- -- [4] Weka v3.9 -- data mining tool New ANTLR v4.8.0 -- parser generator tool New 7 CodART in IUST Developing a comprehensive refactoring engine required thousand of hours of programming. Refactoring is not just understanding and updating the syntax tree. The tool also needs to figure out how to rerender the code into text back in the editor view. According to a quote by Fowler [2] in his well-known refactoring book: \u201cimplementing decent refactoring is a challenging programming exercise\u2014one that I\u2019m mostly unaware of as I gaily use the tools.\u201d We have defined the basic functionalities of the CodART system as several student projects with different proposals. Students who will take our computer science course, including compiler design and construction, advanced compilers, and advanced software engineering, must be worked on these proposals as part of their course fulfillments. These projects try to familiarize students with the practical usage of compilers from the software engineering point of view. The detailed information of our current proposals are available in the following links: Core refactoring operations development (Fall 2020) Core code smells development Current semester (Winter and Spring 2021) Core search-based development (Future semesters) Core refactoring to design patterns development (Future semesters) Note: Students whose final project is confirmed by the reverse engineering laboratory have an opportunity to work on CodART as an independent and advanced research project. The only prerequisite is to pass the compiler graduate course by Dr. Saeed Parsa. 8 Conclusion and remarks Software refactoring is used to reduce the costs and risks of software evolution. Automated software refactoring tools can reduce risks caused by manual refactoring, improve efficiency, and reduce software refactoring difficulties. Researchers have made great efforts to research how to implement and improve automated software refactoring tools. However, the results of automated refactoring tools often deviate from the intentions of the implementer. The goal of this project is to propose an open-source refactoring engine and toolkit that can automatically find the best refactoring sequence required for a given software and apply this sequence. Since the tool is work based on compiler principles, it is reliable to be used in practice and has many benefits for software developer companies. Students who participate in the project will learn compiler techniques such as lexing, parsing, source code analysis, and source code transformation. They also learn about software refactoring, search-based software engineering, optimization, software quality, and object-orient metrics. Conflict of interest The project is supported by the IUST Reverse Engineering Research Laboratory . Interested students may continue working on this project to fulfill their final bachelor and master thesis or their internship. References [1] T. Parr and K. Fisher, \u201cLL(*): the foundation of the ANTLR parser generator,\u201d Proc. 32nd ACM SIGPLAN Conf. Program. Lang. Des. Implement., pp. 425\u2013436, 2011. [2] M. K. B. Fowler, Refactoring: improving the design of existing code, Second Edi. Addison-Wesley, 2018. [3] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. O\u0301 Cinne\u0301ide, and K. Deb, \u201cOn the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,\u201d Empir. Softw. Eng., vol. 21, no. 6, pp. 2503\u20132545, Dec. 2016. [4] M. Mohan, D. Greer, and P. McMullan, \u201cTechnical debt reduction using search based automated refactoring,\u201d J. Syst. Softw., vol. 120, pp. 183\u2013194, Oct. 2016. [5] M. Mohan and D. Greer, \u201cUsing a many-objective approach to investigate automated refactoring,\u201d Inf. Softw. Technol., vol. 112, pp. 83\u2013101, Aug. 2019. [6] W. Mkaouer et al., \u201cMany-Objective Software Remodularization Using NSGA-III,\u201d ACM Trans. Softw. Eng. Methodol., vol. 24, no. 3, pp. 1\u201345, May 2015. [7] M. Mohan and D. Greer, \u201cMultiRefactor: automated refactoring to improve software quality,\u201d 2017, pp. 556\u2013572. [8] N. Tsantalis, T. Chaikalis, and A. Chatzigeorgiou, \u201cTen years of JDeodorant: lessons learned from the hunt for smells,\u201d in 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), 2018, pp. 4\u201314. [9] T. Mens and T. Tourwe, \u201cA survey of software refactoring,\u201d IEEE Trans. Softw. Eng., vol. 30, no. 2, pp. 126\u2013139, Feb. 2004. Related links IUST compiler course official webpage ANTLR slides: PART 1: Introduction ANTLR slides: PART 2: Getting started in Java ANTLR slides: PART 3: Getting started in C# Endnotes [1] https://www.jetbrains.com/idea/ [2] http://www.eclipse.org [3] http://www.netbeans.org [4] https://github.com/mmohan01/MultiRefactor [5] http://sourceforge.net/projects/recoder [6] http://reverse.iust.ac.ir","title":"Home"},{"location":"#codart-automated-source-code-refactoring-toolkit","text":"Morteza Zakeri \u2020 \u2020 Ph.D. Student, Iran University of Science and Technology, Tehran, Iran (m-zakeri@live.com). Version 0.2.2 (16 March 2021) \u251c Download PDF versions v0.1.0 , v0.2.0 Abstract\u2014 Software refactoring is performed by changing the software structure without modifying its external behavior. Many software quality attributes can be enhanced through the source code refactoring, such as reusability, flexibility, understandability, and testability. Refactoring engines are tools that automate the application of refactorings: first, the user chooses a refactoring to apply, then the engine checks if the transformation is safe, and if so, transforms the program. Refactoring engines are a key component of modern Integrated Development Environments (IDEs), and programmers rely on them to perform refactorings. In this project, an open-source software toolkit for refactoring Java source codes, namely CodART, will be developed. ANTLR parser generator is used to create and modify the program syntax-tree and produce the refactored version of the program. To the best of our knowledge, CodART is the first open-source refactoring toolkit based on ANTLR. Index Terms: Software refactoring, refactoring engine, search-based refactoring, ANTLR, Java.","title":"CodART: Automated Source Code Refactoring Toolkit"},{"location":"#1-introduction","text":"R efactoring is a behavior-preserving program transformation that improves the design of a program. Refactoring engines are tools that automate the application of refactorings. The programmer need only select which refactoring to apply, and the engine will automatically check the preconditions and apply the transformations across the entire program if the preconditions are satisfied. Refactoring is gaining popularity, as evidenced by the inclusion of refactoring engines in modern IDEs such as IntelliJ IDEA , Eclipse , or NetBeans for Java. Considering the EncapsulateField refactoring as an illustrative example. This refactoring replaces all references to a field with accesses through setter and getter methods. The EncapsulateField refactoring takes as input the name of the field to encapsulate and the names of the new getter and setter methods. It performs the following transformations: Creates a public getter method that returns the field's value, Creates a public setter method that updates the field's value, to a given parameter's value, Replaces all field reads with calls to the getter method, Replaces all field writes with calls to the setter method, Changes the field's access modifier to private. The EncapsulateField refactoring checks several preconditions, including that the code does not already contain accessor methods and that these methods are applicable to the expressions in which the field appears. Figure 1 shows a sample program before and after encapsulating the field f into the getF and setF methods. Figure 1. Example EncapsulateField refactoring Refactoring engines must be reliable. A fault in a refactoring engine can silently introduce bugs in the refactored program and lead to challenging debugging sessions. If the original program compiles, but the refactored program does not, the refactoring is obviously incorrect and can be easily undone. However, if the refactoring engine erroneously produces a refactored program that compiles but does not preserve the semantics of the original program, this can have severe consequences. To perform refactoring correctly, the tool has to operate on the syntax tree of the code, not on the text. Manipulating the syntax tree is much more reliable to preserve what the code is doing. Refactoring is not just understanding and updating the syntax tree. The tool also needs to figure out how to rerender the code into text back in the editor view, called code transformation. All in all, implementing decent refactoring is a challenging programming exercise, required compiler knowledge. In this project, we develop CodART, a toolkit for applying a given refactoring on the source code and obtain the refactored code. To this aim, we will use ANTLR [1] to generate and modify the program syntax tree. CodART development consists of two phases: In the first phase, 47 common refactoring operations will be automated, and in the second phase, an algorithm to find the best sequence of refactorings to apply on a given software will be developed using many-objective search-based approaches. The rest of this white-paper is organized as follows. Section 2 describes the refactoring operations in detail. Section 3 explains code smells in detail. Section 4 briefly discusses the search-based refactoring techniques and many-objective evolutionary algorithms. Section 5 explains the implementation details of the current version of CodART. Section 6 lists the Java project used to evaluate CodART. Section 7 articulates the proposals that existed behind the CodART projects. Finally, the conclusion and future works are discussed in Section 8.","title":"1 Introduction"},{"location":"#2-refactoring-operations","text":"This section explains the refactoring operations used in the project. A catalog of 72 refactoring operations has been proposed by Fowler [2]. We called this refactorings atomic refactoring operations. Each refactoring operation has a definition and is clearly specified by the entities in which it is involved and the role of each. Table 1 describes the desirable refactorings, which we aim to automate them. It worth noting that not all of these refactoring operations are introduced by Fowler [2]. A concrete example for most of the refactoring operations in the table is available at https://refactoring.com/catalog/ . Examples of other refactorings can be found at https://refactoring.guru/refactoring/techniques and https://sourcemaking.com/refactoring/refactorings . Table 1. Refactoring operations Refactoring Definition Entities Roles Move class Move a class from a package to another package class source package, target package moved class Move method Move a method from a class to another. class method source class, target class moved method Merge packages Merge the elements of a set of packages in one of them package source package, target package Extract/Split package Add a package to compose the elements of another package package source package, target package Extract class Create a new class and move fields and methods from the old class to the new one class method source class, new class moved methods Extract method Extract a code fragment into a method method statement source method, new method moved statements Inline class Move all features of a class in another one and remove it class source class, target class Move field Move a field from a class to another class field source class, target class field Push down field Move a field of a superclass to a subclass class field super class, sub classes move field Push down method Move a method of a superclass to a subclass class method super class, sub classes moved method Pull up field Move a field from subclasses to the superclass class field sub classes, super class moved field Pull up method Move a method from subclasses to the superclass class method sub classes, super class moved method Increase field visibility Increase the visibility of a field from public to protected, protected to package or package to private class field source class source filed Decrease field visibility Decrease the visibility of a field from private to package, package to protected or protected to public class field source class source filed Make field final Make a non-final field final class field source class source filed Make field non-final Make a final field non-final class field source class source filed Make field static Make a non-static field static class field source class source filed Make field non-static Make a static field non-static class field source class source filed Remove field Remove a field from a class class field source class source filed Increase method visibility Increase the visibility of a method from public to protected, protected to package or package to private class method source class source method Decrease method visibility Decrease the visibility of a method from private to package, package to protected or protected to public class method source class source method Make method final Make a non-final method final class method source class source method Make method non-final Make a final method non-final class method source class source method Make method static Make a non-static method static class method source class source method Make method non-static Make a static method non-static class method source class source method Remove method Remove a method from a class class method source class source method Make class-final Make a non-final class final class source class Make class non-final Make a final class non-final class source class Make class abstract Change a concrete class to abstract class source class Make class concrete Change an abstract class to concrete class source class Extract subclass Create a subclass for a set of features class method source class, new subclass moved methods Extract interface Extract methods of a class into an interface class method source class, new interface interface methods Inline method Move the body of a method into its callers and remove the method method source method, callers method Collapse hierarchy Merge a superclass and a subclass class superclass, subclass Remove control flag Replace control flag with a break class method source class source method Replace nested conditional with guard clauses Replace nested conditional with guard clauses class method source class source method Replace constructor with a factory function Replace constructor with a factory function class source class Replace exception with test Replace exception with precheck class method source class source method Rename field Rename a field class field source class source filed Rename method Rename a method class method source class source method Rename class Rename a class class source class Rename package Rename a package package source package Encapsulate field Create setter/mutator and getter/accessor methods for a private field class field source class source filed Replace parameter with query Replace parameter with query class method source class source method Pull up constructor body Move the constructor class method subclass class, superclass constructor Replace control flag with break Replace control flag with break class method source class source method Remove flag argument Remove flag argument class method source class source method Total 47 \u2014 \u2014","title":"2 Refactoring operations"},{"location":"#3-code-smells","text":"Deciding when and where to start refactoring\u2014and when and where to stop\u2014is just as important to refactoring as knowing how to operate its mechanics [2]. To answer this important question, we should know the refactoring activities. The refactoring process consists of six distinct activities [9]: Identify where the software should be refactored. Determine which refactoring(s) should be applied to the identified places. Guarantee that the applied refactoring preserves behavior. Apply the refactoring. Assess the effect of the refactoring on quality characteristics of the software (e.g., complexity, understandability, maintainability) or the process (e.g., productivity, cost, effort). Maintain the consistency between the refactored program code and other software artifacts (such as documentation, design documents, requirements specifications, tests, etc.). Table 2. Code smells Code smell Descriptions and other names God class The class defines many data members (fields) and methods and exhibits low cohesion. The god class smell occurs when a huge class surrounded by many data classes acts as a controller (i.e., takes most of the decisions and monopolizes the software's functionality). Other names: Blob, large class, brain class. Long method This smell occurs when a method is too long to understand and most presumably perform more than one responsibility. Other names: God method, brain method, large method. Feature envy This smell occurs when a method seems more interested in a class other than the one it actually is in. Data class This smell occurs when a class contains only fields and possibly getters/setters without any behavior (methods). Shotgun surgery This smell characterizes the situation when one kind of change leads to many changes to multiple different classes. When the changes are all over the place, they are hard to find, and it is easy to miss a necessary change. Refused bequest This smell occurs when a subclass rejects some of the methods or properties offered by its superclass. Functional decomposition This smell occurs when the experienced developers coming from procedural languages background write highly procedural and non-object-oriented code in an object-oriented language. Long parameter list This smell occurs when a method accepts a long list of parameters. Such lists are hard to understand and difficult to use. Promiscuous package A package can be considered promiscuous if it contains classes implementing too many features, making it too hard to understand and maintain. As for god class and long method, this smell arises when the package has low cohesion since it manages different responsibilities. Misplaced class A Misplaced Class smell suggests a class that is in a package that contains other classes not related to it. Switch statement This smell occurs when switch statements that switch on type codes are spread across the software system instead of exploiting polymorphism. Spaghetti code This smell refers to an unmaintainable, incomprehensible code without any structure. The smell does not exploit and prevents the use of object-orientation mechanisms and concepts. Divergent change Divergent change occurs when one class is commonly changed in different ways for different reasons. Other names: Multifaceted abstraction Deficient encapsulation This smell occurs when the declared accessibility of one or more members of abstraction is more permissive than actually required. Swiss army knife This smell arises when the designer attempts to provide all possible uses of the class and ends up in an excessively complex class interface. Lazy class Unnecessary abstraction Cyclically-dependent modularization This smell arises when two or more abstractions depend on each other directly or indirectly. Primitive obsession This smell occurs when primitive data types are used where an abstraction encapsulating the primitives could serve better. Speculative generality This smell occurs where abstraction is created based on speculated requirements. It is often unnecessary that makes things difficult to understand and maintain. Message chains A message chain occurs when a client requests another object, that object requests yet another one, and so on. These chains mean that the client is dependent on navigation along with the class structure. Any changes in these relationships require modifying the client. Total 20","title":"3 Code smells"},{"location":"#4-search-based-refactoring","text":"After refactoring operations were automated, we must decide which refactorings souled be performed in order to elevate software quality. The concern about using refactoring operations in Table 1 is whether each one of them has a positive impact on the refactored code quality or not. Finding the right sequence of refactorings to be applied in a software artifact is considered a challenging task since there is a wide range of refactorings. The ideal sequence is, therefore, must correlate to different quality attributes to be improved as a result of applying refactorings. Finding the best refactoring sequence is an optimization problem that can be solved by search techniques in the field known as Search-Based Software Engineering (SBSE) [3]. In this approach, refactorings are applied stochastically to the original software solution, and then the software is measured using a fitness function consisting of one or more software metrics. There are various metric suites available to measure characteristics like cohesion and coupling, but different metrics measure the software in different ways, and thus how they are applied will have a different effect on the outcome. The second phase of this project is to use a many-objective search algorithm to find the best sequence of refactoring on a given project. Recently, many-objective SBSE approach for refactoring [3]\u2013[5] and remodularization, regrouping a set of classes C in terms of packages P, [6] has gained more attention due to its ability to find the best sequence of refactoring operations which is led to the improvement in software quality. Therefore, we first focus on implementing the proposed approach approaches in [3], [5], [6] as fundamental works in this area. Then, we will improve their approach. As a new contribution, we add new refactoring operations and new objective functions to improve the quality attribute of the software. We also evaluate our method on the new software projects which are not used in previous works.","title":"4 Search-based refactoring"},{"location":"#5-implementation","text":"This section describes implementation details of the CodART. It includes CodART architecture, high-level repository directories structure, refactoring automation with ANTLR parser generator, and refactoring recommendation through many-objective search-based software engineering techniques.","title":"5 Implementation"},{"location":"#51-codart-architecture","text":"The high-level architecture of CodART is shown in Figure 2. The source code consists of several Python packages and directories. We briefly describe each component in CodART. Figure 2. CodART architecture I. grammars : This directory contains three ANTLR4 grammars for the Java programming language: Java9_v2.g4 : This grammar was used in the initial version of CodART. The main problem of this grammar is that parsing large source code files is performed very slow due to some decisions used in grammar design. We have switched to the fast grammar JavaParserLabled.g4 . JavaLexer.g4 : The lexer of Java fast grammar. This lexer is used for both fast parsers, i.e., JavaParser.g4 and JavaParserLabeled. JavaParser.g4 : The original parser of Java fast grammar. This parser is currently used in some refactoring. In the future release, this grammar will be replaced with JavaPaseredLabled.g4 . JavaParserLabeled.g4 : This file contains the same JavaParsar.g4 grammar. The only difference is that the rules with more than one extension are labled with a specific name. The ANTLR parser generator thus generates separate visitor and listener methods for each extension. This grammar facilitates the development of some refactoring. It is the preferred parser in CodART project. II. gen : The gen packages contain all generated source code for the parser, lexer, visitor, and listener for different grammars available in the grammars directory. To develop refactorings and code smells, gen.JavaLabled package, which contains JavaParserLabled.g4 generated source code, must be used. The content of this package is generated automatically , and therefore it should not be modified manually . Modules within this gen package are just for importing and using in other modules. III. speedy : The python implementation for ANTLR is less efficient than Java or C++ implementation. The speedy module implements a Java parser with a C++ back-end, improving the efficiency and speed of parsing. It uses speedy-antlr implementation with some minor changes. The current version of the speedy module use java9_v2.g4 grammar, which inherently slow as described. To switch to C++ back-end, first, the speedy module must be installed on the client system. It requires a C++ compiler. We recommended to CodART developers using the Python back-end as switching to C++ back-end would be done transparently in the future release. The Python back-end saves debugging and developing time. IV. refactorings : The refactorings package is the main package in the CodART project and contains numerous Python modules that form the kernel functionalities of CodART. Each module implements the automation of one refactoring operation according to standard practices. The modules may include several classes which inherit from ANTLR listeners. Sub-packages in this module contain refactorings, which are in an early step of development or deprecated version of an existing refactoring. This package is under active development and testing. The module in the root packages can be used for testing purposes. V. refactoring_design_patters : The refactoring_design_pattern packages contain modules that implement refactoring to a specific design pattern automatically. VI. smells : The smell package implements the automatic detection of software code and design smells relevant to the refactoring operation supported by CodART. Each smell corresponds to one or more refactoring in the refactoring package. VII. metrics : The metrics packages contain several modules that implement the computation of the most well-known source code metrics. These metrics used to detect code smells and measuring the quality of software in terms of quality attributed. VIII. tests : The test directory contains individual test data and test cases that are used for developing specific refactorings. Typically, each test case is a single Java file that contains one or more Java classes. IX. benchmark_projects : This directory contains several open-source Java projects formerly used in automated refactoring researches by many researchers. Once the implementation of refactoring is completed, it will be executed and tested on all projects in this benchmark to ensure the generalization of functionality proposed by the implementation. X. Other packages : The information of other packages will be announced in the future.","title":"5.1 CodART architecture"},{"location":"#52-refactoring-automation","text":"Each refactoring operation in Table 1 is implemented as an API, with the refactoring name. The API receives the involved entities with their refactoring roles and other required data as inputs, checks the feasibility of the refactoring using refactoring preconditions described in [2], performs the refactoring if it is feasible, and returns the refactored code or return null if the refactoring is not feasible. The core of our refactoring engine is a syntax-tree modification algorithm. Fundamentally, ANTLR is used to generate and modify the syntax-tree of a given program. Each refactoring API is an ANTLR Listener or visitor class, which required argument by its constructor and preform refactoring when call by parse-tree walker object. The refactoring target and input parameters must read from a configuration file, which can be expressed in JSON, XML, or YAML formats. The key to use ANTLR for refactoring tasks is the TokenStreamRewriter object that knows how to give altered views of a token stream without actually modifying the stream. It treats all of the manipulation methods as \"instructions\" and queues them up for lazy execution when traversing the token stream to render it back as text. The rewriter executes those instructions every time we call getText() . This strategy is very effective for the general problem of source code instrumentation or refactoring. The TokenStreamRewriter is a powerful and extremely efficient means of manipulating a token stream.","title":"5.2 Refactoring automation"},{"location":"#53-refactoring-recommendation","text":"A solution consists of a sequence of n refactoring operations applied to different code elements in the source code to fix. In order to represent a candidate solution (individual/chromosome), we use a vector-based representation. Each vector\u2019s dimension represents a refactoring operation where the order of applying these refactoring operations corresponds to their positions in the vector. The initial population is generated by randomly assigning a sequence of refactorings to some code fragments. Each generated refactoring solution is executed on the software system S . Once all required data is computed, the solution is evaluated based on the quality of the resulting design.","title":"5.3 Refactoring recommendation"},{"location":"#6-benchmark-projects-and-testbed","text":"To ensure CodART works properly, we are running it on many real-life software projects. Refactorings are applied to the software systems listed in Table 3. Benchmark projects may update and extend in the future. For the time being, we use a set of well-known open-source Java projects that have been intensely studied in previous works. We have also added two new Java software programs, WEKA and ANTLR, to examine the versatility of CodART performance on real-life software projects. Table 3. Software systems refactored in this project System Release Previous releases Domain Reference Xerces-J v2.7.0 -- software packages for parsing XML [3], [6] Azureus v2.3.0.6 -- Java BitTorrent client for handling multiple torrents [3] ArgoUML v0.26 and v0.3 -- UML tool for object-oriented design [3] Apache Ant v1.5.0 and v1.7.0 -- Java build tool and library [3] GanttProject v1.10.2 and v1.11.1 -- project management [3], [6], [5] JHotDraw v6.1 and v6.0b1 and v5.3 -- graphics tool [6], [5], [4] JFreeChart v1.0.9 -- chart tool [6] Beaver v0.9.11 and v0.9.8 -- parser generator [5], [4] Apache XML-RPC v3.1.1 -- B2B communications [5], [4] JRDF v0.3.4.3 -- semantic web (resource management) [5] XOM v1.2.1 -- XML tool [5] JSON v1.1 -- software packages for parsing JSON [4] JFlex v1.4.1 -- lexical analyzer generator [4] Mango v2.0.1 -- -- [4] Weka v3.9 -- data mining tool New ANTLR v4.8.0 -- parser generator tool New","title":"6 Benchmark projects and testbed"},{"location":"#7-codart-in-iust","text":"Developing a comprehensive refactoring engine required thousand of hours of programming. Refactoring is not just understanding and updating the syntax tree. The tool also needs to figure out how to rerender the code into text back in the editor view. According to a quote by Fowler [2] in his well-known refactoring book: \u201cimplementing decent refactoring is a challenging programming exercise\u2014one that I\u2019m mostly unaware of as I gaily use the tools.\u201d We have defined the basic functionalities of the CodART system as several student projects with different proposals. Students who will take our computer science course, including compiler design and construction, advanced compilers, and advanced software engineering, must be worked on these proposals as part of their course fulfillments. These projects try to familiarize students with the practical usage of compilers from the software engineering point of view. The detailed information of our current proposals are available in the following links: Core refactoring operations development (Fall 2020) Core code smells development Current semester (Winter and Spring 2021) Core search-based development (Future semesters) Core refactoring to design patterns development (Future semesters) Note: Students whose final project is confirmed by the reverse engineering laboratory have an opportunity to work on CodART as an independent and advanced research project. The only prerequisite is to pass the compiler graduate course by Dr. Saeed Parsa.","title":"7 CodART in IUST"},{"location":"#8-conclusion-and-remarks","text":"Software refactoring is used to reduce the costs and risks of software evolution. Automated software refactoring tools can reduce risks caused by manual refactoring, improve efficiency, and reduce software refactoring difficulties. Researchers have made great efforts to research how to implement and improve automated software refactoring tools. However, the results of automated refactoring tools often deviate from the intentions of the implementer. The goal of this project is to propose an open-source refactoring engine and toolkit that can automatically find the best refactoring sequence required for a given software and apply this sequence. Since the tool is work based on compiler principles, it is reliable to be used in practice and has many benefits for software developer companies. Students who participate in the project will learn compiler techniques such as lexing, parsing, source code analysis, and source code transformation. They also learn about software refactoring, search-based software engineering, optimization, software quality, and object-orient metrics.","title":"8 Conclusion and remarks"},{"location":"#conflict-of-interest","text":"The project is supported by the IUST Reverse Engineering Research Laboratory . Interested students may continue working on this project to fulfill their final bachelor and master thesis or their internship.","title":"Conflict of interest"},{"location":"#references","text":"[1] T. Parr and K. Fisher, \u201cLL(*): the foundation of the ANTLR parser generator,\u201d Proc. 32nd ACM SIGPLAN Conf. Program. Lang. Des. Implement., pp. 425\u2013436, 2011. [2] M. K. B. Fowler, Refactoring: improving the design of existing code, Second Edi. Addison-Wesley, 2018. [3] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. O\u0301 Cinne\u0301ide, and K. Deb, \u201cOn the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,\u201d Empir. Softw. Eng., vol. 21, no. 6, pp. 2503\u20132545, Dec. 2016. [4] M. Mohan, D. Greer, and P. McMullan, \u201cTechnical debt reduction using search based automated refactoring,\u201d J. Syst. Softw., vol. 120, pp. 183\u2013194, Oct. 2016. [5] M. Mohan and D. Greer, \u201cUsing a many-objective approach to investigate automated refactoring,\u201d Inf. Softw. Technol., vol. 112, pp. 83\u2013101, Aug. 2019. [6] W. Mkaouer et al., \u201cMany-Objective Software Remodularization Using NSGA-III,\u201d ACM Trans. Softw. Eng. Methodol., vol. 24, no. 3, pp. 1\u201345, May 2015. [7] M. Mohan and D. Greer, \u201cMultiRefactor: automated refactoring to improve software quality,\u201d 2017, pp. 556\u2013572. [8] N. Tsantalis, T. Chaikalis, and A. Chatzigeorgiou, \u201cTen years of JDeodorant: lessons learned from the hunt for smells,\u201d in 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), 2018, pp. 4\u201314. [9] T. Mens and T. Tourwe, \u201cA survey of software refactoring,\u201d IEEE Trans. Softw. Eng., vol. 30, no. 2, pp. 126\u2013139, Feb. 2004.","title":"References"},{"location":"#related-links","text":"IUST compiler course official webpage ANTLR slides: PART 1: Introduction ANTLR slides: PART 2: Getting started in Java ANTLR slides: PART 3: Getting started in C#","title":"Related links"},{"location":"#endnotes","text":"[1] https://www.jetbrains.com/idea/ [2] http://www.eclipse.org [3] http://www.netbeans.org [4] https://github.com/mmohan01/MultiRefactor [5] http://sourceforge.net/projects/recoder [6] http://reverse.iust.ac.ir","title":"Endnotes"},{"location":"about/","text":"About Us Programming is the art of telling another human being what one wants the computer to do. \u2014 Donald Knuth Project Contributors The CodART Project is part of Morteza Zakeri\u2019s Ph.D. thesis to refactor Java source codes automatically and improve their testability. We have defined several sub-projects relevant to CodART to improve software quality. Project Owner Morteza ZAKERI , Ph.D. student at Iran University of Science and Technology Project Supervisors Dr. Saeed Parsa Associate professor at Iran University of Science and Technology Dr. Mehrdad Ashtiani Assistant professor at Iran University of Science and Technology Current Contributors Morteza Zakeri Former contributors Seyyed Ali Ayati, B.Sc. student at Iran University of Science and Technology Mina Tahaei, B.Sc. student at Iran University of Science and Technology IUST B.Sc. Students in compiler course (Spring 2021) IUST B.Sc. Students in compiler course (Fall 2020) IUST M.Sc. students in advanced Compiler course (Fall 2020) More For any question please contact m-zakeri@live.com or visit CodART repo on GitHub: https://github.com/m-zakeri/CodART","title":"About us"},{"location":"about/#about-us","text":"Programming is the art of telling another human being what one wants the computer to do. \u2014 Donald Knuth","title":"About Us"},{"location":"about/#project-contributors","text":"The CodART Project is part of Morteza Zakeri\u2019s Ph.D. thesis to refactor Java source codes automatically and improve their testability. We have defined several sub-projects relevant to CodART to improve software quality.","title":"Project Contributors"},{"location":"about/#project-owner","text":"Morteza ZAKERI , Ph.D. student at Iran University of Science and Technology","title":"Project Owner"},{"location":"about/#project-supervisors","text":"Dr. Saeed Parsa Associate professor at Iran University of Science and Technology Dr. Mehrdad Ashtiani Assistant professor at Iran University of Science and Technology","title":"Project Supervisors"},{"location":"about/#current-contributors","text":"Morteza Zakeri","title":"Current Contributors"},{"location":"about/#former-contributors","text":"Seyyed Ali Ayati, B.Sc. student at Iran University of Science and Technology Mina Tahaei, B.Sc. student at Iran University of Science and Technology IUST B.Sc. Students in compiler course (Spring 2021) IUST B.Sc. Students in compiler course (Fall 2020) IUST M.Sc. students in advanced Compiler course (Fall 2020)","title":"Former contributors"},{"location":"about/#more","text":"For any question please contact m-zakeri@live.com or visit CodART repo on GitHub: https://github.com/m-zakeri/CodART","title":"More"},{"location":"benchmarks/","text":"CodART benchmarks and testbed To ensure CodART works properly, we are running it on many real-life software projects. Refactorings are applied to the software systems listed in Table 3. Benchmark projects may update and extend in the future. For the time being, we use a set of well-known open-source Java projects that have been intensely studied in previous works. We have also added two new Java software programs, WEKA and ANTLR, to examine the versatility of CodART performance on real-life software projects. Table 3. Software systems used as benchmarks in CodeART System Release Previous releases Domain Reference Xerces-J v2.7.0 -- software packages for parsing XML [3], [6] Azureus v2.3.0.6 -- Java BitTorrent client for handling multiple torrents [3] ArgoUML v0.26 and v0.3 -- UML tool for object-oriented design [3] Apache Ant v1.5.0 and v1.7.0 -- Java build tool and library [3] GanttProject v1.10.2 and v1.11.1 -- project management [3], [6], [5] JHotDraw v6.1 and v6.0b1 and v5.3 -- graphics tool [6], [5], [4] JFreeChart v1.0.9 -- chart tool [6] Beaver v0.9.11 and v0.9.8 -- parser generator [5], [4] Apache XML-RPC v3.1.1 -- B2B communications [5], [4] JRDF v0.3.4.3 -- semantic web (resource management) [5] XOM v1.2.1 -- XML tool [5] JSON v1.1 -- software packages for parsing JSON [4] JFlex v1.4.1 -- lexical analyzer generator [4] Mango v2.0.1 -- -- [4] Weka v3.8 -- data mining tool New ANTLR v4.8.0 -- parser generator tool New New projects To be announced. References [3] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. O\u0301 Cinne\u0301ide, and K. Deb, \u201cOn the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,\u201d Empir. Softw. Eng., vol. 21, no. 6, pp. 2503\u20132545, Dec. 2016. [4] M. Mohan, D. Greer, and P. McMullan, \u201cTechnical debt reduction using search based automated refactoring,\u201d J. Syst. Softw., vol. 120, pp. 183\u2013194, Oct. 2016. [5] M. Mohan and D. Greer, \u201cUsing a many-objective approach to investigate automated refactoring,\u201d Inf. Softw. Technol., vol. 112, pp. 83\u2013101, Aug. 2019. [6] W. Mkaouer et al., \u201cMany-Objective Software Remodularization Using NSGA-III,\u201d ACM Trans. Softw. Eng. Methodol., vol. 24, no. 3, pp. 1\u201345, May 2015.","title":"Benchmarks"},{"location":"benchmarks/#codart-benchmarks-and-testbed","text":"To ensure CodART works properly, we are running it on many real-life software projects. Refactorings are applied to the software systems listed in Table 3. Benchmark projects may update and extend in the future. For the time being, we use a set of well-known open-source Java projects that have been intensely studied in previous works. We have also added two new Java software programs, WEKA and ANTLR, to examine the versatility of CodART performance on real-life software projects. Table 3. Software systems used as benchmarks in CodeART System Release Previous releases Domain Reference Xerces-J v2.7.0 -- software packages for parsing XML [3], [6] Azureus v2.3.0.6 -- Java BitTorrent client for handling multiple torrents [3] ArgoUML v0.26 and v0.3 -- UML tool for object-oriented design [3] Apache Ant v1.5.0 and v1.7.0 -- Java build tool and library [3] GanttProject v1.10.2 and v1.11.1 -- project management [3], [6], [5] JHotDraw v6.1 and v6.0b1 and v5.3 -- graphics tool [6], [5], [4] JFreeChart v1.0.9 -- chart tool [6] Beaver v0.9.11 and v0.9.8 -- parser generator [5], [4] Apache XML-RPC v3.1.1 -- B2B communications [5], [4] JRDF v0.3.4.3 -- semantic web (resource management) [5] XOM v1.2.1 -- XML tool [5] JSON v1.1 -- software packages for parsing JSON [4] JFlex v1.4.1 -- lexical analyzer generator [4] Mango v2.0.1 -- -- [4] Weka v3.8 -- data mining tool New ANTLR v4.8.0 -- parser generator tool New","title":"CodART benchmarks and testbed"},{"location":"benchmarks/#new-projects","text":"To be announced.","title":"New projects"},{"location":"benchmarks/#references","text":"[3] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. O\u0301 Cinne\u0301ide, and K. Deb, \u201cOn the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,\u201d Empir. Softw. Eng., vol. 21, no. 6, pp. 2503\u20132545, Dec. 2016. [4] M. Mohan, D. Greer, and P. McMullan, \u201cTechnical debt reduction using search based automated refactoring,\u201d J. Syst. Softw., vol. 120, pp. 183\u2013194, Oct. 2016. [5] M. Mohan and D. Greer, \u201cUsing a many-objective approach to investigate automated refactoring,\u201d Inf. Softw. Technol., vol. 112, pp. 83\u2013101, Aug. 2019. [6] W. Mkaouer et al., \u201cMany-Objective Software Remodularization Using NSGA-III,\u201d ACM Trans. Softw. Eng. Methodol., vol. 24, no. 3, pp. 1\u201345, May 2015.","title":"References"},{"location":"code_smells_list/","text":"Code smells list The following code smells are detected by CodART. Table 2. Code smells Code smell Descriptions and other names God class The class defines many data members (fields) and methods and exhibits low cohesion. The god class smell occurs when a huge class surrounded by many data classes acts as a controller (i.e., takes most of the decisions and monopolizes the software's functionality). Other names: Blob, large class, brain class. Long method This smell occurs when a method is too long to understand and most presumably perform more than one responsibility. Other names: God method, brain method, large method. Feature envy This smell occurs when a method seems more interested in a class other than the one it actually is in. Data class This smell occurs when a class contains only fields and possibly getters/setters without any behavior (methods). Shotgun surgery This smell characterizes the situation when one kind of change leads to many changes to multiple different classes. When the changes are all over the place, they are hard to find, and it is easy to miss a necessary change. Refused bequest This smell occurs when a subclass rejects some of the methods or properties offered by its superclass. Functional decomposition This smell occurs when the experienced developers coming from procedural languages background write highly procedural and non-object-oriented code in an object-oriented language. Long parameter list This smell occurs when a method accepts a long list of parameters. Such lists are hard to understand and difficult to use. Promiscuous package A package can be considered promiscuous if it contains classes implementing too many features, making it too hard to understand and maintain. As for god class and long method, this smell arises when the package has low cohesion since it manages different responsibilities. Misplaced class A Misplaced Class smell suggests a class that is in a package that contains other classes not related to it. Switch statement This smell occurs when switch statements that switch on type codes are spread across the software system instead of exploiting polymorphism. Spaghetti code This smell refers to an unmaintainable, incomprehensible code without any structure. The smell does not exploit and prevents the use of object-orientation mechanisms and concepts. Divergent change Divergent change occurs when one class is commonly changed in different ways for different reasons. Other names: Multifaceted abstraction Deficient encapsulation This smell occurs when the declared accessibility of one or more members of abstraction is more permissive than actually required. Swiss army knife This smell arises when the designer attempts to provide all possible uses of the class and ends up in an excessively complex class interface. Lazy class Unnecessary abstraction Cyclically-dependent modularization This smell arises when two or more abstractions depend on each other directly or indirectly. Primitive obsession This smell occurs when primitive data types are used where an abstraction encapsulating the primitives could serve better. Speculative generality This smell occurs where abstraction is created based on speculated requirements. It is often unnecessary that makes things difficult to understand and maintain. Message chains A message chain occurs when a client requests another object, that object requests yet another one, and so on. These chains mean that the client is dependent on navigation along with the class structure. Any changes in these relationships require modifying the client. Total 20","title":"Code smell list"},{"location":"code_smells_list/#code-smells-list","text":"The following code smells are detected by CodART. Table 2. Code smells Code smell Descriptions and other names God class The class defines many data members (fields) and methods and exhibits low cohesion. The god class smell occurs when a huge class surrounded by many data classes acts as a controller (i.e., takes most of the decisions and monopolizes the software's functionality). Other names: Blob, large class, brain class. Long method This smell occurs when a method is too long to understand and most presumably perform more than one responsibility. Other names: God method, brain method, large method. Feature envy This smell occurs when a method seems more interested in a class other than the one it actually is in. Data class This smell occurs when a class contains only fields and possibly getters/setters without any behavior (methods). Shotgun surgery This smell characterizes the situation when one kind of change leads to many changes to multiple different classes. When the changes are all over the place, they are hard to find, and it is easy to miss a necessary change. Refused bequest This smell occurs when a subclass rejects some of the methods or properties offered by its superclass. Functional decomposition This smell occurs when the experienced developers coming from procedural languages background write highly procedural and non-object-oriented code in an object-oriented language. Long parameter list This smell occurs when a method accepts a long list of parameters. Such lists are hard to understand and difficult to use. Promiscuous package A package can be considered promiscuous if it contains classes implementing too many features, making it too hard to understand and maintain. As for god class and long method, this smell arises when the package has low cohesion since it manages different responsibilities. Misplaced class A Misplaced Class smell suggests a class that is in a package that contains other classes not related to it. Switch statement This smell occurs when switch statements that switch on type codes are spread across the software system instead of exploiting polymorphism. Spaghetti code This smell refers to an unmaintainable, incomprehensible code without any structure. The smell does not exploit and prevents the use of object-orientation mechanisms and concepts. Divergent change Divergent change occurs when one class is commonly changed in different ways for different reasons. Other names: Multifaceted abstraction Deficient encapsulation This smell occurs when the declared accessibility of one or more members of abstraction is more permissive than actually required. Swiss army knife This smell arises when the designer attempts to provide all possible uses of the class and ends up in an excessively complex class interface. Lazy class Unnecessary abstraction Cyclically-dependent modularization This smell arises when two or more abstractions depend on each other directly or indirectly. Primitive obsession This smell occurs when primitive data types are used where an abstraction encapsulating the primitives could serve better. Speculative generality This smell occurs where abstraction is created based on speculated requirements. It is often unnecessary that makes things difficult to understand and maintain. Message chains A message chain occurs when a client requests another object, that object requests yet another one, and so on. These chains mean that the client is dependent on navigation along with the class structure. Any changes in these relationships require modifying the client. Total 20","title":"Code smells list"},{"location":"faq/","text":"Frequently asked question Q1: What is CodART? A1: CodART is an automated source code refactoring toolkit. Q2: How can I contribute to the CodART project? A2: For any other question please contact us at m-zakeri@live.com","title":"FAQ"},{"location":"faq/#frequently-asked-question","text":"Q1: What is CodART? A1: CodART is an automated source code refactoring toolkit. Q2: How can I contribute to the CodART project? A2: For any other question please contact us at m-zakeri@live.com","title":"Frequently asked question"},{"location":"publications/","text":"Publications [1] Nasrabadi, M. Z., & Parsa, S. (2021). Learning to predict software testability. In 26th International Computer Conference, Computer Society of Iran. Tehran: IEEE. [2] [3]","title":"Publications"},{"location":"publications/#publications","text":"[1] Nasrabadi, M. Z., & Parsa, S. (2021). Learning to predict software testability. In 26th International Computer Conference, Computer Society of Iran. Tehran: IEEE. [2] [3]","title":"Publications"},{"location":"refactorings_list/","text":"Refactoring list The following refactoring operations have been automated in CodART. Click on refactoring name to see the API and code. Table 1. Refactoring operations Refactoring Definition Entities Roles Move class Move a class from a package to another package class source package, target package moved class Move method Move a method from a class to another. class method source class, target class moved method Merge packages Merge the elements of a set of packages in one of them package source package, target package Extract/Split package Add a package to compose the elements of another package package source package, target package Extract class Create a new class and move fields and methods from the old class to the new one class method source class, new class moved methods Extract method Extract a code fragment into a method method statement source method, new method moved statements Inline class Move all features of a class in another one and remove it class source class, target class Move field Move a field from a class to another class field source class, target class field Push down field Move a field of a superclass to a subclass class field super class, sub classes move field Push down method Move a method of a superclass to a subclass class method super class, sub classes moved method Pull up field Move a field from subclasses to the superclass class field sub classes, super class moved field Pull up method Move a method from subclasses to the superclass class method sub classes, super class moved method Increase field visibility Increase the visibility of a field from public to protected, protected to package or package to private class field source class source filed Decrease field visibility Decrease the visibility of a field from private to package, package to protected or protected to public class field source class source filed Make field final Make a non-final field final class field source class source filed Make field non-final Make a final field non-final class field source class source filed Make field static Make a non-static field static class field source class source filed Make field non-static Make a static field non-static class field source class source filed Remove field Remove a field from a class class field source class source filed Increase method visibility Increase the visibility of a method from public to protected, protected to package or package to private class method source class source method Decrease method visibility Decrease the visibility of a method from private to package, package to protected or protected to public class method source class source method Make method final Make a non-final method final class method source class source method Make method non-final Make a final method non-final class method source class source method Make method static Make a non-static method static class method source class source method Make method non-static Make a static method non-static class method source class source method Remove method Remove a method from a class class method source class source method Make class-final Make a non-final class final class source class Make class non-final Make a final class non-final class source class Make class abstract Change a concrete class to abstract class source class Make class concrete Change an abstract class to concrete class source class Extract subclass Create a subclass for a set of features class method source class, new subclass moved methods Extract interface Extract methods of a class into an interface class method source class, new interface interface methods Inline method Move the body of a method into its callers and remove the method method source method, callers method Collapse hierarchy Merge a superclass and a subclass class superclass, subclass Remove control flag Replace control flag with a break class method source class source method Replace nested conditional with guard clauses Replace nested conditional with guard clauses class method source class source method Replace constructor with a factory function Replace constructor with a factory function class source class Replace exception with test Replace exception with precheck class method source class source method Rename field Rename a field class field source class source filed Rename method Rename a method class method source class source method Rename class Rename a class class source class Rename package Rename a package package source package Encapsulate field Create setter/mutator and getter/accessor methods for a private field class field source class source filed Replace parameter with query Replace parameter with query class method source class source method Pull up constructor body Move the constructor class method subclass class, superclass constructor Replace control flag with break Replace control flag with break class method source class source method Remove flag argument Remove flag argument class method source class source method Total 47 \u2014 \u2014","title":"Refactoring list"},{"location":"refactorings_list/#refactoring-list","text":"The following refactoring operations have been automated in CodART. Click on refactoring name to see the API and code. Table 1. Refactoring operations Refactoring Definition Entities Roles Move class Move a class from a package to another package class source package, target package moved class Move method Move a method from a class to another. class method source class, target class moved method Merge packages Merge the elements of a set of packages in one of them package source package, target package Extract/Split package Add a package to compose the elements of another package package source package, target package Extract class Create a new class and move fields and methods from the old class to the new one class method source class, new class moved methods Extract method Extract a code fragment into a method method statement source method, new method moved statements Inline class Move all features of a class in another one and remove it class source class, target class Move field Move a field from a class to another class field source class, target class field Push down field Move a field of a superclass to a subclass class field super class, sub classes move field Push down method Move a method of a superclass to a subclass class method super class, sub classes moved method Pull up field Move a field from subclasses to the superclass class field sub classes, super class moved field Pull up method Move a method from subclasses to the superclass class method sub classes, super class moved method Increase field visibility Increase the visibility of a field from public to protected, protected to package or package to private class field source class source filed Decrease field visibility Decrease the visibility of a field from private to package, package to protected or protected to public class field source class source filed Make field final Make a non-final field final class field source class source filed Make field non-final Make a final field non-final class field source class source filed Make field static Make a non-static field static class field source class source filed Make field non-static Make a static field non-static class field source class source filed Remove field Remove a field from a class class field source class source filed Increase method visibility Increase the visibility of a method from public to protected, protected to package or package to private class method source class source method Decrease method visibility Decrease the visibility of a method from private to package, package to protected or protected to public class method source class source method Make method final Make a non-final method final class method source class source method Make method non-final Make a final method non-final class method source class source method Make method static Make a non-static method static class method source class source method Make method non-static Make a static method non-static class method source class source method Remove method Remove a method from a class class method source class source method Make class-final Make a non-final class final class source class Make class non-final Make a final class non-final class source class Make class abstract Change a concrete class to abstract class source class Make class concrete Change an abstract class to concrete class source class Extract subclass Create a subclass for a set of features class method source class, new subclass moved methods Extract interface Extract methods of a class into an interface class method source class, new interface interface methods Inline method Move the body of a method into its callers and remove the method method source method, callers method Collapse hierarchy Merge a superclass and a subclass class superclass, subclass Remove control flag Replace control flag with a break class method source class source method Replace nested conditional with guard clauses Replace nested conditional with guard clauses class method source class source method Replace constructor with a factory function Replace constructor with a factory function class source class Replace exception with test Replace exception with precheck class method source class source method Rename field Rename a field class field source class source filed Rename method Rename a method class method source class source method Rename class Rename a class class source class Rename package Rename a package package source package Encapsulate field Create setter/mutator and getter/accessor methods for a private field class field source class source filed Replace parameter with query Replace parameter with query class method source class source method Pull up constructor body Move the constructor class method subclass class, superclass constructor Replace control flag with break Replace control flag with break class method source class source method Remove flag argument Remove flag argument class method source class source method Total 47 \u2014 \u2014","title":"Refactoring list"},{"location":"code_smells/feature_envy/","text":"Feature envy To be constructed...","title":"Feature envy"},{"location":"code_smells/feature_envy/#feature-envy","text":"To be constructed...","title":"Feature envy"},{"location":"code_smells/large_class/","text":"Large class To be constructed...","title":"Large class"},{"location":"code_smells/large_class/#large-class","text":"To be constructed...","title":"Large class"},{"location":"code_smells/long_method/","text":"Long method To be constructed...","title":"Long method"},{"location":"code_smells/long_method/#long-method","text":"To be constructed...","title":"Long method"},{"location":"metrics/testability/","text":"Testability prediction Introduction This module contains light-weight version of testability prediction script (with 68 metrics) to be used in refactoring process in addition to QMOOD metrics. Changelog v0.2.3 Remove dependency to metrics_jcode_odor v0.2.2 Add scikit-learn 1 compatibility Reference [1] ADAFEST paper [2] TsDD paper PreProcess Writes all metrics in a csv file and performs preprocessing compute_metrics_by_class_list ( project_db_path , n_jobs ) classmethod Source code in metrics\\testability_prediction2.py @classmethod def compute_metrics_by_class_list ( cls , project_db_path , n_jobs ): \"\"\" \"\"\" # class_entities = cls.read_project_classes(db=db, classes_names_list=class_list, ) # print(project_db_path) db = und . open ( project_db_path ) class_list = UnderstandUtility . get_project_classes_longnames_java ( db = db ) db . close () # del db if n_jobs == 0 : # Sequential computing res = [ do ( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ] else : # Parallel computing res = Parallel ( n_jobs = n_jobs , )( delayed ( do )( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ) res = list ( filter ( None , res )) columns = [ 'Class' ] columns . extend ( TestabilityMetrics . get_all_primary_metrics_names ()) df = pd . DataFrame ( data = res , columns = columns ) # print('df for class {0} with shape {1}'.format(project_name, df.shape)) # df.to_csv(csv_path + project_name + '.csv', index=False) # print(df) return df TestabilityMetrics Compute all required metrics for computing Coverageability and testability. compute_java_class_metrics2 ( db = None , entity = None ) classmethod Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Parameters: Name Type Description Default db understand.Db None entity understand.Ent None Returns: Type Description dict Class-level metrics Source code in metrics\\testability_prediction2.py @classmethod def compute_java_class_metrics2 ( cls , db = None , entity = None ): \"\"\" Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Args: db (understand.Db): entity (understand.Ent): Returns: dict: Class-level metrics \"\"\" method_list = UnderstandUtility . get_method_of_class_java2 ( db = db , class_name = entity . longname ()) if method_list is None : # raise TypeError('method_list is none for class \"{}\"'.format(entity.longname())) print ( 'method_list is none for class \" {} \"' . format ( entity . longname ())) return None metrics_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'SumCyclomatic' , 'MaxNesting' , 'PercentLackOfCohesion' , 'CountClassCoupled' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , 'MaxInheritanceTree' , 'CountClassDerived' , 'CountClassBase' , ] class_metrics = entity . metric ( metrics_list ) parameters_length_list = list () for method in method_list : params = method . parameters () . split ( ',' ) if len ( params ) == 1 : if params [ 0 ] == ' ' or params [ 0 ] == '' or params [ 0 ] is None : parameters_length_list . append ( 0 ) else : parameters_length_list . append ( 1 ) else : parameters_length_list . append ( len ( params )) parameters_length_list = list ( filter ( None , parameters_length_list )) class_metrics . update ({ 'SumCSNOP' : sum ( parameters_length_list )}) class_metrics . update ({ 'RFC' : UnderstandUtility . RFC ( class_name = entity )}) class_metrics . update ({ 'FANIN' : UnderstandUtility . FANIN ( db = db , class_entity = entity )}) class_metrics . update ({ 'FANOUT' : UnderstandUtility . FANOUT ( db = db , class_entity = entity )}) class_metrics . update ({ 'ATFD' : UnderstandUtility . ATFD ( db = db , class_entity = entity )}) ### not implement class_metrics . update ({ 'CFNAMM' : UnderstandUtility . CFNAMM_Class ( class_name = entity )}) class_metrics . update ({ 'DAC' : UnderstandUtility . get_data_abstraction_coupling ( db = db , class_entity = entity )}) class_metrics . update ({ 'NumberOfMethodCalls' : UnderstandUtility . number_of_method_call ( class_entity = entity )}) # Visibility metrics # Understand built-in metrics plus one custom metric. class_metrics . update ({ 'CSNOAMM' : UnderstandUtility . NOMAMM ( class_entity = entity )}) # Inheritance metrics class_metrics . update ({ 'NIM' : UnderstandUtility . NIM ( class_name = entity )}) class_metrics . update ({ 'NMO' : UnderstandUtility . NMO ( class_name = entity )}) class_metrics . update ({ 'NOII' : UnderstandUtility . NOII ( db = db )}) # Not implemented class_count_path_list = list () class_knots_list = list () for method in method_list : class_count_path_list . append ( method . metric ([ 'CountPath' ])[ 'CountPath' ]) class_knots_list . append ( method . metric ([ 'Knots' ])[ 'Knots' ]) class_count_path_list = list ( filter ( None , class_count_path_list )) class_metrics . update ({ 'SumCountPath' : sum ( class_count_path_list )}) class_knots_list = list ( filter ( None , class_knots_list )) class_metrics . update ({ 'SumKnots' : sum ( class_knots_list )}) class_metrics . update ({ 'NumberOfDepends' : len ( entity . depends ())}) class_metrics . update ({ 'NumberOfDependsBy' : len ( entity . dependsby ())}) class_metrics . update ({ 'NumberOfMethods' : class_metrics [ 'CountDeclInstanceMethod' ] + class_metrics [ 'CountDeclClassMethod' ]}) # print('class metrics', len(class_metrics), class_metrics) return class_metrics compute_java_class_metrics_lexicon ( entity = None ) classmethod Parameters: Name Type Description Default entity understand.Ent None Returns: Type Description dict class-level metrics Source code in metrics\\testability_prediction2.py @classmethod def compute_java_class_metrics_lexicon ( cls , entity = None ): \"\"\" Args: entity (understand.Ent): Returns: dict: class-level metrics \"\"\" class_lexicon_metrics_dict = dict () tokens_list = list () identifiers_list = list () keywords_list = list () operators_list = list () return_and_print_count = 0 return_and_print_kw_list = [ 'return' , 'print' , 'printf' , 'println' , 'write' , 'writeln' ] condition_count = 0 condition_kw_list = [ 'if' , 'for' , 'while' , 'switch' , '?' , 'assert' , ] uncondition_count = 0 uncondition_kw_list = [ 'break' , 'continue' , ] exception_count = 0 exception_kw_list = [ 'try' , 'catch' , 'throw' , 'throws' , 'finally' , ] new_count = 0 new_count_kw_list = [ 'new' ] super_count = 0 super_count_kw_list = [ 'super' ] dots_count = 0 lexeme = entity . lexer ( show_inactive = False ) . first () while lexeme is not None : tokens_list . append ( lexeme . text ()) if lexeme . token () == 'Identifier' : identifiers_list . append ( lexeme . text ()) if lexeme . token () == 'Keyword' : keywords_list . append ( lexeme . text ()) if lexeme . token () == 'Operator' : operators_list . append ( lexeme . text ()) if lexeme . text () in return_and_print_kw_list : return_and_print_count += 1 if lexeme . text () in condition_kw_list : condition_count += 1 if lexeme . text () in uncondition_kw_list : uncondition_count += 1 if lexeme . text () in exception_kw_list : exception_count += 1 if lexeme . text () in new_count_kw_list : new_count += 1 if lexeme . text () in super_count_kw_list : super_count += 1 if lexeme . text () == '.' : dots_count += 1 lexeme = lexeme . next () number_of_assignments = operators_list . count ( '=' ) number_of_operators_without_assignments = len ( operators_list ) - number_of_assignments number_of_unique_operators = len ( set ( list ( filter ( '=' . __ne__ , operators_list )))) class_lexicon_metrics_dict . update ({ 'NumberOfTokens' : len ( tokens_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueTokens' : len ( set ( tokens_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfIdentifies' : len ( identifiers_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueIdentifiers' : len ( set ( identifiers_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfKeywords' : len ( keywords_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueKeywords' : len ( set ( keywords_list ))}) class_lexicon_metrics_dict . update ( { 'NumberOfOperatorsWithoutAssignments' : number_of_operators_without_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfAssignments' : number_of_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueOperators' : number_of_unique_operators }) class_lexicon_metrics_dict . update ({ 'NumberOfDots' : dots_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSemicolons' : entity . metric ([ 'CountSemicolon' ])[ 'CountSemicolon' ]}) class_lexicon_metrics_dict . update ({ 'NumberOfReturnAndPrintStatements' : return_and_print_count }) class_lexicon_metrics_dict . update ({ 'NumberOfConditionalJumpStatements' : condition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfUnConditionalJumpStatements' : uncondition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfExceptionStatements' : exception_count }) class_lexicon_metrics_dict . update ({ 'NumberOfNewStatements' : new_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSuperStatements' : super_count }) # print('class lexicon metrics dict', len(class_lexicon_metrics_dict), class_lexicon_metrics_dict) return class_lexicon_metrics_dict compute_java_package_metrics ( db = None , entity = None ) classmethod Find package: strategy 2: Dominated strategy Source code in metrics\\testability_prediction2.py @classmethod def compute_java_package_metrics ( cls , db = None , entity = None ): \"\"\" Find package: strategy 2: Dominated strategy \"\"\" # class_name = entity . longname () class_name_list = class_name . split ( '.' )[: - 1 ] package_name = '.' . join ( class_name_list ) # print('package_name string', package_name) package_list = db . lookup ( package_name + '$' , 'Package' ) if package_list is None : return None if len ( package_list ) == 0 : # if len != 1 return None! return None package = package_list [ 0 ] # print('kind:', package.kind()) # print('Computing package metrics for class: \"{0}\" in package: \"{1}\"'.format(class_name, package.longname())) metric_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'CountDeclClass' , 'CountDeclFile' , 'SumCyclomatic' , 'MaxNesting' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , ] package_metrics = package . metric ( metric_list ) classes_and_interfaces_list = package . ents ( 'Contain' , 'Java Type ~Unknown ~Unresolved ~Jar ~Library' ) # PKNOMNAMM: Package number of not accessor or mutator methods pk_accessor_and_mutator_methods_list = list () for type_entity in classes_and_interfaces_list : pk_accessor_and_mutator_methods_list . append ( UnderstandUtility . NOMAMM ( type_entity )) pk_accessor_and_mutator_methods_list = list ( filter ( None , pk_accessor_and_mutator_methods_list )) package_metrics . update ({ 'PKNOAMM' : sum ( pk_accessor_and_mutator_methods_list )}) pknoi = len ( UnderstandUtility . get_package_interfaces_java ( package_entity = package )) pknoac = len ( UnderstandUtility . get_package_abstract_class_java ( package_entity = package )) package_metrics . update ({ 'PKNOI' : pknoi }) package_metrics . update ({ 'PKNOAC' : pknoac }) # print('package metrics', len(package_metrics), package_metrics) return package_metrics TestabilityModel Testability prediction model main ( project_db_path , initial_value = 1.0 , verbose = False , log_path = None ) testability_prediction module API Source code in metrics\\testability_prediction2.py def main ( project_db_path , initial_value = 1.0 , verbose = False , log_path = None ): \"\"\" testability_prediction module API \"\"\" df = PreProcess () . compute_metrics_by_class_list ( project_db_path , n_jobs = 0 ) # n_job must be set to number of CPU cores testability_ = TestabilityModel () . inference ( df_predict_data = df , verbose = verbose , log_path = log_path ) # print('testability=', testability_) return round ( testability_ / initial_value , 5 )","title":"Testability prediction"},{"location":"metrics/testability/#testability-prediction","text":"","title":"Testability prediction"},{"location":"metrics/testability/#metrics.testability_prediction2--introduction","text":"This module contains light-weight version of testability prediction script (with 68 metrics) to be used in refactoring process in addition to QMOOD metrics.","title":"Introduction"},{"location":"metrics/testability/#metrics.testability_prediction2--changelog","text":"","title":"Changelog"},{"location":"metrics/testability/#metrics.testability_prediction2--v023","text":"Remove dependency to metrics_jcode_odor","title":"v0.2.3"},{"location":"metrics/testability/#metrics.testability_prediction2--v022","text":"Add scikit-learn 1 compatibility","title":"v0.2.2"},{"location":"metrics/testability/#metrics.testability_prediction2--reference","text":"[1] ADAFEST paper [2] TsDD paper","title":"Reference"},{"location":"metrics/testability/#metrics.testability_prediction2.PreProcess","text":"Writes all metrics in a csv file and performs preprocessing","title":"PreProcess"},{"location":"metrics/testability/#metrics.testability_prediction2.PreProcess.compute_metrics_by_class_list","text":"Source code in metrics\\testability_prediction2.py @classmethod def compute_metrics_by_class_list ( cls , project_db_path , n_jobs ): \"\"\" \"\"\" # class_entities = cls.read_project_classes(db=db, classes_names_list=class_list, ) # print(project_db_path) db = und . open ( project_db_path ) class_list = UnderstandUtility . get_project_classes_longnames_java ( db = db ) db . close () # del db if n_jobs == 0 : # Sequential computing res = [ do ( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ] else : # Parallel computing res = Parallel ( n_jobs = n_jobs , )( delayed ( do )( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ) res = list ( filter ( None , res )) columns = [ 'Class' ] columns . extend ( TestabilityMetrics . get_all_primary_metrics_names ()) df = pd . DataFrame ( data = res , columns = columns ) # print('df for class {0} with shape {1}'.format(project_name, df.shape)) # df.to_csv(csv_path + project_name + '.csv', index=False) # print(df) return df","title":"compute_metrics_by_class_list()"},{"location":"metrics/testability/#metrics.testability_prediction2.TestabilityMetrics","text":"Compute all required metrics for computing Coverageability and testability.","title":"TestabilityMetrics"},{"location":"metrics/testability/#metrics.testability_prediction2.TestabilityMetrics.compute_java_class_metrics2","text":"Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Parameters: Name Type Description Default db understand.Db None entity understand.Ent None Returns: Type Description dict Class-level metrics Source code in metrics\\testability_prediction2.py @classmethod def compute_java_class_metrics2 ( cls , db = None , entity = None ): \"\"\" Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Args: db (understand.Db): entity (understand.Ent): Returns: dict: Class-level metrics \"\"\" method_list = UnderstandUtility . get_method_of_class_java2 ( db = db , class_name = entity . longname ()) if method_list is None : # raise TypeError('method_list is none for class \"{}\"'.format(entity.longname())) print ( 'method_list is none for class \" {} \"' . format ( entity . longname ())) return None metrics_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'SumCyclomatic' , 'MaxNesting' , 'PercentLackOfCohesion' , 'CountClassCoupled' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , 'MaxInheritanceTree' , 'CountClassDerived' , 'CountClassBase' , ] class_metrics = entity . metric ( metrics_list ) parameters_length_list = list () for method in method_list : params = method . parameters () . split ( ',' ) if len ( params ) == 1 : if params [ 0 ] == ' ' or params [ 0 ] == '' or params [ 0 ] is None : parameters_length_list . append ( 0 ) else : parameters_length_list . append ( 1 ) else : parameters_length_list . append ( len ( params )) parameters_length_list = list ( filter ( None , parameters_length_list )) class_metrics . update ({ 'SumCSNOP' : sum ( parameters_length_list )}) class_metrics . update ({ 'RFC' : UnderstandUtility . RFC ( class_name = entity )}) class_metrics . update ({ 'FANIN' : UnderstandUtility . FANIN ( db = db , class_entity = entity )}) class_metrics . update ({ 'FANOUT' : UnderstandUtility . FANOUT ( db = db , class_entity = entity )}) class_metrics . update ({ 'ATFD' : UnderstandUtility . ATFD ( db = db , class_entity = entity )}) ### not implement class_metrics . update ({ 'CFNAMM' : UnderstandUtility . CFNAMM_Class ( class_name = entity )}) class_metrics . update ({ 'DAC' : UnderstandUtility . get_data_abstraction_coupling ( db = db , class_entity = entity )}) class_metrics . update ({ 'NumberOfMethodCalls' : UnderstandUtility . number_of_method_call ( class_entity = entity )}) # Visibility metrics # Understand built-in metrics plus one custom metric. class_metrics . update ({ 'CSNOAMM' : UnderstandUtility . NOMAMM ( class_entity = entity )}) # Inheritance metrics class_metrics . update ({ 'NIM' : UnderstandUtility . NIM ( class_name = entity )}) class_metrics . update ({ 'NMO' : UnderstandUtility . NMO ( class_name = entity )}) class_metrics . update ({ 'NOII' : UnderstandUtility . NOII ( db = db )}) # Not implemented class_count_path_list = list () class_knots_list = list () for method in method_list : class_count_path_list . append ( method . metric ([ 'CountPath' ])[ 'CountPath' ]) class_knots_list . append ( method . metric ([ 'Knots' ])[ 'Knots' ]) class_count_path_list = list ( filter ( None , class_count_path_list )) class_metrics . update ({ 'SumCountPath' : sum ( class_count_path_list )}) class_knots_list = list ( filter ( None , class_knots_list )) class_metrics . update ({ 'SumKnots' : sum ( class_knots_list )}) class_metrics . update ({ 'NumberOfDepends' : len ( entity . depends ())}) class_metrics . update ({ 'NumberOfDependsBy' : len ( entity . dependsby ())}) class_metrics . update ({ 'NumberOfMethods' : class_metrics [ 'CountDeclInstanceMethod' ] + class_metrics [ 'CountDeclClassMethod' ]}) # print('class metrics', len(class_metrics), class_metrics) return class_metrics","title":"compute_java_class_metrics2()"},{"location":"metrics/testability/#metrics.testability_prediction2.TestabilityMetrics.compute_java_class_metrics_lexicon","text":"Parameters: Name Type Description Default entity understand.Ent None Returns: Type Description dict class-level metrics Source code in metrics\\testability_prediction2.py @classmethod def compute_java_class_metrics_lexicon ( cls , entity = None ): \"\"\" Args: entity (understand.Ent): Returns: dict: class-level metrics \"\"\" class_lexicon_metrics_dict = dict () tokens_list = list () identifiers_list = list () keywords_list = list () operators_list = list () return_and_print_count = 0 return_and_print_kw_list = [ 'return' , 'print' , 'printf' , 'println' , 'write' , 'writeln' ] condition_count = 0 condition_kw_list = [ 'if' , 'for' , 'while' , 'switch' , '?' , 'assert' , ] uncondition_count = 0 uncondition_kw_list = [ 'break' , 'continue' , ] exception_count = 0 exception_kw_list = [ 'try' , 'catch' , 'throw' , 'throws' , 'finally' , ] new_count = 0 new_count_kw_list = [ 'new' ] super_count = 0 super_count_kw_list = [ 'super' ] dots_count = 0 lexeme = entity . lexer ( show_inactive = False ) . first () while lexeme is not None : tokens_list . append ( lexeme . text ()) if lexeme . token () == 'Identifier' : identifiers_list . append ( lexeme . text ()) if lexeme . token () == 'Keyword' : keywords_list . append ( lexeme . text ()) if lexeme . token () == 'Operator' : operators_list . append ( lexeme . text ()) if lexeme . text () in return_and_print_kw_list : return_and_print_count += 1 if lexeme . text () in condition_kw_list : condition_count += 1 if lexeme . text () in uncondition_kw_list : uncondition_count += 1 if lexeme . text () in exception_kw_list : exception_count += 1 if lexeme . text () in new_count_kw_list : new_count += 1 if lexeme . text () in super_count_kw_list : super_count += 1 if lexeme . text () == '.' : dots_count += 1 lexeme = lexeme . next () number_of_assignments = operators_list . count ( '=' ) number_of_operators_without_assignments = len ( operators_list ) - number_of_assignments number_of_unique_operators = len ( set ( list ( filter ( '=' . __ne__ , operators_list )))) class_lexicon_metrics_dict . update ({ 'NumberOfTokens' : len ( tokens_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueTokens' : len ( set ( tokens_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfIdentifies' : len ( identifiers_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueIdentifiers' : len ( set ( identifiers_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfKeywords' : len ( keywords_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueKeywords' : len ( set ( keywords_list ))}) class_lexicon_metrics_dict . update ( { 'NumberOfOperatorsWithoutAssignments' : number_of_operators_without_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfAssignments' : number_of_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueOperators' : number_of_unique_operators }) class_lexicon_metrics_dict . update ({ 'NumberOfDots' : dots_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSemicolons' : entity . metric ([ 'CountSemicolon' ])[ 'CountSemicolon' ]}) class_lexicon_metrics_dict . update ({ 'NumberOfReturnAndPrintStatements' : return_and_print_count }) class_lexicon_metrics_dict . update ({ 'NumberOfConditionalJumpStatements' : condition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfUnConditionalJumpStatements' : uncondition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfExceptionStatements' : exception_count }) class_lexicon_metrics_dict . update ({ 'NumberOfNewStatements' : new_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSuperStatements' : super_count }) # print('class lexicon metrics dict', len(class_lexicon_metrics_dict), class_lexicon_metrics_dict) return class_lexicon_metrics_dict","title":"compute_java_class_metrics_lexicon()"},{"location":"metrics/testability/#metrics.testability_prediction2.TestabilityMetrics.compute_java_package_metrics","text":"Find package: strategy 2: Dominated strategy Source code in metrics\\testability_prediction2.py @classmethod def compute_java_package_metrics ( cls , db = None , entity = None ): \"\"\" Find package: strategy 2: Dominated strategy \"\"\" # class_name = entity . longname () class_name_list = class_name . split ( '.' )[: - 1 ] package_name = '.' . join ( class_name_list ) # print('package_name string', package_name) package_list = db . lookup ( package_name + '$' , 'Package' ) if package_list is None : return None if len ( package_list ) == 0 : # if len != 1 return None! return None package = package_list [ 0 ] # print('kind:', package.kind()) # print('Computing package metrics for class: \"{0}\" in package: \"{1}\"'.format(class_name, package.longname())) metric_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'CountDeclClass' , 'CountDeclFile' , 'SumCyclomatic' , 'MaxNesting' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , ] package_metrics = package . metric ( metric_list ) classes_and_interfaces_list = package . ents ( 'Contain' , 'Java Type ~Unknown ~Unresolved ~Jar ~Library' ) # PKNOMNAMM: Package number of not accessor or mutator methods pk_accessor_and_mutator_methods_list = list () for type_entity in classes_and_interfaces_list : pk_accessor_and_mutator_methods_list . append ( UnderstandUtility . NOMAMM ( type_entity )) pk_accessor_and_mutator_methods_list = list ( filter ( None , pk_accessor_and_mutator_methods_list )) package_metrics . update ({ 'PKNOAMM' : sum ( pk_accessor_and_mutator_methods_list )}) pknoi = len ( UnderstandUtility . get_package_interfaces_java ( package_entity = package )) pknoac = len ( UnderstandUtility . get_package_abstract_class_java ( package_entity = package )) package_metrics . update ({ 'PKNOI' : pknoi }) package_metrics . update ({ 'PKNOAC' : pknoac }) # print('package metrics', len(package_metrics), package_metrics) return package_metrics","title":"compute_java_package_metrics()"},{"location":"metrics/testability/#metrics.testability_prediction2.TestabilityModel","text":"Testability prediction model","title":"TestabilityModel"},{"location":"metrics/testability/#metrics.testability_prediction2.main","text":"testability_prediction module API Source code in metrics\\testability_prediction2.py def main ( project_db_path , initial_value = 1.0 , verbose = False , log_path = None ): \"\"\" testability_prediction module API \"\"\" df = PreProcess () . compute_metrics_by_class_list ( project_db_path , n_jobs = 0 ) # n_job must be set to number of CPU cores testability_ = TestabilityModel () . inference ( df_predict_data = df , verbose = verbose , log_path = log_path ) # print('testability=', testability_) return round ( testability_ / initial_value , 5 )","title":"main()"},{"location":"optimization/initialize/","text":"Search-based refactoring initialization Introduction This module implements finding refactoring candidates for the search-based algorithms Initialization: The abstract class and common utility functions. RandomInitialization: For initialling random candidates. Changelog Version 0.4.0 Enhances module's design. Version 0.3.2 Initialization The superclass of initialization contains init_refactoring methods __init__ ( self , udb_path , population_size = 50 , lower_band = 10 , upper_band = 50 ) special Parameters: Name Type Description Default udb_path str Path for understand database file. required population_size int The length of population for GA. 50 lower_band int The minimum length of individual for GA. 10 upper_band int The maximum length of individual for GA. 50 Returns: Type Description None Source code in sbse\\initialize.py def __init__ ( self , udb_path , population_size = 50 , lower_band = 10 , upper_band = 50 ): \"\"\" Args: udb_path (str): Path for understand database file. population_size (int): The length of population for GA. lower_band (int): The minimum length of individual for GA. upper_band (int): The maximum length of individual for GA. Returns: None \"\"\" random . seed ( None ) self . udb_path = udb_path self . population_size = population_size self . lower_band = lower_band self . upper_band = upper_band self . population = [] self . initializers = ( self . init_make_field_non_static , # 0 self . init_make_field_static , # 1 self . init_make_method_static , # 2 self . init_make_method_non_static , # 3 self . init_pullup_field , # 4 self . init_move_field , # 5 self . init_move_method , # 6 # self.init_move_method, # 6.2 self . init_move_class , # 7 # self.init_move_class, # 7.2 self . init_push_down_field , # 8 self . init_extract_class , # 9 # self.init_extract_class, # 9.2 self . init_pullup_method , # 10 self . init_push_down_method , # 11 self . init_pullup_constructor , # 12 self . init_decrease_field_visibility , # 13 self . init_increase_field_visibility , # 14 self . init_decrease_method_visibility , # 15 self . init_increase_method_visibility , # 16 self . init_extract_interface , # 17 # self.init_extract_interface, # 17.2 # self.init_extract_method, # 18 ) self . _variables = self . get_all_variables () self . _static_variables = self . get_all_variables ( static = True ) self . _methods = self . get_all_methods () self . _static_methods = self . get_all_methods ( static = True ) self . _pullup_field_candidates = self . find_pullup_field_candidates () self . _push_down_field_candidates = self . find_push_down_field_candidates () self . _pullup_method_candidates = self . find_pullup_method_candidates () self . _pullup_constructor_candidates = self . find_pullup_constructor_candidates () self . _push_down_method_candidates = self . find_push_down_method_candidates () self . _extract_interface_candidates = self . find_extract_interface_candidate () generate_population ( self ) Generate population abstract method Source code in sbse\\initialize.py def generate_population ( self ): \"\"\" Generate population abstract method \"\"\" pass select_random ( self ) Randomly selects a refactoring. If there are no candidates it tries again! Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def select_random ( self ): \"\"\" Randomly selects a refactoring. If there are no candidates it tries again! Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" initializer = random . choice ( self . initializers ) logger . debug ( f '>>> Randomly selected refactoring: { initializer . __name__ } ' ) main_function , params , name = handle_index_error ( initializer )() if main_function is None : print ( f 'Inside the select_random method { name } ' ) return self . select_random () else : return main_function , params , name RandomInitialization Use to randomly initialize the refactoring population in search-based algorithms generate_population ( self ) Generate randomly (unbiased) initialized refactoring population Returns: Type Description list List of refactoring sequences (list of refactoring operations) Source code in sbse\\initialize.py def generate_population ( self ): \"\"\" Generate randomly (unbiased) initialized refactoring population Returns: list: List of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a random initial population ...' ) # population = [] for _ in range ( self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a random initial population was finished.' ) return self . population init_decrease_field_visibility ( self ) Finds a none-external-reference-public field to decrease its visibility to private. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_decrease_field_visibility ( self ): \"\"\" Finds a none-external-reference-public field to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _variables )) # print(candidates) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Decrease Field Visibility' init_decrease_method_visibility ( self ) Finds a none-external-reference-public method to decrease its visibility to private. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_decrease_method_visibility ( self ): \"\"\" Finds a none-external-reference-public method to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Decrease Method Visibility' init_extract_class ( self ) Finds a set of methods and fields which should be extracted as a new class Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_extract_class ( self ): \"\"\" Finds a set of methods and fields which should be extracted as a new class Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Type Class ~Unknown ~Anonymous\" ) random_class = random . choice ( classes ) params . update ( { \"source_class\" : random_class . simplename (), \"file_path\" : random_class . parent () . longname () } ) class_fields = [] class_methods = [] for ref in random_class . refs ( \"define\" , \"variable\" ): class_fields . append ( ref . ent ()) for ref in random_class . refs ( \"define\" , \"method\" ): class_methods . append ( ref . ent ()) params . update ( { \"moved_fields\" : [ ent . simplename () for ent in random . sample ( class_fields , random . randint ( 0 , len ( class_fields )))], \"moved_methods\" : [ ent . simplename () for ent in random . sample ( class_methods , random . randint ( 0 , len ( class_methods )))], } ) _db . close () return refactoring_main , params , 'Extract Class' init_extract_interface ( self ) Finds a class which should have an interface Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_extract_interface ( self ): \"\"\" Finds a class which should have an interface Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_interface2 . main # params = {\"udb_path\": str(Path(self.udb_path))} random_class = random . choice ( self . _extract_interface_candidates ) params = { 'class_path' : random_class } return refactoring_main , params , 'Extract Interface' init_increase_field_visibility ( self ) Finds a private field to increase its visibility to public. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_increase_field_visibility ( self ): \"\"\" Finds a private field to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _variables )) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Increase Field Visibility' init_increase_method_visibility ( self ) Finds a private method to increase its visibility to public. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_increase_method_visibility ( self ): \"\"\" Finds a private method to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Increase Method Visibility' init_make_field_non_static ( self ) Finds all static fields and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_make_field_non_static ( self ): \"\"\" Finds all static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_non_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Non-Static' init_make_field_static ( self ) Finds all non-static fields and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_make_field_static ( self ): \"\"\" Finds all non-static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Static' init_make_method_non_static ( self ) Finds all static methods and randomly chooses one of them Returns: Type Description tuple refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_make_method_non_static ( self ): \"\"\" Finds all static methods and randomly chooses one of them Returns: tuple: refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_non_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Non-Static' init_make_method_static ( self ) Finds all non-static methods and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_make_method_static ( self ): \"\"\" Finds all non-static methods and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Static' init_move_class ( self ) Finds a class which should be moved to another existing package Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_class ( self ): \"\"\" Finds a class which should be moved to another existing package Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Java Class Public ~TypeVariable ~Anonymous ~Unknown ~Unresolved ~Private ~Static\" ) selected_class = random . choice ( classes ) package_list = selected_class . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_class . parent () is not None : package_list = selected_class . parent () . ents ( 'Containin' , 'Java Package' ) selected_class = selected_class . parent () # print(package_list) params . update ({ \"class_name\" : selected_class . simplename ()}) if len ( package_list ) < 1 : params . update ({ \"source_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"source_package\" : package_list [ 0 ] . longname ()}) entity_filter = \"Import, Importby, Contain, Containin, Couple, Coupleby, \" entity_filter += \"Create, Createby, DotRef, DotRefby, Declare, Declarein, Define, Definein\" related_entities = selected_class . ents ( entity_filter , \"Type ~Unknown ~Anonymous\" # \"Package\" ) # print('Parameters', params) # print(\"related_entities\", related_entities) # for e in related_entities: # print(e.longname(), e.kind()) trials = 0 while trials < 25 : if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) else : packages = _db . ents ( \"Package ~Unknown ~Unresolved ~Unnamed\" ) if packages is not None and len ( packages ) > 0 : selected_package = random . choice ( packages ) params . update ({ \"target_package\" : selected_package . longname ()}) else : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) # print(params['source_package'], params['target_package']) if params [ 'source_package' ] != params [ 'target_package' ] and params [ 'target_package' ] != '(Unnamed_Package)' : break trials += 1 _db . close () return refactoring_main , params , 'Move Class' init_move_field ( self ) Finds fields with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_field ( self ): \"\"\" Finds fields with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_field = random . choice ( self . _variables ) params . update ( random_field ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Field' init_move_field2 ( self ) Finds fields with a class to move (version 2) Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_field2 ( self ): \"\"\" Finds fields with a class to move (version 2) Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes_fields = [] random_field = random . choice ( classes_fields ) params . update ( random_field ) related_entities = random_field . ents ( \"Set, Setby, Contain, Containin, Use, Useby, Create, Createby, DotRef, DotRefby, Define, Definein\" , \"Type ~Unknown ~Anonymous\" # \"Package\" ) print ( 'Parameters' , params ) print ( \"related_entities\" , related_entities ) for e in related_entities : print ( e . longname (), e . kind ()) if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) init_move_method ( self ) Finds methods with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_method ( self ): \"\"\" Finds methods with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_method = random . choice ( self . _methods ) params . update ( random_method ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Method' init_pullup_constructor ( self ) Finds statements in class constructors to be pulled-up Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_pullup_constructor ( self ): \"\"\" Finds statements in class constructors to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_constructor . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_constructor_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Constructor' init_pullup_field ( self ) Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Type Description Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_pullup_field ( self ): \"\"\" Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_field . main # params = {\"project_dir\": str(Path(self.udb_path).parent)} params = { \"project_dir\" : config . PROJECT_PATH } candidates = self . _pullup_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Field' init_pullup_method ( self ) Finds methods to be pulled-up Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_pullup_method ( self ): \"\"\" Finds methods to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Method' init_push_down_field ( self ) Finds fields to be push-down Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_push_down_field ( self ): \"\"\" Finds fields to be push-down Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_field2 . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Field' init_push_down_method ( self ) Finds methods to be pushed-downs Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_push_down_method ( self ): \"\"\" Finds methods to be pushed-downs Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Method' SmellInitialization Use to initialize refactoring population based on refactoring opportunities __init__ ( self , * args , ** kwargs ) special Returns: Type Description SmellInitialization An instance of SmellInitialization class Source code in sbse\\initialize.py def __init__ ( self , * args , ** kwargs ): \"\"\" Returns: SmellInitialization: An instance of SmellInitialization class \"\"\" super ( SmellInitialization , self ) . __init__ ( * args , ** kwargs ) # Load csv files self . move_method_candidates = self . load_move_method_candidates () self . extract_class_candidates = self . load_extract_class_candidates () # self.extract_method_candidates = self.load_extract_method_candidates() # We leave extract method for now. generate_population ( self ) Generate a biased initial population consists of first-time validated refactorings Returns: Type Description list list of refactoring sequences (list of refactoring operations) Source code in sbse\\initialize.py def generate_population ( self ): \"\"\" Generate a biased initial population consists of first-time validated refactorings Return: list: list of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a biased initial population ...' ) for _ in range ( 0 , self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) while is_correct_refactoring is False : reset_project () main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) #### # update_understand_database(self.udb_path) # quit() #### individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) reset_project () logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a biased initial population was finished.' ) return self . population init_extract_class ( self ) Finds a set of methods and fields which should be extracted as a new class Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_extract_class ( self ): main = extract_class . main params = random . choice ( self . extract_class_candidates ) params [ \"udb_path\" ] = self . udb_path return main , params , \"Extract Class\" init_move_method ( self ) Finds methods with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_method ( self ): params = random . choice ( self . move_method_candidates ) params [ \"udb_path\" ] = self . udb_path main = move_method . main # print(params) return main , params , \"Move Method\"","title":"Population initialization"},{"location":"optimization/initialize/#search-based-refactoring-initialization","text":"","title":"Search-based refactoring initialization"},{"location":"optimization/initialize/#sbse.initialize--introduction","text":"This module implements finding refactoring candidates for the search-based algorithms Initialization: The abstract class and common utility functions. RandomInitialization: For initialling random candidates.","title":"Introduction"},{"location":"optimization/initialize/#sbse.initialize--changelog","text":"","title":"Changelog"},{"location":"optimization/initialize/#sbse.initialize--version-040","text":"Enhances module's design.","title":"Version 0.4.0"},{"location":"optimization/initialize/#sbse.initialize--version-032","text":"","title":"Version 0.3.2"},{"location":"optimization/initialize/#sbse.initialize.Initialization","text":"The superclass of initialization contains init_refactoring methods","title":"Initialization"},{"location":"optimization/initialize/#sbse.initialize.Initialization.__init__","text":"Parameters: Name Type Description Default udb_path str Path for understand database file. required population_size int The length of population for GA. 50 lower_band int The minimum length of individual for GA. 10 upper_band int The maximum length of individual for GA. 50 Returns: Type Description None Source code in sbse\\initialize.py def __init__ ( self , udb_path , population_size = 50 , lower_band = 10 , upper_band = 50 ): \"\"\" Args: udb_path (str): Path for understand database file. population_size (int): The length of population for GA. lower_band (int): The minimum length of individual for GA. upper_band (int): The maximum length of individual for GA. Returns: None \"\"\" random . seed ( None ) self . udb_path = udb_path self . population_size = population_size self . lower_band = lower_band self . upper_band = upper_band self . population = [] self . initializers = ( self . init_make_field_non_static , # 0 self . init_make_field_static , # 1 self . init_make_method_static , # 2 self . init_make_method_non_static , # 3 self . init_pullup_field , # 4 self . init_move_field , # 5 self . init_move_method , # 6 # self.init_move_method, # 6.2 self . init_move_class , # 7 # self.init_move_class, # 7.2 self . init_push_down_field , # 8 self . init_extract_class , # 9 # self.init_extract_class, # 9.2 self . init_pullup_method , # 10 self . init_push_down_method , # 11 self . init_pullup_constructor , # 12 self . init_decrease_field_visibility , # 13 self . init_increase_field_visibility , # 14 self . init_decrease_method_visibility , # 15 self . init_increase_method_visibility , # 16 self . init_extract_interface , # 17 # self.init_extract_interface, # 17.2 # self.init_extract_method, # 18 ) self . _variables = self . get_all_variables () self . _static_variables = self . get_all_variables ( static = True ) self . _methods = self . get_all_methods () self . _static_methods = self . get_all_methods ( static = True ) self . _pullup_field_candidates = self . find_pullup_field_candidates () self . _push_down_field_candidates = self . find_push_down_field_candidates () self . _pullup_method_candidates = self . find_pullup_method_candidates () self . _pullup_constructor_candidates = self . find_pullup_constructor_candidates () self . _push_down_method_candidates = self . find_push_down_method_candidates () self . _extract_interface_candidates = self . find_extract_interface_candidate ()","title":"__init__()"},{"location":"optimization/initialize/#sbse.initialize.Initialization.generate_population","text":"Generate population abstract method Source code in sbse\\initialize.py def generate_population ( self ): \"\"\" Generate population abstract method \"\"\" pass","title":"generate_population()"},{"location":"optimization/initialize/#sbse.initialize.Initialization.select_random","text":"Randomly selects a refactoring. If there are no candidates it tries again! Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def select_random ( self ): \"\"\" Randomly selects a refactoring. If there are no candidates it tries again! Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" initializer = random . choice ( self . initializers ) logger . debug ( f '>>> Randomly selected refactoring: { initializer . __name__ } ' ) main_function , params , name = handle_index_error ( initializer )() if main_function is None : print ( f 'Inside the select_random method { name } ' ) return self . select_random () else : return main_function , params , name","title":"select_random()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization","text":"Use to randomly initialize the refactoring population in search-based algorithms","title":"RandomInitialization"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.generate_population","text":"Generate randomly (unbiased) initialized refactoring population Returns: Type Description list List of refactoring sequences (list of refactoring operations) Source code in sbse\\initialize.py def generate_population ( self ): \"\"\" Generate randomly (unbiased) initialized refactoring population Returns: list: List of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a random initial population ...' ) # population = [] for _ in range ( self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a random initial population was finished.' ) return self . population","title":"generate_population()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_decrease_field_visibility","text":"Finds a none-external-reference-public field to decrease its visibility to private. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_decrease_field_visibility ( self ): \"\"\" Finds a none-external-reference-public field to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _variables )) # print(candidates) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Decrease Field Visibility'","title":"init_decrease_field_visibility()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_decrease_method_visibility","text":"Finds a none-external-reference-public method to decrease its visibility to private. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_decrease_method_visibility ( self ): \"\"\" Finds a none-external-reference-public method to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Decrease Method Visibility'","title":"init_decrease_method_visibility()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_extract_class","text":"Finds a set of methods and fields which should be extracted as a new class Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_extract_class ( self ): \"\"\" Finds a set of methods and fields which should be extracted as a new class Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Type Class ~Unknown ~Anonymous\" ) random_class = random . choice ( classes ) params . update ( { \"source_class\" : random_class . simplename (), \"file_path\" : random_class . parent () . longname () } ) class_fields = [] class_methods = [] for ref in random_class . refs ( \"define\" , \"variable\" ): class_fields . append ( ref . ent ()) for ref in random_class . refs ( \"define\" , \"method\" ): class_methods . append ( ref . ent ()) params . update ( { \"moved_fields\" : [ ent . simplename () for ent in random . sample ( class_fields , random . randint ( 0 , len ( class_fields )))], \"moved_methods\" : [ ent . simplename () for ent in random . sample ( class_methods , random . randint ( 0 , len ( class_methods )))], } ) _db . close () return refactoring_main , params , 'Extract Class'","title":"init_extract_class()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_extract_interface","text":"Finds a class which should have an interface Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_extract_interface ( self ): \"\"\" Finds a class which should have an interface Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_interface2 . main # params = {\"udb_path\": str(Path(self.udb_path))} random_class = random . choice ( self . _extract_interface_candidates ) params = { 'class_path' : random_class } return refactoring_main , params , 'Extract Interface'","title":"init_extract_interface()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_increase_field_visibility","text":"Finds a private field to increase its visibility to public. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_increase_field_visibility ( self ): \"\"\" Finds a private field to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _variables )) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Increase Field Visibility'","title":"init_increase_field_visibility()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_increase_method_visibility","text":"Finds a private method to increase its visibility to public. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_increase_method_visibility ( self ): \"\"\" Finds a private method to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Increase Method Visibility'","title":"init_increase_method_visibility()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_make_field_non_static","text":"Finds all static fields and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_make_field_non_static ( self ): \"\"\" Finds all static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_non_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Non-Static'","title":"init_make_field_non_static()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_make_field_static","text":"Finds all non-static fields and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_make_field_static ( self ): \"\"\" Finds all non-static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Static'","title":"init_make_field_static()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_make_method_non_static","text":"Finds all static methods and randomly chooses one of them Returns: Type Description tuple refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_make_method_non_static ( self ): \"\"\" Finds all static methods and randomly chooses one of them Returns: tuple: refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_non_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Non-Static'","title":"init_make_method_non_static()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_make_method_static","text":"Finds all non-static methods and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_make_method_static ( self ): \"\"\" Finds all non-static methods and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Static'","title":"init_make_method_static()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_move_class","text":"Finds a class which should be moved to another existing package Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_class ( self ): \"\"\" Finds a class which should be moved to another existing package Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Java Class Public ~TypeVariable ~Anonymous ~Unknown ~Unresolved ~Private ~Static\" ) selected_class = random . choice ( classes ) package_list = selected_class . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_class . parent () is not None : package_list = selected_class . parent () . ents ( 'Containin' , 'Java Package' ) selected_class = selected_class . parent () # print(package_list) params . update ({ \"class_name\" : selected_class . simplename ()}) if len ( package_list ) < 1 : params . update ({ \"source_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"source_package\" : package_list [ 0 ] . longname ()}) entity_filter = \"Import, Importby, Contain, Containin, Couple, Coupleby, \" entity_filter += \"Create, Createby, DotRef, DotRefby, Declare, Declarein, Define, Definein\" related_entities = selected_class . ents ( entity_filter , \"Type ~Unknown ~Anonymous\" # \"Package\" ) # print('Parameters', params) # print(\"related_entities\", related_entities) # for e in related_entities: # print(e.longname(), e.kind()) trials = 0 while trials < 25 : if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) else : packages = _db . ents ( \"Package ~Unknown ~Unresolved ~Unnamed\" ) if packages is not None and len ( packages ) > 0 : selected_package = random . choice ( packages ) params . update ({ \"target_package\" : selected_package . longname ()}) else : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) # print(params['source_package'], params['target_package']) if params [ 'source_package' ] != params [ 'target_package' ] and params [ 'target_package' ] != '(Unnamed_Package)' : break trials += 1 _db . close () return refactoring_main , params , 'Move Class'","title":"init_move_class()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_move_field","text":"Finds fields with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_field ( self ): \"\"\" Finds fields with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_field = random . choice ( self . _variables ) params . update ( random_field ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Field'","title":"init_move_field()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_move_field2","text":"Finds fields with a class to move (version 2) Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_field2 ( self ): \"\"\" Finds fields with a class to move (version 2) Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes_fields = [] random_field = random . choice ( classes_fields ) params . update ( random_field ) related_entities = random_field . ents ( \"Set, Setby, Contain, Containin, Use, Useby, Create, Createby, DotRef, DotRefby, Define, Definein\" , \"Type ~Unknown ~Anonymous\" # \"Package\" ) print ( 'Parameters' , params ) print ( \"related_entities\" , related_entities ) for e in related_entities : print ( e . longname (), e . kind ()) if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()})","title":"init_move_field2()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_move_method","text":"Finds methods with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_method ( self ): \"\"\" Finds methods with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_method = random . choice ( self . _methods ) params . update ( random_method ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Method'","title":"init_move_method()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_pullup_constructor","text":"Finds statements in class constructors to be pulled-up Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_pullup_constructor ( self ): \"\"\" Finds statements in class constructors to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_constructor . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_constructor_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Constructor'","title":"init_pullup_constructor()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_pullup_field","text":"Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Type Description Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_pullup_field ( self ): \"\"\" Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_field . main # params = {\"project_dir\": str(Path(self.udb_path).parent)} params = { \"project_dir\" : config . PROJECT_PATH } candidates = self . _pullup_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Field'","title":"init_pullup_field()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_pullup_method","text":"Finds methods to be pulled-up Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_pullup_method ( self ): \"\"\" Finds methods to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Method'","title":"init_pullup_method()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_push_down_field","text":"Finds fields to be push-down Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_push_down_field ( self ): \"\"\" Finds fields to be push-down Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_field2 . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Field'","title":"init_push_down_field()"},{"location":"optimization/initialize/#sbse.initialize.RandomInitialization.init_push_down_method","text":"Finds methods to be pushed-downs Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_push_down_method ( self ): \"\"\" Finds methods to be pushed-downs Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Method'","title":"init_push_down_method()"},{"location":"optimization/initialize/#sbse.initialize.SmellInitialization","text":"Use to initialize refactoring population based on refactoring opportunities","title":"SmellInitialization"},{"location":"optimization/initialize/#sbse.initialize.SmellInitialization.__init__","text":"Returns: Type Description SmellInitialization An instance of SmellInitialization class Source code in sbse\\initialize.py def __init__ ( self , * args , ** kwargs ): \"\"\" Returns: SmellInitialization: An instance of SmellInitialization class \"\"\" super ( SmellInitialization , self ) . __init__ ( * args , ** kwargs ) # Load csv files self . move_method_candidates = self . load_move_method_candidates () self . extract_class_candidates = self . load_extract_class_candidates () # self.extract_method_candidates = self.load_extract_method_candidates() # We leave extract method for now.","title":"__init__()"},{"location":"optimization/initialize/#sbse.initialize.SmellInitialization.generate_population","text":"Generate a biased initial population consists of first-time validated refactorings Returns: Type Description list list of refactoring sequences (list of refactoring operations) Source code in sbse\\initialize.py def generate_population ( self ): \"\"\" Generate a biased initial population consists of first-time validated refactorings Return: list: list of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a biased initial population ...' ) for _ in range ( 0 , self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) while is_correct_refactoring is False : reset_project () main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) #### # update_understand_database(self.udb_path) # quit() #### individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) reset_project () logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a biased initial population was finished.' ) return self . population","title":"generate_population()"},{"location":"optimization/initialize/#sbse.initialize.SmellInitialization.init_extract_class","text":"Finds a set of methods and fields which should be extracted as a new class Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_extract_class ( self ): main = extract_class . main params = random . choice ( self . extract_class_candidates ) params [ \"udb_path\" ] = self . udb_path return main , params , \"Extract Class\"","title":"init_extract_class()"},{"location":"optimization/initialize/#sbse.initialize.SmellInitialization.init_move_method","text":"Finds methods with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in sbse\\initialize.py def init_move_method ( self ): params = random . choice ( self . move_method_candidates ) params [ \"udb_path\" ] = self . udb_path main = move_method . main # print(params) return main , params , \"Move Method\"","title":"init_move_method()"},{"location":"optimization/search-based_refactoring/","text":"Search-based refactoring module Module description This module implements the search-based refactoring with various search strategy using pymoo framework. Classes Gene, RefactoringOperation: One refactoring with params Individual: A list of RefactoringOperation PureRandomInitialization: Population, list of Individual References [1] https://pymoo.org/customization/custom.html [2] https://pymoo.org/misc/reference_directions.html Changelog version 0.2.3 1. Fix PEP 8 warnings version 0.2.2 1. Add a separate log directory for each execution 2. Add possibility to resume algorithm version 0.2.1 1. minor updates 2. fix bugs 3. rename variables names version 0.2.0 1. Crossover function is added. 2. Termination criteria are added. 3. Computation of highly trade-off points is added. 4. Tournament-selection is added. 5. _evaluate function in NSGA-III is now works on population instead of an individual (population-based versus element-wise). 6. Other setting for NSGA-III including adding energy-references point instead of Das and Dennis approach. === AdaptiveSinglePointCrossover This class implements solution variation, the adaptive one-point or single-point crossover operator. The crossover operator combines parents to create offsprings. It starts by selecting and splitting at random two parent solutions or individuals. Then, this operator creates two child solutions by putting, for the first child, the first part of the first parent with the second part of the second parent, and vice versa for the second child. Note 1: In the pymoo framework, the crossover operator retrieves the input already with predefined matings. The default parent selection algorithm is TournamentSelection. Note 2: It is better to create children that are close to their parents to have a more efficient search process, a so-called adaptive crossover , specifically in many-objective optimization. Therefore, the cutting point of the one-point crossover operator are controlled by restricting its position to be either belonging to the first tier of the refactoring sequence or belonging to the last tier. __init__ ( self , prob = 0.9 ) special prob (float): crossover probability Source code in sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.9 ): \"\"\" Args: prob (float): crossover probability \"\"\" # Define the crossover: number of parents, number of offsprings, and cross-over probability super () . __init__ ( n_parents = 2 , n_offsprings = 2 , prob = prob ) BitStringMutation This class implements solution variation, a bit-string mutation operator. The bit-string mutation operator that picks probabilistically one or more refactoring operations from its or their associated sequence and replaces them by other ones from the initial list of possible refactorings. Each chromosome dimension would be changed according to the mutation probability. For example, for a mutation probability of 0.2, for each dimension, we generate randomly a number x between 0 and 1, if x < mutation_probability (e.g., 0.2) we change the refactoring operation in that dimension, otherwise no changes are taken into account. __init__ ( self , prob = 0.2 , initializer = None ) special Parameters: Name Type Description Default prob float mutation probability 0.2 Source code in sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer BitStringMutation2 Select an individual to mutate with mutation probability. Only flip one refactoring operation in the selected individual. __init__ ( self , prob = 0.2 , initializer = None ) special Parameters: Name Type Description Default prob float mutation probability 0.2 Source code in sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer self . _initializer . load_population () Gene The base class for the Gene in genetic algorithms. __init__ ( self , ** kwargs ) special Parameters: Name Type Description Default name str Refactoring operation name required params dict Refactoring operation parameters required main function Refactoring operation main function (API) required Source code in sbse\\search_based_refactoring2.py def __init__ ( self , ** kwargs ): \"\"\" Args: name (str): Refactoring operation name params (dict): Refactoring operation parameters main (function): Refactoring operation main function (API) \"\"\" self . name = kwargs . get ( 'name' ) self . params = kwargs . get ( 'params' ) self . main = kwargs . get ( 'main' ) Individual The class define a data structure (list) to hold an individual during the search process. Each individual (also called, chromosome or solution in the context of genetic programming) is an array of refactoring operations where the order of their execution is accorded by their positions in the array. __init__ ( self ) special Source code in sbse\\search_based_refactoring2.py def __init__ ( self ): \"\"\" Args: \"\"\" super ( Individual , self ) . __init__ () self . refactoring_operations = [] append ( self , _Individual__object ) Append object to the end of the list. Source code in sbse\\search_based_refactoring2.py def append ( self , __object : RefactoringOperation ) -> None : self . insert ( len ( self . refactoring_operations ), __object ) insert ( self , _Individual__index , _Individual__object ) Insert object before index. Source code in sbse\\search_based_refactoring2.py def insert ( self , __index : int , __object : RefactoringOperation ) -> None : self . refactoring_operations . insert ( __index , __object ) LogCallback Logging useful information after each iteration of the search algorithms PopulationInitialization This class create the initial population, x, consists of n_samples, pop_size. For each refactoring operation, a set of controlling parameters (e.g., actors and roles) is picked based on existing code smells in the program to be refactored. The selected refactoring operations are randomly arranged in each individual. Assigning randomly a sequence of refactorings to certain code fragments generates the initial population __init__ ( self , initializer = None ) special Parameters: Name Type Description Default initializer Initialization An initializer object to be used for generating initial population None Source code in sbse\\search_based_refactoring2.py def __init__ ( self , initializer : Initialization = None ): \"\"\" Args: initializer (Initialization): An initializer object to be used for generating initial population \"\"\" super ( PopulationInitialization , self ) . __init__ () self . _initializer = initializer ProblemManyObjective The CodART many-objective optimization work with eight objective: Objective 1 to 6: QMOOD metrics Objective 7: Testability Objective 8: Modularity __init__ ( self , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , verbose_design_metrics = False ) special Parameters: Name Type Description Default n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 evaluate_in_parallel bool Whether the objectives computed in parallel or not False verbose_design_metrics bool Whether log the design metrics for each refactoring sequences or not False Source code in sbse\\search_based_refactoring2.py def __init__ ( self , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , verbose_design_metrics = False , ): \"\"\" Args: n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives computed in parallel or not verbose_design_metrics (bool): Whether log the design metrics for each refactoring sequences or not \"\"\" super ( ProblemManyObjective , self ) . __init__ ( n_var = 1 , n_obj = 8 , n_constr = 0 , ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . verbose_design_metrics = verbose_design_metrics ProblemMultiObjective The CodART multi-objective optimization work with three objective: Objective 1: Mean value of QMOOD metrics Objective 2: Testability Objective 3: Modularity ProblemSingleObjective The CodART single-objective optimization work with only one objective, testability: __init__ ( self , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , mode = 'single' ) special Parameters: Name Type Description Default n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 mode str 'single' or 'multi' 'single' Source code in sbse\\search_based_refactoring2.py def __init__ ( self , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , mode = 'single' # 'multi' ): \"\"\" Args: n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences mode (str): 'single' or 'multi' \"\"\" super ( ProblemSingleObjective , self ) . __init__ ( n_var = 1 , n_obj = 1 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . mode = mode RefactoringOperation The class define a data structure (dictionary) to hold a refactoring operation Each refactoring operation hold as a dictionary contains the required parameters. Example: ``` make_field_static refactoring is marshaled as the following dict: params = { 'refactoring_name': 'make_field_static' 'api': 'main_function' 'source_class': 'name_of_source_class' 'field_name': 'name_of_the_field_to_be_static' } ``` do_refactoring ( self ) Check preconditions and apply refactoring operation to source code Returns: Type Description result (boolean) The result statues of the applied refactoring Source code in sbse\\search_based_refactoring2.py def do_refactoring ( self ): \"\"\" Check preconditions and apply refactoring operation to source code Returns: result (boolean): The result statues of the applied refactoring \"\"\" logger . info ( f \"Running { self . name } \" ) logger . info ( f \"Parameters { self . params } \" ) try : res = self . main ( ** self . params ) return res except Exception as e : logger . error ( f \"Unexpected error in executing refactoring: \\n { e } \" ) return False binary_tournament ( pop , P , ** kwargs ) Implements the binary tournament selection algorithm Source code in sbse\\search_based_refactoring2.py def binary_tournament ( pop , P , ** kwargs ): \"\"\" Implements the binary tournament selection algorithm \"\"\" # The P input defines the tournaments and competitors n_tournaments , n_competitors = P . shape if n_competitors != 2 : raise Exception ( \"Only pressure=2 allowed for binary tournament!\" ) S = np . full ( n_tournaments , - 1 , dtype = np . int64 ) # Now do all the tournaments for i in range ( n_tournaments ): a , b = P [ i ] # If the first individual is better, choose it if pop [ a ] . F . all () <= pop [ a ] . F . all (): S [ i ] = a # Otherwise, take the other individual else : S [ i ] = b return S is_equal_2_refactorings_list ( a , b ) This method implement is_equal method which should return True if two instances of Individual class are equal. Otherwise, it returns False. The duplicate instances are removed from population at each generation. Only one instance is held to speed up the search algorithm Source code in sbse\\search_based_refactoring2.py def is_equal_2_refactorings_list ( a , b ): \"\"\" This method implement is_equal method which should return True if two instances of Individual class are equal. Otherwise, it returns False. The duplicate instances are removed from population at each generation. Only one instance is held to speed up the search algorithm \"\"\" if len ( a . X [ 0 ]) != len ( b . X [ 0 ]): return False for i , ro in enumerate ( a . X [ 0 ]): if ro . name != b . X [ 0 ][ i ] . name : return False if ro . params != b . X [ 0 ][ i ] . params : return False return True log_project_info ( reset_ = True , design_metrics_path = None , quality_attributes_path = None , generation = 0 , testability_verbose = True , testability_log_path = None ) Logging project metrics and information Source code in sbse\\search_based_refactoring2.py def log_project_info ( reset_ = True , design_metrics_path = None , quality_attributes_path = None , generation = 0 , testability_verbose = True , testability_log_path = None ): \"\"\" Logging project metrics and information \"\"\" if reset_ : reset_project () if quality_attributes_path is None : quality_attributes_path = os . path . join ( config . PROJECT_LOG_DIR , 'quality_attrs_initial_values.csv' ) if design_metrics_path is None : design_metrics_path = os . path . join ( config . PROJECT_LOG_DIR , 'design_metrics.csv' ) design_quality_attribute = DesignQualityAttributes ( config . UDB_PATH ) avg_ , sum_ = design_quality_attribute . average_sum predicted_testability = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 ), verbose = testability_verbose , log_path = testability_log_path ) mdg_modularity = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 ) ) design_metrics = { \"DSC\" : [ design_quality_attribute . DSC ], \"NOH\" : [ design_quality_attribute . NOH ], \"ANA\" : [ design_quality_attribute . ANA ], \"MOA\" : [ design_quality_attribute . MOA ], \"DAM\" : [ design_quality_attribute . DAM ], \"CAMC\" : [ design_quality_attribute . CAMC ], \"CIS\" : [ design_quality_attribute . CIS ], \"NOM\" : [ design_quality_attribute . NOM ], \"DCC\" : [ design_quality_attribute . DCC ], \"MFA\" : [ design_quality_attribute . MFA ], \"NOP\" : [ design_quality_attribute . NOP ] } quality_objectives = { \"generation\" : [ generation ], \"reusability\" : [ design_quality_attribute . reusability ], \"understandability\" : [ design_quality_attribute . understandability ], \"flexibility\" : [ design_quality_attribute . flexibility ], \"functionality\" : [ design_quality_attribute . functionality ], \"effectiveness\" : [ design_quality_attribute . effectiveness ], \"extendability\" : [ design_quality_attribute . extendability ], \"testability\" : [ predicted_testability ], \"modularity\" : [ mdg_modularity ], } logger . info ( 'QMOOD design metrics (N):' ) logger . info ( design_metrics ) logger . info ( 'Objectives:' ) logger . info ( quality_objectives ) logger . info ( 'QMOOD quality attributes sum:' ) logger . info ( sum_ ) logger . info ( 'QMOOD quality attributes mean:' ) logger . info ( avg_ ) df_quality_attributes = pd . DataFrame ( data = quality_objectives ) if os . path . exists ( quality_attributes_path ): df = pd . read_csv ( quality_attributes_path , index_col = False ) df_result = pd . concat ([ df , df_quality_attributes ], ignore_index = True ) df_result . to_csv ( quality_attributes_path , index = False ) else : df_quality_attributes . to_csv ( quality_attributes_path , index = False ) df_design_metrics = pd . DataFrame ( data = design_metrics ) if os . path . exists ( design_metrics_path ): df = pd . read_csv ( design_metrics_path , index_col = False ) df_results = pd . concat ([ df , df_design_metrics ], ignore_index = True ) # df = df.append(df_design_metrics, ignore_index=True) df_results . to_csv ( design_metrics_path , index = False ) else : df_design_metrics . to_csv ( design_metrics_path , index = False ) main () Optimization module main driver Source code in sbse\\search_based_refactoring2.py def main (): \"\"\" Optimization module main driver \"\"\" # Define initialization objects initializer_class = SmellInitialization if config . WARM_START else RandomInitialization initializer_object = initializer_class ( udb_path = config . UDB_PATH , population_size = config . POPULATION_SIZE , lower_band = config . LOWER_BAND , upper_band = config . UPPER_BAND ) # Define search algorithms algorithms = list () # 1: GA alg1 = GA ( pop_size = config . POPULATION_SIZE , sampling = PopulationInitialization ( initializer_object ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg1 ) # 2: NSGA II alg2 = NSGA2 ( pop_size = config . POPULATION_SIZE , sampling = PopulationInitialization ( initializer_object ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg2 ) # 3: NSGA III # pop_size must be equal or larger than the number of reference directions number_of_references_points = config . POPULATION_SIZE - int ( config . POPULATION_SIZE * 0.20 ) ref_dirs = get_reference_directions ( 'energy' , # algorithm config . NUMBER_OBJECTIVES , # number of objectives number_of_references_points , # number of reference directions seed = 1 ) alg3 = NSGA3 ( ref_dirs = ref_dirs , pop_size = config . POPULATION_SIZE , # 200 sampling = PopulationInitialization ( initializer_object ), selection = TournamentSelection ( func_comp = binary_tournament ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY , ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg3 ) # ------------------------------------------- # Define problems problems = list () # 0: Genetic (Single), 1: NSGA-II (Multi), 2: NSGA-III (Many) objectives problems problems . append ( ProblemSingleObjective ( n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , ) ) problems . append ( ProblemMultiObjective ( n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , ) ) problems . append ( ProblemManyObjective ( n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , verbose_design_metrics = True , ) ) # Termination of algorithms my_termination = MultiObjectiveDefaultTermination ( x_tol = None , cv_tol = None , f_tol = 0.0015 , nth_gen = 5 , n_last = 5 , n_max_gen = config . MAX_ITERATIONS , # about 1000 - 1400 n_max_evals = 1e6 ) # Do optimization for various problems with various algorithms res = minimize ( problem = problems [ config . PROBLEM ], algorithm = algorithms [ config . PROBLEM ], termination = my_termination , seed = 1 , verbose = False , copy_algorithm = True , copy_termination = True , save_history = False , callback = LogCallback (), ) # np.save('checkpoint', res.algorithm) # Log results logger . info ( f \"***** Algorithm was finished in { res . algorithm . n_gen + config . NGEN } generations *****\" ) logger . info ( \" \" ) logger . info ( \"============ time information ============\" ) logger . info ( f \"Start time: { datetime . fromtimestamp ( res . start_time ) . strftime ( '%Y-%m- %d %H:%M:%S' ) } \" ) logger . info ( f \"End time: { datetime . fromtimestamp ( res . end_time ) . strftime ( '%Y-%m- %d %H:%M:%S' ) } \" ) logger . info ( f \"Execution time in seconds: { res . exec_time } \" ) logger . info ( f \"Execution time in minutes: { res . exec_time / 60 } \" ) logger . info ( f \"Execution time in hours: { res . exec_time / ( 60 * 60 ) } \" ) # logger.info(f\"Number of generations: {res.algorithm.n_gen}\") # logger.info(f\"Number of generations\", res.algorithm.termination) # Log optimum solutions logger . info ( \"============ All opt solutions ============\" ) for i , ind in enumerate ( res . opt ): logger . info ( f 'Opt refactoring sequence { i } :' ) logger . info ( ind . X ) logger . info ( f 'Opt refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind . F ) logger . info ( \"-\" * 75 ) # Log best refactorings logger . info ( \"============ Best refactoring sequences (a set of non-dominated solutions) ============\" ) for i , ind in enumerate ( res . X ): logger . info ( f 'Best refactoring sequence { i } :' ) logger . info ( ind ) logger . info ( \"-\" * 75 ) logger . info ( \"============ Best objective values (a set of non-dominated solutions) ============\" ) for i , ind_objective in enumerate ( res . F ): logger . info ( f 'Best refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind_objective ) logger . info ( \"-\" * 75 ) # Save best refactorings population_trimmed = [] objective_values_content = '' for chromosome in res . X : chromosome_new = [] if config . PROBLEM == 0 : # i.e., single objective problem for gene_ in chromosome : chromosome_new . append (( gene_ . name , gene_ . params )) else : for gene_ in chromosome [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) for objective_vector in res . F : objective_values_content += f ' { res . algorithm . n_gen + config . NGEN } ,' if config . PROBLEM == 0 : objective_values_content += f ' { objective_vector } ,' else : for objective_ in objective_vector : objective_values_content += f ' { objective_ } ,' objective_values_content += ' \\n ' best_refactoring_sequences_path = os . path . join ( config . PROJECT_LOG_DIR , f 'best_refactoring_sequences_after_ { res . algorithm . n_gen + config . NGEN } gens.json' ) with open ( best_refactoring_sequences_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) best_refactoring_sequences_objectives_path = os . path . join ( config . PROJECT_LOG_DIR , f 'best_refactoring_sequences_objectives_after_ { res . algorithm . n_gen + config . NGEN } gens.csv' ) with open ( best_refactoring_sequences_objectives_path , mode = 'w' , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) try : pf = res . F # dm = HighTradeoffPoints() dm = get_decision_making ( \"high-tradeoff\" ) I = dm . do ( pf ) logger . info ( \"============ High-tradeoff points refactoring sequences ============\" ) for i , ind in enumerate ( res . X [ I ]): logger . info ( f 'High tradeoff points refactoring sequence { i } :' ) logger . info ( ind ) logger . info ( \"-\" * 75 ) logger . info ( \"============ High-tradeoff points objective values ============\" ) for i , ind_objective in enumerate ( pf [ I ]): logger . info ( f 'High-tradeoff points refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind_objective ) logger . info ( \"-\" * 75 ) logger . info ( \"High-tradeoff points mean:\" ) logger . info ( np . mean ( pf [ I ], axis = 0 )) logger . info ( \"High-tradeoff points median:\" ) logger . info ( np . median ( pf [ I ], axis = 0 )) # Save high-tradeoff refactorings population_trimmed = [] objective_values_content = '' for chromosome in res . X [ I ]: chromosome_new = [] if config . PROBLEM == 0 : # i.e., single objective problem for gene_ in chromosome : chromosome_new . append (( gene_ . name , gene_ . params )) else : for gene_ in chromosome [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) for objective_vector in pf [ I ]: objective_values_content += f ' { res . algorithm . n_gen + config . NGEN } ,' if config . PROBLEM == 0 : objective_values_content += f ' { objective_vector } ,' else : for objective_ in objective_vector : objective_values_content += f ' { objective_ } ,' objective_values_content += ' \\n ' high_tradeoff_path = os . path . join ( config . PROJECT_LOG_DIR , f 'high_tradeoff_points_refactoring_after_ { res . algorithm . n_gen + config . NGEN } gens.json' ) with open ( high_tradeoff_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) high_tradeoff_path_objectives_path = os . path . join ( config . PROJECT_LOG_DIR , f 'high_tradeoff_points_after_ { res . algorithm . n_gen + config . NGEN } gens.csv' ) with open ( high_tradeoff_path_objectives_path , mode = 'w' , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) except : logger . error ( \"No multi-optimal solutions (error in computing high tradeoff points)!\" )","title":"Search-based refactoring"},{"location":"optimization/search-based_refactoring/#search-based-refactoring-module","text":"","title":"Search-based refactoring module"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2--module-description","text":"This module implements the search-based refactoring with various search strategy using pymoo framework.","title":"Module description"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2--classes","text":"Gene, RefactoringOperation: One refactoring with params Individual: A list of RefactoringOperation PureRandomInitialization: Population, list of Individual","title":"Classes"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2--references","text":"[1] https://pymoo.org/customization/custom.html [2] https://pymoo.org/misc/reference_directions.html","title":"References"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2--changelog","text":"","title":"Changelog"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2--version-023","text":"1. Fix PEP 8 warnings","title":"version 0.2.3"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2--version-022","text":"1. Add a separate log directory for each execution 2. Add possibility to resume algorithm","title":"version 0.2.2"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2--version-021","text":"1. minor updates 2. fix bugs 3. rename variables names","title":"version 0.2.1"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2--version-020","text":"1. Crossover function is added. 2. Termination criteria are added. 3. Computation of highly trade-off points is added. 4. Tournament-selection is added. 5. _evaluate function in NSGA-III is now works on population instead of an individual (population-based versus element-wise). 6. Other setting for NSGA-III including adding energy-references point instead of Das and Dennis approach. ===","title":"version 0.2.0"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.AdaptiveSinglePointCrossover","text":"This class implements solution variation, the adaptive one-point or single-point crossover operator. The crossover operator combines parents to create offsprings. It starts by selecting and splitting at random two parent solutions or individuals. Then, this operator creates two child solutions by putting, for the first child, the first part of the first parent with the second part of the second parent, and vice versa for the second child. Note 1: In the pymoo framework, the crossover operator retrieves the input already with predefined matings. The default parent selection algorithm is TournamentSelection. Note 2: It is better to create children that are close to their parents to have a more efficient search process, a so-called adaptive crossover , specifically in many-objective optimization. Therefore, the cutting point of the one-point crossover operator are controlled by restricting its position to be either belonging to the first tier of the refactoring sequence or belonging to the last tier.","title":"AdaptiveSinglePointCrossover"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.AdaptiveSinglePointCrossover.__init__","text":"prob (float): crossover probability Source code in sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.9 ): \"\"\" Args: prob (float): crossover probability \"\"\" # Define the crossover: number of parents, number of offsprings, and cross-over probability super () . __init__ ( n_parents = 2 , n_offsprings = 2 , prob = prob )","title":"__init__()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.BitStringMutation","text":"This class implements solution variation, a bit-string mutation operator. The bit-string mutation operator that picks probabilistically one or more refactoring operations from its or their associated sequence and replaces them by other ones from the initial list of possible refactorings. Each chromosome dimension would be changed according to the mutation probability. For example, for a mutation probability of 0.2, for each dimension, we generate randomly a number x between 0 and 1, if x < mutation_probability (e.g., 0.2) we change the refactoring operation in that dimension, otherwise no changes are taken into account.","title":"BitStringMutation"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.BitStringMutation.__init__","text":"Parameters: Name Type Description Default prob float mutation probability 0.2 Source code in sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer","title":"__init__()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.BitStringMutation2","text":"Select an individual to mutate with mutation probability. Only flip one refactoring operation in the selected individual.","title":"BitStringMutation2"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.BitStringMutation2.__init__","text":"Parameters: Name Type Description Default prob float mutation probability 0.2 Source code in sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer self . _initializer . load_population ()","title":"__init__()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.Gene","text":"The base class for the Gene in genetic algorithms.","title":"Gene"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.Gene.__init__","text":"Parameters: Name Type Description Default name str Refactoring operation name required params dict Refactoring operation parameters required main function Refactoring operation main function (API) required Source code in sbse\\search_based_refactoring2.py def __init__ ( self , ** kwargs ): \"\"\" Args: name (str): Refactoring operation name params (dict): Refactoring operation parameters main (function): Refactoring operation main function (API) \"\"\" self . name = kwargs . get ( 'name' ) self . params = kwargs . get ( 'params' ) self . main = kwargs . get ( 'main' )","title":"__init__()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.Individual","text":"The class define a data structure (list) to hold an individual during the search process. Each individual (also called, chromosome or solution in the context of genetic programming) is an array of refactoring operations where the order of their execution is accorded by their positions in the array.","title":"Individual"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.Individual.__init__","text":"Source code in sbse\\search_based_refactoring2.py def __init__ ( self ): \"\"\" Args: \"\"\" super ( Individual , self ) . __init__ () self . refactoring_operations = []","title":"__init__()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.Individual.append","text":"Append object to the end of the list. Source code in sbse\\search_based_refactoring2.py def append ( self , __object : RefactoringOperation ) -> None : self . insert ( len ( self . refactoring_operations ), __object )","title":"append()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.Individual.insert","text":"Insert object before index. Source code in sbse\\search_based_refactoring2.py def insert ( self , __index : int , __object : RefactoringOperation ) -> None : self . refactoring_operations . insert ( __index , __object )","title":"insert()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.LogCallback","text":"Logging useful information after each iteration of the search algorithms","title":"LogCallback"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.PopulationInitialization","text":"This class create the initial population, x, consists of n_samples, pop_size. For each refactoring operation, a set of controlling parameters (e.g., actors and roles) is picked based on existing code smells in the program to be refactored. The selected refactoring operations are randomly arranged in each individual. Assigning randomly a sequence of refactorings to certain code fragments generates the initial population","title":"PopulationInitialization"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.PopulationInitialization.__init__","text":"Parameters: Name Type Description Default initializer Initialization An initializer object to be used for generating initial population None Source code in sbse\\search_based_refactoring2.py def __init__ ( self , initializer : Initialization = None ): \"\"\" Args: initializer (Initialization): An initializer object to be used for generating initial population \"\"\" super ( PopulationInitialization , self ) . __init__ () self . _initializer = initializer","title":"__init__()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.ProblemManyObjective","text":"The CodART many-objective optimization work with eight objective: Objective 1 to 6: QMOOD metrics Objective 7: Testability Objective 8: Modularity","title":"ProblemManyObjective"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.ProblemManyObjective.__init__","text":"Parameters: Name Type Description Default n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 evaluate_in_parallel bool Whether the objectives computed in parallel or not False verbose_design_metrics bool Whether log the design metrics for each refactoring sequences or not False Source code in sbse\\search_based_refactoring2.py def __init__ ( self , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , verbose_design_metrics = False , ): \"\"\" Args: n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives computed in parallel or not verbose_design_metrics (bool): Whether log the design metrics for each refactoring sequences or not \"\"\" super ( ProblemManyObjective , self ) . __init__ ( n_var = 1 , n_obj = 8 , n_constr = 0 , ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . verbose_design_metrics = verbose_design_metrics","title":"__init__()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.ProblemMultiObjective","text":"The CodART multi-objective optimization work with three objective: Objective 1: Mean value of QMOOD metrics Objective 2: Testability Objective 3: Modularity","title":"ProblemMultiObjective"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.ProblemSingleObjective","text":"The CodART single-objective optimization work with only one objective, testability:","title":"ProblemSingleObjective"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.ProblemSingleObjective.__init__","text":"Parameters: Name Type Description Default n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 mode str 'single' or 'multi' 'single' Source code in sbse\\search_based_refactoring2.py def __init__ ( self , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , mode = 'single' # 'multi' ): \"\"\" Args: n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences mode (str): 'single' or 'multi' \"\"\" super ( ProblemSingleObjective , self ) . __init__ ( n_var = 1 , n_obj = 1 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . mode = mode","title":"__init__()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.RefactoringOperation","text":"The class define a data structure (dictionary) to hold a refactoring operation Each refactoring operation hold as a dictionary contains the required parameters. Example: ``` make_field_static refactoring is marshaled as the following dict: params = { 'refactoring_name': 'make_field_static' 'api': 'main_function' 'source_class': 'name_of_source_class' 'field_name': 'name_of_the_field_to_be_static' } ```","title":"RefactoringOperation"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.RefactoringOperation.do_refactoring","text":"Check preconditions and apply refactoring operation to source code Returns: Type Description result (boolean) The result statues of the applied refactoring Source code in sbse\\search_based_refactoring2.py def do_refactoring ( self ): \"\"\" Check preconditions and apply refactoring operation to source code Returns: result (boolean): The result statues of the applied refactoring \"\"\" logger . info ( f \"Running { self . name } \" ) logger . info ( f \"Parameters { self . params } \" ) try : res = self . main ( ** self . params ) return res except Exception as e : logger . error ( f \"Unexpected error in executing refactoring: \\n { e } \" ) return False","title":"do_refactoring()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.binary_tournament","text":"Implements the binary tournament selection algorithm Source code in sbse\\search_based_refactoring2.py def binary_tournament ( pop , P , ** kwargs ): \"\"\" Implements the binary tournament selection algorithm \"\"\" # The P input defines the tournaments and competitors n_tournaments , n_competitors = P . shape if n_competitors != 2 : raise Exception ( \"Only pressure=2 allowed for binary tournament!\" ) S = np . full ( n_tournaments , - 1 , dtype = np . int64 ) # Now do all the tournaments for i in range ( n_tournaments ): a , b = P [ i ] # If the first individual is better, choose it if pop [ a ] . F . all () <= pop [ a ] . F . all (): S [ i ] = a # Otherwise, take the other individual else : S [ i ] = b return S","title":"binary_tournament()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.is_equal_2_refactorings_list","text":"This method implement is_equal method which should return True if two instances of Individual class are equal. Otherwise, it returns False. The duplicate instances are removed from population at each generation. Only one instance is held to speed up the search algorithm Source code in sbse\\search_based_refactoring2.py def is_equal_2_refactorings_list ( a , b ): \"\"\" This method implement is_equal method which should return True if two instances of Individual class are equal. Otherwise, it returns False. The duplicate instances are removed from population at each generation. Only one instance is held to speed up the search algorithm \"\"\" if len ( a . X [ 0 ]) != len ( b . X [ 0 ]): return False for i , ro in enumerate ( a . X [ 0 ]): if ro . name != b . X [ 0 ][ i ] . name : return False if ro . params != b . X [ 0 ][ i ] . params : return False return True","title":"is_equal_2_refactorings_list()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.log_project_info","text":"Logging project metrics and information Source code in sbse\\search_based_refactoring2.py def log_project_info ( reset_ = True , design_metrics_path = None , quality_attributes_path = None , generation = 0 , testability_verbose = True , testability_log_path = None ): \"\"\" Logging project metrics and information \"\"\" if reset_ : reset_project () if quality_attributes_path is None : quality_attributes_path = os . path . join ( config . PROJECT_LOG_DIR , 'quality_attrs_initial_values.csv' ) if design_metrics_path is None : design_metrics_path = os . path . join ( config . PROJECT_LOG_DIR , 'design_metrics.csv' ) design_quality_attribute = DesignQualityAttributes ( config . UDB_PATH ) avg_ , sum_ = design_quality_attribute . average_sum predicted_testability = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 ), verbose = testability_verbose , log_path = testability_log_path ) mdg_modularity = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 ) ) design_metrics = { \"DSC\" : [ design_quality_attribute . DSC ], \"NOH\" : [ design_quality_attribute . NOH ], \"ANA\" : [ design_quality_attribute . ANA ], \"MOA\" : [ design_quality_attribute . MOA ], \"DAM\" : [ design_quality_attribute . DAM ], \"CAMC\" : [ design_quality_attribute . CAMC ], \"CIS\" : [ design_quality_attribute . CIS ], \"NOM\" : [ design_quality_attribute . NOM ], \"DCC\" : [ design_quality_attribute . DCC ], \"MFA\" : [ design_quality_attribute . MFA ], \"NOP\" : [ design_quality_attribute . NOP ] } quality_objectives = { \"generation\" : [ generation ], \"reusability\" : [ design_quality_attribute . reusability ], \"understandability\" : [ design_quality_attribute . understandability ], \"flexibility\" : [ design_quality_attribute . flexibility ], \"functionality\" : [ design_quality_attribute . functionality ], \"effectiveness\" : [ design_quality_attribute . effectiveness ], \"extendability\" : [ design_quality_attribute . extendability ], \"testability\" : [ predicted_testability ], \"modularity\" : [ mdg_modularity ], } logger . info ( 'QMOOD design metrics (N):' ) logger . info ( design_metrics ) logger . info ( 'Objectives:' ) logger . info ( quality_objectives ) logger . info ( 'QMOOD quality attributes sum:' ) logger . info ( sum_ ) logger . info ( 'QMOOD quality attributes mean:' ) logger . info ( avg_ ) df_quality_attributes = pd . DataFrame ( data = quality_objectives ) if os . path . exists ( quality_attributes_path ): df = pd . read_csv ( quality_attributes_path , index_col = False ) df_result = pd . concat ([ df , df_quality_attributes ], ignore_index = True ) df_result . to_csv ( quality_attributes_path , index = False ) else : df_quality_attributes . to_csv ( quality_attributes_path , index = False ) df_design_metrics = pd . DataFrame ( data = design_metrics ) if os . path . exists ( design_metrics_path ): df = pd . read_csv ( design_metrics_path , index_col = False ) df_results = pd . concat ([ df , df_design_metrics ], ignore_index = True ) # df = df.append(df_design_metrics, ignore_index=True) df_results . to_csv ( design_metrics_path , index = False ) else : df_design_metrics . to_csv ( design_metrics_path , index = False )","title":"log_project_info()"},{"location":"optimization/search-based_refactoring/#sbse.search_based_refactoring2.main","text":"Optimization module main driver Source code in sbse\\search_based_refactoring2.py def main (): \"\"\" Optimization module main driver \"\"\" # Define initialization objects initializer_class = SmellInitialization if config . WARM_START else RandomInitialization initializer_object = initializer_class ( udb_path = config . UDB_PATH , population_size = config . POPULATION_SIZE , lower_band = config . LOWER_BAND , upper_band = config . UPPER_BAND ) # Define search algorithms algorithms = list () # 1: GA alg1 = GA ( pop_size = config . POPULATION_SIZE , sampling = PopulationInitialization ( initializer_object ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg1 ) # 2: NSGA II alg2 = NSGA2 ( pop_size = config . POPULATION_SIZE , sampling = PopulationInitialization ( initializer_object ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg2 ) # 3: NSGA III # pop_size must be equal or larger than the number of reference directions number_of_references_points = config . POPULATION_SIZE - int ( config . POPULATION_SIZE * 0.20 ) ref_dirs = get_reference_directions ( 'energy' , # algorithm config . NUMBER_OBJECTIVES , # number of objectives number_of_references_points , # number of reference directions seed = 1 ) alg3 = NSGA3 ( ref_dirs = ref_dirs , pop_size = config . POPULATION_SIZE , # 200 sampling = PopulationInitialization ( initializer_object ), selection = TournamentSelection ( func_comp = binary_tournament ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY , ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg3 ) # ------------------------------------------- # Define problems problems = list () # 0: Genetic (Single), 1: NSGA-II (Multi), 2: NSGA-III (Many) objectives problems problems . append ( ProblemSingleObjective ( n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , ) ) problems . append ( ProblemMultiObjective ( n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , ) ) problems . append ( ProblemManyObjective ( n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , verbose_design_metrics = True , ) ) # Termination of algorithms my_termination = MultiObjectiveDefaultTermination ( x_tol = None , cv_tol = None , f_tol = 0.0015 , nth_gen = 5 , n_last = 5 , n_max_gen = config . MAX_ITERATIONS , # about 1000 - 1400 n_max_evals = 1e6 ) # Do optimization for various problems with various algorithms res = minimize ( problem = problems [ config . PROBLEM ], algorithm = algorithms [ config . PROBLEM ], termination = my_termination , seed = 1 , verbose = False , copy_algorithm = True , copy_termination = True , save_history = False , callback = LogCallback (), ) # np.save('checkpoint', res.algorithm) # Log results logger . info ( f \"***** Algorithm was finished in { res . algorithm . n_gen + config . NGEN } generations *****\" ) logger . info ( \" \" ) logger . info ( \"============ time information ============\" ) logger . info ( f \"Start time: { datetime . fromtimestamp ( res . start_time ) . strftime ( '%Y-%m- %d %H:%M:%S' ) } \" ) logger . info ( f \"End time: { datetime . fromtimestamp ( res . end_time ) . strftime ( '%Y-%m- %d %H:%M:%S' ) } \" ) logger . info ( f \"Execution time in seconds: { res . exec_time } \" ) logger . info ( f \"Execution time in minutes: { res . exec_time / 60 } \" ) logger . info ( f \"Execution time in hours: { res . exec_time / ( 60 * 60 ) } \" ) # logger.info(f\"Number of generations: {res.algorithm.n_gen}\") # logger.info(f\"Number of generations\", res.algorithm.termination) # Log optimum solutions logger . info ( \"============ All opt solutions ============\" ) for i , ind in enumerate ( res . opt ): logger . info ( f 'Opt refactoring sequence { i } :' ) logger . info ( ind . X ) logger . info ( f 'Opt refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind . F ) logger . info ( \"-\" * 75 ) # Log best refactorings logger . info ( \"============ Best refactoring sequences (a set of non-dominated solutions) ============\" ) for i , ind in enumerate ( res . X ): logger . info ( f 'Best refactoring sequence { i } :' ) logger . info ( ind ) logger . info ( \"-\" * 75 ) logger . info ( \"============ Best objective values (a set of non-dominated solutions) ============\" ) for i , ind_objective in enumerate ( res . F ): logger . info ( f 'Best refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind_objective ) logger . info ( \"-\" * 75 ) # Save best refactorings population_trimmed = [] objective_values_content = '' for chromosome in res . X : chromosome_new = [] if config . PROBLEM == 0 : # i.e., single objective problem for gene_ in chromosome : chromosome_new . append (( gene_ . name , gene_ . params )) else : for gene_ in chromosome [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) for objective_vector in res . F : objective_values_content += f ' { res . algorithm . n_gen + config . NGEN } ,' if config . PROBLEM == 0 : objective_values_content += f ' { objective_vector } ,' else : for objective_ in objective_vector : objective_values_content += f ' { objective_ } ,' objective_values_content += ' \\n ' best_refactoring_sequences_path = os . path . join ( config . PROJECT_LOG_DIR , f 'best_refactoring_sequences_after_ { res . algorithm . n_gen + config . NGEN } gens.json' ) with open ( best_refactoring_sequences_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) best_refactoring_sequences_objectives_path = os . path . join ( config . PROJECT_LOG_DIR , f 'best_refactoring_sequences_objectives_after_ { res . algorithm . n_gen + config . NGEN } gens.csv' ) with open ( best_refactoring_sequences_objectives_path , mode = 'w' , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) try : pf = res . F # dm = HighTradeoffPoints() dm = get_decision_making ( \"high-tradeoff\" ) I = dm . do ( pf ) logger . info ( \"============ High-tradeoff points refactoring sequences ============\" ) for i , ind in enumerate ( res . X [ I ]): logger . info ( f 'High tradeoff points refactoring sequence { i } :' ) logger . info ( ind ) logger . info ( \"-\" * 75 ) logger . info ( \"============ High-tradeoff points objective values ============\" ) for i , ind_objective in enumerate ( pf [ I ]): logger . info ( f 'High-tradeoff points refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind_objective ) logger . info ( \"-\" * 75 ) logger . info ( \"High-tradeoff points mean:\" ) logger . info ( np . mean ( pf [ I ], axis = 0 )) logger . info ( \"High-tradeoff points median:\" ) logger . info ( np . median ( pf [ I ], axis = 0 )) # Save high-tradeoff refactorings population_trimmed = [] objective_values_content = '' for chromosome in res . X [ I ]: chromosome_new = [] if config . PROBLEM == 0 : # i.e., single objective problem for gene_ in chromosome : chromosome_new . append (( gene_ . name , gene_ . params )) else : for gene_ in chromosome [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) for objective_vector in pf [ I ]: objective_values_content += f ' { res . algorithm . n_gen + config . NGEN } ,' if config . PROBLEM == 0 : objective_values_content += f ' { objective_vector } ,' else : for objective_ in objective_vector : objective_values_content += f ' { objective_ } ,' objective_values_content += ' \\n ' high_tradeoff_path = os . path . join ( config . PROJECT_LOG_DIR , f 'high_tradeoff_points_refactoring_after_ { res . algorithm . n_gen + config . NGEN } gens.json' ) with open ( high_tradeoff_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) high_tradeoff_path_objectives_path = os . path . join ( config . PROJECT_LOG_DIR , f 'high_tradeoff_points_after_ { res . algorithm . n_gen + config . NGEN } gens.csv' ) with open ( high_tradeoff_path_objectives_path , mode = 'w' , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) except : logger . error ( \"No multi-optimal solutions (error in computing high tradeoff points)!\" )","title":"main()"},{"location":"proposals/core_code_smell_development/","text":"Core code smell development The following proposal has been initially prepared for the IUST Compiler and Advanced Software Engineering courses in Winter and Spring 2021 . Note: Before reading this proposal ensure that you have read and understood the CodART white-paper . Students may form groups of up to three persons. Each group must develop mechanisms for a subset of code smells listed in Table 2 . The exact list of code smells will be assigned to each group subsequently. The refactoring operations in Table 1 and code smells in Table 2 may update during the semester. To facilitate and organized the development process, this proposal defines the project in various phases. The project is divided into three separate phases. In the first phase, students must read about refactoring and code smells and understand the current state of the CodART completely. As a practice, they are asked to fix the existing issues on the project repository about refactoring operations developed in the first proposal. In the second phase, each group is asked to develop algorithms to automatically detect one or more code smells in a given Java project using ANTLR tool and other compiler techniques. TA team frequently helps the students at this phase to develop their algorithms. In the third phase, each group is asked to connect the code smells detection scripts to the corresponding refactoring and automate the overall quality improvement process. Grading policy for BSc students Table 6 shows the grading policy for the BSc students. It may change in the future. Table 6. grading policy for BSc students Activity Score (100) Understanding the CodART project and Fix the existing issues 30 Implementing smell detection approaches 40 Connecting code smells to refactoring and harnessing the overall process 20 Documenting the new source codes and pushing them to GitHub 10 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) Grading policy for MSc students Table 7 shows the grading policy for the MSc students. It may change in the future. Table 7. grading policy for MSc students Activity Score (100) Understanding the paper and presenting it 20 Implementing the paper 30 Evaluating the implementation 30 Documenting the project 20 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) To follow project's future phases, meet our next proposal: Core search-based development.","title":"Core code smell development"},{"location":"proposals/core_code_smell_development/#core-code-smell-development","text":"The following proposal has been initially prepared for the IUST Compiler and Advanced Software Engineering courses in Winter and Spring 2021 . Note: Before reading this proposal ensure that you have read and understood the CodART white-paper . Students may form groups of up to three persons. Each group must develop mechanisms for a subset of code smells listed in Table 2 . The exact list of code smells will be assigned to each group subsequently. The refactoring operations in Table 1 and code smells in Table 2 may update during the semester. To facilitate and organized the development process, this proposal defines the project in various phases. The project is divided into three separate phases. In the first phase, students must read about refactoring and code smells and understand the current state of the CodART completely. As a practice, they are asked to fix the existing issues on the project repository about refactoring operations developed in the first proposal. In the second phase, each group is asked to develop algorithms to automatically detect one or more code smells in a given Java project using ANTLR tool and other compiler techniques. TA team frequently helps the students at this phase to develop their algorithms. In the third phase, each group is asked to connect the code smells detection scripts to the corresponding refactoring and automate the overall quality improvement process.","title":"Core code smell development"},{"location":"proposals/core_code_smell_development/#grading-policy-for-bsc-students","text":"Table 6 shows the grading policy for the BSc students. It may change in the future. Table 6. grading policy for BSc students Activity Score (100) Understanding the CodART project and Fix the existing issues 30 Implementing smell detection approaches 40 Connecting code smells to refactoring and harnessing the overall process 20 Documenting the new source codes and pushing them to GitHub 10 Testing project on all projects available in CodART benchmarks 20+ (extra bonus)","title":"Grading policy for BSc students"},{"location":"proposals/core_code_smell_development/#grading-policy-for-msc-students","text":"Table 7 shows the grading policy for the MSc students. It may change in the future. Table 7. grading policy for MSc students Activity Score (100) Understanding the paper and presenting it 20 Implementing the paper 30 Evaluating the implementation 30 Documenting the project 20 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) To follow project's future phases, meet our next proposal: Core search-based development.","title":"Grading policy for MSc students"},{"location":"proposals/core_refactoring_to_design_patterns_development/","text":"Core refactoring to design patterns development To be announced.","title":"Core refactoring to patterns development"},{"location":"proposals/core_refactoring_to_design_patterns_development/#core-refactoring-to-design-patterns-development","text":"To be announced.","title":"Core refactoring to design patterns development"},{"location":"proposals/core_refactorings_development/","text":"Core refactoring development The following proposal was initially prepared for the IUST Compiler and Advanced compiler courses in Fall 2020. Students must form groups of up to three persons, and each group must implement several refactoring operations. The exact list of refactoring will be assigned to each group subsequently. The refactoring operations in Table 1 may update during the semester. As an example of refactoring automation, we have implemented the EncapsulateField refactoring, illustrated in Figure 1. A na\u00efve implementation is available on the project official Github page at https://m-zakeri.github.io/CodART . In addition, 26 refactoring operations in Table 1 have been implemented by MultiRefactor [7] based on RECODER , three of them have been implemented by JDeodrant [8], and other operations have been automated in [3], [6]. RECODER extracts a model of the code that can be used to analyze and modify the code before the changes are applied and written to file. The tool takes Java source code as input and will output the modified source code to a specified folder. The input must be fully compilable and must be accompanied by any necessary library files as compressed jar files. Grading policy for BSc students Table 4 shows the grading policy for the BSc students. It may change in the future. Table 4. grading policy for BSc students Activity Score (100) Refactoring operations implementation (moderate level) 50 Evaluation of the tool on the benchmark projects 30 Documentations 20 Search-based refactoring recommendation 30+ (extra bonus) Grading policy for MSc students Table 5 shows the grading policy for the MSc students. It may change in the future. Table 5. grading policy for MSc students Activity Score (100) Refactoring operations implementation (advanced level) 40 Search-based refactoring recommendation 30 Evaluation of the tool on the benchmark projects 20 Documentations 10 Improving the state-of-the-arts papers 30+ (extra bonus) To follow project's phases, refer to our next proposal: Core code smell development.","title":"Core refactoring development"},{"location":"proposals/core_refactorings_development/#core-refactoring-development","text":"The following proposal was initially prepared for the IUST Compiler and Advanced compiler courses in Fall 2020. Students must form groups of up to three persons, and each group must implement several refactoring operations. The exact list of refactoring will be assigned to each group subsequently. The refactoring operations in Table 1 may update during the semester. As an example of refactoring automation, we have implemented the EncapsulateField refactoring, illustrated in Figure 1. A na\u00efve implementation is available on the project official Github page at https://m-zakeri.github.io/CodART . In addition, 26 refactoring operations in Table 1 have been implemented by MultiRefactor [7] based on RECODER , three of them have been implemented by JDeodrant [8], and other operations have been automated in [3], [6]. RECODER extracts a model of the code that can be used to analyze and modify the code before the changes are applied and written to file. The tool takes Java source code as input and will output the modified source code to a specified folder. The input must be fully compilable and must be accompanied by any necessary library files as compressed jar files.","title":"Core refactoring development"},{"location":"proposals/core_refactorings_development/#grading-policy-for-bsc-students","text":"Table 4 shows the grading policy for the BSc students. It may change in the future. Table 4. grading policy for BSc students Activity Score (100) Refactoring operations implementation (moderate level) 50 Evaluation of the tool on the benchmark projects 30 Documentations 20 Search-based refactoring recommendation 30+ (extra bonus)","title":"Grading policy for BSc students"},{"location":"proposals/core_refactorings_development/#grading-policy-for-msc-students","text":"Table 5 shows the grading policy for the MSc students. It may change in the future. Table 5. grading policy for MSc students Activity Score (100) Refactoring operations implementation (advanced level) 40 Search-based refactoring recommendation 30 Evaluation of the tool on the benchmark projects 20 Documentations 10 Improving the state-of-the-arts papers 30+ (extra bonus) To follow project's phases, refer to our next proposal: Core code smell development.","title":"Grading policy for MSc students"},{"location":"proposals/core_search_based_development/","text":"Core search-based development To be announced.","title":"Core search-based development"},{"location":"proposals/core_search_based_development/#core-search-based-development","text":"To be announced.","title":"Core search-based development"},{"location":"refactorings/decrease_field_visibility/","text":"Decrease field visibility Introduction Decrease field visibility refactoring Decrease the visibility of a field from public to protected, protected to package or package to private. Pre and post-conditions Pre-conditions: User must enter the field's name, and the source class's name for the refactoring in order to decrease the target field's visibility. Post-conditions: No specific post-condition DecreaseFieldVisibilityListener To implement \u0650Decrease Field Visibility refactoring based on its actors. Detects the required field and decreases/changes its visibility status. __init__ ( self , source_class , source_field , rewriter ) special Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_field str Name of the field whose visibility status has to be changed required rewriter TokenStreamRewriter An instance of TokenStreamRewriter required Returns: Type Description object (DecreaseFieldVisibilityListener) An instance of DecreaseFieldVisibilityListener Source code in refactorings\\decrease_field_visibility.py def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseFieldVisibilityListener): An instance of DecreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ) Source code in refactorings\\decrease_field_visibility.py def main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) field_ent = db . lookup ( f \" { source_package } . { source_class } . { source_field } \" , \"Variable\" ) if len ( field_ent ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False field_ent = field_ent [ 0 ] if field_ent . simplename () != source_field : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not field_ent.kind().check(\"Public\"): # logger.error(\"Field is not public.\") # db.close() # return False for ref in field_ent . refs ( \"Useby,Setby\" ): ent = ref . ent () if f \" { source_package } . { source_class } \" not in ent . longname (): logger . debug ( f \" { source_package } . { source_class } not in { ent . longname () } \" ) logger . error ( \"Field cannot set to private.\" ) db . close () return False parent = field_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () db . close () parse_and_walk ( file_path = main_file , listener_class = DecreaseFieldVisibilityListener , has_write = True , source_class = source_class , source_field = source_field ) return True","title":"Decrease field visibility"},{"location":"refactorings/decrease_field_visibility/#decrease-field-visibility","text":"","title":"Decrease field visibility"},{"location":"refactorings/decrease_field_visibility/#refactorings.decrease_field_visibility--introduction","text":"Decrease field visibility refactoring Decrease the visibility of a field from public to protected, protected to package or package to private.","title":"Introduction"},{"location":"refactorings/decrease_field_visibility/#refactorings.decrease_field_visibility--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/decrease_field_visibility/#refactorings.decrease_field_visibility--pre-conditions","text":"User must enter the field's name, and the source class's name for the refactoring in order to decrease the target field's visibility.","title":"Pre-conditions:"},{"location":"refactorings/decrease_field_visibility/#refactorings.decrease_field_visibility--post-conditions","text":"No specific post-condition","title":"Post-conditions:"},{"location":"refactorings/decrease_field_visibility/#refactorings.decrease_field_visibility.DecreaseFieldVisibilityListener","text":"To implement \u0650Decrease Field Visibility refactoring based on its actors. Detects the required field and decreases/changes its visibility status.","title":"DecreaseFieldVisibilityListener"},{"location":"refactorings/decrease_field_visibility/#refactorings.decrease_field_visibility.DecreaseFieldVisibilityListener.__init__","text":"Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_field str Name of the field whose visibility status has to be changed required rewriter TokenStreamRewriter An instance of TokenStreamRewriter required Returns: Type Description object (DecreaseFieldVisibilityListener) An instance of DecreaseFieldVisibilityListener Source code in refactorings\\decrease_field_visibility.py def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseFieldVisibilityListener): An instance of DecreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter","title":"__init__()"},{"location":"refactorings/decrease_field_visibility/#refactorings.decrease_field_visibility.main","text":"Source code in refactorings\\decrease_field_visibility.py def main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) field_ent = db . lookup ( f \" { source_package } . { source_class } . { source_field } \" , \"Variable\" ) if len ( field_ent ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False field_ent = field_ent [ 0 ] if field_ent . simplename () != source_field : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not field_ent.kind().check(\"Public\"): # logger.error(\"Field is not public.\") # db.close() # return False for ref in field_ent . refs ( \"Useby,Setby\" ): ent = ref . ent () if f \" { source_package } . { source_class } \" not in ent . longname (): logger . debug ( f \" { source_package } . { source_class } not in { ent . longname () } \" ) logger . error ( \"Field cannot set to private.\" ) db . close () return False parent = field_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () db . close () parse_and_walk ( file_path = main_file , listener_class = DecreaseFieldVisibilityListener , has_write = True , source_class = source_class , source_field = source_field ) return True","title":"main()"},{"location":"refactorings/decrease_method_visibility/","text":"Decrease method visibility Introduction Decrease method visibility refactoring Decrease the visibility of a method from public to protected, protected to package or package to private. DecreaseMethodVisibilityListener To implement \u0650Decrease Method Visibility refactoring based on its actors. Detects the required method and decreases/changes its visibility status. __init__ ( self , source_class , source_method , rewriter ) special Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_method str Name of the field whose visibility status has to be changed required rewriter TokenStreamRewriter An instance of TokenStreamRewriter required Returns: Type Description object (DecreaseMethodVisibilityListener) An instance of DecreaseMethodVisibilityListener Source code in refactorings\\decrease_method_visibility.py def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseMethodVisibilityListener): An instance of DecreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ) Source code in refactorings\\decrease_method_visibility.py def main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) method_ent = db . lookup ( f \" { source_package } . { source_class } . { source_method } \" , \"Method\" ) if len ( method_ent ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False method_ent = method_ent [ 0 ] if method_ent . simplename () != source_method : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not method_ent.kind().check(\"Public\"): # logger.error(\"Method is not public.\") # db.close() # return False for ent in method_ent . ents ( \"CallBy\" ): if f \" { source_package } . { source_class } \" not in ent . longname (): logger . error ( \"Method cannot set to private.\" ) db . close () return False parent = method_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () db . close () parse_and_walk ( file_path = main_file , listener_class = DecreaseMethodVisibilityListener , has_write = True , source_class = source_class , source_method = source_method ) return True","title":"Decrease method visibility"},{"location":"refactorings/decrease_method_visibility/#decrease-method-visibility","text":"","title":"Decrease method visibility"},{"location":"refactorings/decrease_method_visibility/#refactorings.decrease_method_visibility--introduction","text":"Decrease method visibility refactoring Decrease the visibility of a method from public to protected, protected to package or package to private.","title":"Introduction"},{"location":"refactorings/decrease_method_visibility/#refactorings.decrease_method_visibility.DecreaseMethodVisibilityListener","text":"To implement \u0650Decrease Method Visibility refactoring based on its actors. Detects the required method and decreases/changes its visibility status.","title":"DecreaseMethodVisibilityListener"},{"location":"refactorings/decrease_method_visibility/#refactorings.decrease_method_visibility.DecreaseMethodVisibilityListener.__init__","text":"Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_method str Name of the field whose visibility status has to be changed required rewriter TokenStreamRewriter An instance of TokenStreamRewriter required Returns: Type Description object (DecreaseMethodVisibilityListener) An instance of DecreaseMethodVisibilityListener Source code in refactorings\\decrease_method_visibility.py def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseMethodVisibilityListener): An instance of DecreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter","title":"__init__()"},{"location":"refactorings/decrease_method_visibility/#refactorings.decrease_method_visibility.main","text":"Source code in refactorings\\decrease_method_visibility.py def main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) method_ent = db . lookup ( f \" { source_package } . { source_class } . { source_method } \" , \"Method\" ) if len ( method_ent ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False method_ent = method_ent [ 0 ] if method_ent . simplename () != source_method : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not method_ent.kind().check(\"Public\"): # logger.error(\"Method is not public.\") # db.close() # return False for ent in method_ent . ents ( \"CallBy\" ): if f \" { source_package } . { source_class } \" not in ent . longname (): logger . error ( \"Method cannot set to private.\" ) db . close () return False parent = method_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () db . close () parse_and_walk ( file_path = main_file , listener_class = DecreaseMethodVisibilityListener , has_write = True , source_class = source_class , source_method = source_method ) return True","title":"main()"},{"location":"refactorings/encapsulate_field/","text":"Encapsulate field Introduction The module implements encapsulate field refactoring in response to Deficient Encapsulation design smell. References [1] G. Suryanarayana, G. Samarthyam, and T. Sharma, Refactoring for software design smells: managing technical debt, 1st ed. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 2014. EncapsulateFiledRefactoringListener To implement encapsulate field refactoring. Makes a public field private and provide accessors and mutator methods. __init__ ( self , common_token_stream = None , package_name = None , source_class_name = None , field_identifier = None ) special Parameters: Name Type Description Default common_token_stream CommonTokenStream contains the program tokens None package_name str The enclosing package of the field None source_class_name str The enclosing class of the field None field_identifier str The field name to be encapsulated None Returns: Type Description object (DecreaseMethodVisibilityListener) An instance of EncapsulateFiledRefactoringListener Source code in refactorings\\encapsulate_field.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , source_class_name : str = None , field_identifier : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): contains the program tokens package_name (str): The enclosing package of the field source_class_name (str): The enclosing class of the field field_identifier (str): The field name to be encapsulated Returns: object (DecreaseMethodVisibilityListener): An instance of EncapsulateFiledRefactoringListener \"\"\" self . token_stream = common_token_stream if package_name is None : self . package_name = '' else : self . package_name = package_name self . source_class_name = source_class_name self . field_identifier = field_identifier self . getter_exist = False self . setter_exist = False self . in_source_class = False self . in_selected_package = True if self . package_name == '' else False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = \\ TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"Encapsulate field"},{"location":"refactorings/encapsulate_field/#encapsulate-field","text":"","title":"Encapsulate field"},{"location":"refactorings/encapsulate_field/#refactorings.encapsulate_field--introduction","text":"The module implements encapsulate field refactoring in response to Deficient Encapsulation design smell.","title":"Introduction"},{"location":"refactorings/encapsulate_field/#refactorings.encapsulate_field--references","text":"[1] G. Suryanarayana, G. Samarthyam, and T. Sharma, Refactoring for software design smells: managing technical debt, 1st ed. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 2014.","title":"References"},{"location":"refactorings/encapsulate_field/#refactorings.encapsulate_field.EncapsulateFiledRefactoringListener","text":"To implement encapsulate field refactoring. Makes a public field private and provide accessors and mutator methods.","title":"EncapsulateFiledRefactoringListener"},{"location":"refactorings/encapsulate_field/#refactorings.encapsulate_field.EncapsulateFiledRefactoringListener.__init__","text":"Parameters: Name Type Description Default common_token_stream CommonTokenStream contains the program tokens None package_name str The enclosing package of the field None source_class_name str The enclosing class of the field None field_identifier str The field name to be encapsulated None Returns: Type Description object (DecreaseMethodVisibilityListener) An instance of EncapsulateFiledRefactoringListener Source code in refactorings\\encapsulate_field.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , source_class_name : str = None , field_identifier : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): contains the program tokens package_name (str): The enclosing package of the field source_class_name (str): The enclosing class of the field field_identifier (str): The field name to be encapsulated Returns: object (DecreaseMethodVisibilityListener): An instance of EncapsulateFiledRefactoringListener \"\"\" self . token_stream = common_token_stream if package_name is None : self . package_name = '' else : self . package_name = package_name self . source_class_name = source_class_name self . field_identifier = field_identifier self . getter_exist = False self . setter_exist = False self . in_source_class = False self . in_selected_package = True if self . package_name == '' else False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = \\ TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"refactorings/extract_class/","text":"Extract class Introduction The module implements the extract class refactoring to fix God/Large/Blob class code smell. Extract a set of filed and methods from the class to a new class. Pre and Post Conditions Pre Conditions: Post Conditions: Changelog v0.2.1 Fix bugs in getting entity.parent() None DependencyPreConditionListener ExtractClassRefactoringListener To implement extract class refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one","title":"Extract class"},{"location":"refactorings/extract_class/#extract-class","text":"","title":"Extract class"},{"location":"refactorings/extract_class/#refactorings.extract_class--introduction","text":"The module implements the extract class refactoring to fix God/Large/Blob class code smell. Extract a set of filed and methods from the class to a new class.","title":"Introduction"},{"location":"refactorings/extract_class/#refactorings.extract_class--pre-and-post-conditions","text":"","title":"Pre and Post Conditions"},{"location":"refactorings/extract_class/#refactorings.extract_class--pre-conditions","text":"","title":"Pre Conditions:"},{"location":"refactorings/extract_class/#refactorings.extract_class--post-conditions","text":"","title":"Post Conditions:"},{"location":"refactorings/extract_class/#refactorings.extract_class--changelog","text":"","title":"Changelog"},{"location":"refactorings/extract_class/#refactorings.extract_class--v021","text":"Fix bugs in getting entity.parent() None","title":"v0.2.1"},{"location":"refactorings/extract_class/#refactorings.extract_class.DependencyPreConditionListener","text":"","title":"DependencyPreConditionListener"},{"location":"refactorings/extract_class/#refactorings.extract_class.ExtractClassRefactoringListener","text":"To implement extract class refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one","title":"ExtractClassRefactoringListener"},{"location":"refactorings/extract_interface/","text":"Extract interface Introduction When multiple clients are using the same part of a class interface, or part of the interface in two classes is the same; Extract Interface Refactoring moves this identical portion to its own interface. Pre and post-conditions Pre-conditions: precondition is whether the package name, all the class names and method names in those classes exist. The parameter types and return types of each method should be the same across the classes. Post-conditions: No specific Post Condition ExtractInterfaceRefactoring The class that does the process of extract interface refactoring. Splits the identical,reused portion of the interface, creates a new interface, and moves the split portion to the new interface. __init__ ( self , source_filenames , package_name , class_names , method_keys , interface_name , interface_filename , filename_mapping =< function ExtractInterfaceRefactoring .< lambda > at 0x0000016CFD64EF70 > ) special Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the classes) required class_names list The classes which are going to implement the new interface required method_keys list The methods which are going to be included in the interface required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function ExtractInterfaceRefactoring.<lambda> at 0x0000016CFD64EF70> interface_name str The new interface name required interface_filename str The new interface file name required Returns: Type Description object (ExtractInterfaceRefactoring) An instance of ExtractInterfaceRefactoring class Source code in refactorings\\extract_interface.py def __init__ ( self , source_filenames : list , package_name : str , class_names : list , method_keys : list , interface_name : str , interface_filename : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done (contains the classes) class_names (str): The classes which are going to implement the new interface method_keys (str): The methods which are going to be included in the interface filename_mapping (str): Mapping the file's name to the correct format so that it can be processed interface_name (str): The new interface name interface_filename (str): The new interface file name Returns: object (ExtractInterfaceRefactoring): An instance of ExtractInterfaceRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_names = class_names self . method_keys = method_keys self . interface_name = interface_name self . interface_filename = interface_filename self . filename_mapping = filename_mapping main ( source_filenames , package_name , class_names , method_keys , interface_name , interface_filename , ** kwargs ) The main API for extract interface refactoring Source code in refactorings\\extract_interface.py def main ( source_filenames , package_name , class_names , method_keys , interface_name , interface_filename , ** kwargs ): \"\"\" The main API for extract interface refactoring \"\"\" extract_interface_object = ExtractInterfaceRefactoring ( source_filenames = source_filenames , package_name = package_name , class_names = class_names , method_keys = method_keys , interface_name = interface_name , interface_filename = interface_filename , ) res = extract_interface_object . do_refactor () if not res : config . logger . error ( \"Cannot perform extract interface refactoring.\" ) return res","title":"Extract interface"},{"location":"refactorings/extract_interface/#extract-interface","text":"","title":"Extract interface"},{"location":"refactorings/extract_interface/#refactorings.extract_interface--introduction","text":"When multiple clients are using the same part of a class interface, or part of the interface in two classes is the same; Extract Interface Refactoring moves this identical portion to its own interface.","title":"Introduction"},{"location":"refactorings/extract_interface/#refactorings.extract_interface--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/extract_interface/#refactorings.extract_interface--pre-conditions","text":"precondition is whether the package name, all the class names and method names in those classes exist. The parameter types and return types of each method should be the same across the classes.","title":"Pre-conditions:"},{"location":"refactorings/extract_interface/#refactorings.extract_interface--post-conditions","text":"No specific Post Condition","title":"Post-conditions:"},{"location":"refactorings/extract_interface/#refactorings.extract_interface.ExtractInterfaceRefactoring","text":"The class that does the process of extract interface refactoring. Splits the identical,reused portion of the interface, creates a new interface, and moves the split portion to the new interface.","title":"ExtractInterfaceRefactoring"},{"location":"refactorings/extract_interface/#refactorings.extract_interface.ExtractInterfaceRefactoring.__init__","text":"Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the classes) required class_names list The classes which are going to implement the new interface required method_keys list The methods which are going to be included in the interface required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function ExtractInterfaceRefactoring.<lambda> at 0x0000016CFD64EF70> interface_name str The new interface name required interface_filename str The new interface file name required Returns: Type Description object (ExtractInterfaceRefactoring) An instance of ExtractInterfaceRefactoring class Source code in refactorings\\extract_interface.py def __init__ ( self , source_filenames : list , package_name : str , class_names : list , method_keys : list , interface_name : str , interface_filename : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done (contains the classes) class_names (str): The classes which are going to implement the new interface method_keys (str): The methods which are going to be included in the interface filename_mapping (str): Mapping the file's name to the correct format so that it can be processed interface_name (str): The new interface name interface_filename (str): The new interface file name Returns: object (ExtractInterfaceRefactoring): An instance of ExtractInterfaceRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_names = class_names self . method_keys = method_keys self . interface_name = interface_name self . interface_filename = interface_filename self . filename_mapping = filename_mapping","title":"__init__()"},{"location":"refactorings/extract_interface/#refactorings.extract_interface.main","text":"The main API for extract interface refactoring Source code in refactorings\\extract_interface.py def main ( source_filenames , package_name , class_names , method_keys , interface_name , interface_filename , ** kwargs ): \"\"\" The main API for extract interface refactoring \"\"\" extract_interface_object = ExtractInterfaceRefactoring ( source_filenames = source_filenames , package_name = package_name , class_names = class_names , method_keys = method_keys , interface_name = interface_name , interface_filename = interface_filename , ) res = extract_interface_object . do_refactor () if not res : config . logger . error ( \"Cannot perform extract interface refactoring.\" ) return res","title":"main()"},{"location":"refactorings/extract_interface2/","text":"Extract interface 2 Introduction The module implements a light version of extract interface refactoring described in extract_interface.py Pre and post-conditions Pre-conditions: The interface should not be already exist. precondition is whether the package name, all the class names and method names in those classes exist. The parameter types and return types of each method should be the same across the classes. Post-conditions: No specific post-condition main ( class_path ) Parameters: Name Type Description Default class_path str The java file path containing the public class required Source code in refactorings\\extract_interface2.py def main ( class_path ): \"\"\" Args: class_path (str): The java file path containing the public class \"\"\" # Precondition 1: The interface should not be already exist. interface_path = os . path . join ( os . path . dirname ( class_path ), f 'I { os . path . splitext ( os . path . basename ( class_path ))[ 0 ] } .java' ) if os . path . exists ( interface_path ): return False stream = FileStream ( class_path , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = InterfaceInfoListener () walker = ParseTreeWalker () walker . walk ( listener = listener , t = tree ) interface_info_ = listener . get_interface_info () interface_info_ [ 'name' ] = 'I' + interface_info_ [ 'name' ] interface_info_ [ 'path' ] = os . path . dirname ( class_path ) ic = InterfaceCreator ( interface_info_ , class_path ) ic . add_implement_statement_to_class () ic . save () return True","title":"Extract interface 2"},{"location":"refactorings/extract_interface2/#extract-interface-2","text":"","title":"Extract interface 2"},{"location":"refactorings/extract_interface2/#refactorings.extract_interface2--introduction","text":"The module implements a light version of extract interface refactoring described in extract_interface.py","title":"Introduction"},{"location":"refactorings/extract_interface2/#refactorings.extract_interface2--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/extract_interface2/#refactorings.extract_interface2--pre-conditions","text":"The interface should not be already exist. precondition is whether the package name, all the class names and method names in those classes exist. The parameter types and return types of each method should be the same across the classes.","title":"Pre-conditions:"},{"location":"refactorings/extract_interface2/#refactorings.extract_interface2--post-conditions","text":"No specific post-condition","title":"Post-conditions:"},{"location":"refactorings/extract_interface2/#refactorings.extract_interface2.main","text":"Parameters: Name Type Description Default class_path str The java file path containing the public class required Source code in refactorings\\extract_interface2.py def main ( class_path ): \"\"\" Args: class_path (str): The java file path containing the public class \"\"\" # Precondition 1: The interface should not be already exist. interface_path = os . path . join ( os . path . dirname ( class_path ), f 'I { os . path . splitext ( os . path . basename ( class_path ))[ 0 ] } .java' ) if os . path . exists ( interface_path ): return False stream = FileStream ( class_path , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = InterfaceInfoListener () walker = ParseTreeWalker () walker . walk ( listener = listener , t = tree ) interface_info_ = listener . get_interface_info () interface_info_ [ 'name' ] = 'I' + interface_info_ [ 'name' ] interface_info_ [ 'path' ] = os . path . dirname ( class_path ) ic = InterfaceCreator ( interface_info_ , class_path ) ic . add_implement_statement_to_class () ic . save () return True","title":"main()"},{"location":"refactorings/extract_method/","text":"Extract method Introduction An Extraction method refactoring class for using compiler listeners Description about the code: - statements are each line of code showing an act for example a = 5; is a statement. - exact each method of each class. Pre and post-conditions Pre-conditions: No specific pre-condition Post-conditions: No specific Post-condition Conf object help Lines are calculated from beginning the beginning of file starting from 1 . limitations Extracted lines must be a part of a method or a class constructor any other format simply would not work. (though we don't know java even supports any other format) ExtractMethodRefactoring Extract method factoring class extending javaParserLabeledListener __init__ ( self , lines ) special Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: Type Description object (ExtractMethodRefactoring) An instance of ExtractMethodRefactoring Source code in refactorings\\extract_method.py def __init__ ( self , lines : list ): \"\"\" Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: object (ExtractMethodRefactoring): An instance of ExtractMethodRefactoring \"\"\" # checks Target method and lines to be valid if lines is None or len ( lines ) == 0 : raise Exception ( 'target lines are not specified.' ) # setting variables self . lines = np . array ( lines ) self . lines . reshape (( len ( lines ), 1 )) self . last_line = self . lines . max () self . first_line = self . lines . min () self . post_variables = {} self . pre_variables = {} self . mid_variables = {} self . is_in_target_method = False self . is_target_method_static = False self . is_result_valid = False self . exception_thrown_in_target_method = None self . assigning_value_pre = False self . assigning_value_mid = False self . assigning_value_post = False self . method_stop_line = 0 self . return_variable = None self . return_variable_type = None self . methods_name = [] main ( file_path , lines ) The main API for Extract Method refactoring operation Source code in refactorings\\extract_method.py def main ( file_path , lines : dict ): \"\"\" The main API for Extract Method refactoring operation \"\"\" print ( \"Started Extract Method\" ) _conf = { 'target_file' : file_path , 'output_file' : file_path , 'lines' : lines , 'new_method_name' : 'newMethodByCodArt' , } extract_method ( _conf ) print ( \"Finished Extract Method\" )","title":"Extract method"},{"location":"refactorings/extract_method/#extract-method","text":"","title":"Extract method"},{"location":"refactorings/extract_method/#refactorings.extract_method--introduction","text":"An Extraction method refactoring class for using compiler listeners Description about the code: - statements are each line of code showing an act for example a = 5; is a statement. - exact each method of each class.","title":"Introduction"},{"location":"refactorings/extract_method/#refactorings.extract_method--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/extract_method/#refactorings.extract_method--pre-conditions","text":"No specific pre-condition","title":"Pre-conditions:"},{"location":"refactorings/extract_method/#refactorings.extract_method--post-conditions","text":"No specific Post-condition","title":"Post-conditions:"},{"location":"refactorings/extract_method/#refactorings.extract_method--conf-object-help","text":"Lines are calculated from beginning the beginning of file starting from 1 .","title":"Conf object help"},{"location":"refactorings/extract_method/#refactorings.extract_method--limitations","text":"Extracted lines must be a part of a method or a class constructor any other format simply would not work. (though we don't know java even supports any other format)","title":"limitations"},{"location":"refactorings/extract_method/#refactorings.extract_method.ExtractMethodRefactoring","text":"Extract method factoring class extending javaParserLabeledListener","title":"ExtractMethodRefactoring"},{"location":"refactorings/extract_method/#refactorings.extract_method.ExtractMethodRefactoring.__init__","text":"Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: Type Description object (ExtractMethodRefactoring) An instance of ExtractMethodRefactoring Source code in refactorings\\extract_method.py def __init__ ( self , lines : list ): \"\"\" Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: object (ExtractMethodRefactoring): An instance of ExtractMethodRefactoring \"\"\" # checks Target method and lines to be valid if lines is None or len ( lines ) == 0 : raise Exception ( 'target lines are not specified.' ) # setting variables self . lines = np . array ( lines ) self . lines . reshape (( len ( lines ), 1 )) self . last_line = self . lines . max () self . first_line = self . lines . min () self . post_variables = {} self . pre_variables = {} self . mid_variables = {} self . is_in_target_method = False self . is_target_method_static = False self . is_result_valid = False self . exception_thrown_in_target_method = None self . assigning_value_pre = False self . assigning_value_mid = False self . assigning_value_post = False self . method_stop_line = 0 self . return_variable = None self . return_variable_type = None self . methods_name = []","title":"__init__()"},{"location":"refactorings/extract_method/#refactorings.extract_method.main","text":"The main API for Extract Method refactoring operation Source code in refactorings\\extract_method.py def main ( file_path , lines : dict ): \"\"\" The main API for Extract Method refactoring operation \"\"\" print ( \"Started Extract Method\" ) _conf = { 'target_file' : file_path , 'output_file' : file_path , 'lines' : lines , 'new_method_name' : 'newMethodByCodArt' , } extract_method ( _conf ) print ( \"Finished Extract Method\" )","title":"main()"},{"location":"refactorings/extract_subclass/","text":"Extract subclass Introduction Extract subclass refactoring ExtractSubClassRefactoringListener To implement extract subclass refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one enterClassDeclaration ( self , ctx ) It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. Source code in refactorings\\extract_subclass.py def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. \"\"\" class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True self . code += self . NEW_LINE * 2 self . code += f \"// New class( { self . new_class } ) generated by CodART\" + self . NEW_LINE self . code += f \"class { self . new_class } extends { self . source_class }{ self . NEW_LINE } \" + \"{\" + self . NEW_LINE self . code += f \"public { self . new_class } ()\" + \"{ }\" + self . NEW_LINE else : self . is_source_class = False enterMethodDeclaration ( self , ctx ) It sets the detected field to the method if it is one of the moved methods. Source code in refactorings\\extract_subclass.py def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It sets the detected field to the method if it is one of the moved methods. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if method_identifier in self . moved_methods : self . detected_method = method_identifier enterVariableDeclaratorId ( self , ctx ) It sets the detected field to the field if it is one of the moved fields. Source code in refactorings\\extract_subclass.py def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): \"\"\" It sets the detected field to the field if it is one of the moved fields. \"\"\" if not self . is_source_class : return None field_identifier = ctx . IDENTIFIER () . getText () if field_identifier in self . moved_fields : self . detected_field = field_identifier exitClassDeclaration ( self , ctx ) It closes the opened curly brackets If it is the source class. Source code in refactorings\\extract_subclass.py def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It closes the opened curly brackets If it is the source class. \"\"\" if self . is_source_class : self . code += \"}\" self . is_source_class = False exitCompilationUnit ( self , ctx ) It writes self.code in the output path. Source code in refactorings\\extract_subclass.py def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): \"\"\" It writes self.code in the output path. \"\"\" child_file_name = self . new_class + \".java\" with open ( os . path . join ( self . output_path , child_file_name ), \"w+\" ) as f : f . write ( self . code . replace ( ' \\r\\n ' , ' \\n ' )) exitFieldDeclaration ( self , ctx ) It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. Source code in refactorings\\extract_subclass.py def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): \"\"\" It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. \"\"\" if not self . is_source_class : return None field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () field_names = list () field_names . append ( field_identifier ) # print(\"field_names=\", field_names) grand_parent_ctx = ctx . parentCtx . parentCtx if self . detected_field in field_names : if not grand_parent_ctx . modifier (): modifier = \"\" else : modifier = grand_parent_ctx . modifier ( 0 ) . getText () field_type = ctx . typeType () . getText () self . code += f \" { self . TAB }{ modifier } { field_type } { self . detected_field } ; { self . NEW_LINE } \" # delete field from source class ==>new start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . parentCtx . parentCtx . stop . tokenIndex self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_field = None exitMethodDeclaration ( self , ctx ) It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. Source code in refactorings\\extract_subclass.py def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if self . detected_method == method_identifier : start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . stop . tokenIndex method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . code += ( self . NEW_LINE + self . TAB + method_text + self . NEW_LINE ) # delete method from source class self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_method = None main () it builds the parse tree and walk its corresponding walker so that our overridden methods run. Source code in refactorings\\extract_subclass.py def main (): \"\"\" it builds the parse tree and walk its corresponding walker so that our overridden methods run. \"\"\" # udb_path = \"/home/ali/Desktop/code/TestProject/TestProject.udb\" # udb_path=create_understand_database(\"C:\\\\Users\\\\asus\\\\Desktop\\\\test_project\") # source_class = \"GodClass\" # moved_methods = ['method1', 'method3', ] # moved_fields = ['field1', 'field2', ] udb_path = \"C: \\\\ Users \\\\ asus \\\\ Desktop \\\\ test_project \\\\ test_project.udb\" # moved_methods = ['getValue', 'rowToJSONArray', 'getVal', ] # moved_fields = ['number_2', 'number_1', ] source_class = \"GodClass\" moved_methods = [ 'method1' , 'method3' ] moved_fields = [ 'field1' , 'field2' ] father_path_file = \"/data/Dev/JavaSample/src/GodClass.java\" father_path_directory = \"/data/Dev/JavaSample/src\" path_to_refactor = \"/data/Dev/JavaSample/src\" new_class_file = \"/data/Dev/JavaSample/src/GodSubClass.java\" # source_class = \"TaskNode\" # moved_methods = ['getUserObject'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\\\\TaskNode.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\\\\TaskNodeextracted.java\" # source_class = \"SecuritySupport\" # moved_methods = ['getSystemProperty'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\\\\SecuritySupport.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\\\\SecuritySupportextracted.java\" # source_class = \"BaseMarkupSerializer\" # moved_methods = ['setOutputCharStream'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\\\\BaseMarkupSerializer.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\\\\BaseMarkupSerializerextracted.java\" # source_class = \"Piece\" # moved_methods = ['setX'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\\\\Piece.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\\\\Pieceextracted.java\" stream = FileStream ( father_path_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = ExtractSubClassRefactoringListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( father_path_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) extractJavaFilesAndProcess ( path_to_refactor , father_path_file , new_class_file ) for file in files_to_refactor : stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = FindUsagesListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory ) # output_path=father_path_directory) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) tmp_aul = my_listener . aul with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # after find usages try : stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = PropagationListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory , aul = tmp_aul ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) except : print ( \"not utf8\" )","title":"Extract subclass"},{"location":"refactorings/extract_subclass/#extract-subclass","text":"","title":"Extract subclass"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass--introduction","text":"Extract subclass refactoring","title":"Introduction"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.ExtractSubClassRefactoringListener","text":"To implement extract subclass refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one","title":"ExtractSubClassRefactoringListener"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.ExtractSubClassRefactoringListener.enterClassDeclaration","text":"It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. Source code in refactorings\\extract_subclass.py def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. \"\"\" class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True self . code += self . NEW_LINE * 2 self . code += f \"// New class( { self . new_class } ) generated by CodART\" + self . NEW_LINE self . code += f \"class { self . new_class } extends { self . source_class }{ self . NEW_LINE } \" + \"{\" + self . NEW_LINE self . code += f \"public { self . new_class } ()\" + \"{ }\" + self . NEW_LINE else : self . is_source_class = False","title":"enterClassDeclaration()"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.ExtractSubClassRefactoringListener.enterMethodDeclaration","text":"It sets the detected field to the method if it is one of the moved methods. Source code in refactorings\\extract_subclass.py def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It sets the detected field to the method if it is one of the moved methods. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if method_identifier in self . moved_methods : self . detected_method = method_identifier","title":"enterMethodDeclaration()"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.ExtractSubClassRefactoringListener.enterVariableDeclaratorId","text":"It sets the detected field to the field if it is one of the moved fields. Source code in refactorings\\extract_subclass.py def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): \"\"\" It sets the detected field to the field if it is one of the moved fields. \"\"\" if not self . is_source_class : return None field_identifier = ctx . IDENTIFIER () . getText () if field_identifier in self . moved_fields : self . detected_field = field_identifier","title":"enterVariableDeclaratorId()"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.ExtractSubClassRefactoringListener.exitClassDeclaration","text":"It closes the opened curly brackets If it is the source class. Source code in refactorings\\extract_subclass.py def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It closes the opened curly brackets If it is the source class. \"\"\" if self . is_source_class : self . code += \"}\" self . is_source_class = False","title":"exitClassDeclaration()"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.ExtractSubClassRefactoringListener.exitCompilationUnit","text":"It writes self.code in the output path. Source code in refactorings\\extract_subclass.py def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): \"\"\" It writes self.code in the output path. \"\"\" child_file_name = self . new_class + \".java\" with open ( os . path . join ( self . output_path , child_file_name ), \"w+\" ) as f : f . write ( self . code . replace ( ' \\r\\n ' , ' \\n ' ))","title":"exitCompilationUnit()"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.ExtractSubClassRefactoringListener.exitFieldDeclaration","text":"It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. Source code in refactorings\\extract_subclass.py def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): \"\"\" It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. \"\"\" if not self . is_source_class : return None field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () field_names = list () field_names . append ( field_identifier ) # print(\"field_names=\", field_names) grand_parent_ctx = ctx . parentCtx . parentCtx if self . detected_field in field_names : if not grand_parent_ctx . modifier (): modifier = \"\" else : modifier = grand_parent_ctx . modifier ( 0 ) . getText () field_type = ctx . typeType () . getText () self . code += f \" { self . TAB }{ modifier } { field_type } { self . detected_field } ; { self . NEW_LINE } \" # delete field from source class ==>new start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . parentCtx . parentCtx . stop . tokenIndex self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_field = None","title":"exitFieldDeclaration()"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.ExtractSubClassRefactoringListener.exitMethodDeclaration","text":"It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. Source code in refactorings\\extract_subclass.py def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if self . detected_method == method_identifier : start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . stop . tokenIndex method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . code += ( self . NEW_LINE + self . TAB + method_text + self . NEW_LINE ) # delete method from source class self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_method = None","title":"exitMethodDeclaration()"},{"location":"refactorings/extract_subclass/#refactorings.extract_subclass.main","text":"it builds the parse tree and walk its corresponding walker so that our overridden methods run. Source code in refactorings\\extract_subclass.py def main (): \"\"\" it builds the parse tree and walk its corresponding walker so that our overridden methods run. \"\"\" # udb_path = \"/home/ali/Desktop/code/TestProject/TestProject.udb\" # udb_path=create_understand_database(\"C:\\\\Users\\\\asus\\\\Desktop\\\\test_project\") # source_class = \"GodClass\" # moved_methods = ['method1', 'method3', ] # moved_fields = ['field1', 'field2', ] udb_path = \"C: \\\\ Users \\\\ asus \\\\ Desktop \\\\ test_project \\\\ test_project.udb\" # moved_methods = ['getValue', 'rowToJSONArray', 'getVal', ] # moved_fields = ['number_2', 'number_1', ] source_class = \"GodClass\" moved_methods = [ 'method1' , 'method3' ] moved_fields = [ 'field1' , 'field2' ] father_path_file = \"/data/Dev/JavaSample/src/GodClass.java\" father_path_directory = \"/data/Dev/JavaSample/src\" path_to_refactor = \"/data/Dev/JavaSample/src\" new_class_file = \"/data/Dev/JavaSample/src/GodSubClass.java\" # source_class = \"TaskNode\" # moved_methods = ['getUserObject'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\\\\TaskNode.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\\\\TaskNodeextracted.java\" # source_class = \"SecuritySupport\" # moved_methods = ['getSystemProperty'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\\\\SecuritySupport.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\\\\SecuritySupportextracted.java\" # source_class = \"BaseMarkupSerializer\" # moved_methods = ['setOutputCharStream'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\\\\BaseMarkupSerializer.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\\\\BaseMarkupSerializerextracted.java\" # source_class = \"Piece\" # moved_methods = ['setX'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\\\\Piece.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\\\\Pieceextracted.java\" stream = FileStream ( father_path_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = ExtractSubClassRefactoringListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( father_path_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) extractJavaFilesAndProcess ( path_to_refactor , father_path_file , new_class_file ) for file in files_to_refactor : stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = FindUsagesListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory ) # output_path=father_path_directory) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) tmp_aul = my_listener . aul with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # after find usages try : stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = PropagationListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory , aul = tmp_aul ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) except : print ( \"not utf8\" )","title":"main()"},{"location":"refactorings/increase_field_visibility/","text":"Increase field visibility Introduction Increase field visibility refactoring Increase the visibility of a field from private to package, package to protected or protected to public. Pre and post-conditions Pre-conditions: User must enter the field's name, and the source class's name for the refactoring in order to increase the target field's visibility. Post-conditions: No specific post-condition IncreaseFieldVisibilityListener To implement \u0650Increase Field Visibility refactoring based on its actors. Detects the required field and increases/changes its visibility status. __init__ ( self , source_class , source_field , rewriter ) special Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_field str Name of the field whose visibility status has to be changed required rewriter TokenStreamRewriter An instance of TokenStreamRewriter required Returns: Type Description object (IncreaseFieldVisibilityListener) An instance of IncreaseFieldVisibilityListener Source code in refactorings\\increase_field_visibility.py def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseFieldVisibilityListener): An instance of IncreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ) Source code in refactorings\\increase_field_visibility.py def main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) fields = db . lookup ( f \" { source_package } . { source_class } . { source_field } \" , \"Variable\" ) if len ( fields ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False field_ent = fields [ 0 ] if field_ent . simplename () != source_field : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not field_ent.kind().check(\"private\"): # logger.error(\"Field is not private.\") # db.close() # return False parent = field_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = str ( parent . longname ()) db . close () parse_and_walk ( file_path = main_file , listener_class = IncreaseFieldVisibilityListener , has_write = True , source_class = source_class , source_field = source_field ) # db.close() return True","title":"Increase field visibility"},{"location":"refactorings/increase_field_visibility/#increase-field-visibility","text":"","title":"Increase field visibility"},{"location":"refactorings/increase_field_visibility/#refactorings.increase_field_visibility--introduction","text":"Increase field visibility refactoring Increase the visibility of a field from private to package, package to protected or protected to public.","title":"Introduction"},{"location":"refactorings/increase_field_visibility/#refactorings.increase_field_visibility--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/increase_field_visibility/#refactorings.increase_field_visibility--pre-conditions","text":"User must enter the field's name, and the source class's name for the refactoring in order to increase the target field's visibility.","title":"Pre-conditions:"},{"location":"refactorings/increase_field_visibility/#refactorings.increase_field_visibility--post-conditions","text":"No specific post-condition","title":"Post-conditions:"},{"location":"refactorings/increase_field_visibility/#refactorings.increase_field_visibility.IncreaseFieldVisibilityListener","text":"To implement \u0650Increase Field Visibility refactoring based on its actors. Detects the required field and increases/changes its visibility status.","title":"IncreaseFieldVisibilityListener"},{"location":"refactorings/increase_field_visibility/#refactorings.increase_field_visibility.IncreaseFieldVisibilityListener.__init__","text":"Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_field str Name of the field whose visibility status has to be changed required rewriter TokenStreamRewriter An instance of TokenStreamRewriter required Returns: Type Description object (IncreaseFieldVisibilityListener) An instance of IncreaseFieldVisibilityListener Source code in refactorings\\increase_field_visibility.py def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseFieldVisibilityListener): An instance of IncreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter","title":"__init__()"},{"location":"refactorings/increase_field_visibility/#refactorings.increase_field_visibility.main","text":"Source code in refactorings\\increase_field_visibility.py def main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) fields = db . lookup ( f \" { source_package } . { source_class } . { source_field } \" , \"Variable\" ) if len ( fields ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False field_ent = fields [ 0 ] if field_ent . simplename () != source_field : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not field_ent.kind().check(\"private\"): # logger.error(\"Field is not private.\") # db.close() # return False parent = field_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = str ( parent . longname ()) db . close () parse_and_walk ( file_path = main_file , listener_class = IncreaseFieldVisibilityListener , has_write = True , source_class = source_class , source_field = source_field ) # db.close() return True","title":"main()"},{"location":"refactorings/increase_method_visibility/","text":"Increase method visibility Introduction Increase method visibility refactoring Increase the visibility of a method from private to package, package to protected or protected to public. Pre and post-conditions Pre-conditions: User must enter the method's name, and the source class's name for the refactoring in order to increase the target method's visibility. Post-conditions: No specific post-condition IncreaseMethodVisibilityListener To implement \u0650Increase Method Visibility refactoring based on its actors. Detects the required method and increases/changes its visibility status. __init__ ( self , source_class , source_method , rewriter ) special Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_method str Name of the field whose visibility status has to be changed required rewriter TokenStreamRewriter An instance of TokenStreamRewriter required Returns: Type Description object (IncreaseMethodVisibilityListener) An instance of IncreaseMethodVisibilityListener Source code in refactorings\\increase_method_visibility.py def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseMethodVisibilityListener): An instance of IncreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ) Source code in refactorings\\increase_method_visibility.py def main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) methods = db . lookup ( f \" { source_package } . { source_class } . { source_method } \" , \"Method\" ) if methods is None or len ( methods ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False method_entity = methods [ 0 ] if method_entity . simplename () != source_method : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not method_entity.kind().check(\"Private\"): # logger.error(\"Method is not private.\") # db.close() # return False parent = method_entity . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () # The file that contain the method db . close () parse_and_walk ( file_path = main_file , listener_class = IncreaseMethodVisibilityListener , has_write = True , source_class = source_class , source_method = source_method ) # db.close() return True","title":"Increase method visibility"},{"location":"refactorings/increase_method_visibility/#increase-method-visibility","text":"","title":"Increase method visibility"},{"location":"refactorings/increase_method_visibility/#refactorings.increase_method_visibility--introduction","text":"Increase method visibility refactoring Increase the visibility of a method from private to package, package to protected or protected to public.","title":"Introduction"},{"location":"refactorings/increase_method_visibility/#refactorings.increase_method_visibility--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/increase_method_visibility/#refactorings.increase_method_visibility--pre-conditions","text":"User must enter the method's name, and the source class's name for the refactoring in order to increase the target method's visibility.","title":"Pre-conditions:"},{"location":"refactorings/increase_method_visibility/#refactorings.increase_method_visibility--post-conditions","text":"No specific post-condition","title":"Post-conditions:"},{"location":"refactorings/increase_method_visibility/#refactorings.increase_method_visibility.IncreaseMethodVisibilityListener","text":"To implement \u0650Increase Method Visibility refactoring based on its actors. Detects the required method and increases/changes its visibility status.","title":"IncreaseMethodVisibilityListener"},{"location":"refactorings/increase_method_visibility/#refactorings.increase_method_visibility.IncreaseMethodVisibilityListener.__init__","text":"Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_method str Name of the field whose visibility status has to be changed required rewriter TokenStreamRewriter An instance of TokenStreamRewriter required Returns: Type Description object (IncreaseMethodVisibilityListener) An instance of IncreaseMethodVisibilityListener Source code in refactorings\\increase_method_visibility.py def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseMethodVisibilityListener): An instance of IncreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter","title":"__init__()"},{"location":"refactorings/increase_method_visibility/#refactorings.increase_method_visibility.main","text":"Source code in refactorings\\increase_method_visibility.py def main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) methods = db . lookup ( f \" { source_package } . { source_class } . { source_method } \" , \"Method\" ) if methods is None or len ( methods ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False method_entity = methods [ 0 ] if method_entity . simplename () != source_method : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not method_entity.kind().check(\"Private\"): # logger.error(\"Method is not private.\") # db.close() # return False parent = method_entity . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () # The file that contain the method db . close () parse_and_walk ( file_path = main_file , listener_class = IncreaseMethodVisibilityListener , has_write = True , source_class = source_class , source_method = source_method ) # db.close() return True","title":"main()"},{"location":"refactorings/inline_class/","text":"Increase method visibility Introduction The script implements inline class refactoring Merge to class into one class InlineClassRefactoringListener To implement inline class refactoring based on its actors. Creates a new class and move fields and methods from two old class to the new one, then delete the two class __init__ ( self , common_token_stream = None , source_class = None , source_class_data = None , target_class = None , target_class_data = None , is_complete = False ) special Source code in refactorings\\inline_class.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , source_class_data : dict = None , target_class : str = None , target_class_data : dict = None , is_complete : bool = False ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if target_class is None : raise ValueError ( \"new_class is None\" ) else : self . target_class = target_class if target_class : self . target_class = target_class if source_class_data : self . source_class_data = source_class_data else : self . source_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} if target_class_data : self . target_class_data = target_class_data else : self . target_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} self . field_that_has_source = [] self . has_source_new = False self . is_complete = is_complete self . is_target_class = False self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\"","title":"Inline class"},{"location":"refactorings/inline_class/#increase-method-visibility","text":"","title":"Increase method visibility"},{"location":"refactorings/inline_class/#refactorings.inline_class--introduction","text":"The script implements inline class refactoring Merge to class into one class","title":"Introduction"},{"location":"refactorings/inline_class/#refactorings.inline_class.InlineClassRefactoringListener","text":"To implement inline class refactoring based on its actors. Creates a new class and move fields and methods from two old class to the new one, then delete the two class","title":"InlineClassRefactoringListener"},{"location":"refactorings/inline_class/#refactorings.inline_class.InlineClassRefactoringListener.__init__","text":"Source code in refactorings\\inline_class.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , source_class_data : dict = None , target_class : str = None , target_class_data : dict = None , is_complete : bool = False ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if target_class is None : raise ValueError ( \"new_class is None\" ) else : self . target_class = target_class if target_class : self . target_class = target_class if source_class_data : self . source_class_data = source_class_data else : self . source_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} if target_class_data : self . target_class_data = target_class_data else : self . target_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} self . field_that_has_source = [] self . has_source_new = False self . is_complete = is_complete self . is_target_class = False self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\"","title":"__init__()"},{"location":"refactorings/make_field_final/","text":"Make field final Introduction Add the \"final\" property / keyword to a field, so that it never changes once it is initialized. Pre and post-conditions Pre-conditions: User must enter the field's name and the name of the source class in order to make it final Check if the field exists, then make it final Post-conditions: The value of this field should never be changed in the project MakeFieldFinalRefactoringListener The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and changes its status to final. __init__ ( self , common_token_stream = None , source_class = None , field_name = None ) special Parameters: Name Type Description Default common_token_stream CommonTokenStream A stream of tokens generated by parsing the main file using the ANTLR parser generator. None source_class str Name of the class in which the refactoring has to be done. None field_name str Name of the field whose final status has to be changed. None Returns: Type Description object (MakeFieldFinalRefactoringListener) An instance of MakeFieldFinalRefactoringListener. Source code in refactorings\\make_field_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using \\ the ANTLR parser generator. source_class (str): Name of the class in which the refactoring has to be done. field_name (str): Name of the field whose final status has to be changed. Returns: object (MakeFieldFinalRefactoringListener): An instance of MakeFieldFinalRefactoringListener. \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"Make field final"},{"location":"refactorings/make_field_final/#make-field-final","text":"","title":"Make field final"},{"location":"refactorings/make_field_final/#refactorings.make_field_final--introduction","text":"Add the \"final\" property / keyword to a field, so that it never changes once it is initialized.","title":"Introduction"},{"location":"refactorings/make_field_final/#refactorings.make_field_final--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_field_final/#refactorings.make_field_final--pre-conditions","text":"User must enter the field's name and the name of the source class in order to make it final Check if the field exists, then make it final","title":"Pre-conditions:"},{"location":"refactorings/make_field_final/#refactorings.make_field_final--post-conditions","text":"The value of this field should never be changed in the project","title":"Post-conditions:"},{"location":"refactorings/make_field_final/#refactorings.make_field_final.MakeFieldFinalRefactoringListener","text":"The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and changes its status to final.","title":"MakeFieldFinalRefactoringListener"},{"location":"refactorings/make_field_final/#refactorings.make_field_final.MakeFieldFinalRefactoringListener.__init__","text":"Parameters: Name Type Description Default common_token_stream CommonTokenStream A stream of tokens generated by parsing the main file using the ANTLR parser generator. None source_class str Name of the class in which the refactoring has to be done. None field_name str Name of the field whose final status has to be changed. None Returns: Type Description object (MakeFieldFinalRefactoringListener) An instance of MakeFieldFinalRefactoringListener. Source code in refactorings\\make_field_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using \\ the ANTLR parser generator. source_class (str): Name of the class in which the refactoring has to be done. field_name (str): Name of the field whose final status has to be changed. Returns: object (MakeFieldFinalRefactoringListener): An instance of MakeFieldFinalRefactoringListener. \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"__init__()"},{"location":"refactorings/make_field_non_final/","text":"Make field non-final Introduction Remove the \"final\" property from a field, so that it can be changed after initialization. Pre and post-conditions Pre-conditions: User must enter the field's name and the name of the source class in order to make it non-final Check if the field exists, then make it non-final Post-conditions: No specific Post Condition MakeFieldNonFinalRefactoringListener The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and removes the \"final\" keyword from its properties. __init__ ( self , common_token_stream = None , source_class = None , field_name = None ) special Parameters: Name Type Description Default common_token_stream CommonTokenStream A stream of tokens generated by parsing the main file using the ANTLR parser generator None source_class str Name of the class in which the refactoring has to be done None field_name str Name of the field whose final status has to be changed None Returns: Type Description object (MakeFieldNonFinalRefactoringListener) An instance of MakeFieldNonFinalRefactoringListener Source code in refactorings\\make_field_non_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using the ANTLR parser generator source_class (str): Name of the class in which the refactoring has to be done field_name (str):Name of the field whose final status has to be changed Returns: object (MakeFieldNonFinalRefactoringListener): An instance of MakeFieldNonFinalRefactoringListener \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"Make field non-final"},{"location":"refactorings/make_field_non_final/#make-field-non-final","text":"","title":"Make field non-final"},{"location":"refactorings/make_field_non_final/#refactorings.make_field_non_final--introduction","text":"Remove the \"final\" property from a field, so that it can be changed after initialization.","title":"Introduction"},{"location":"refactorings/make_field_non_final/#refactorings.make_field_non_final--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_field_non_final/#refactorings.make_field_non_final--pre-conditions","text":"User must enter the field's name and the name of the source class in order to make it non-final Check if the field exists, then make it non-final","title":"Pre-conditions:"},{"location":"refactorings/make_field_non_final/#refactorings.make_field_non_final--post-conditions","text":"No specific Post Condition","title":"Post-conditions:"},{"location":"refactorings/make_field_non_final/#refactorings.make_field_non_final.MakeFieldNonFinalRefactoringListener","text":"The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and removes the \"final\" keyword from its properties.","title":"MakeFieldNonFinalRefactoringListener"},{"location":"refactorings/make_field_non_final/#refactorings.make_field_non_final.MakeFieldNonFinalRefactoringListener.__init__","text":"Parameters: Name Type Description Default common_token_stream CommonTokenStream A stream of tokens generated by parsing the main file using the ANTLR parser generator None source_class str Name of the class in which the refactoring has to be done None field_name str Name of the field whose final status has to be changed None Returns: Type Description object (MakeFieldNonFinalRefactoringListener) An instance of MakeFieldNonFinalRefactoringListener Source code in refactorings\\make_field_non_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using the ANTLR parser generator source_class (str): Name of the class in which the refactoring has to be done field_name (str):Name of the field whose final status has to be changed Returns: object (MakeFieldNonFinalRefactoringListener): An instance of MakeFieldNonFinalRefactoringListener \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"__init__()"},{"location":"refactorings/make_field_non_static/","text":"Make field non-static Introduction Make static field non-static refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeFieldNonStaticRefactoringListener To implement Make static field non-static refactoring operation based on its actors. __init__ ( self , common_token_stream = None , source_class = None , field_name = None ) special Source code in refactorings\\make_field_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False main ( udb_path , source_class , field_name , * args , ** kwargs ) Main API for make field non-static Source code in refactorings\\make_field_non_static.py def main ( udb_path , source_class , field_name , * args , ** kwargs ): \"\"\" Main API for make field non-static \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeFieldNonStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , field_name = field_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"Make field non-static"},{"location":"refactorings/make_field_non_static/#make-field-non-static","text":"","title":"Make field non-static"},{"location":"refactorings/make_field_non_static/#refactorings.make_field_non_static--introduction","text":"Make static field non-static refactoring operation","title":"Introduction"},{"location":"refactorings/make_field_non_static/#refactorings.make_field_non_static--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_field_non_static/#refactorings.make_field_non_static--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_field_non_static/#refactorings.make_field_non_static--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_field_non_static/#refactorings.make_field_non_static.MakeFieldNonStaticRefactoringListener","text":"To implement Make static field non-static refactoring operation based on its actors.","title":"MakeFieldNonStaticRefactoringListener"},{"location":"refactorings/make_field_non_static/#refactorings.make_field_non_static.MakeFieldNonStaticRefactoringListener.__init__","text":"Source code in refactorings\\make_field_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_field_non_static/#refactorings.make_field_non_static.main","text":"Main API for make field non-static Source code in refactorings\\make_field_non_static.py def main ( udb_path , source_class , field_name , * args , ** kwargs ): \"\"\" Main API for make field non-static \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeFieldNonStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , field_name = field_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_field_static/","text":"Make field static Introduction Make static field static refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeFieldStaticRefactoringListener To implement make field static refactoring based on its actors. __init__ ( self , common_token_stream = None , source_class = None , field_name = None ) special Source code in refactorings\\make_field_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False main ( udb_path , source_class , field_name , * args , ** kwargs ) The main API for make field static Source code in refactorings\\make_field_static.py def main ( udb_path , source_class , field_name , * args , ** kwargs ): \"\"\" The main API for make field static \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeFieldStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , field_name = field_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"Make field static"},{"location":"refactorings/make_field_static/#make-field-static","text":"","title":"Make field static"},{"location":"refactorings/make_field_static/#refactorings.make_field_static--introduction","text":"Make static field static refactoring operation","title":"Introduction"},{"location":"refactorings/make_field_static/#refactorings.make_field_static--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_field_static/#refactorings.make_field_static--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_field_static/#refactorings.make_field_static--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_field_static/#refactorings.make_field_static.MakeFieldStaticRefactoringListener","text":"To implement make field static refactoring based on its actors.","title":"MakeFieldStaticRefactoringListener"},{"location":"refactorings/make_field_static/#refactorings.make_field_static.MakeFieldStaticRefactoringListener.__init__","text":"Source code in refactorings\\make_field_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_field_static/#refactorings.make_field_static.main","text":"The main API for make field static Source code in refactorings\\make_field_static.py def main ( udb_path , source_class , field_name , * args , ** kwargs ): \"\"\" The main API for make field static \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeFieldStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , field_name = field_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_method_final/","text":"Make method final Introduction Make method final refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodFinalRefactoringListener To implement Make method final refactoring based on its actors. __init__ ( self , common_token_stream = None , source_class = None , method_name = None ) special Source code in refactorings\\make_method_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"Make method final"},{"location":"refactorings/make_method_final/#make-method-final","text":"","title":"Make method final"},{"location":"refactorings/make_method_final/#refactorings.make_method_final--introduction","text":"Make method final refactoring operation","title":"Introduction"},{"location":"refactorings/make_method_final/#refactorings.make_method_final--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_final/#refactorings.make_method_final--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_final/#refactorings.make_method_final--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_final/#refactorings.make_method_final.MakeMethodFinalRefactoringListener","text":"To implement Make method final refactoring based on its actors.","title":"MakeMethodFinalRefactoringListener"},{"location":"refactorings/make_method_final/#refactorings.make_method_final.MakeMethodFinalRefactoringListener.__init__","text":"Source code in refactorings\\make_method_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_method_non_final/","text":"Make method non-final Introduction Make method non-final refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodNonFinalRefactoringListener To implement Make Method Non-Final refactoring based on its actors. __init__ ( self , common_token_stream = None , source_class = None , method_name = None ) special Source code in refactorings\\make_method_non_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"Make method non-final"},{"location":"refactorings/make_method_non_final/#make-method-non-final","text":"","title":"Make method non-final"},{"location":"refactorings/make_method_non_final/#refactorings.make_method_non_final--introduction","text":"Make method non-final refactoring operation","title":"Introduction"},{"location":"refactorings/make_method_non_final/#refactorings.make_method_non_final--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_non_final/#refactorings.make_method_non_final--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_non_final/#refactorings.make_method_non_final--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_non_final/#refactorings.make_method_non_final.MakeMethodNonFinalRefactoringListener","text":"To implement Make Method Non-Final refactoring based on its actors.","title":"MakeMethodNonFinalRefactoringListener"},{"location":"refactorings/make_method_non_final/#refactorings.make_method_non_final.MakeMethodNonFinalRefactoringListener.__init__","text":"Source code in refactorings\\make_method_non_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"__init__()"},{"location":"refactorings/make_method_non_static/","text":"Make method non-static Introduction The module implements make method non-static refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodNonStaticRefactoringListener To implement Make Method None-Static refactoring based on its actors. __init__ ( self , common_token_stream = None , target_class = None , target_methods = None ) special Source code in refactorings\\make_method_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" main ( udb_path , target_class , target_methods ) Source code in refactorings\\make_method_non_static.py def main ( udb_path , target_class , target_methods ): \"\"\" \"\"\" main_file = None db = understand . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == target_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , target_class = target_class , target_methods = target_methods ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True Introduction The module implements a light-weight version of make method non-static refactoring operation described in make_method_non_static . Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodNonStaticRefactoringListener To implement Make Method Non-Static refactoring based on its actors (version 2). __init__ ( self , common_token_stream = None , source_class = None , method_name = None ) special Source code in refactorings\\make_method_non_static2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False main ( udb_path = None , source_class = None , method_name = None , * args , ** kwargs ) Source code in refactorings\\make_method_non_static2.py def main ( udb_path = None , source_class = None , method_name = None , * args , ** kwargs ): \"\"\" \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . parent () is not None : if cls . simplename () == source_class : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , method_name = method_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"Make method non-static"},{"location":"refactorings/make_method_non_static/#make-method-non-static","text":"","title":"Make method non-static"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static--introduction","text":"The module implements make method non-static refactoring operation","title":"Introduction"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static.MakeMethodNonStaticRefactoringListener","text":"To implement Make Method None-Static refactoring based on its actors.","title":"MakeMethodNonStaticRefactoringListener"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static.MakeMethodNonStaticRefactoringListener.__init__","text":"Source code in refactorings\\make_method_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\"","title":"__init__()"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static.main","text":"Source code in refactorings\\make_method_non_static.py def main ( udb_path , target_class , target_methods ): \"\"\" \"\"\" main_file = None db = understand . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == target_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , target_class = target_class , target_methods = target_methods ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static2--introduction","text":"The module implements a light-weight version of make method non-static refactoring operation described in make_method_non_static .","title":"Introduction"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static2--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static2.MakeMethodNonStaticRefactoringListener","text":"To implement Make Method Non-Static refactoring based on its actors (version 2).","title":"MakeMethodNonStaticRefactoringListener"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static2.MakeMethodNonStaticRefactoringListener.__init__","text":"Source code in refactorings\\make_method_non_static2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_method_non_static/#refactorings.make_method_non_static2.main","text":"Source code in refactorings\\make_method_non_static2.py def main ( udb_path = None , source_class = None , method_name = None , * args , ** kwargs ): \"\"\" \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . parent () is not None : if cls . simplename () == source_class : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , method_name = method_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_method_static/","text":"Make method static Introduction The module implements make method non-static refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodNonStaticRefactoringListener To implement Make Method None-Static refactoring based on its actors. __init__ ( self , common_token_stream = None , target_class = None , target_methods = None ) special Source code in refactorings\\make_method_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" main ( udb_path , target_class , target_methods ) Source code in refactorings\\make_method_non_static.py def main ( udb_path , target_class , target_methods ): \"\"\" \"\"\" main_file = None db = understand . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == target_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , target_class = target_class , target_methods = target_methods ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True Make method static 2 Introduction The module implements a light-weight version of make method static refactoring operation described in make_method_static . Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodStaticRefactoringListener To implement make method static (version 2). __init__ ( self , common_token_stream = None , source_class = None , method_name = None ) special Source code in refactorings\\make_method_static2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False main ( udb_path , source_class , method_name , * args , ** kwargs ) Source code in refactorings\\make_method_static2.py def main ( udb_path , source_class , method_name , * args , ** kwargs ): \"\"\" \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , method_name = method_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf-8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"Make method static"},{"location":"refactorings/make_method_static/#make-method-static","text":"","title":"Make method static"},{"location":"refactorings/make_method_static/#refactorings.make_method_non_static--introduction","text":"The module implements make method non-static refactoring operation","title":"Introduction"},{"location":"refactorings/make_method_static/#refactorings.make_method_non_static--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_static/#refactorings.make_method_non_static--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_static/#refactorings.make_method_non_static--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_static/#refactorings.make_method_non_static.MakeMethodNonStaticRefactoringListener","text":"To implement Make Method None-Static refactoring based on its actors.","title":"MakeMethodNonStaticRefactoringListener"},{"location":"refactorings/make_method_static/#refactorings.make_method_non_static.MakeMethodNonStaticRefactoringListener.__init__","text":"Source code in refactorings\\make_method_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\"","title":"__init__()"},{"location":"refactorings/make_method_static/#refactorings.make_method_non_static.main","text":"Source code in refactorings\\make_method_non_static.py def main ( udb_path , target_class , target_methods ): \"\"\" \"\"\" main_file = None db = understand . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == target_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , target_class = target_class , target_methods = target_methods ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_method_static/#make-method-static-2","text":"","title":"Make method static 2"},{"location":"refactorings/make_method_static/#refactorings.make_method_static2--introduction","text":"The module implements a light-weight version of make method static refactoring operation described in make_method_static .","title":"Introduction"},{"location":"refactorings/make_method_static/#refactorings.make_method_static2--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_static/#refactorings.make_method_static2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_static/#refactorings.make_method_static2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_static/#refactorings.make_method_static2.MakeMethodStaticRefactoringListener","text":"To implement make method static (version 2).","title":"MakeMethodStaticRefactoringListener"},{"location":"refactorings/make_method_static/#refactorings.make_method_static2.MakeMethodStaticRefactoringListener.__init__","text":"Source code in refactorings\\make_method_static2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_method_static/#refactorings.make_method_static2.main","text":"Source code in refactorings\\make_method_static2.py def main ( udb_path , source_class , method_name , * args , ** kwargs ): \"\"\" \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , method_name = method_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf-8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/move_class/","text":"Move class Introduction The module implements Move Class refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MoveClassAPI __init__ ( self , udb_path , source_package , target_package , class_name ) special Source code in refactorings\\move_class.py def __init__ ( self , udb_path : str , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . udb_path = udb_path self . source_package = source_package self . target_package = target_package self . class_name = class_name self . source_package_dir = None self . target_package_dir = None self . _class_current_path = None self . class_content = None self . usages = None self . _class_new_path = None UpdateImportsListener __init__ ( self , rewriter , source_package , target_package , class_name ) special Source code in refactorings\\move_class.py def __init__ ( self , rewriter : TokenStreamRewriter , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . rewriter = rewriter self . source_package = source_package self . target_package = target_package self . class_name = class_name self . current_package = None self . imported = False self . import_loc = None main ( udb_path , source_package , target_package , class_name , * args , ** kwargs ) The main API for Move Class refactoring Source code in refactorings\\move_class.py def main ( udb_path : str , source_package : str , target_package : str , class_name : str , * args , ** kwargs ): \"\"\" The main API for Move Class refactoring \"\"\" move_class = MoveClassAPI ( udb_path , source_package , target_package , class_name ) res = move_class . do_refactor () return res","title":"Move class"},{"location":"refactorings/move_class/#move-class","text":"","title":"Move class"},{"location":"refactorings/move_class/#refactorings.move_class--introduction","text":"The module implements Move Class refactoring operation","title":"Introduction"},{"location":"refactorings/move_class/#refactorings.move_class--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/move_class/#refactorings.move_class--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/move_class/#refactorings.move_class--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/move_class/#refactorings.move_class.MoveClassAPI","text":"","title":"MoveClassAPI"},{"location":"refactorings/move_class/#refactorings.move_class.MoveClassAPI.__init__","text":"Source code in refactorings\\move_class.py def __init__ ( self , udb_path : str , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . udb_path = udb_path self . source_package = source_package self . target_package = target_package self . class_name = class_name self . source_package_dir = None self . target_package_dir = None self . _class_current_path = None self . class_content = None self . usages = None self . _class_new_path = None","title":"__init__()"},{"location":"refactorings/move_class/#refactorings.move_class.UpdateImportsListener","text":"","title":"UpdateImportsListener"},{"location":"refactorings/move_class/#refactorings.move_class.UpdateImportsListener.__init__","text":"Source code in refactorings\\move_class.py def __init__ ( self , rewriter : TokenStreamRewriter , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . rewriter = rewriter self . source_package = source_package self . target_package = target_package self . class_name = class_name self . current_package = None self . imported = False self . import_loc = None","title":"__init__()"},{"location":"refactorings/move_class/#refactorings.move_class.main","text":"The main API for Move Class refactoring Source code in refactorings\\move_class.py def main ( udb_path : str , source_package : str , target_package : str , class_name : str , * args , ** kwargs ): \"\"\" The main API for Move Class refactoring \"\"\" move_class = MoveClassAPI ( udb_path , source_package , target_package , class_name ) res = move_class . do_refactor () return res","title":"main()"},{"location":"refactorings/move_field/","text":"Move field Introduction The module implements Move Field refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions CutFieldListener __init__ ( self , class_name , instance_name , field_name , is_static , import_statement , rewriter ) special Source code in refactorings\\move_field.py def __init__ ( self , class_name : str , instance_name : str , field_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . field_name = field_name self . is_static = is_static self . import_statement = import_statement self . rewriter = rewriter self . instance_name = instance_name self . instance_name = class_name . lower () + \"ByCodArt\" self . is_member = False self . do_delete = False self . field_text = \"\" main ( source_class , source_package , target_class , target_package , field_name , udb_path , * args , ** kwargs ) Source code in refactorings\\move_field.py def main ( source_class : str , source_package : str , target_class : str , target_package : str , field_name : str , udb_path : str , * args , ** kwargs ): \"\"\" \"\"\" import_statement = None if source_package != target_package : import_statement = f \" \\n import { target_package } . { target_class } ;\" instance_name = target_class . lower () + \"ByCodArt\" db = und . open ( udb_path ) # Check if field is static field_ent = db . lookup ( f \" { source_package } . { source_class } . { field_name } \" , \"Variable\" ) if len ( field_ent ) == 0 : logger . error ( f \"Entity not found with query: { source_package } . { source_class } . { field_name } .\" ) db . close () return False if source_package == target_package and source_class == target_class : logger . error ( \"Can not move to self.\" ) db . close () return False field_ent = field_ent [ 0 ] is_static = field_ent . kindname () == STATIC if is_static : logger . warning ( \"Field is static!\" ) # Find usages usages = {} for ref in field_ent . refs ( \"Setby,Useby\" ): file = ref . file () . longname () if file in usages : usages [ file ] . append ( ref . line ()) else : usages [ file ] = [ ref . line (), ] try : src_class_file = db . lookup ( f \" { source_package } . { source_class } .java\" )[ 0 ] . longname () target_class_file = db . lookup ( f \" { target_package } . { target_class } .java\" )[ 0 ] . longname () except IndexError : logger . error ( \"This is a nested class.\" ) logger . info ( f \" { source_package } . { source_class } .java\" ) logger . info ( f \" { target_package } . { target_class } .java\" ) db . close () return False db . close () # Check if there is an cycle listener = parse_and_walk ( file_path = target_class_file , listener_class = CheckCycleListener , class_name = source_class , ) if not listener . is_valid : logger . error ( f \"Can not move field because there is a cycle between { source_class } , { target_class } \" ) # db.close() return False # Propagate Changes for file in usages . keys (): parse_and_walk ( file_path = file , listener_class = PropagateListener , has_write = True , field_name = field_name , new_name = f \" { instance_name } . { field_name } \" , lines = usages [ file ], ) # Do the cut and paste! # Cut listener = parse_and_walk ( file_path = src_class_file , listener_class = CutFieldListener , has_write = True , class_name = target_class , instance_name = instance_name , field_name = field_name , is_static = is_static , import_statement = import_statement ) field_text = listener . field_text # Paste parse_and_walk ( file_path = target_class_file , listener_class = PasteFieldListener , has_write = True , field_text = field_text , ) # db.close() return True","title":"Mode field"},{"location":"refactorings/move_field/#move-field","text":"","title":"Move field"},{"location":"refactorings/move_field/#refactorings.move_field--introduction","text":"The module implements Move Field refactoring operation","title":"Introduction"},{"location":"refactorings/move_field/#refactorings.move_field--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/move_field/#refactorings.move_field--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/move_field/#refactorings.move_field--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/move_field/#refactorings.move_field.CutFieldListener","text":"","title":"CutFieldListener"},{"location":"refactorings/move_field/#refactorings.move_field.CutFieldListener.__init__","text":"Source code in refactorings\\move_field.py def __init__ ( self , class_name : str , instance_name : str , field_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . field_name = field_name self . is_static = is_static self . import_statement = import_statement self . rewriter = rewriter self . instance_name = instance_name self . instance_name = class_name . lower () + \"ByCodArt\" self . is_member = False self . do_delete = False self . field_text = \"\"","title":"__init__()"},{"location":"refactorings/move_field/#refactorings.move_field.main","text":"Source code in refactorings\\move_field.py def main ( source_class : str , source_package : str , target_class : str , target_package : str , field_name : str , udb_path : str , * args , ** kwargs ): \"\"\" \"\"\" import_statement = None if source_package != target_package : import_statement = f \" \\n import { target_package } . { target_class } ;\" instance_name = target_class . lower () + \"ByCodArt\" db = und . open ( udb_path ) # Check if field is static field_ent = db . lookup ( f \" { source_package } . { source_class } . { field_name } \" , \"Variable\" ) if len ( field_ent ) == 0 : logger . error ( f \"Entity not found with query: { source_package } . { source_class } . { field_name } .\" ) db . close () return False if source_package == target_package and source_class == target_class : logger . error ( \"Can not move to self.\" ) db . close () return False field_ent = field_ent [ 0 ] is_static = field_ent . kindname () == STATIC if is_static : logger . warning ( \"Field is static!\" ) # Find usages usages = {} for ref in field_ent . refs ( \"Setby,Useby\" ): file = ref . file () . longname () if file in usages : usages [ file ] . append ( ref . line ()) else : usages [ file ] = [ ref . line (), ] try : src_class_file = db . lookup ( f \" { source_package } . { source_class } .java\" )[ 0 ] . longname () target_class_file = db . lookup ( f \" { target_package } . { target_class } .java\" )[ 0 ] . longname () except IndexError : logger . error ( \"This is a nested class.\" ) logger . info ( f \" { source_package } . { source_class } .java\" ) logger . info ( f \" { target_package } . { target_class } .java\" ) db . close () return False db . close () # Check if there is an cycle listener = parse_and_walk ( file_path = target_class_file , listener_class = CheckCycleListener , class_name = source_class , ) if not listener . is_valid : logger . error ( f \"Can not move field because there is a cycle between { source_class } , { target_class } \" ) # db.close() return False # Propagate Changes for file in usages . keys (): parse_and_walk ( file_path = file , listener_class = PropagateListener , has_write = True , field_name = field_name , new_name = f \" { instance_name } . { field_name } \" , lines = usages [ file ], ) # Do the cut and paste! # Cut listener = parse_and_walk ( file_path = src_class_file , listener_class = CutFieldListener , has_write = True , class_name = target_class , instance_name = instance_name , field_name = field_name , is_static = is_static , import_statement = import_statement ) field_text = listener . field_text # Paste parse_and_walk ( file_path = target_class_file , listener_class = PasteFieldListener , has_write = True , field_text = field_text , ) # db.close() return True","title":"main()"},{"location":"refactorings/move_method/","text":"Move method Introduction The module implements Move Method refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions CutMethodListener __init__ ( self , class_name , instance_name , method_name , is_static , import_statement , rewriter ) special Source code in refactorings\\move_method.py def __init__ ( self , class_name : str , instance_name : str , method_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . method_name = method_name self . is_static = is_static self . rewriter = rewriter self . import_statement = import_statement self . instance_name = instance_name self . is_member = False self . do_delete = False self . method_text = \"\" self . imports = \"\" main ( source_class , source_package , target_class , target_package , method_name , udb_path , * args , ** kwargs ) Source code in refactorings\\move_method.py def main ( source_class : str , source_package : str , target_class : str , target_package : str , method_name : str , udb_path : str , * args , ** kwargs ): \"\"\" \"\"\" import_statement = None if source_package != target_package : import_statement = f \" \\n import { target_package } . { target_class } ;\" instance_name = target_class . lower () + \"ByCodArt\" db = und . open ( udb_path ) method_map , class_ent = get_source_class_map ( db , source_class ) if class_ent is None : logger . error ( \"Class entity is None\" ) return False # Strong overlay precondition # if class_ent.refs(\"Extend ~Implicit, ExtendBy, Implement\"): # logger.error(\"Class is in inheritance or implements an interface.\") # db.close() # return False # Check if method is static method_ent = db . lookup ( f \" { source_package } . { source_class } . { method_name } \" , \"Method\" ) if len ( method_ent ) >= 1 : method_ent = method_ent [ 0 ] else : logger . error ( \"Entity not found.\" ) db . close () return False if method_ent . simplename () != method_name : logger . error ( \"Can not move method duo to duplicated entities.\" ) logger . info ( f \" { method_ent } , { method_ent . kindname () } \" ) db . close () return False if source_package == target_package and source_class == target_class : logger . error ( \"Can not move to self.\" ) db . close () return False is_static = STATIC in method_ent . kindname () # Find usages usages = {} for ref in method_ent . refs ( \"Callby\" ): file = ref . file () . longname () if file in usages : usages [ file ] . append ( ref . line ()) else : usages [ file ] = [ ref . line (), ] try : src_class_file = db . lookup ( f \" { source_package } . { source_class } .java\" , \"File\" )[ 0 ] . longname () target_class_file = db . lookup ( f \" { target_package } . { target_class } .java\" , \"File\" )[ 0 ] . longname () except IndexError : logger . error ( \"This is a nested method.\" ) logger . info ( f \" { source_package } . { source_class } .java\" ) logger . info ( f \" { target_package } . { target_class } .java\" ) db . close () return False db . close () # Check if there is an cycle listener = parse_and_walk ( file_path = target_class_file , listener_class = CheckCycleListener , class_name = source_class ) if not listener . is_valid : logger . error ( f \"Can not move method because there is a cycle between { source_class } , { target_class } \" ) # db.close() return False # Propagate Changes for file in usages . keys (): public_class_name = os . path . basename ( file ) . split ( \".\" )[ 0 ] is_in_target_class = public_class_name == target_class parse_and_walk ( file_path = file , listener_class = PropagateListener , has_write = True , method_name = method_name , new_name = f \" { instance_name } . { method_name } \" , lines = usages [ file ], is_in_target_class = is_in_target_class , method_map = method_map , ) # exit(-1) # Do the cut and paste! # Cut listener = parse_and_walk ( file_path = src_class_file , listener_class = CutMethodListener , has_write = True , class_name = target_class , instance_name = instance_name , method_name = method_name , is_static = is_static , import_statement = import_statement , ) method_text = listener . method_text # Paste listener = parse_and_walk ( file_path = target_class_file , listener_class = PasteMethodListener , has_write = True , method_text = method_text , source_class = source_class , method_map = method_map , imports = listener . imports , ) # Post-Paste: Reference Injection parse_and_walk ( file_path = target_class_file , listener_class = ReferenceInjectorAndConstructorListener , has_write = True , method_text = method_text , source_class = source_class , method_map = method_map , imports = None , has_empty_cons = listener . has_empty_cons , ) # db.close() return True","title":"Move method"},{"location":"refactorings/move_method/#move-method","text":"","title":"Move method"},{"location":"refactorings/move_method/#refactorings.move_method--introduction","text":"The module implements Move Method refactoring operation","title":"Introduction"},{"location":"refactorings/move_method/#refactorings.move_method--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/move_method/#refactorings.move_method--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/move_method/#refactorings.move_method--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/move_method/#refactorings.move_method.CutMethodListener","text":"","title":"CutMethodListener"},{"location":"refactorings/move_method/#refactorings.move_method.CutMethodListener.__init__","text":"Source code in refactorings\\move_method.py def __init__ ( self , class_name : str , instance_name : str , method_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . method_name = method_name self . is_static = is_static self . rewriter = rewriter self . import_statement = import_statement self . instance_name = instance_name self . is_member = False self . do_delete = False self . method_text = \"\" self . imports = \"\"","title":"__init__()"},{"location":"refactorings/move_method/#refactorings.move_method.main","text":"Source code in refactorings\\move_method.py def main ( source_class : str , source_package : str , target_class : str , target_package : str , method_name : str , udb_path : str , * args , ** kwargs ): \"\"\" \"\"\" import_statement = None if source_package != target_package : import_statement = f \" \\n import { target_package } . { target_class } ;\" instance_name = target_class . lower () + \"ByCodArt\" db = und . open ( udb_path ) method_map , class_ent = get_source_class_map ( db , source_class ) if class_ent is None : logger . error ( \"Class entity is None\" ) return False # Strong overlay precondition # if class_ent.refs(\"Extend ~Implicit, ExtendBy, Implement\"): # logger.error(\"Class is in inheritance or implements an interface.\") # db.close() # return False # Check if method is static method_ent = db . lookup ( f \" { source_package } . { source_class } . { method_name } \" , \"Method\" ) if len ( method_ent ) >= 1 : method_ent = method_ent [ 0 ] else : logger . error ( \"Entity not found.\" ) db . close () return False if method_ent . simplename () != method_name : logger . error ( \"Can not move method duo to duplicated entities.\" ) logger . info ( f \" { method_ent } , { method_ent . kindname () } \" ) db . close () return False if source_package == target_package and source_class == target_class : logger . error ( \"Can not move to self.\" ) db . close () return False is_static = STATIC in method_ent . kindname () # Find usages usages = {} for ref in method_ent . refs ( \"Callby\" ): file = ref . file () . longname () if file in usages : usages [ file ] . append ( ref . line ()) else : usages [ file ] = [ ref . line (), ] try : src_class_file = db . lookup ( f \" { source_package } . { source_class } .java\" , \"File\" )[ 0 ] . longname () target_class_file = db . lookup ( f \" { target_package } . { target_class } .java\" , \"File\" )[ 0 ] . longname () except IndexError : logger . error ( \"This is a nested method.\" ) logger . info ( f \" { source_package } . { source_class } .java\" ) logger . info ( f \" { target_package } . { target_class } .java\" ) db . close () return False db . close () # Check if there is an cycle listener = parse_and_walk ( file_path = target_class_file , listener_class = CheckCycleListener , class_name = source_class ) if not listener . is_valid : logger . error ( f \"Can not move method because there is a cycle between { source_class } , { target_class } \" ) # db.close() return False # Propagate Changes for file in usages . keys (): public_class_name = os . path . basename ( file ) . split ( \".\" )[ 0 ] is_in_target_class = public_class_name == target_class parse_and_walk ( file_path = file , listener_class = PropagateListener , has_write = True , method_name = method_name , new_name = f \" { instance_name } . { method_name } \" , lines = usages [ file ], is_in_target_class = is_in_target_class , method_map = method_map , ) # exit(-1) # Do the cut and paste! # Cut listener = parse_and_walk ( file_path = src_class_file , listener_class = CutMethodListener , has_write = True , class_name = target_class , instance_name = instance_name , method_name = method_name , is_static = is_static , import_statement = import_statement , ) method_text = listener . method_text # Paste listener = parse_and_walk ( file_path = target_class_file , listener_class = PasteMethodListener , has_write = True , method_text = method_text , source_class = source_class , method_map = method_map , imports = listener . imports , ) # Post-Paste: Reference Injection parse_and_walk ( file_path = target_class_file , listener_class = ReferenceInjectorAndConstructorListener , has_write = True , method_text = method_text , source_class = source_class , method_map = method_map , imports = None , has_empty_cons = listener . has_empty_cons , ) # db.close() return True","title":"main()"},{"location":"refactorings/pull_up_constructor/","text":"Pull-up constructor Introduction When subclasses grow and get developed separately, your code may have constructors that perform similar work. Pull up constructor refactoring removes the repetitive method from subclasses and moves it to a superclass. Pre and post-conditions Pre-conditions: The source package, class and constructor should exist. The order of the params in the constructor should be equal in the child classes. empty package name is addressable using \"\". Post Conditions: No specific post-condition PullUpConstructorListener __init__ ( self , rewriter , is_father , class_name , has_father_con , common_sets , params ) special Source code in refactorings\\pullup_constructor.py def __init__ ( self , rewriter : TokenStreamRewriter , is_father : bool , class_name : str , has_father_con : bool , common_sets : [], params : str ): \"\"\" \"\"\" self . rewriter = rewriter self . is_father = is_father self . has_father_con = has_father_con self . class_name = class_name self . common_sets = common_sets self . params = params self . in_con = False self . delete = False get_cons ( program , packagename , superclassname , class_name ) A function to complete the Pull-up constructor refactoring by finding all the classes with similar constructors. Source code in refactorings\\pullup_constructor.py def get_cons ( program : Program , packagename : str , superclassname : str , class_name : str ): \"\"\" A function to complete the Pull-up constructor refactoring by finding all the classes with similar constructors. \"\"\" extendedclass = [] removemethods = {} removemethods1 = [] removemethods3 = {} mets = program . packages [ packagename ] . classes [ class_name ] . methods met = [] methodkey = \"\" for methodName , method in mets . items (): if method . is_constructor : met = method methodkey = methodName break body_text_method = met . body_text parammethod = met . parameters for package_name in program . packages : package = program . packages [ package_name ] for class_ in package . classes : _class = package . classes [ class_ ] if _class . superclass_name == superclassname : extendedclass . append ( _class ) i = 0 for d in extendedclass : class_ = extendedclass [ i ] i = i + 1 for mk in class_ . methods : m_ = class_ . methods [ mk ] m = mk [: mk . find ( '(' )] if m_ . body_text == body_text_method and m_ . parameters == parammethod and m_ . is_constructor == True : if class_ . name not in removemethods : removemethods [ class_ . name ] = [ methodkey ] else : removemethods [ class_ . name ] . append ( methodkey ) elif m_ . is_constructor == True : listBody_text = body_text_method . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . split ( \";\" ) listm_body = m_ . body_text . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . split ( \";\" ) s1 = set ( listBody_text ) s2 = set ( listm_body ) if s2 . issubset ( s1 ): removemethods1 . append ( diff_lists ( listBody_text , listm_body )) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) elif s1 . issubset ( s2 ): removemethods1 . append ( diff_lists ( listm_body , listBody_text )) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) else : a = diff_lists ( listBody_text , listm_body ) if class_ . name not in removemethods3 : removemethods3 [ class_ . name ] = [ a ] else : removemethods3 [ class_ . name ] . append ( a ) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) removemethods [ class_name ] = [ methodkey ] return removemethods , removemethods1 main ( udb_path , source_package , target_class , class_names , * args , ** kwargs ) Source code in refactorings\\pullup_constructor.py def main ( udb_path , source_package , target_class , class_names : list , * args , ** kwargs ): \"\"\" \"\"\" if len ( class_names ) < 2 : logger . error ( \"class_names is empty.\" ) return False db = und . open ( udb_path ) parent_cons = [] # Check children parent = db . lookup ( f \" { target_class } \" , \"Public Class\" ) if len ( parent ) != 1 : logger . error ( \"Count of target class is not 1.\" ) db . close () return False parent = parent [ 0 ] parent_file = db . lookup ( f \" { target_class } .java\" , \"File\" )[ 0 ] . longname () for i in parent . ents ( \"Define\" , \"Constructor\" ): parent_cons . append ( i . parameters ()) # Find constructor entities group by signature constructors = {} for child in class_names : cons = db . lookup ( f \" { child } . { child } \" , \"Constructor\" ) for con in cons : if con . parent () is not None : if source_package not in con . parent () . longname (): logger . error ( \"Source package does not match.\" ) db . close () return False parameters = con . parameters () if parameters in constructors : constructors [ parameters ] . append ( con ) else : constructors [ parameters ] = [ con ] # Find common statements for k in constructors : meta_data = { parent_file : { 'is_father' : True , 'has_father_con' : k in parent_cons , 'class_name' : parent . simplename ()}, } con = constructors [ k ][ 0 ] ents = [] for ref in con . refs ( \"Set\" ): data = { 'is_father' : False , 'has_father_con' : k in parent_cons , 'class_name' : con . parent () . simplename ()} if ref . file () . longname () not in meta_data . keys (): meta_data [ ref . file () . longname ()] = data if target_class in ref . ent () . longname (): ents . append ( ref . ent () . simplename ()) for i in range ( 1 , len ( constructors [ k ])): con2 = constructors [ k ][ i ] for ref in con2 . refs ( \"Set\" ): data = { 'is_father' : False , 'has_father_con' : k in parent_cons , 'class_name' : con2 . parent () . simplename () } if ref . file () . longname () not in meta_data . keys (): meta_data [ ref . file () . longname ()] = data if target_class in ref . ent () . longname (): ents . append ( ref . ent () . simplename ()) ents = [ item for item , count in collections . Counter ( ents ) . items () if count > 1 ] if len ( meta_data . keys ()) > 1 : for file_name in meta_data : data = meta_data [ file_name ] parse_and_walk ( file_name , PullUpConstructorListener , has_write = True , is_father = data [ 'is_father' ], has_father_con = data [ 'has_father_con' ], common_sets = ents , class_name = data [ 'class_name' ], params = k ) db . close () return True","title":"Pull-up constructor"},{"location":"refactorings/pull_up_constructor/#pull-up-constructor","text":"","title":"Pull-up constructor"},{"location":"refactorings/pull_up_constructor/#refactorings.pullup_constructor--introduction","text":"When subclasses grow and get developed separately, your code may have constructors that perform similar work. Pull up constructor refactoring removes the repetitive method from subclasses and moves it to a superclass.","title":"Introduction"},{"location":"refactorings/pull_up_constructor/#refactorings.pullup_constructor--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/pull_up_constructor/#refactorings.pullup_constructor--pre-conditions","text":"The source package, class and constructor should exist. The order of the params in the constructor should be equal in the child classes. empty package name is addressable using \"\".","title":"Pre-conditions:"},{"location":"refactorings/pull_up_constructor/#refactorings.pullup_constructor--post-conditions","text":"No specific post-condition","title":"Post Conditions:"},{"location":"refactorings/pull_up_constructor/#refactorings.pullup_constructor.PullUpConstructorListener","text":"","title":"PullUpConstructorListener"},{"location":"refactorings/pull_up_constructor/#refactorings.pullup_constructor.PullUpConstructorListener.__init__","text":"Source code in refactorings\\pullup_constructor.py def __init__ ( self , rewriter : TokenStreamRewriter , is_father : bool , class_name : str , has_father_con : bool , common_sets : [], params : str ): \"\"\" \"\"\" self . rewriter = rewriter self . is_father = is_father self . has_father_con = has_father_con self . class_name = class_name self . common_sets = common_sets self . params = params self . in_con = False self . delete = False","title":"__init__()"},{"location":"refactorings/pull_up_constructor/#refactorings.pullup_constructor.get_cons","text":"A function to complete the Pull-up constructor refactoring by finding all the classes with similar constructors. Source code in refactorings\\pullup_constructor.py def get_cons ( program : Program , packagename : str , superclassname : str , class_name : str ): \"\"\" A function to complete the Pull-up constructor refactoring by finding all the classes with similar constructors. \"\"\" extendedclass = [] removemethods = {} removemethods1 = [] removemethods3 = {} mets = program . packages [ packagename ] . classes [ class_name ] . methods met = [] methodkey = \"\" for methodName , method in mets . items (): if method . is_constructor : met = method methodkey = methodName break body_text_method = met . body_text parammethod = met . parameters for package_name in program . packages : package = program . packages [ package_name ] for class_ in package . classes : _class = package . classes [ class_ ] if _class . superclass_name == superclassname : extendedclass . append ( _class ) i = 0 for d in extendedclass : class_ = extendedclass [ i ] i = i + 1 for mk in class_ . methods : m_ = class_ . methods [ mk ] m = mk [: mk . find ( '(' )] if m_ . body_text == body_text_method and m_ . parameters == parammethod and m_ . is_constructor == True : if class_ . name not in removemethods : removemethods [ class_ . name ] = [ methodkey ] else : removemethods [ class_ . name ] . append ( methodkey ) elif m_ . is_constructor == True : listBody_text = body_text_method . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . split ( \";\" ) listm_body = m_ . body_text . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . split ( \";\" ) s1 = set ( listBody_text ) s2 = set ( listm_body ) if s2 . issubset ( s1 ): removemethods1 . append ( diff_lists ( listBody_text , listm_body )) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) elif s1 . issubset ( s2 ): removemethods1 . append ( diff_lists ( listm_body , listBody_text )) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) else : a = diff_lists ( listBody_text , listm_body ) if class_ . name not in removemethods3 : removemethods3 [ class_ . name ] = [ a ] else : removemethods3 [ class_ . name ] . append ( a ) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) removemethods [ class_name ] = [ methodkey ] return removemethods , removemethods1","title":"get_cons()"},{"location":"refactorings/pull_up_constructor/#refactorings.pullup_constructor.main","text":"Source code in refactorings\\pullup_constructor.py def main ( udb_path , source_package , target_class , class_names : list , * args , ** kwargs ): \"\"\" \"\"\" if len ( class_names ) < 2 : logger . error ( \"class_names is empty.\" ) return False db = und . open ( udb_path ) parent_cons = [] # Check children parent = db . lookup ( f \" { target_class } \" , \"Public Class\" ) if len ( parent ) != 1 : logger . error ( \"Count of target class is not 1.\" ) db . close () return False parent = parent [ 0 ] parent_file = db . lookup ( f \" { target_class } .java\" , \"File\" )[ 0 ] . longname () for i in parent . ents ( \"Define\" , \"Constructor\" ): parent_cons . append ( i . parameters ()) # Find constructor entities group by signature constructors = {} for child in class_names : cons = db . lookup ( f \" { child } . { child } \" , \"Constructor\" ) for con in cons : if con . parent () is not None : if source_package not in con . parent () . longname (): logger . error ( \"Source package does not match.\" ) db . close () return False parameters = con . parameters () if parameters in constructors : constructors [ parameters ] . append ( con ) else : constructors [ parameters ] = [ con ] # Find common statements for k in constructors : meta_data = { parent_file : { 'is_father' : True , 'has_father_con' : k in parent_cons , 'class_name' : parent . simplename ()}, } con = constructors [ k ][ 0 ] ents = [] for ref in con . refs ( \"Set\" ): data = { 'is_father' : False , 'has_father_con' : k in parent_cons , 'class_name' : con . parent () . simplename ()} if ref . file () . longname () not in meta_data . keys (): meta_data [ ref . file () . longname ()] = data if target_class in ref . ent () . longname (): ents . append ( ref . ent () . simplename ()) for i in range ( 1 , len ( constructors [ k ])): con2 = constructors [ k ][ i ] for ref in con2 . refs ( \"Set\" ): data = { 'is_father' : False , 'has_father_con' : k in parent_cons , 'class_name' : con2 . parent () . simplename () } if ref . file () . longname () not in meta_data . keys (): meta_data [ ref . file () . longname ()] = data if target_class in ref . ent () . longname (): ents . append ( ref . ent () . simplename ()) ents = [ item for item , count in collections . Counter ( ents ) . items () if count > 1 ] if len ( meta_data . keys ()) > 1 : for file_name in meta_data : data = meta_data [ file_name ] parse_and_walk ( file_name , PullUpConstructorListener , has_write = True , is_father = data [ 'is_father' ], has_father_con = data [ 'has_father_con' ], common_sets = ents , class_name = data [ 'class_name' ], params = k ) db . close () return True","title":"main()"},{"location":"refactorings/pull_up_field/","text":"Pull-up field Introduction When subclasses grow and get developed separately, identical (or nearly identical) fields and methods appear. Pull up field refactoring removes the repetitive field from subclasses and moves it to a superclass. Pre and Post Conditions Pre Conditions: There should exist a corresponding child and parent in the project. The field that should be pulled up must be valid. The user must enter the package's name, class's name and the fields that need to be removed. Post Conditions: The changed field's usages and callings will also change respectively. There will be children and parents having their desired fields added or removed. Check for multilevel inheritance. PullUpFieldRefactoring The class that does the process of pull up field refactoring. Removes the repetitive fields from the subclasses, creates the superclass, and moves the fields to the superclass. __init__ ( self , source_filenames , package_name , class_name , field_name , filename_mapping =< function PullUpFieldRefactoring .< lambda > at 0x0000016CFD262040 > ) special Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the classes/superclasses) required class_name str Name of the class that the field is pulled up from required field_name str Name of the field that has to be refactored required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function PullUpFieldRefactoring.<lambda> at 0x0000016CFD262040> Returns: Type Description object (PullUpFieldRefactoring) An instance of PullUpFieldRefactoring class Source code in refactorings\\pullup_field.py def __init__ ( self , source_filenames : list , package_name : str , class_name : str , field_name : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the classes/superclasses) class_name (str): Name of the class that the field is pulled up from field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PullUpFieldRefactoring): An instance of PullUpFieldRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_name = class_name self . field_name = field_name self . filename_mapping = filename_mapping main ( project_dir , package_name , children_class , field_name , * args , ** kwargs ) Source code in refactorings\\pullup_field.py def main ( project_dir : str , package_name : str , children_class : str , field_name : str , * args , ** kwargs ): \"\"\" \"\"\" # print(\"Pull-up field\") result = PullUpFieldRefactoring ( symbol_table . get_filenames_in_dir ( project_dir ), package_name , children_class , field_name # lambda x: \"tests/pullup_field_ant/\" + x[len(ant_dir):] ) . do_refactor () # print(f\"Success pull-up field {field_name}\" if result else f\"Cannot pull-up field {field_name}\") return result","title":"Pull-up field"},{"location":"refactorings/pull_up_field/#pull-up-field","text":"","title":"Pull-up field"},{"location":"refactorings/pull_up_field/#refactorings.pullup_field--introduction","text":"When subclasses grow and get developed separately, identical (or nearly identical) fields and methods appear. Pull up field refactoring removes the repetitive field from subclasses and moves it to a superclass.","title":"Introduction"},{"location":"refactorings/pull_up_field/#refactorings.pullup_field--pre-and-post-conditions","text":"","title":"Pre and Post Conditions"},{"location":"refactorings/pull_up_field/#refactorings.pullup_field--pre-conditions","text":"There should exist a corresponding child and parent in the project. The field that should be pulled up must be valid. The user must enter the package's name, class's name and the fields that need to be removed.","title":"Pre Conditions:"},{"location":"refactorings/pull_up_field/#refactorings.pullup_field--post-conditions","text":"The changed field's usages and callings will also change respectively. There will be children and parents having their desired fields added or removed. Check for multilevel inheritance.","title":"Post Conditions:"},{"location":"refactorings/pull_up_field/#refactorings.pullup_field.PullUpFieldRefactoring","text":"The class that does the process of pull up field refactoring. Removes the repetitive fields from the subclasses, creates the superclass, and moves the fields to the superclass.","title":"PullUpFieldRefactoring"},{"location":"refactorings/pull_up_field/#refactorings.pullup_field.PullUpFieldRefactoring.__init__","text":"Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the classes/superclasses) required class_name str Name of the class that the field is pulled up from required field_name str Name of the field that has to be refactored required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function PullUpFieldRefactoring.<lambda> at 0x0000016CFD262040> Returns: Type Description object (PullUpFieldRefactoring) An instance of PullUpFieldRefactoring class Source code in refactorings\\pullup_field.py def __init__ ( self , source_filenames : list , package_name : str , class_name : str , field_name : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the classes/superclasses) class_name (str): Name of the class that the field is pulled up from field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PullUpFieldRefactoring): An instance of PullUpFieldRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_name = class_name self . field_name = field_name self . filename_mapping = filename_mapping","title":"__init__()"},{"location":"refactorings/pull_up_field/#refactorings.pullup_field.main","text":"Source code in refactorings\\pullup_field.py def main ( project_dir : str , package_name : str , children_class : str , field_name : str , * args , ** kwargs ): \"\"\" \"\"\" # print(\"Pull-up field\") result = PullUpFieldRefactoring ( symbol_table . get_filenames_in_dir ( project_dir ), package_name , children_class , field_name # lambda x: \"tests/pullup_field_ant/\" + x[len(ant_dir):] ) . do_refactor () # print(f\"Success pull-up field {field_name}\" if result else f\"Cannot pull-up field {field_name}\") return result","title":"main()"},{"location":"refactorings/pull_up_method/","text":"Pull-up method Introduction The module implements pull-up method refactoring operation. Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions PullUpMethodRefactoringListener To implement pull-up method refactoring based on its actors. __init__ ( self , common_token_stream = None , destination_class = None , children_class = None , moved_methods = None , method_text = None ) special Source code in refactorings\\pullup_method.py def __init__ ( self , common_token_stream : CommonTokenStream = None , destination_class : str = None , children_class : list = None , moved_methods = None , method_text : str = None ): \"\"\" \"\"\" if method_text is None : self . mothod_text = [] else : self . method_text = method_text if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if children_class is None : self . children_class = [] else : self . children_class = children_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if destination_class is None : raise ValueError ( \"source_class is None\" ) else : self . destination_class = destination_class self . is_children_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . tempdeclarationcode = \"\" main ( udb_path , children_classes , method_name , * args , ** kwargs ) Source code in refactorings\\pullup_method.py def main ( udb_path : str , children_classes : list , method_name : str , * args , ** kwargs ): \"\"\" \"\"\" if len ( children_classes ) <= 1 : logger . error ( \"len(children_classes) should be gte 2\" ) return False # Initialize with understand destination_class = \"\" fileslist_to_be_rafeactored = set () fileslist_to_be_propagate = set () propagation_classes = set () db = und . open ( udb_path ) try : method_ents = [ db . lookup ( i + \".\" + method_name , \"method\" )[ 0 ] for i in children_classes ] except IndexError : # print([db.lookup(i + \".\" + method_name, \"method\") for i in children_classes]) logger . error ( f \"Method { method_name } does not exists in all children_classes.\" ) db . close () return False # Get method text method_text = method_ents [ 0 ] . contents () . strip () for method_ent in method_ents : if method_ent . contents () . strip () != method_text : logger . error ( \"Method content is different.\" ) db . close () return False for ref in method_ent . refs ( \"Use,Call\" ): if ref . ent () . parent () is not None : if ref . ent () . parent () . simplename () in children_classes : logger . error ( \"Method has internal dependencies.\" ) db . close () return False for mth in db . ents ( \"Java Method\" ): for child in children_classes : if mth . longname () . endswith ( child + \".\" + method_name ): fileslist_to_be_rafeactored . add ( mth . parent () . parent () . longname ()) for fth in mth . parent () . refs ( \"Extend\" ): destination_class = fth . ent () . longname () fileslist_to_be_rafeactored . add ( fth . ent () . parent () . longname ()) for ref in mth . refs ( \"Java Callby\" ): propagation_classes . add ( ref . ent () . parent () . longname ()) fileslist_to_be_propagate . add ( ref . ent () . parent () . parent () . longname ()) db . close () # print(\"=========================================\") # print(\"fileslist_to_be_propagate :\", fileslist_to_be_propagate) # print(\"propagation_classes : \", propagation_classes) # print(\"fileslist_to_be_rafeactored :\", fileslist_to_be_rafeactored) # print(\"father class :\", destination_class) fileslist_to_be_rafeactored = list ( fileslist_to_be_rafeactored ) fileslist_to_be_propagate = list ( fileslist_to_be_propagate ) propagation_class = list ( propagation_classes ) # refactored start for file in fileslist_to_be_rafeactored : try : stream = FileStream ( file , encoding = 'utf-8' , errors = 'ignore' ) except : continue lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener_refactor = PullUpMethodRefactoringListener ( common_token_stream = token_stream , destination_class = destination_class , children_class = children_classes , moved_methods = method_name , method_text = method_text ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener_refactor ) with open ( file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener_refactor . token_stream_rewriter . getDefaultText ()) # end refactoring # beginning of propagate for file in fileslist_to_be_propagate : if not os . path . exists ( file ): continue stream = FileStream ( file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener_propagate = PropagationPullUpMethodRefactoringListener ( token_stream_rewriter = token_stream , old_class_name = children_classes , new_class_name = destination_class , propagated_class_name = propagation_class ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener_propagate ) with open ( file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener_propagate . token_stream_rewriter . getDefaultText ()) # end of propagate return True","title":"Pull-up method"},{"location":"refactorings/pull_up_method/#pull-up-method","text":"","title":"Pull-up method"},{"location":"refactorings/pull_up_method/#refactorings.pullup_method--introduction","text":"The module implements pull-up method refactoring operation.","title":"Introduction"},{"location":"refactorings/pull_up_method/#refactorings.pullup_method--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/pull_up_method/#refactorings.pullup_method--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/pull_up_method/#refactorings.pullup_method.PullUpMethodRefactoringListener","text":"To implement pull-up method refactoring based on its actors.","title":"PullUpMethodRefactoringListener"},{"location":"refactorings/pull_up_method/#refactorings.pullup_method.PullUpMethodRefactoringListener.__init__","text":"Source code in refactorings\\pullup_method.py def __init__ ( self , common_token_stream : CommonTokenStream = None , destination_class : str = None , children_class : list = None , moved_methods = None , method_text : str = None ): \"\"\" \"\"\" if method_text is None : self . mothod_text = [] else : self . method_text = method_text if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if children_class is None : self . children_class = [] else : self . children_class = children_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if destination_class is None : raise ValueError ( \"source_class is None\" ) else : self . destination_class = destination_class self . is_children_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . tempdeclarationcode = \"\"","title":"__init__()"},{"location":"refactorings/pull_up_method/#refactorings.pullup_method.main","text":"Source code in refactorings\\pullup_method.py def main ( udb_path : str , children_classes : list , method_name : str , * args , ** kwargs ): \"\"\" \"\"\" if len ( children_classes ) <= 1 : logger . error ( \"len(children_classes) should be gte 2\" ) return False # Initialize with understand destination_class = \"\" fileslist_to_be_rafeactored = set () fileslist_to_be_propagate = set () propagation_classes = set () db = und . open ( udb_path ) try : method_ents = [ db . lookup ( i + \".\" + method_name , \"method\" )[ 0 ] for i in children_classes ] except IndexError : # print([db.lookup(i + \".\" + method_name, \"method\") for i in children_classes]) logger . error ( f \"Method { method_name } does not exists in all children_classes.\" ) db . close () return False # Get method text method_text = method_ents [ 0 ] . contents () . strip () for method_ent in method_ents : if method_ent . contents () . strip () != method_text : logger . error ( \"Method content is different.\" ) db . close () return False for ref in method_ent . refs ( \"Use,Call\" ): if ref . ent () . parent () is not None : if ref . ent () . parent () . simplename () in children_classes : logger . error ( \"Method has internal dependencies.\" ) db . close () return False for mth in db . ents ( \"Java Method\" ): for child in children_classes : if mth . longname () . endswith ( child + \".\" + method_name ): fileslist_to_be_rafeactored . add ( mth . parent () . parent () . longname ()) for fth in mth . parent () . refs ( \"Extend\" ): destination_class = fth . ent () . longname () fileslist_to_be_rafeactored . add ( fth . ent () . parent () . longname ()) for ref in mth . refs ( \"Java Callby\" ): propagation_classes . add ( ref . ent () . parent () . longname ()) fileslist_to_be_propagate . add ( ref . ent () . parent () . parent () . longname ()) db . close () # print(\"=========================================\") # print(\"fileslist_to_be_propagate :\", fileslist_to_be_propagate) # print(\"propagation_classes : \", propagation_classes) # print(\"fileslist_to_be_rafeactored :\", fileslist_to_be_rafeactored) # print(\"father class :\", destination_class) fileslist_to_be_rafeactored = list ( fileslist_to_be_rafeactored ) fileslist_to_be_propagate = list ( fileslist_to_be_propagate ) propagation_class = list ( propagation_classes ) # refactored start for file in fileslist_to_be_rafeactored : try : stream = FileStream ( file , encoding = 'utf-8' , errors = 'ignore' ) except : continue lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener_refactor = PullUpMethodRefactoringListener ( common_token_stream = token_stream , destination_class = destination_class , children_class = children_classes , moved_methods = method_name , method_text = method_text ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener_refactor ) with open ( file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener_refactor . token_stream_rewriter . getDefaultText ()) # end refactoring # beginning of propagate for file in fileslist_to_be_propagate : if not os . path . exists ( file ): continue stream = FileStream ( file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener_propagate = PropagationPullUpMethodRefactoringListener ( token_stream_rewriter = token_stream , old_class_name = children_classes , new_class_name = destination_class , propagated_class_name = propagation_class ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener_propagate ) with open ( file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener_propagate . token_stream_rewriter . getDefaultText ()) # end of propagate return True","title":"main()"},{"location":"refactorings/push_down_field/","text":"Push-down field Introduction Although it was planned to use a field universally for all classes, in reality the field is used only in some subclasses. This situation can occur when planned features fail to pan out, for example. because of this, we push down the field from the superclass into its related subclass. Pre and Post Conditions Pre Conditions: There should exist a corresponding child and parent in the project. The field that should be pushed down must be valid. The user must enter the package's name, class's name and the fields that need to be added. Post Conditions: The changed field's usages and callings will also change respectively. There will be children and parents having their desired fields added or removed. PushDownField The main function that does the process of pull up field refactoring. Adds the necessary fields to the subclasses and removes them from the superclass. __init__ ( self , source_filenames , package_name , superclass_name , field_name , class_names = [], filename_mapping =< function PushDownField .< lambda > at 0x0000016CFD8FADC0 > ) special Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the superclass) required superclass_name str The name of the needed superclass required class_names list Name of the classes in which the refactoring has to be done (the classes to push down field from) [] field_name str Name of the field that has to be refactored required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function PushDownField.<lambda> at 0x0000016CFD8FADC0> Returns: Type Description object (PushDownField) An instance of PushDownField class Source code in refactorings\\pushdown_field.py def __init__ ( self , source_filenames : list , package_name : str , superclass_name : str , field_name : str , class_names : list = [], filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the superclass) superclass_name (str): The name of the needed superclass class_names (list): Name of the classes in which the refactoring has to be done \\ (the classes to push down field from) field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PushDownField): An instance of PushDownField class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . superclass_name = superclass_name self . field_name = field_name self . class_names = class_names self . filename_mapping = filename_mapping main ( project_dir , source_package , source_class , field_name , target_classes , * args , ** kwargs ) Source code in refactorings\\pushdown_field.py def main ( project_dir , source_package , source_class , field_name , target_classes : list , * args , ** kwargs ): \"\"\" \"\"\" res = PushDownField ( symbol_table . get_filenames_in_dir ( project_dir ), package_name = source_package , superclass_name = source_class , field_name = field_name , class_names = target_classes , ) . do_refactor () if not res : logger . error ( \"Cannot push-down field\" ) return False return True Push-down field 2 Introduction The module implements a light-weight version of push-down field refactoring described in pushdown_field.py . Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions CutFieldListener Removes the field declaration from the parent class. __init__ ( self , source_class , field_name , rewriter ) special Parameters: Name Type Description Default source_class str (str) Parent's class name. required field_name str (str) Field's name. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description field_content (CutFieldListener) The full string of field declaration Source code in refactorings\\pushdown_field2.py def __init__ ( self , source_class : str , field_name : str , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. field_name: (str) Field's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutFieldListener): The full string of field declaration \"\"\" self . source_class = source_class self . field_name = field_name self . rewriter = rewriter self . field_content = \"\" self . import_statements = \"\" self . detected_field = False self . is_source_class = False PasteFieldListener Inserts field declaration to children classes. __init__ ( self , source_class , field_content , import_statements , rewriter ) special Parameters: Name Type Description Default source_class Child class name. required field_content Full string of the field declaration. required rewriter TokenStreamRewriter Antlr's token stream rewriter. required Returns: Type Description object (PasteFieldListener) An instance of PasteFieldListener class Source code in refactorings\\pushdown_field2.py def __init__ ( self , source_class , field_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: Child class name. field_content: Full string of the field declaration. rewriter: Antlr's token stream rewriter. Returns: object (PasteFieldListener): An instance of PasteFieldListener class \"\"\" self . source_class = source_class self . rewriter = rewriter self . field_content = field_content self . import_statements = import_statements self . is_source_class = False main ( udb_path = None , source_package = None , source_class = None , field_name = None , target_classes = None , * args , ** kwargs ) The main API for push-down field refactoring Source code in refactorings\\pushdown_field2.py def main ( udb_path = None , source_package = None , source_class = None , field_name = None , target_classes : list = None , * args , ** kwargs ): \"\"\" The main API for push-down field refactoring \"\"\" if udb_path is None : db = und . open ( sbse . config . UDB_PATH ) else : db = und . open ( udb_path ) source_class_ent = None source_class_ents = db . lookup ( f \" { source_package } . { source_class } \" , \"Class\" ) if len ( source_class_ents ) == 0 : logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False else : for ent in source_class_ents : if ent . simplename () == source_class : source_class_ent = ent break if source_class_ent is None : logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False fields = db . lookup ( f \" { source_package } . { source_class } . { field_name } \" , \"Variable\" ) if fields is None or len ( fields ) == 0 : logger . error ( f \"Cannot find field to pushdown: { field_name } \" ) db . close () return False else : field_ent = fields [ 0 ] target_class_ents_files = [] target_class_ents_simplenames = [] for ref in source_class_ent . refs ( \"Extendby\" ): if ref . ent () . simplename () not in target_classes : logger . error ( \"Target classes are not children classes\" ) db . close () return False target_class_ents_files . append ( ref . ent () . parent () . longname ()) target_class_ents_simplenames . append ( ref . ent () . simplename ()) for ref in field_ent . refs ( \"Useby,Setby\" ): if ref . file () . simplename () . split ( \".\" )[ 0 ] in target_classes : continue else : logger . error ( \"Field has dependencies.\" ) db . close () return False source_class_file = source_class_ent . parent () . longname () db . close () # Remove field from source class listener = parse_and_walk ( file_path = source_class_file , listener_class = CutFieldListener , has_write = True , source_class = source_class , field_name = field_name , debug = False ) # Insert field in children classes for i , target_class_file in enumerate ( target_class_ents_files ): parse_and_walk ( file_path = target_class_file , listener_class = PasteFieldListener , has_write = True , source_class = target_class_ents_simplenames [ i ], field_content = listener . field_content , import_statements = listener . import_statements , debug = False ) # db.close() return True","title":"Push-down field"},{"location":"refactorings/push_down_field/#push-down-field","text":"","title":"Push-down field"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field--introduction","text":"Although it was planned to use a field universally for all classes, in reality the field is used only in some subclasses. This situation can occur when planned features fail to pan out, for example. because of this, we push down the field from the superclass into its related subclass.","title":"Introduction"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field--pre-and-post-conditions","text":"","title":"Pre and Post Conditions"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field--pre-conditions","text":"There should exist a corresponding child and parent in the project. The field that should be pushed down must be valid. The user must enter the package's name, class's name and the fields that need to be added.","title":"Pre Conditions:"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field--post-conditions","text":"The changed field's usages and callings will also change respectively. There will be children and parents having their desired fields added or removed.","title":"Post Conditions:"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field.PushDownField","text":"The main function that does the process of pull up field refactoring. Adds the necessary fields to the subclasses and removes them from the superclass.","title":"PushDownField"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field.PushDownField.__init__","text":"Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the superclass) required superclass_name str The name of the needed superclass required class_names list Name of the classes in which the refactoring has to be done (the classes to push down field from) [] field_name str Name of the field that has to be refactored required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function PushDownField.<lambda> at 0x0000016CFD8FADC0> Returns: Type Description object (PushDownField) An instance of PushDownField class Source code in refactorings\\pushdown_field.py def __init__ ( self , source_filenames : list , package_name : str , superclass_name : str , field_name : str , class_names : list = [], filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the superclass) superclass_name (str): The name of the needed superclass class_names (list): Name of the classes in which the refactoring has to be done \\ (the classes to push down field from) field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PushDownField): An instance of PushDownField class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . superclass_name = superclass_name self . field_name = field_name self . class_names = class_names self . filename_mapping = filename_mapping","title":"__init__()"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field.main","text":"Source code in refactorings\\pushdown_field.py def main ( project_dir , source_package , source_class , field_name , target_classes : list , * args , ** kwargs ): \"\"\" \"\"\" res = PushDownField ( symbol_table . get_filenames_in_dir ( project_dir ), package_name = source_package , superclass_name = source_class , field_name = field_name , class_names = target_classes , ) . do_refactor () if not res : logger . error ( \"Cannot push-down field\" ) return False return True","title":"main()"},{"location":"refactorings/push_down_field/#push-down-field-2","text":"","title":"Push-down field 2"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field2--introduction","text":"The module implements a light-weight version of push-down field refactoring described in pushdown_field.py .","title":"Introduction"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field2.CutFieldListener","text":"Removes the field declaration from the parent class.","title":"CutFieldListener"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field2.CutFieldListener.__init__","text":"Parameters: Name Type Description Default source_class str (str) Parent's class name. required field_name str (str) Field's name. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description field_content (CutFieldListener) The full string of field declaration Source code in refactorings\\pushdown_field2.py def __init__ ( self , source_class : str , field_name : str , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. field_name: (str) Field's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutFieldListener): The full string of field declaration \"\"\" self . source_class = source_class self . field_name = field_name self . rewriter = rewriter self . field_content = \"\" self . import_statements = \"\" self . detected_field = False self . is_source_class = False","title":"__init__()"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field2.PasteFieldListener","text":"Inserts field declaration to children classes.","title":"PasteFieldListener"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field2.PasteFieldListener.__init__","text":"Parameters: Name Type Description Default source_class Child class name. required field_content Full string of the field declaration. required rewriter TokenStreamRewriter Antlr's token stream rewriter. required Returns: Type Description object (PasteFieldListener) An instance of PasteFieldListener class Source code in refactorings\\pushdown_field2.py def __init__ ( self , source_class , field_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: Child class name. field_content: Full string of the field declaration. rewriter: Antlr's token stream rewriter. Returns: object (PasteFieldListener): An instance of PasteFieldListener class \"\"\" self . source_class = source_class self . rewriter = rewriter self . field_content = field_content self . import_statements = import_statements self . is_source_class = False","title":"__init__()"},{"location":"refactorings/push_down_field/#refactorings.pushdown_field2.main","text":"The main API for push-down field refactoring Source code in refactorings\\pushdown_field2.py def main ( udb_path = None , source_package = None , source_class = None , field_name = None , target_classes : list = None , * args , ** kwargs ): \"\"\" The main API for push-down field refactoring \"\"\" if udb_path is None : db = und . open ( sbse . config . UDB_PATH ) else : db = und . open ( udb_path ) source_class_ent = None source_class_ents = db . lookup ( f \" { source_package } . { source_class } \" , \"Class\" ) if len ( source_class_ents ) == 0 : logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False else : for ent in source_class_ents : if ent . simplename () == source_class : source_class_ent = ent break if source_class_ent is None : logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False fields = db . lookup ( f \" { source_package } . { source_class } . { field_name } \" , \"Variable\" ) if fields is None or len ( fields ) == 0 : logger . error ( f \"Cannot find field to pushdown: { field_name } \" ) db . close () return False else : field_ent = fields [ 0 ] target_class_ents_files = [] target_class_ents_simplenames = [] for ref in source_class_ent . refs ( \"Extendby\" ): if ref . ent () . simplename () not in target_classes : logger . error ( \"Target classes are not children classes\" ) db . close () return False target_class_ents_files . append ( ref . ent () . parent () . longname ()) target_class_ents_simplenames . append ( ref . ent () . simplename ()) for ref in field_ent . refs ( \"Useby,Setby\" ): if ref . file () . simplename () . split ( \".\" )[ 0 ] in target_classes : continue else : logger . error ( \"Field has dependencies.\" ) db . close () return False source_class_file = source_class_ent . parent () . longname () db . close () # Remove field from source class listener = parse_and_walk ( file_path = source_class_file , listener_class = CutFieldListener , has_write = True , source_class = source_class , field_name = field_name , debug = False ) # Insert field in children classes for i , target_class_file in enumerate ( target_class_ents_files ): parse_and_walk ( file_path = target_class_file , listener_class = PasteFieldListener , has_write = True , source_class = target_class_ents_simplenames [ i ], field_content = listener . field_content , import_statements = listener . import_statements , debug = False ) # db.close() return True","title":"main()"},{"location":"refactorings/push_down_method/","text":"Push-down method Introduction The module implements push-down method refactoring Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions DeleteSourceListener __init__ ( self , common_token_stream , source_method ) special Source code in refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_method : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_method = source_method PropagationListener __init__ ( self , common_token_stream , source_class , child_class , class_name , method_name , ref_line , target_package ) special Source code in refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , child_class : str , class_name : str , method_name : str , ref_line : int , target_package : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_class = source_class self . child_class = child_class self . class_name = class_name self . method_name = method_name self . ref_line = ref_line self . target_package = target_package self . start = None self . stop = None self . is_safe = False self . need_cast = False self . variable = None self . detected_class = False self . detected_package = False self . import_end = None PropagationNonStaticListener PropagationStaticListener PushDownMethodRefactoringListener __init__ ( self , common_token_stream , source_class , source_method_text ) special Source code in refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , source_method_text : str ): \"\"\" \"\"\" self . source_method_text = source_method_text self . source_class = source_class self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_safe = False main ( udb_path , source_package , source_class , method_name , target_classes , * args , ** kwargs ) The main API for the push-down method refactoring operation Source code in refactorings\\pushdown_method.py def main ( udb_path , source_package , source_class , method_name , target_classes : list , * args , ** kwargs ): \"\"\" The main API for the push-down method refactoring operation \"\"\" target_package = source_package source_method = method_name main_file = None source_method_entity = None is_static = False propagation_files = [] propagation_classes = [] propagation_lines = [] children_classes = [] children_files = [] # Initialize with understand db = und . open ( udb_path ) methods = db . ents ( \"Java Method\" ) for mth in methods : if mth . longname () == source_package + \".\" + source_class + \".\" + source_method : source_method_entity = mth for child_ref in mth . parent () . refs ( \"Extendby\" ): child_ref = child_ref . ent () if child_ref . simplename () in target_classes : children_classes . append ( child_ref . simplename ()) children_files . append ( child_ref . parent () . longname ()) # print(\"mainfile : \", mth.parent().parent().longname()) is_static = mth . kind () . check ( \"static\" ) main_file = mth . parent () . parent () . longname () for ref in mth . refs ( \"Callby\" ): propagation_files . append ( ref . ent () . parent () . parent () . longname ()) propagation_classes . append ( ref . ent () . parent () . simplename ()) propagation_lines . append ( ref . line ()) # Check pre-condition if not len ( target_classes ) == 1 : logger . error ( f \"len(target_classes) is not 1.\" ) db . close () return False if not len ( children_classes ) == 1 : logger . error ( f \"len(children_classes) is not 1.\" ) db . close () return False if not len ( children_files ) == 1 : logger . error ( f \"len(children_files) is not 1.\" ) db . close () return False for mth in methods : if mth . simplename () == source_method : if mth . parent () . simplename () in target_classes : if mth . type () == source_method_entity . type (): if mth . kind () == source_method_entity . kind (): if mth . parameters () == source_method_entity . parameters (): logger . error ( \"Duplicated method\" ) db . close () return False for ref in source_method_entity . refs ( \"use, call\" ): ref_ent = ref . ent () is_public = ref_ent . kind () . check ( \"public\" ) if not is_public : logger . error ( \"Has internal dependencies.\" ) db . close () return False # get text method_text = source_method_entity . contents () db . close () # Delete source method stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = DeleteSourceListener ( common_token_stream = token_stream , source_method = source_method ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( main_file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # Do the push down for child_file , child_class in zip ( children_files , children_classes ): stream = FileStream ( child_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = PushDownMethodRefactoringListener ( common_token_stream = token_stream , source_class = child_class , source_method_text = method_text ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( child_file , mode = 'w' , encoding = 'utf8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # Propagation for file , _class , line in zip ( propagation_files , propagation_classes , propagation_lines ): stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () if is_static : my_listener = PropagationStaticListener ( common_token_stream = token_stream , source_class = source_class , child_class = children_classes [ 0 ], class_name = _class , method_name = source_method , ref_line = line , target_package = target_package ) else : my_listener = PropagationNonStaticListener ( common_token_stream = token_stream , source_class = source_class , child_class = children_classes [ 0 ], class_name = _class , method_name = source_method , ref_line = line , target_package = target_package ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True Push-down method 2 Introduction The module implements a light-weight version of the push-down method refactoring described in pushdown_method.py Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions CutMethodListener Removes the method declaration from the parent class. __init__ ( self , source_class , method_name , rewriter ) special Parameters: Name Type Description Default source_class (str) Parent's class name. required method_name (str) Method's name. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description field_content (CutMethodListener) The full string of method declaration Source code in refactorings\\pushdown_method2.py def __init__ ( self , source_class , method_name , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. method_name: (str) Method's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutMethodListener): The full string of method declaration \"\"\" self . source_class = source_class self . method_name = method_name self . rewriter = rewriter self . method_content = \"\" self . import_statements = \"\" self . detected_method = False self . is_source_class = False PasteMethodListener Inserts method declaration to children classes. __init__ ( self , source_class , method_content , import_statements , rewriter ) special Parameters: Name Type Description Default source_class str Child class name. required method_content str Full string of the method declaration. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description object (PasteMethodListener) An instance of PasteMethodListener class. Source code in refactorings\\pushdown_method2.py def __init__ ( self , source_class , method_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Child class name. method_content (str): Full string of the method declaration. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: object (PasteMethodListener): An instance of PasteMethodListener class. \"\"\" self . source_class = source_class self . rewriter = rewriter self . method_content = method_content self . import_statements = import_statements self . is_source_class = False main ( udb_path , source_package , source_class , method_name , target_classes , * args , ** kwargs ) The main API for the push-down method refactoring (version 2) Source code in refactorings\\pushdown_method2.py def main ( udb_path , source_package , source_class , method_name , target_classes : list , * args , ** kwargs ): \"\"\" The main API for the push-down method refactoring (version 2) \"\"\" db = und . open ( udb_path ) source_class_ents = db . lookup ( f \" { source_package } . { source_class } \" , \"Class\" ) target_class_ents = [] source_class_ent = None if len ( source_class_ents ) == 0 : config . logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False else : for ent in source_class_ents : if ent . simplename () == source_class : source_class_ent = ent break if source_class_ent is None : config . logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False method_ent = db . lookup ( f \" { source_package } . { source_class } . { method_name } \" , \"Method\" ) if len ( method_ent ) == 0 : config . logger . error ( f \"Cannot find method to pushdown: { method_name } \" ) db . close () return False else : method_ent = method_ent [ 0 ] for ref in source_class_ent . refs ( \"extendBy\" ): if ref . ent () . simplename () not in target_classes : config . logger . error ( \"Target classes are not children classes\" ) db . close () return False target_class_ents . append ( ref . ent ()) for ref in method_ent . refs ( \"callBy\" ): if ref . file () . simplename () . split ( \".\" )[ 0 ] in target_classes : continue else : config . logger . error ( \"Method has dependencies.\" ) db . close () return False # Remove field from source class listener = parse_and_walk ( file_path = source_class_ent . parent () . longname (), listener_class = CutMethodListener , has_write = True , source_class = source_class , method_name = method_name , debug = False ) # Insert field in children classes for target_class in target_class_ents : parse_and_walk ( file_path = target_class . parent () . longname (), listener_class = PasteMethodListener , has_write = True , source_class = target_class . simplename (), method_content = listener . method_content , import_statements = listener . import_statements , debug = False ) db . close ()","title":"Push-down method"},{"location":"refactorings/push_down_method/#push-down-method","text":"","title":"Push-down method"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method--introduction","text":"The module implements push-down method refactoring","title":"Introduction"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.DeleteSourceListener","text":"","title":"DeleteSourceListener"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.DeleteSourceListener.__init__","text":"Source code in refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_method : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_method = source_method","title":"__init__()"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.PropagationListener","text":"","title":"PropagationListener"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.PropagationListener.__init__","text":"Source code in refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , child_class : str , class_name : str , method_name : str , ref_line : int , target_package : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_class = source_class self . child_class = child_class self . class_name = class_name self . method_name = method_name self . ref_line = ref_line self . target_package = target_package self . start = None self . stop = None self . is_safe = False self . need_cast = False self . variable = None self . detected_class = False self . detected_package = False self . import_end = None","title":"__init__()"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.PropagationNonStaticListener","text":"","title":"PropagationNonStaticListener"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.PropagationStaticListener","text":"","title":"PropagationStaticListener"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.PushDownMethodRefactoringListener","text":"","title":"PushDownMethodRefactoringListener"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.PushDownMethodRefactoringListener.__init__","text":"Source code in refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , source_method_text : str ): \"\"\" \"\"\" self . source_method_text = source_method_text self . source_class = source_class self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_safe = False","title":"__init__()"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method.main","text":"The main API for the push-down method refactoring operation Source code in refactorings\\pushdown_method.py def main ( udb_path , source_package , source_class , method_name , target_classes : list , * args , ** kwargs ): \"\"\" The main API for the push-down method refactoring operation \"\"\" target_package = source_package source_method = method_name main_file = None source_method_entity = None is_static = False propagation_files = [] propagation_classes = [] propagation_lines = [] children_classes = [] children_files = [] # Initialize with understand db = und . open ( udb_path ) methods = db . ents ( \"Java Method\" ) for mth in methods : if mth . longname () == source_package + \".\" + source_class + \".\" + source_method : source_method_entity = mth for child_ref in mth . parent () . refs ( \"Extendby\" ): child_ref = child_ref . ent () if child_ref . simplename () in target_classes : children_classes . append ( child_ref . simplename ()) children_files . append ( child_ref . parent () . longname ()) # print(\"mainfile : \", mth.parent().parent().longname()) is_static = mth . kind () . check ( \"static\" ) main_file = mth . parent () . parent () . longname () for ref in mth . refs ( \"Callby\" ): propagation_files . append ( ref . ent () . parent () . parent () . longname ()) propagation_classes . append ( ref . ent () . parent () . simplename ()) propagation_lines . append ( ref . line ()) # Check pre-condition if not len ( target_classes ) == 1 : logger . error ( f \"len(target_classes) is not 1.\" ) db . close () return False if not len ( children_classes ) == 1 : logger . error ( f \"len(children_classes) is not 1.\" ) db . close () return False if not len ( children_files ) == 1 : logger . error ( f \"len(children_files) is not 1.\" ) db . close () return False for mth in methods : if mth . simplename () == source_method : if mth . parent () . simplename () in target_classes : if mth . type () == source_method_entity . type (): if mth . kind () == source_method_entity . kind (): if mth . parameters () == source_method_entity . parameters (): logger . error ( \"Duplicated method\" ) db . close () return False for ref in source_method_entity . refs ( \"use, call\" ): ref_ent = ref . ent () is_public = ref_ent . kind () . check ( \"public\" ) if not is_public : logger . error ( \"Has internal dependencies.\" ) db . close () return False # get text method_text = source_method_entity . contents () db . close () # Delete source method stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = DeleteSourceListener ( common_token_stream = token_stream , source_method = source_method ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( main_file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # Do the push down for child_file , child_class in zip ( children_files , children_classes ): stream = FileStream ( child_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = PushDownMethodRefactoringListener ( common_token_stream = token_stream , source_class = child_class , source_method_text = method_text ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( child_file , mode = 'w' , encoding = 'utf8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # Propagation for file , _class , line in zip ( propagation_files , propagation_classes , propagation_lines ): stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () if is_static : my_listener = PropagationStaticListener ( common_token_stream = token_stream , source_class = source_class , child_class = children_classes [ 0 ], class_name = _class , method_name = source_method , ref_line = line , target_package = target_package ) else : my_listener = PropagationNonStaticListener ( common_token_stream = token_stream , source_class = source_class , child_class = children_classes [ 0 ], class_name = _class , method_name = source_method , ref_line = line , target_package = target_package ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/push_down_method/#push-down-method-2","text":"","title":"Push-down method 2"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method2--introduction","text":"The module implements a light-weight version of the push-down method refactoring described in pushdown_method.py","title":"Introduction"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method2.CutMethodListener","text":"Removes the method declaration from the parent class.","title":"CutMethodListener"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method2.CutMethodListener.__init__","text":"Parameters: Name Type Description Default source_class (str) Parent's class name. required method_name (str) Method's name. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description field_content (CutMethodListener) The full string of method declaration Source code in refactorings\\pushdown_method2.py def __init__ ( self , source_class , method_name , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. method_name: (str) Method's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutMethodListener): The full string of method declaration \"\"\" self . source_class = source_class self . method_name = method_name self . rewriter = rewriter self . method_content = \"\" self . import_statements = \"\" self . detected_method = False self . is_source_class = False","title":"__init__()"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method2.PasteMethodListener","text":"Inserts method declaration to children classes.","title":"PasteMethodListener"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method2.PasteMethodListener.__init__","text":"Parameters: Name Type Description Default source_class str Child class name. required method_content str Full string of the method declaration. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description object (PasteMethodListener) An instance of PasteMethodListener class. Source code in refactorings\\pushdown_method2.py def __init__ ( self , source_class , method_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Child class name. method_content (str): Full string of the method declaration. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: object (PasteMethodListener): An instance of PasteMethodListener class. \"\"\" self . source_class = source_class self . rewriter = rewriter self . method_content = method_content self . import_statements = import_statements self . is_source_class = False","title":"__init__()"},{"location":"refactorings/push_down_method/#refactorings.pushdown_method2.main","text":"The main API for the push-down method refactoring (version 2) Source code in refactorings\\pushdown_method2.py def main ( udb_path , source_package , source_class , method_name , target_classes : list , * args , ** kwargs ): \"\"\" The main API for the push-down method refactoring (version 2) \"\"\" db = und . open ( udb_path ) source_class_ents = db . lookup ( f \" { source_package } . { source_class } \" , \"Class\" ) target_class_ents = [] source_class_ent = None if len ( source_class_ents ) == 0 : config . logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False else : for ent in source_class_ents : if ent . simplename () == source_class : source_class_ent = ent break if source_class_ent is None : config . logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False method_ent = db . lookup ( f \" { source_package } . { source_class } . { method_name } \" , \"Method\" ) if len ( method_ent ) == 0 : config . logger . error ( f \"Cannot find method to pushdown: { method_name } \" ) db . close () return False else : method_ent = method_ent [ 0 ] for ref in source_class_ent . refs ( \"extendBy\" ): if ref . ent () . simplename () not in target_classes : config . logger . error ( \"Target classes are not children classes\" ) db . close () return False target_class_ents . append ( ref . ent ()) for ref in method_ent . refs ( \"callBy\" ): if ref . file () . simplename () . split ( \".\" )[ 0 ] in target_classes : continue else : config . logger . error ( \"Method has dependencies.\" ) db . close () return False # Remove field from source class listener = parse_and_walk ( file_path = source_class_ent . parent () . longname (), listener_class = CutMethodListener , has_write = True , source_class = source_class , method_name = method_name , debug = False ) # Insert field in children classes for target_class in target_class_ents : parse_and_walk ( file_path = target_class . parent () . longname (), listener_class = PasteMethodListener , has_write = True , source_class = target_class . simplename (), method_content = listener . method_content , import_statements = listener . import_statements , debug = False ) db . close ()","title":"main()"},{"location":"refactorings/rename_method/","text":"Rename method RenameMethodListener Introduction When the name of a method does not explain what the method does (method's functionality), it needs to be changed. Pre and Post Conditions Pre Conditions: User must enter the existing method's name, The source class's name for the refactoring, and the new method name in order to rename. Check if the method exist, then rename it. Post Conditions: After refactoring, all the old method names in the project should be changed. See whether the method is defined in a superclass or subclass. If so, you must repeat all steps in these classes too. The next method is important for maintaining the functionality of the program during the refactoring process. Create a new method with a new name. Copy the code of the old method to it. Delete all the code in the old method and, instead of it, insert a call for the new method. Find all references to the old method and replace them with references to the new one. Delete the old method. If the old method is part of a public interface, don\u2019t perform this step. Instead, mark the old method as deprecated. __init__ ( self , java_file_path , common_token_stream , scope_class_name , target_method_name , new_name , reference = None ) special The Main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required scope_class_name(str) Name of the class in which the refactoring has to be done required target_method_name(str) Name of the method in which the refactoring has to be done required new_name(str) The new name of the refactored method required Returns: Type Description No returns Source code in refactorings\\rename_method.py def __init__ ( self , java_file_path , common_token_stream , scope_class_name , target_method_name , new_name , reference = None ): \"\"\"The Main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Args: java_file_path(str): Address path to the test/source file scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method Returns: No returns \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . class_name = scope_class_name self . method_name = target_method_name self . new_method_name = new_name self . in_class = False self . changed = False self . reference = reference get_method_calls ( udb_path , scope_class_name , new_name ) Finds all of the refactored method calls in the database file and returns all of the correct references !!! args udb_path (str): Address path to the database file scope_class_name (str): Name of the class in which the refactoring has to be done new_name (str): The new name of the refactored method !!! returns References Source code in refactorings\\rename_method.py def get_method_calls ( udb_path , scope_class_name , new_name ): # Open Database \"\"\"Finds all of the refactored method calls in the database file and returns all of the correct references Args: udb_path (str): Address path to the database file scope_class_name (str): Name of the class in which the refactoring has to be done new_name (str): The new name of the refactored method Returns: References \"\"\" if not os . path . exists ( path = udb_path ): raise ValueError ( \"Database file does not exist!\" ) db = und . open ( udb_path ) method_scope = scope_class_name + \".\" + new_name references = [] # Find All Method Calls for ent in sorted ( db . ents (), key = lambda ent : ent . name ()): for ref in ent . refs ( refkindstring = \"Call\" ): scope = str ( ref . ent ()) if scope == method_scope : references . append ({ \"scope\" : str ( ref . scope ()), \"file_name\" : str ( ref . file ()), \"file_path\" : str ( ref . file () . longname ()), \"line\" : ref . line (), \"column\" : ref . column () }) db . close () return references rename_method ( java_file_path , scope_class_name , target_method_name , new_name , reference = None ) Main Entry Point to the Listener and Tree Walker Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required scope_class_name(str) Name of the class in which the refactoring has to be done required target_method_name(str) Name of the method in which the refactoring has to be done required new_name(str) The new name of the refactored method required reference(str) Keeping track for all of the method references in the project scope required Returns: Type Description No Returns Source code in refactorings\\rename_method.py def rename_method ( java_file_path , scope_class_name , target_method_name , new_name , reference = None ): \"\"\"Main Entry Point to the Listener and Tree Walker Args: java_file_path(str): Address path to the test/source file scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method reference(str): Keeping track for all of the method references in the project scope Returns: No Returns \"\"\" stream = FileStream ( java_file_path ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = RenameMethodListener ( java_file_path = java_file_path , common_token_stream = tokens , scope_class_name = scope_class_name , target_method_name = target_method_name , new_name = new_name , reference = reference ) walker = ParseTreeWalker () walker . walk ( listener , tree ) if listener . changed : print ( java_file_path ) new_file = open ( file = java_file_path , mode = 'w' ) new_file . write ( listener . token_stream_rewriter . getDefaultText () . replace ( ' \\r ' , '' ))","title":"Rename method"},{"location":"refactorings/rename_method/#rename-method","text":"","title":"Rename method"},{"location":"refactorings/rename_method/#refactorings.rename_method.RenameMethodListener","text":"","title":"RenameMethodListener"},{"location":"refactorings/rename_method/#refactorings.rename_method.RenameMethodListener--introduction","text":"When the name of a method does not explain what the method does (method's functionality), it needs to be changed.","title":"Introduction"},{"location":"refactorings/rename_method/#refactorings.rename_method.RenameMethodListener--pre-and-post-conditions","text":"","title":"Pre and Post Conditions"},{"location":"refactorings/rename_method/#refactorings.rename_method.RenameMethodListener--pre-conditions","text":"User must enter the existing method's name, The source class's name for the refactoring, and the new method name in order to rename. Check if the method exist, then rename it.","title":"Pre Conditions:"},{"location":"refactorings/rename_method/#refactorings.rename_method.RenameMethodListener--post-conditions","text":"After refactoring, all the old method names in the project should be changed. See whether the method is defined in a superclass or subclass. If so, you must repeat all steps in these classes too. The next method is important for maintaining the functionality of the program during the refactoring process. Create a new method with a new name. Copy the code of the old method to it. Delete all the code in the old method and, instead of it, insert a call for the new method. Find all references to the old method and replace them with references to the new one. Delete the old method. If the old method is part of a public interface, don\u2019t perform this step. Instead, mark the old method as deprecated.","title":"Post Conditions:"},{"location":"refactorings/rename_method/#refactorings.rename_method.RenameMethodListener.__init__","text":"The Main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required scope_class_name(str) Name of the class in which the refactoring has to be done required target_method_name(str) Name of the method in which the refactoring has to be done required new_name(str) The new name of the refactored method required Returns: Type Description No returns Source code in refactorings\\rename_method.py def __init__ ( self , java_file_path , common_token_stream , scope_class_name , target_method_name , new_name , reference = None ): \"\"\"The Main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Args: java_file_path(str): Address path to the test/source file scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method Returns: No returns \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . class_name = scope_class_name self . method_name = target_method_name self . new_method_name = new_name self . in_class = False self . changed = False self . reference = reference","title":"__init__()"},{"location":"refactorings/rename_method/#refactorings.rename_method.get_method_calls","text":"Finds all of the refactored method calls in the database file and returns all of the correct references !!! args udb_path (str): Address path to the database file scope_class_name (str): Name of the class in which the refactoring has to be done new_name (str): The new name of the refactored method !!! returns References Source code in refactorings\\rename_method.py def get_method_calls ( udb_path , scope_class_name , new_name ): # Open Database \"\"\"Finds all of the refactored method calls in the database file and returns all of the correct references Args: udb_path (str): Address path to the database file scope_class_name (str): Name of the class in which the refactoring has to be done new_name (str): The new name of the refactored method Returns: References \"\"\" if not os . path . exists ( path = udb_path ): raise ValueError ( \"Database file does not exist!\" ) db = und . open ( udb_path ) method_scope = scope_class_name + \".\" + new_name references = [] # Find All Method Calls for ent in sorted ( db . ents (), key = lambda ent : ent . name ()): for ref in ent . refs ( refkindstring = \"Call\" ): scope = str ( ref . ent ()) if scope == method_scope : references . append ({ \"scope\" : str ( ref . scope ()), \"file_name\" : str ( ref . file ()), \"file_path\" : str ( ref . file () . longname ()), \"line\" : ref . line (), \"column\" : ref . column () }) db . close () return references","title":"get_method_calls()"},{"location":"refactorings/rename_method/#refactorings.rename_method.rename_method","text":"Main Entry Point to the Listener and Tree Walker Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required scope_class_name(str) Name of the class in which the refactoring has to be done required target_method_name(str) Name of the method in which the refactoring has to be done required new_name(str) The new name of the refactored method required reference(str) Keeping track for all of the method references in the project scope required Returns: Type Description No Returns Source code in refactorings\\rename_method.py def rename_method ( java_file_path , scope_class_name , target_method_name , new_name , reference = None ): \"\"\"Main Entry Point to the Listener and Tree Walker Args: java_file_path(str): Address path to the test/source file scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method reference(str): Keeping track for all of the method references in the project scope Returns: No Returns \"\"\" stream = FileStream ( java_file_path ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = RenameMethodListener ( java_file_path = java_file_path , common_token_stream = tokens , scope_class_name = scope_class_name , target_method_name = target_method_name , new_name = new_name , reference = reference ) walker = ParseTreeWalker () walker . walk ( listener , tree ) if listener . changed : print ( java_file_path ) new_file = open ( file = java_file_path , mode = 'w' ) new_file . write ( listener . token_stream_rewriter . getDefaultText () . replace ( ' \\r ' , '' ))","title":"rename_method()"},{"location":"tutorials/antlr_advanced/","text":"ANTLR advanced tutorials By: Morteza Zakeri Last update: April 30, 2022 Compiler background We first define some terms used in compiler literature when analyzing the program based on the ANTLR vocabulary. Compiler pass. Each time that the walk method of ParseTreeWalker class is called, it visits all nodes of the parse tree. In compiler literature, we called this process a pass. The ANTLR pass can be annotated with listener classes to perform specific analysis or transformation. An analysis pass refers to the pass in which some information is obtained from the source code, but the source code is not changed, or no new code is generated. A transformation pass refers to the pass in which the program source code is modified or new codes are generated. As we discussed in the next sections, refactoring automation consists of both the analysis and transformation passes. Single v.s. multiple pass. Often to perform specific analyses or transformations, the program should be visited multiple times. Indeed, such tasks required multiple passes. For instance, if a class attribute is defined after it is used in a method, which is possible in Java programming language, to find the definition of the field and then modify its usage, we should visit the program twice. The reason is that the program tokens are read from left to right, and then when traversing the parse tree, the node only is visited once in the order they appear in the program text. For a given task, if we visit a node and require the information obtained from the next nodes, we cannot complete the task in one pass. In such a case, a pass is required to obtain the necessary information from the next nodes, and another pass is required to use this information for the current node. Most refactoring operations we described in this chapter require multiple passes to complete the refactoring process. For each pass, we develop a separate listener class and pass it to ParseTreeWalker class.","title":"ANTLR advanced"},{"location":"tutorials/antlr_advanced/#antlr-advanced-tutorials","text":"By: Morteza Zakeri Last update: April 30, 2022","title":"ANTLR advanced tutorials"},{"location":"tutorials/antlr_advanced/#compiler-background","text":"We first define some terms used in compiler literature when analyzing the program based on the ANTLR vocabulary. Compiler pass. Each time that the walk method of ParseTreeWalker class is called, it visits all nodes of the parse tree. In compiler literature, we called this process a pass. The ANTLR pass can be annotated with listener classes to perform specific analysis or transformation. An analysis pass refers to the pass in which some information is obtained from the source code, but the source code is not changed, or no new code is generated. A transformation pass refers to the pass in which the program source code is modified or new codes are generated. As we discussed in the next sections, refactoring automation consists of both the analysis and transformation passes. Single v.s. multiple pass. Often to perform specific analyses or transformations, the program should be visited multiple times. Indeed, such tasks required multiple passes. For instance, if a class attribute is defined after it is used in a method, which is possible in Java programming language, to find the definition of the field and then modify its usage, we should visit the program twice. The reason is that the program tokens are read from left to right, and then when traversing the parse tree, the node only is visited once in the order they appear in the program text. For a given task, if we visit a node and require the information obtained from the next nodes, we cannot complete the task in one pass. In such a case, a pass is required to obtain the necessary information from the next nodes, and another pass is required to use this information for the current node. Most refactoring operations we described in this chapter require multiple passes to complete the refactoring process. For each pass, we develop a separate listener class and pass it to ParseTreeWalker class.","title":"Compiler background"},{"location":"tutorials/antlr_basics/","text":"ANTLR basic tutorials By: Morteza Zakeri Last update: April 30, 2022 Introduction The ANTLR tool generates a top-down parser from the grammar rules defined with the ANTLR meta-grammar (Parr and Fisher 2011). The initial version of ANTLR generated the target parser source code in Java. In the current version (version 4), the parser source code can be generated in a wide range of programming languages listed on the ANTLR official website (Parr 2022a). For simplicity, we generate the parser in Python 3, which provides us to run the tool on every platform having Python 3 installed on it. Another reason to use Python is that we can integrate the developed program easily with other libraries available in Python, such as machine learning and optimization libraries. Finally, I found that there is no comprehensive tutorial on using ANTLR with the Python backend. To use ANTLR in other programming languages, specifically Java and C#, refer to the ANTLR slides I created before this tutorial. The ANTLR tool is a small \u201c.jar\u201d file that must be run from the command line to generate the parser codes. The ANTLR tool jar file can be downloaded from here . Generating parser As mentioned, to generate a parser for a programming language, the grammar specification described with ANTLR meta-grammar is required. ANTLR grammar files are named with the \u201c.g4\u201d suffix. We obtain the grammar of Java 8 to build our parser for the Java programming language. The grammar can be downloaded from ANTLR 4 grammar repository on GitHub: https://github.com/antlr/grammars-v4 . Once the ANTLR tool and required grammar files are prepared, we can generate the parser for that with the following command: > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -o . JavaLexer.g4 > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -visitor -listener -o . JavaLabeledParser.g4 The first command generates the lexer from the JavaLexer.g4 description file and the second command generates the parser from the JavaLabeledParser.g4 description file. It is worth noting that the lexer and parser can be written in one file. In such a case, a single command generates all required codes in one step. The grammar files used in the above command are also available in grammars directory of the CodART repository. You may see that I have made some modifications to the Parser rules. In the above commands, the antlr-4.9.3-complete.jar is the ANTLR tool that requires Java to be executed. -Dlanguage denotes the destination language that the ANTLR parser (and lexer) source code is generated in which. In our case, we set it to Python3. After executing the ANTLR parser generation commands, eight files, including parser source code and other required information, are generated. Figure 1 shows the generated files. The \u201c.py\u201d contains lexer and parser source code that can parse any Java input file. The -visitor -listener switches in the second command result in generating two separate source files, JavaLabledParserListener.py and JavaLabledParserVistor.py , which provide interfaces to implement the required codes for a specific language application. Our application is source code refactoring which uses the listener mechanism to implement necessary actions transforming the program to the refactored version. The parse tree structure in and listener mechanism are discussed in the next sections. Figure 1. Generated files by ANTLR. It should be noted that to use the generated classes in Figure 1, for developing a specific program, we need to install the appropriate ANTLR runtime library. For creating ANTLR-based programs in Python, the command pip install antlr-python3-runtime can be used. It installed all runtime dependencies required to program using the ANTLR library. ANTLR parse tree The generated parser by ANTLR is responsible for parsing every Java source code file and generating the parse tree or designating the syntax errors in the input file. The parse tree for real-world programs with thousands of lines of code has a non-trivial structure. ANTLR developers have provided some IDE plugins that can visualize the parse tree to better understand the structure of the parse tree generated by ANTLR. We use Pycharm IDE developed by Jetbrains to work with Python code. Figure 2 shows how we can install the ANTLR plugin in PyCharm. The plugin source code is available on the GitHub repo . When the plugin is installed, the ANTLR preview widow is applied at the bottom of the PyCharm IDE. In addition, the IDE can be recognized as \u201c.g4\u201d files and some other options added to the IDE. The main option is the ability to test a grammar rule and visualize the corresponding parse tree to that rule. Figure 2. Installing the ANTLR plugin in the PyCharm IDE. In order to use the ANTLR preview tab, the ANTLR grammar should be opened in the PyCharm IDE. We then select a rule (typically the start rule) of our grammar, right-click on the rule, and select the \u201cTest Rule rule_name \u201d option from the opened menu, shown in Figure 3. We now write our sample input program in the left panel of the ANTLR preview, and the parse tree is shown in the right panel. Figure 3. Test the grammar rule in the ANTLR PyCharm plugin. Figure 4 shows a simple Java class and the corresponding parse tree generated by the ANTLR. The leaves of the parse tree are program tokens, while the intermediate nodes are grammar rules that the evaluating program is derived from them. Also, the root of the tree is the grammar rule, which we selected to start parsing. It means that we can select and test every rule independently. However, a complete Java program can only parse from the start rule of the given grammar, i.e., the compilaionUnit rule. Figure 4. Test the grammar rule in the ANTLR PyCharm plugin. It should be mentioned that the ANTLR Preview window is based on a grammar interpreter, not on the actual generated parser described in the previous section. It means that grammar attributes such as actions and predicates will not be evaluated during live preview because the interpreter is language agnostic. For the same reasons, if the generated parser and/or lexer classes extend a custom implementation of the base parser/lexer classes, the custom code will not be run during the live preview. In addition to the parse tree visualization, the ANTLR plugin provides facilities such as profiling, code generation, etc., described in here (Parr 2022b). For example, the profile tab shows the execution time of each rule in the parser for a given input string. I want to emphasize that visualizing the parse tree with the ANTLR plugin is really helpful when developing code and fixing bugs described in the next section of this tutorial. Traversing the parse tree programmatically ANTLR is not a simple parser generator. It provides a depth-first parse tree visiting and a callback mechanism called listener to implement the required program analysis or transformation passes. The depth-first search is performed by instantiating an object from the ANTLR ParseTreeWalker class and calling the walk method, which takes an instance of ParseTree as an input argument and traverses it. Obviously, if we visit the parse tree with the depth-first search algorithm, all program tokens are visited in the same order that they appeared in the source code file. However, the depth-first search contains additional information about when a node in the tree is visited and when the visiting all nodes in its subtree is finished. Therefore, we can add the required actions when visiting a node to perform a special task. For example, according to Figure 4, for counting the number of classes in a code snippet, we can define a counter variable, initialize it to zero, and increase it whenever the walker visits the \u201cclassDeclartion\u201d node. ANTLR provides two callback functions for each node in the parse tree. One is called by the walker when it is entered into a node, i.e., visit the node, but the children are not visited yet. Another is called when all nodes in the subtree of the visited node have been visited, and the walker is exiting the node. These callback functions are available in the listener class generated by the ANTLR for every rule in a given grammar. In our example for counting the number of classes, we implement all required logic in the body of enterClassDeclartion method of the JavaLabledParserListener class. We called these logic codes grammar\u2019s actions since, indeed, they are bunded to a grammar rule. It is worth noting that we can add these actions codes in the grammar file ( .g4 file) to form an attributed grammar. Embedding actions in grammar increase the efficiency of the analyzing process. However, when we need many complex actions, the listener mechanism provides a better way to implement them. Indeed, ANTLR 4 emphasizes separating the language applications from the language grammar by using the listener mechanism. Listing 1 shows the implementation program for counting the number of classes using the ANTLR listener mechanism. The DesignMetrics class inherits from JavaLabeledParserListener class which is the default listener class generated by ANTLR. We only implement the enterClassDeclartion method, which increases the value of the __dsc counter each time the walker visits a Java class. # module: JavaLabledParserListener.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * if __name__ is not None and \".\" in __name__: from .JavaLabeledParser import JavaLabeledParser else: from JavaLabeledParser import JavaLabeledParser class JavaLabeledParserListener(ParseTreeListener): # \u2026 def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): pass # \u2026 class DesignMetrics(JavaLabeledParserListener): def __init__(self): self.__dsc:int = 0 # Keep design size in classes @property def get_design_size(self): return self.__dsc def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): self.__dsc += 1 Listing 1: Programs that count the number of classes in a Java source code. Wiring the modules To complete our simple analysis task, first, the parse tree for a given input should be constructed. Then, the DesignMetrics class should be instantiated and passed to an object of ParseTreeWalker class. We created a driver module in Python beside the generated code by ANTLR to connect different parts of our program and complete our task. Listing 2 shows the implementation of the main driver for a program that counts the number of classes in Java source codes. # Module: main_driver.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * from JavaLabledLexer import JavaLabledLexer from JavaLeabledParser import JavaLabledParser from JavaLabledParserListener import DesignMetrics def main(args): # Step 1: Load input source into the stream object stream = FileStream(args.file, encoding='utf8') # Step 2: Create an instance of AssignmentStLexer lexer = JavaLabledLexer(stream) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream(lexer) # Step 4: Create an instance of the AssignmentStParser parser = JavaLabledParser(token_stream) # Step 5: Create parse tree parse_tree = parser.compilationUnit() # Step 6: Create an instance of DesignMetrics listener class my_listener = DesignMetrics() # Step 7: Create a walker to traverse the parse tree and callback our listener walker = ParseTreeWalker() walker.walk(t=parse_tree, listener=my_listener) # Step 8: Getting the results print(f'DSC={my_listener.get_design_size}') Listing 2: Main driver module for the program in Listing 1 Conclusion and remarks In this tutorial, we described the basic concepts regarding using the ANTLR tool to generate and walk phase three and implement custom program analysis applications with the help of the ANTLR listener mechanism. The most important point is that we used the real-world programming languages grammars to show the parsing and analyzing process. The discussed topics form the underlying concepts of our approach for automated refactoring used in CodART. Check out the ANTLR advanced tutorial to find out how we can use ANTLR for reliable and efficient program transformation. References Parr T ANTLR (ANother Tool for Language Recognition). https://www.antlr.org. Accessed 10 Jan 2022a Parr T IntelliJ Idea Plugin for ANTLR v4. https://github.com/antlr/intellij-plugin-v4. Accessed 10 Jan 2022b Parr T, Fisher K (2011) LL(*): the foundation of the ANTLR parser generator. Proc 32nd ACM SIGPLAN Conf Program Lang Des Implement 425\u2013436. https://doi.org/http://doi.acm.org/10.1145/1993498.1993548","title":"ANTLR basics"},{"location":"tutorials/antlr_basics/#antlr-basic-tutorials","text":"By: Morteza Zakeri Last update: April 30, 2022","title":"ANTLR basic tutorials"},{"location":"tutorials/antlr_basics/#introduction","text":"The ANTLR tool generates a top-down parser from the grammar rules defined with the ANTLR meta-grammar (Parr and Fisher 2011). The initial version of ANTLR generated the target parser source code in Java. In the current version (version 4), the parser source code can be generated in a wide range of programming languages listed on the ANTLR official website (Parr 2022a). For simplicity, we generate the parser in Python 3, which provides us to run the tool on every platform having Python 3 installed on it. Another reason to use Python is that we can integrate the developed program easily with other libraries available in Python, such as machine learning and optimization libraries. Finally, I found that there is no comprehensive tutorial on using ANTLR with the Python backend. To use ANTLR in other programming languages, specifically Java and C#, refer to the ANTLR slides I created before this tutorial. The ANTLR tool is a small \u201c.jar\u201d file that must be run from the command line to generate the parser codes. The ANTLR tool jar file can be downloaded from here .","title":"Introduction"},{"location":"tutorials/antlr_basics/#generating-parser","text":"As mentioned, to generate a parser for a programming language, the grammar specification described with ANTLR meta-grammar is required. ANTLR grammar files are named with the \u201c.g4\u201d suffix. We obtain the grammar of Java 8 to build our parser for the Java programming language. The grammar can be downloaded from ANTLR 4 grammar repository on GitHub: https://github.com/antlr/grammars-v4 . Once the ANTLR tool and required grammar files are prepared, we can generate the parser for that with the following command: > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -o . JavaLexer.g4 > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -visitor -listener -o . JavaLabeledParser.g4 The first command generates the lexer from the JavaLexer.g4 description file and the second command generates the parser from the JavaLabeledParser.g4 description file. It is worth noting that the lexer and parser can be written in one file. In such a case, a single command generates all required codes in one step. The grammar files used in the above command are also available in grammars directory of the CodART repository. You may see that I have made some modifications to the Parser rules. In the above commands, the antlr-4.9.3-complete.jar is the ANTLR tool that requires Java to be executed. -Dlanguage denotes the destination language that the ANTLR parser (and lexer) source code is generated in which. In our case, we set it to Python3. After executing the ANTLR parser generation commands, eight files, including parser source code and other required information, are generated. Figure 1 shows the generated files. The \u201c.py\u201d contains lexer and parser source code that can parse any Java input file. The -visitor -listener switches in the second command result in generating two separate source files, JavaLabledParserListener.py and JavaLabledParserVistor.py , which provide interfaces to implement the required codes for a specific language application. Our application is source code refactoring which uses the listener mechanism to implement necessary actions transforming the program to the refactored version. The parse tree structure in and listener mechanism are discussed in the next sections. Figure 1. Generated files by ANTLR. It should be noted that to use the generated classes in Figure 1, for developing a specific program, we need to install the appropriate ANTLR runtime library. For creating ANTLR-based programs in Python, the command pip install antlr-python3-runtime can be used. It installed all runtime dependencies required to program using the ANTLR library.","title":"Generating parser"},{"location":"tutorials/antlr_basics/#antlr-parse-tree","text":"The generated parser by ANTLR is responsible for parsing every Java source code file and generating the parse tree or designating the syntax errors in the input file. The parse tree for real-world programs with thousands of lines of code has a non-trivial structure. ANTLR developers have provided some IDE plugins that can visualize the parse tree to better understand the structure of the parse tree generated by ANTLR. We use Pycharm IDE developed by Jetbrains to work with Python code. Figure 2 shows how we can install the ANTLR plugin in PyCharm. The plugin source code is available on the GitHub repo . When the plugin is installed, the ANTLR preview widow is applied at the bottom of the PyCharm IDE. In addition, the IDE can be recognized as \u201c.g4\u201d files and some other options added to the IDE. The main option is the ability to test a grammar rule and visualize the corresponding parse tree to that rule. Figure 2. Installing the ANTLR plugin in the PyCharm IDE. In order to use the ANTLR preview tab, the ANTLR grammar should be opened in the PyCharm IDE. We then select a rule (typically the start rule) of our grammar, right-click on the rule, and select the \u201cTest Rule rule_name \u201d option from the opened menu, shown in Figure 3. We now write our sample input program in the left panel of the ANTLR preview, and the parse tree is shown in the right panel. Figure 3. Test the grammar rule in the ANTLR PyCharm plugin. Figure 4 shows a simple Java class and the corresponding parse tree generated by the ANTLR. The leaves of the parse tree are program tokens, while the intermediate nodes are grammar rules that the evaluating program is derived from them. Also, the root of the tree is the grammar rule, which we selected to start parsing. It means that we can select and test every rule independently. However, a complete Java program can only parse from the start rule of the given grammar, i.e., the compilaionUnit rule. Figure 4. Test the grammar rule in the ANTLR PyCharm plugin. It should be mentioned that the ANTLR Preview window is based on a grammar interpreter, not on the actual generated parser described in the previous section. It means that grammar attributes such as actions and predicates will not be evaluated during live preview because the interpreter is language agnostic. For the same reasons, if the generated parser and/or lexer classes extend a custom implementation of the base parser/lexer classes, the custom code will not be run during the live preview. In addition to the parse tree visualization, the ANTLR plugin provides facilities such as profiling, code generation, etc., described in here (Parr 2022b). For example, the profile tab shows the execution time of each rule in the parser for a given input string. I want to emphasize that visualizing the parse tree with the ANTLR plugin is really helpful when developing code and fixing bugs described in the next section of this tutorial.","title":"ANTLR parse tree"},{"location":"tutorials/antlr_basics/#traversing-the-parse-tree-programmatically","text":"ANTLR is not a simple parser generator. It provides a depth-first parse tree visiting and a callback mechanism called listener to implement the required program analysis or transformation passes. The depth-first search is performed by instantiating an object from the ANTLR ParseTreeWalker class and calling the walk method, which takes an instance of ParseTree as an input argument and traverses it. Obviously, if we visit the parse tree with the depth-first search algorithm, all program tokens are visited in the same order that they appeared in the source code file. However, the depth-first search contains additional information about when a node in the tree is visited and when the visiting all nodes in its subtree is finished. Therefore, we can add the required actions when visiting a node to perform a special task. For example, according to Figure 4, for counting the number of classes in a code snippet, we can define a counter variable, initialize it to zero, and increase it whenever the walker visits the \u201cclassDeclartion\u201d node. ANTLR provides two callback functions for each node in the parse tree. One is called by the walker when it is entered into a node, i.e., visit the node, but the children are not visited yet. Another is called when all nodes in the subtree of the visited node have been visited, and the walker is exiting the node. These callback functions are available in the listener class generated by the ANTLR for every rule in a given grammar. In our example for counting the number of classes, we implement all required logic in the body of enterClassDeclartion method of the JavaLabledParserListener class. We called these logic codes grammar\u2019s actions since, indeed, they are bunded to a grammar rule. It is worth noting that we can add these actions codes in the grammar file ( .g4 file) to form an attributed grammar. Embedding actions in grammar increase the efficiency of the analyzing process. However, when we need many complex actions, the listener mechanism provides a better way to implement them. Indeed, ANTLR 4 emphasizes separating the language applications from the language grammar by using the listener mechanism. Listing 1 shows the implementation program for counting the number of classes using the ANTLR listener mechanism. The DesignMetrics class inherits from JavaLabeledParserListener class which is the default listener class generated by ANTLR. We only implement the enterClassDeclartion method, which increases the value of the __dsc counter each time the walker visits a Java class. # module: JavaLabledParserListener.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * if __name__ is not None and \".\" in __name__: from .JavaLabeledParser import JavaLabeledParser else: from JavaLabeledParser import JavaLabeledParser class JavaLabeledParserListener(ParseTreeListener): # \u2026 def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): pass # \u2026 class DesignMetrics(JavaLabeledParserListener): def __init__(self): self.__dsc:int = 0 # Keep design size in classes @property def get_design_size(self): return self.__dsc def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): self.__dsc += 1 Listing 1: Programs that count the number of classes in a Java source code.","title":"Traversing the parse tree programmatically"},{"location":"tutorials/antlr_basics/#wiring-the-modules","text":"To complete our simple analysis task, first, the parse tree for a given input should be constructed. Then, the DesignMetrics class should be instantiated and passed to an object of ParseTreeWalker class. We created a driver module in Python beside the generated code by ANTLR to connect different parts of our program and complete our task. Listing 2 shows the implementation of the main driver for a program that counts the number of classes in Java source codes. # Module: main_driver.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * from JavaLabledLexer import JavaLabledLexer from JavaLeabledParser import JavaLabledParser from JavaLabledParserListener import DesignMetrics def main(args): # Step 1: Load input source into the stream object stream = FileStream(args.file, encoding='utf8') # Step 2: Create an instance of AssignmentStLexer lexer = JavaLabledLexer(stream) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream(lexer) # Step 4: Create an instance of the AssignmentStParser parser = JavaLabledParser(token_stream) # Step 5: Create parse tree parse_tree = parser.compilationUnit() # Step 6: Create an instance of DesignMetrics listener class my_listener = DesignMetrics() # Step 7: Create a walker to traverse the parse tree and callback our listener walker = ParseTreeWalker() walker.walk(t=parse_tree, listener=my_listener) # Step 8: Getting the results print(f'DSC={my_listener.get_design_size}') Listing 2: Main driver module for the program in Listing 1","title":"Wiring the modules"},{"location":"tutorials/antlr_basics/#conclusion-and-remarks","text":"In this tutorial, we described the basic concepts regarding using the ANTLR tool to generate and walk phase three and implement custom program analysis applications with the help of the ANTLR listener mechanism. The most important point is that we used the real-world programming languages grammars to show the parsing and analyzing process. The discussed topics form the underlying concepts of our approach for automated refactoring used in CodART. Check out the ANTLR advanced tutorial to find out how we can use ANTLR for reliable and efficient program transformation.","title":"Conclusion and remarks"},{"location":"tutorials/antlr_basics/#references","text":"Parr T ANTLR (ANother Tool for Language Recognition). https://www.antlr.org. Accessed 10 Jan 2022a Parr T IntelliJ Idea Plugin for ANTLR v4. https://github.com/antlr/intellij-plugin-v4. Accessed 10 Jan 2022b Parr T, Fisher K (2011) LL(*): the foundation of the ANTLR parser generator. Proc 32nd ACM SIGPLAN Conf Program Lang Des Implement 425\u2013436. https://doi.org/http://doi.acm.org/10.1145/1993498.1993548","title":"References"},{"location":"tutorials/antlr_slides/","text":"ANTLR slides Introduction to ANTLR: Part I Antlr part1 introduction from Morteza Zakeri Introduction to ANTLR: Part II Antlr part2 getting_started_in_java from Morteza Zakeri Introduction to ANTLR: Part III Antlr part3 getting_started_in_c_sharp from Morteza Zakeri","title":"ANTLR slides"},{"location":"tutorials/antlr_slides/#antlr-slides","text":"","title":"ANTLR slides"},{"location":"tutorials/antlr_slides/#introduction-to-antlr-part-i","text":"Antlr part1 introduction from Morteza Zakeri","title":"Introduction to ANTLR: Part I"},{"location":"tutorials/antlr_slides/#introduction-to-antlr-part-ii","text":"Antlr part2 getting_started_in_java from Morteza Zakeri","title":"Introduction to ANTLR: Part II"},{"location":"tutorials/antlr_slides/#introduction-to-antlr-part-iii","text":"Antlr part3 getting_started_in_c_sharp from Morteza Zakeri","title":"Introduction to ANTLR: Part III"},{"location":"tutorials/refactorings_basics/","text":"Refactoring basic tutorials Please refer to a related blog post Automated Refactoring of the Java Codes using ANTLR in Python .","title":"Refactoring basics"},{"location":"tutorials/refactorings_basics/#refactoring-basic-tutorials","text":"Please refer to a related blog post Automated Refactoring of the Java Codes using ANTLR in Python .","title":"Refactoring basic tutorials"}]}