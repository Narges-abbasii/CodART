{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CodART: Automated Source Code Refactoring Toolkit Morteza Zakeri \u2020 \u2020 Ph.D. Student, Iran University of Science and Technology, Tehran, Iran (m-zakeri@live.com). Version 0.2.3 (25 May 2022) \u251c Download PDF versions v0.1.0 , v0.2.0 Abstract\u2014 Software refactoring is performed by changing the software structure without modifying its external behavior. Many software quality attributes can be enhanced through the source code refactoring, such as reusability, flexibility, understandability, and testability. Refactoring engines are tools that automate the application of refactorings: first, the user chooses a refactoring to apply, then the engine checks if the transformation is safe, and if so, transforms the program. Refactoring engines are a key component of modern Integrated Development Environments (IDEs), and programmers rely on them to perform refactorings. In this project, an open-source software toolkit for refactoring Java source codes, namely CodART, will be developed. ANTLR parser generator is used to create and modify the program syntax-tree and produce the refactored version of the program. To the best of our knowledge, CodART is the first open-source refactoring toolkit based on ANTLR. Index Terms: Software refactoring, refactoring engine, search-based refactoring, ANTLR, Java. 1 Introduction R efactoring is a behavior-preserving program transformation that improves the design of a program. Refactoring engines are tools that automate the application of refactorings. The programmer need only select which refactoring to apply, and the engine will automatically check the preconditions and apply the transformations across the entire program if the preconditions are satisfied. Refactoring is gaining popularity, as evidenced by the inclusion of refactoring engines in modern IDEs such as IntelliJ IDEA , Eclipse , or NetBeans for Java. Considering the EncapsulateField refactoring as an illustrative example. This refactoring replaces all references to a field with accesses through setter and getter methods. The EncapsulateField refactoring takes as input the name of the field to encapsulate and the names of the new getter and setter methods. It performs the following transformations: Creates a public getter method that returns the field's value, Creates a public setter method that updates the field's value, to a given parameter's value, Replaces all field reads with calls to the getter method, Replaces all field writes with calls to the setter method, Changes the field's access modifier to private. The EncapsulateField refactoring checks several preconditions, including that the code does not already contain accessor methods and that these methods are applicable to the expressions in which the field appears. Figure 1 shows a sample program before and after encapsulating the field f into the getF and setF methods. Figure 1. Example EncapsulateField refactoring Refactoring engines must be reliable. A fault in a refactoring engine can silently introduce bugs in the refactored program and lead to challenging debugging sessions. If the original program compiles, but the refactored program does not, the refactoring is obviously incorrect and can be easily undone. However, if the refactoring engine erroneously produces a refactored program that compiles but does not preserve the semantics of the original program, this can have severe consequences. To perform refactoring correctly, the tool has to operate on the syntax tree of the code, not on the text. Manipulating the syntax tree is much more reliable to preserve what the code is doing. Refactoring is not just understanding and updating the syntax tree. The tool also needs to figure out how to rerender the code into text back in the editor view, called code transformation. All in all, implementing decent refactoring is a challenging programming exercise, required compiler knowledge. In this project, we develop CodART, a toolkit for applying a given refactoring on the source code and obtain the refactored code. To this aim, we will use ANTLR [1] to generate and modify the program syntax tree. CodART development consists of two phases: In the first phase, 47 common refactoring operations will be automated, and in the second phase, an algorithm to find the best sequence of refactorings to apply on a given software will be developed using many-objective search-based approaches. The rest of this white-paper is organized as follows. Section 2 describes the refactoring operations in detail. Section 3 explains code smells in detail. Section 4 briefly discusses the search-based refactoring techniques and many-objective evolutionary algorithms. Section 5 explains the implementation details of the current version of CodART. Section 6 lists the Java project used to evaluate CodART. Section 7 articulates the proposals that existed behind the CodART projects. Finally, the conclusion and future works are discussed in Section 8. 2 Refactoring operations This section explains the refactoring operations used in the project. A catalog of 72 refactoring operations has been proposed by Fowler [2]. We called this refactorings atomic refactoring operations. Each refactoring operation has a definition and is clearly specified by the entities in which it is involved and the role of each. Table 1 describes the desirable refactorings, which we aim to automate them. It worth noting that not all of these refactoring operations are introduced by Fowler [2]. A concrete example for most of the refactoring operations in the table is available at https://refactoring.com/catalog/ . Examples of other refactorings can be found at https://refactoring.guru/refactoring/techniques and https://sourcemaking.com/refactoring/refactorings . Table 1. Refactoring operations Refactoring Definition Entities Roles Move class Move a class from a package to another package class source package, target package moved class Move method Move a method from a class to another. class method source class, target class moved method Merge packages Merge the elements of a set of packages in one of them package source package, target package Extract/Split package Add a package to compose the elements of another package package source package, target package Extract class Create a new class and move fields and methods from the old class to the new one class method source class, new class moved methods Extract method Extract a code fragment into a method method statement source method, new method moved statements Inline class Move all features of a class in another one and remove it class source class, target class Move field Move a field from a class to another class field source class, target class field Push down field Move a field of a superclass to a subclass class field super class, sub classes move field Push down method Move a method of a superclass to a subclass class method super class, sub classes moved method Pull up field Move a field from subclasses to the superclass class field sub classes, super class moved field Pull up method Move a method from subclasses to the superclass class method sub classes, super class moved method Increase field visibility Increase the visibility of a field from public to protected, protected to package or package to private class field source class source filed Decrease field visibility Decrease the visibility of a field from private to package, package to protected or protected to public class field source class source filed Make field final Make a non-final field final class field source class source filed Make field non-final Make a final field non-final class field source class source filed Make field static Make a non-static field static class field source class source filed Make field non-static Make a static field non-static class field source class source filed Remove field Remove a field from a class class field source class source filed Increase method visibility Increase the visibility of a method from public to protected, protected to package or package to private class method source class source method Decrease method visibility Decrease the visibility of a method from private to package, package to protected or protected to public class method source class source method Make method final Make a non-final method final class method source class source method Make method non-final Make a final method non-final class method source class source method Make method static Make a non-static method static class method source class source method Make method non-static Make a static method non-static class method source class source method Remove method Remove a method from a class class method source class source method Make class-final Make a non-final class final class source class Make class non-final Make a final class non-final class source class Make class abstract Change a concrete class to abstract class source class Make class concrete Change an abstract class to concrete class source class Extract subclass Create a subclass for a set of features class method source class, new subclass moved methods Extract interface Extract methods of a class into an interface class method source class, new interface interface methods Inline method Move the body of a method into its callers and remove the method method source method, callers method Collapse hierarchy Merge a superclass and a subclass class superclass, subclass Remove control flag Replace control flag with a break class method source class source method Replace nested conditional with guard clauses Replace nested conditional with guard clauses class method source class source method Replace constructor with a factory function Replace constructor with a factory function class source class Replace exception with test Replace exception with precheck class method source class source method Rename field Rename a field class field source class source filed Rename method Rename a method class method source class source method Rename class Rename a class class source class Rename package Rename a package package source package Encapsulate field Create setter/mutator and getter/accessor methods for a private field class field source class source filed Replace parameter with query Replace parameter with query class method source class source method Pull up constructor body Move the constructor class method subclass class, superclass constructor Replace control flag with break Replace control flag with break class method source class source method Remove flag argument Remove flag argument class method source class source method Total 47 \u2014 \u2014 3 Code smells Deciding when and where to start refactoring\u2014and when and where to stop\u2014is just as important to refactoring as knowing how to operate its mechanics [2]. To answer this important question, we should know the refactoring activities. The refactoring process consists of six distinct activities [9]: Identify where the software should be refactored. Determine which refactoring(s) should be applied to the identified places. Guarantee that the applied refactoring preserves behavior. Apply the refactoring. Assess the effect of the refactoring on quality characteristics of the software (e.g., complexity, understandability, maintainability) or the process (e.g., productivity, cost, effort). Maintain the consistency between the refactored program code and other software artifacts (such as documentation, design documents, requirements specifications, tests, etc.). Table 2. Code smells Code smell Descriptions and other names God class The class defines many data members (fields) and methods and exhibits low cohesion. The god class smell occurs when a huge class surrounded by many data classes acts as a controller (i.e., takes most of the decisions and monopolizes the software's functionality). Other names: Blob, large class, brain class. Long method This smell occurs when a method is too long to understand and most presumably perform more than one responsibility. Other names: God method, brain method, large method. Feature envy This smell occurs when a method seems more interested in a class other than the one it actually is in. Data class This smell occurs when a class contains only fields and possibly getters/setters without any behavior (methods). Shotgun surgery This smell characterizes the situation when one kind of change leads to many changes to multiple different classes. When the changes are all over the place, they are hard to find, and it is easy to miss a necessary change. Refused bequest This smell occurs when a subclass rejects some of the methods or properties offered by its superclass. Functional decomposition This smell occurs when the experienced developers coming from procedural languages background write highly procedural and non-object-oriented code in an object-oriented language. Long parameter list This smell occurs when a method accepts a long list of parameters. Such lists are hard to understand and difficult to use. Promiscuous package A package can be considered promiscuous if it contains classes implementing too many features, making it too hard to understand and maintain. As for god class and long method, this smell arises when the package has low cohesion since it manages different responsibilities. Misplaced class A Misplaced Class smell suggests a class that is in a package that contains other classes not related to it. Switch statement This smell occurs when switch statements that switch on type codes are spread across the software system instead of exploiting polymorphism. Spaghetti code This smell refers to an unmaintainable, incomprehensible code without any structure. The smell does not exploit and prevents the use of object-orientation mechanisms and concepts. Divergent change Divergent change occurs when one class is commonly changed in different ways for different reasons. Other names: Multifaceted abstraction Deficient encapsulation This smell occurs when the declared accessibility of one or more members of abstraction is more permissive than actually required. Swiss army knife This smell arises when the designer attempts to provide all possible uses of the class and ends up in an excessively complex class interface. Lazy class Unnecessary abstraction Cyclically-dependent modularization This smell arises when two or more abstractions depend on each other directly or indirectly. Primitive obsession This smell occurs when primitive data types are used where an abstraction encapsulating the primitives could serve better. Speculative generality This smell occurs where abstraction is created based on speculated requirements. It is often unnecessary that makes things difficult to understand and maintain. Message chains A message chain occurs when a client requests another object, that object requests yet another one, and so on. These chains mean that the client is dependent on navigation along with the class structure. Any changes in these relationships require modifying the client. Total 20 4 Search-based refactoring After refactoring operations were automated, we must decide which refactorings souled be performed in order to elevate software quality. The concern about using refactoring operations in Table 1 is whether each one of them has a positive impact on the refactored code quality or not. Finding the right sequence of refactorings to be applied in a software artifact is considered a challenging task since there is a wide range of refactorings. The ideal sequence is, therefore, must correlate to different quality attributes to be improved as a result of applying refactorings. Finding the best refactoring sequence is an optimization problem that can be solved by search techniques in the field known as Search-Based Software Engineering (SBSE) [3]. In this approach, refactorings are applied stochastically to the original software solution, and then the software is measured using a fitness function consisting of one or more software metrics. There are various metric suites available to measure characteristics like cohesion and coupling, but different metrics measure the software in different ways, and thus how they are applied will have a different effect on the outcome. The second phase of this project is to use a many-objective search algorithm to find the best sequence of refactoring on a given project. Recently, many-objective SBSE approach for refactoring [3]\u2013[5] and remodularization, regrouping a set of classes C in terms of packages P, [6] has gained more attention due to its ability to find the best sequence of refactoring operations which is led to the improvement in software quality. Therefore, we first focus on implementing the proposed approach approaches in [3], [5], [6] as fundamental works in this area. Then, we will improve their approach. As a new contribution, we add new refactoring operations and new objective functions to improve the quality attribute of the software. We also evaluate our method on the new software projects which are not used in previous works. 5 Implementation This section describes implementation details of the CodART. It includes CodART architecture, high-level repository directories structure, refactoring automation with ANTLR parser generator, and refactoring recommendation through many-objective search-based software engineering techniques. 5.1 CodART architecture The high-level architecture of CodART is shown in Figure 2. The source code consists of several Python packages and directories. We briefly describe each component in CodART. Figure 2. CodART architecture I. grammars : The directory contains three ANTLR v4 grammars for the Java programming language: Java9_v2.g4 : This grammar was used in the initial version of CodART. The main problem of this grammar is that parsing large source code files is performed very slow due to some decisions used in grammar design. We have switched to the fast grammar JavaParserLabled.g4 . JavaLexer.g4 : The lexer of Java fast grammar. This lexer is used for both fast parsers, i.e., JavaParser.g4 and JavaParserLabeled. JavaParser.g4 : The original parser of Java fast grammar. This parser is currently used in some refactoring. In the future release, this grammar will be replaced with JavaPaseredLabled.g4 . JavaParserLabeled.g4 : This file contains the same JavaParsar.g4 grammar. The only difference is that the rules with more than one extension are labeled with a specific name. The ANTLR parser generator thus generates separate visitor and listener methods for each extension. This grammar facilitates the development of some refactoring. It is the preferred parser in CodART project. II. codart.gen : The codart.gen packages contain all generated source code for the parser, lexer, visitor, and listener for different grammars available in the grammars' directory. To develop refactorings and code smells, codart.gen.JavaLabled package, which contains JavaParserLabled.g4 generated source code, must be used. The content of this package is generated automatically , and therefore it should not be modified manually . Modules within this gen package are just for importing and using in other modules. III. speedy : The python implementation for ANTLR is less efficient than Java or C++ implementation. The speedy component implements a Java parser with a C++ back-end, improving the efficiency and speed of parsing. It uses speedy-antlr implementation with some minor changes. The current version of the speedy module use java9_v2.g4 grammar, which inherently slow as described. To switch to C++ back-end, first, the speedy module must be installed on the client system. It requires a C++ compiler. We recommended to CodART developers using the Python back-end as switching to C++ back-end would be done transparently in the future release. The Python back-end saves debugging and developing time. IV. codart.refactorings : The codart.refactorings package is the main package in the CodART project and contains numerous Python modules that form the kernel functionalities of CodART. Each module implements the automation of one refactoring operation according to standard practices. The modules may include several classes which inherit from ANTLR listeners. Sub-packages in this module contain refactorings, which are in an early step of development or deprecated version of an existing refactoring. This package is under active development and testing. The module in the root packages can be used for testing purposes. V. codart.refactoring_design_patters : The codart.refactoring_design_pattern package contain modules that implement refactoring to a specific design pattern automatically. VI. codart.smells : The codart.smells package implements the automatic detection of software code and design smells relevant to the refactoring operation supported by CodART. Each smell corresponds to one or more refactoring in the refactoring package. VII. codart.metrics : The codart.metrics packages contain several modules that implement the computation of the most well-known source code metrics. These metrics used to detect code smells and measuring the quality of software in terms of quality attributed. VIII. codart.sbse : The codart.sbse packages include scripts that implement the search-based refactoring processes. It mainly uses Pymoo multi-objective framework to find the best sequence of refactoring operations to maximize the source code and design quality. IX. tests : The test directory contains individual test data and test cases that are used for developing specific refactorings. Typically, each test case is a single Java file that contains one or more Java classes. X. benchmark_projects : This directory contains several open-source Java projects formerly used in automated refactoring researches by many researchers. Once the implementation of refactoring is completed, it will be executed and tested on all projects in this benchmark to ensure the generalization of functionality proposed by the implementation. XI. Other packages : The information of other packages will be announced in the future. 5.2 Refactoring automation Each refactoring operation in Table 1 is implemented as an API, with the refactoring name. The API receives the involved entities with their refactoring roles and other required data as inputs, checks the feasibility of the refactoring using refactoring preconditions described in [2], performs the refactoring if it is feasible, and returns the refactored code or return null if the refactoring is not feasible. The core of our refactoring engine is a syntax-tree modification algorithm. Fundamentally, ANTLR is used to generate and modify the syntax-tree of a given program. Each refactoring API is an ANTLR Listener or visitor class, which required argument by its constructor and preform refactoring when call by parse-tree walker object. The refactoring target and input parameters must read from a configuration file, which can be expressed in JSON, XML, or YAML formats. The key to use ANTLR for refactoring tasks is the TokenStreamRewriter object that knows how to give altered views of a token stream without actually modifying the stream. It treats all of the manipulation methods as \"instructions\" and queues them up for lazy execution when traversing the token stream to render it back as text. The rewriter executes those instructions every time we call getText() . This strategy is very effective for the general problem of source code instrumentation or refactoring. The TokenStreamRewriter is a powerful and extremely efficient means of manipulating a token stream. 5.3 Refactoring recommendation A solution consists of a sequence of n refactoring operations applied to different code elements in the source code to fix. In order to represent a candidate solution (individual/chromosome), we use a vector-based representation. Each vector\u2019s dimension represents a refactoring operation where the order of applying these refactoring operations corresponds to their positions in the vector. The initial population is generated by randomly assigning a sequence of refactorings to some code fragments. Each generated refactoring solution is executed on the software system S . Once all required data is computed, the solution is evaluated based on the quality of the resulting design. 6 Benchmark projects and testbed To ensure CodART works properly, we are running it on many real-life software projects. Refactorings are applied to the software systems listed in Table 3. Benchmark projects may update and extend in the future. For the time being, we use a set of well-known open-source Java projects that have been intensely studied in previous works. We have also added two new Java software programs, WEKA and ANTLR, to examine the versatility of CodART performance on real-life software projects. Table 3. Software systems refactored in this project System Release Previous releases Domain Reference Xerces-J v2.7.0 -- software packages for parsing XML [3], [6] Azureus v2.3.0.6 -- Java BitTorrent client for handling multiple torrents [3] ArgoUML v0.26 and v0.3 -- UML tool for object-oriented design [3] Apache Ant v1.5.0 and v1.7.0 -- Java build tool and library [3] GanttProject v1.10.2 and v1.11.1 -- project management [3], [6], [5] JHotDraw v6.1 and v6.0b1 and v5.3 -- graphics tool [6], [5], [4] JFreeChart v1.0.9 -- chart tool [6] Beaver v0.9.11 and v0.9.8 -- parser generator [5], [4] Apache XML-RPC v3.1.1 -- B2B communications [5], [4] JRDF v0.3.4.3 -- semantic web (resource management) [5] XOM v1.2.1 -- XML tool [5] JSON v1.1 -- software packages for parsing JSON [4] JFlex v1.4.1 -- lexical analyzer generator [4] Mango v2.0.1 -- -- [4] Weka v3.9 -- data mining tool New ANTLR v4.8.0 -- parser generator tool New 7 CodART in IUST Developing a comprehensive refactoring engine required thousand of hours of programming. Refactoring is not just understanding and updating the syntax tree. The tool also needs to figure out how to rerender the code into text back in the editor view. According to a quote by Fowler [2] in his well-known refactoring book: \u201cimplementing decent refactoring is a challenging programming exercise\u2014one that I\u2019m mostly unaware of as I gaily use the tools.\u201d We have defined the basic functionalities of the CodART system as several student projects with different proposals. Students who will take our computer science course, including compiler design and construction, advanced compilers, and advanced software engineering, must be worked on these proposals as part of their course fulfillments. These projects try to familiarize students with the practical usage of compilers from the software engineering point of view. The detailed information of our current proposals are available in the following links: Core refactoring operations development (Fall 2020) Core code smells development Current semester (Winter and Spring 2021) Core search-based development (Future semesters) Core refactoring to design patterns development (Future semesters) Note: Students whose final project is confirmed by the reverse engineering laboratory have an opportunity to work on CodART as an independent and advanced research project. The only prerequisite is to pass the compiler graduate course by Dr. Saeed Parsa. 8 Conclusion and remarks Software refactoring is used to reduce the costs and risks of software evolution. Automated software refactoring tools can reduce risks caused by manual refactoring, improve efficiency, and reduce software refactoring difficulties. Researchers have made great efforts to research how to implement and improve automated software refactoring tools. However, the results of automated refactoring tools often deviate from the intentions of the implementer. The goal of this project is to propose an open-source refactoring engine and toolkit that can automatically find the best refactoring sequence required for a given software and apply this sequence. Since the tool is work based on compiler principles, it is reliable to be used in practice and has many benefits for software developer companies. Students who participate in the project will learn compiler techniques such as lexing, parsing, source code analysis, and source code transformation. They also learn about software refactoring, search-based software engineering, optimization, software quality, and object-orient metrics. Conflict of interest The project is supported by the IUST Reverse Engineering Research Laboratory . Interested students may continue working on this project to fulfill their final bachelor and master thesis or their internship. References [1] T. Parr and K. Fisher, \u201cLL(*): the foundation of the ANTLR parser generator,\u201d Proc. 32nd ACM SIGPLAN Conf. Program. Lang. Des. Implement., pp. 425\u2013436, 2011. [2] M. K. B. Fowler, Refactoring: improving the design of existing code, Second Edi. Addison-Wesley, 2018. [3] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. O\u0301 Cinne\u0301ide, and K. Deb, \u201cOn the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,\u201d Empir. Softw. Eng., vol. 21, no. 6, pp. 2503\u20132545, Dec. 2016. [4] M. Mohan, D. Greer, and P. McMullan, \u201cTechnical debt reduction using search based automated refactoring,\u201d J. Syst. Softw., vol. 120, pp. 183\u2013194, Oct. 2016. [5] M. Mohan and D. Greer, \u201cUsing a many-objective approach to investigate automated refactoring,\u201d Inf. Softw. Technol., vol. 112, pp. 83\u2013101, Aug. 2019. [6] W. Mkaouer et al., \u201cMany-Objective Software Remodularization Using NSGA-III,\u201d ACM Trans. Softw. Eng. Methodol., vol. 24, no. 3, pp. 1\u201345, May 2015. [7] M. Mohan and D. Greer, \u201cMultiRefactor: automated refactoring to improve software quality,\u201d 2017, pp. 556\u2013572. [8] N. Tsantalis, T. Chaikalis, and A. Chatzigeorgiou, \u201cTen years of JDeodorant: lessons learned from the hunt for smells,\u201d in 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), 2018, pp. 4\u201314. [9] T. Mens and T. Tourwe, \u201cA survey of software refactoring,\u201d IEEE Trans. Softw. Eng., vol. 30, no. 2, pp. 126\u2013139, Feb. 2004. Related links IUST compiler course official webpage ANTLR slides: PART 1: Introduction ANTLR slides: PART 2: Getting started in Java ANTLR slides: PART 3: Getting started in C# Endnotes [1] https://www.jetbrains.com/idea/ [2] http://www.eclipse.org [3] http://www.netbeans.org [4] https://github.com/mmohan01/MultiRefactor [5] http://sourceforge.net/projects/recoder [6] http://reverse.iust.ac.ir","title":"Home"},{"location":"#codart-automated-source-code-refactoring-toolkit","text":"Morteza Zakeri \u2020 \u2020 Ph.D. Student, Iran University of Science and Technology, Tehran, Iran (m-zakeri@live.com). Version 0.2.3 (25 May 2022) \u251c Download PDF versions v0.1.0 , v0.2.0 Abstract\u2014 Software refactoring is performed by changing the software structure without modifying its external behavior. Many software quality attributes can be enhanced through the source code refactoring, such as reusability, flexibility, understandability, and testability. Refactoring engines are tools that automate the application of refactorings: first, the user chooses a refactoring to apply, then the engine checks if the transformation is safe, and if so, transforms the program. Refactoring engines are a key component of modern Integrated Development Environments (IDEs), and programmers rely on them to perform refactorings. In this project, an open-source software toolkit for refactoring Java source codes, namely CodART, will be developed. ANTLR parser generator is used to create and modify the program syntax-tree and produce the refactored version of the program. To the best of our knowledge, CodART is the first open-source refactoring toolkit based on ANTLR. Index Terms: Software refactoring, refactoring engine, search-based refactoring, ANTLR, Java.","title":"CodART: Automated Source Code Refactoring Toolkit"},{"location":"#1-introduction","text":"R efactoring is a behavior-preserving program transformation that improves the design of a program. Refactoring engines are tools that automate the application of refactorings. The programmer need only select which refactoring to apply, and the engine will automatically check the preconditions and apply the transformations across the entire program if the preconditions are satisfied. Refactoring is gaining popularity, as evidenced by the inclusion of refactoring engines in modern IDEs such as IntelliJ IDEA , Eclipse , or NetBeans for Java. Considering the EncapsulateField refactoring as an illustrative example. This refactoring replaces all references to a field with accesses through setter and getter methods. The EncapsulateField refactoring takes as input the name of the field to encapsulate and the names of the new getter and setter methods. It performs the following transformations: Creates a public getter method that returns the field's value, Creates a public setter method that updates the field's value, to a given parameter's value, Replaces all field reads with calls to the getter method, Replaces all field writes with calls to the setter method, Changes the field's access modifier to private. The EncapsulateField refactoring checks several preconditions, including that the code does not already contain accessor methods and that these methods are applicable to the expressions in which the field appears. Figure 1 shows a sample program before and after encapsulating the field f into the getF and setF methods. Figure 1. Example EncapsulateField refactoring Refactoring engines must be reliable. A fault in a refactoring engine can silently introduce bugs in the refactored program and lead to challenging debugging sessions. If the original program compiles, but the refactored program does not, the refactoring is obviously incorrect and can be easily undone. However, if the refactoring engine erroneously produces a refactored program that compiles but does not preserve the semantics of the original program, this can have severe consequences. To perform refactoring correctly, the tool has to operate on the syntax tree of the code, not on the text. Manipulating the syntax tree is much more reliable to preserve what the code is doing. Refactoring is not just understanding and updating the syntax tree. The tool also needs to figure out how to rerender the code into text back in the editor view, called code transformation. All in all, implementing decent refactoring is a challenging programming exercise, required compiler knowledge. In this project, we develop CodART, a toolkit for applying a given refactoring on the source code and obtain the refactored code. To this aim, we will use ANTLR [1] to generate and modify the program syntax tree. CodART development consists of two phases: In the first phase, 47 common refactoring operations will be automated, and in the second phase, an algorithm to find the best sequence of refactorings to apply on a given software will be developed using many-objective search-based approaches. The rest of this white-paper is organized as follows. Section 2 describes the refactoring operations in detail. Section 3 explains code smells in detail. Section 4 briefly discusses the search-based refactoring techniques and many-objective evolutionary algorithms. Section 5 explains the implementation details of the current version of CodART. Section 6 lists the Java project used to evaluate CodART. Section 7 articulates the proposals that existed behind the CodART projects. Finally, the conclusion and future works are discussed in Section 8.","title":"1 Introduction"},{"location":"#2-refactoring-operations","text":"This section explains the refactoring operations used in the project. A catalog of 72 refactoring operations has been proposed by Fowler [2]. We called this refactorings atomic refactoring operations. Each refactoring operation has a definition and is clearly specified by the entities in which it is involved and the role of each. Table 1 describes the desirable refactorings, which we aim to automate them. It worth noting that not all of these refactoring operations are introduced by Fowler [2]. A concrete example for most of the refactoring operations in the table is available at https://refactoring.com/catalog/ . Examples of other refactorings can be found at https://refactoring.guru/refactoring/techniques and https://sourcemaking.com/refactoring/refactorings . Table 1. Refactoring operations Refactoring Definition Entities Roles Move class Move a class from a package to another package class source package, target package moved class Move method Move a method from a class to another. class method source class, target class moved method Merge packages Merge the elements of a set of packages in one of them package source package, target package Extract/Split package Add a package to compose the elements of another package package source package, target package Extract class Create a new class and move fields and methods from the old class to the new one class method source class, new class moved methods Extract method Extract a code fragment into a method method statement source method, new method moved statements Inline class Move all features of a class in another one and remove it class source class, target class Move field Move a field from a class to another class field source class, target class field Push down field Move a field of a superclass to a subclass class field super class, sub classes move field Push down method Move a method of a superclass to a subclass class method super class, sub classes moved method Pull up field Move a field from subclasses to the superclass class field sub classes, super class moved field Pull up method Move a method from subclasses to the superclass class method sub classes, super class moved method Increase field visibility Increase the visibility of a field from public to protected, protected to package or package to private class field source class source filed Decrease field visibility Decrease the visibility of a field from private to package, package to protected or protected to public class field source class source filed Make field final Make a non-final field final class field source class source filed Make field non-final Make a final field non-final class field source class source filed Make field static Make a non-static field static class field source class source filed Make field non-static Make a static field non-static class field source class source filed Remove field Remove a field from a class class field source class source filed Increase method visibility Increase the visibility of a method from public to protected, protected to package or package to private class method source class source method Decrease method visibility Decrease the visibility of a method from private to package, package to protected or protected to public class method source class source method Make method final Make a non-final method final class method source class source method Make method non-final Make a final method non-final class method source class source method Make method static Make a non-static method static class method source class source method Make method non-static Make a static method non-static class method source class source method Remove method Remove a method from a class class method source class source method Make class-final Make a non-final class final class source class Make class non-final Make a final class non-final class source class Make class abstract Change a concrete class to abstract class source class Make class concrete Change an abstract class to concrete class source class Extract subclass Create a subclass for a set of features class method source class, new subclass moved methods Extract interface Extract methods of a class into an interface class method source class, new interface interface methods Inline method Move the body of a method into its callers and remove the method method source method, callers method Collapse hierarchy Merge a superclass and a subclass class superclass, subclass Remove control flag Replace control flag with a break class method source class source method Replace nested conditional with guard clauses Replace nested conditional with guard clauses class method source class source method Replace constructor with a factory function Replace constructor with a factory function class source class Replace exception with test Replace exception with precheck class method source class source method Rename field Rename a field class field source class source filed Rename method Rename a method class method source class source method Rename class Rename a class class source class Rename package Rename a package package source package Encapsulate field Create setter/mutator and getter/accessor methods for a private field class field source class source filed Replace parameter with query Replace parameter with query class method source class source method Pull up constructor body Move the constructor class method subclass class, superclass constructor Replace control flag with break Replace control flag with break class method source class source method Remove flag argument Remove flag argument class method source class source method Total 47 \u2014 \u2014","title":"2 Refactoring operations"},{"location":"#3-code-smells","text":"Deciding when and where to start refactoring\u2014and when and where to stop\u2014is just as important to refactoring as knowing how to operate its mechanics [2]. To answer this important question, we should know the refactoring activities. The refactoring process consists of six distinct activities [9]: Identify where the software should be refactored. Determine which refactoring(s) should be applied to the identified places. Guarantee that the applied refactoring preserves behavior. Apply the refactoring. Assess the effect of the refactoring on quality characteristics of the software (e.g., complexity, understandability, maintainability) or the process (e.g., productivity, cost, effort). Maintain the consistency between the refactored program code and other software artifacts (such as documentation, design documents, requirements specifications, tests, etc.). Table 2. Code smells Code smell Descriptions and other names God class The class defines many data members (fields) and methods and exhibits low cohesion. The god class smell occurs when a huge class surrounded by many data classes acts as a controller (i.e., takes most of the decisions and monopolizes the software's functionality). Other names: Blob, large class, brain class. Long method This smell occurs when a method is too long to understand and most presumably perform more than one responsibility. Other names: God method, brain method, large method. Feature envy This smell occurs when a method seems more interested in a class other than the one it actually is in. Data class This smell occurs when a class contains only fields and possibly getters/setters without any behavior (methods). Shotgun surgery This smell characterizes the situation when one kind of change leads to many changes to multiple different classes. When the changes are all over the place, they are hard to find, and it is easy to miss a necessary change. Refused bequest This smell occurs when a subclass rejects some of the methods or properties offered by its superclass. Functional decomposition This smell occurs when the experienced developers coming from procedural languages background write highly procedural and non-object-oriented code in an object-oriented language. Long parameter list This smell occurs when a method accepts a long list of parameters. Such lists are hard to understand and difficult to use. Promiscuous package A package can be considered promiscuous if it contains classes implementing too many features, making it too hard to understand and maintain. As for god class and long method, this smell arises when the package has low cohesion since it manages different responsibilities. Misplaced class A Misplaced Class smell suggests a class that is in a package that contains other classes not related to it. Switch statement This smell occurs when switch statements that switch on type codes are spread across the software system instead of exploiting polymorphism. Spaghetti code This smell refers to an unmaintainable, incomprehensible code without any structure. The smell does not exploit and prevents the use of object-orientation mechanisms and concepts. Divergent change Divergent change occurs when one class is commonly changed in different ways for different reasons. Other names: Multifaceted abstraction Deficient encapsulation This smell occurs when the declared accessibility of one or more members of abstraction is more permissive than actually required. Swiss army knife This smell arises when the designer attempts to provide all possible uses of the class and ends up in an excessively complex class interface. Lazy class Unnecessary abstraction Cyclically-dependent modularization This smell arises when two or more abstractions depend on each other directly or indirectly. Primitive obsession This smell occurs when primitive data types are used where an abstraction encapsulating the primitives could serve better. Speculative generality This smell occurs where abstraction is created based on speculated requirements. It is often unnecessary that makes things difficult to understand and maintain. Message chains A message chain occurs when a client requests another object, that object requests yet another one, and so on. These chains mean that the client is dependent on navigation along with the class structure. Any changes in these relationships require modifying the client. Total 20","title":"3 Code smells"},{"location":"#4-search-based-refactoring","text":"After refactoring operations were automated, we must decide which refactorings souled be performed in order to elevate software quality. The concern about using refactoring operations in Table 1 is whether each one of them has a positive impact on the refactored code quality or not. Finding the right sequence of refactorings to be applied in a software artifact is considered a challenging task since there is a wide range of refactorings. The ideal sequence is, therefore, must correlate to different quality attributes to be improved as a result of applying refactorings. Finding the best refactoring sequence is an optimization problem that can be solved by search techniques in the field known as Search-Based Software Engineering (SBSE) [3]. In this approach, refactorings are applied stochastically to the original software solution, and then the software is measured using a fitness function consisting of one or more software metrics. There are various metric suites available to measure characteristics like cohesion and coupling, but different metrics measure the software in different ways, and thus how they are applied will have a different effect on the outcome. The second phase of this project is to use a many-objective search algorithm to find the best sequence of refactoring on a given project. Recently, many-objective SBSE approach for refactoring [3]\u2013[5] and remodularization, regrouping a set of classes C in terms of packages P, [6] has gained more attention due to its ability to find the best sequence of refactoring operations which is led to the improvement in software quality. Therefore, we first focus on implementing the proposed approach approaches in [3], [5], [6] as fundamental works in this area. Then, we will improve their approach. As a new contribution, we add new refactoring operations and new objective functions to improve the quality attribute of the software. We also evaluate our method on the new software projects which are not used in previous works.","title":"4 Search-based refactoring"},{"location":"#5-implementation","text":"This section describes implementation details of the CodART. It includes CodART architecture, high-level repository directories structure, refactoring automation with ANTLR parser generator, and refactoring recommendation through many-objective search-based software engineering techniques.","title":"5 Implementation"},{"location":"#51-codart-architecture","text":"The high-level architecture of CodART is shown in Figure 2. The source code consists of several Python packages and directories. We briefly describe each component in CodART. Figure 2. CodART architecture I. grammars : The directory contains three ANTLR v4 grammars for the Java programming language: Java9_v2.g4 : This grammar was used in the initial version of CodART. The main problem of this grammar is that parsing large source code files is performed very slow due to some decisions used in grammar design. We have switched to the fast grammar JavaParserLabled.g4 . JavaLexer.g4 : The lexer of Java fast grammar. This lexer is used for both fast parsers, i.e., JavaParser.g4 and JavaParserLabeled. JavaParser.g4 : The original parser of Java fast grammar. This parser is currently used in some refactoring. In the future release, this grammar will be replaced with JavaPaseredLabled.g4 . JavaParserLabeled.g4 : This file contains the same JavaParsar.g4 grammar. The only difference is that the rules with more than one extension are labeled with a specific name. The ANTLR parser generator thus generates separate visitor and listener methods for each extension. This grammar facilitates the development of some refactoring. It is the preferred parser in CodART project. II. codart.gen : The codart.gen packages contain all generated source code for the parser, lexer, visitor, and listener for different grammars available in the grammars' directory. To develop refactorings and code smells, codart.gen.JavaLabled package, which contains JavaParserLabled.g4 generated source code, must be used. The content of this package is generated automatically , and therefore it should not be modified manually . Modules within this gen package are just for importing and using in other modules. III. speedy : The python implementation for ANTLR is less efficient than Java or C++ implementation. The speedy component implements a Java parser with a C++ back-end, improving the efficiency and speed of parsing. It uses speedy-antlr implementation with some minor changes. The current version of the speedy module use java9_v2.g4 grammar, which inherently slow as described. To switch to C++ back-end, first, the speedy module must be installed on the client system. It requires a C++ compiler. We recommended to CodART developers using the Python back-end as switching to C++ back-end would be done transparently in the future release. The Python back-end saves debugging and developing time. IV. codart.refactorings : The codart.refactorings package is the main package in the CodART project and contains numerous Python modules that form the kernel functionalities of CodART. Each module implements the automation of one refactoring operation according to standard practices. The modules may include several classes which inherit from ANTLR listeners. Sub-packages in this module contain refactorings, which are in an early step of development or deprecated version of an existing refactoring. This package is under active development and testing. The module in the root packages can be used for testing purposes. V. codart.refactoring_design_patters : The codart.refactoring_design_pattern package contain modules that implement refactoring to a specific design pattern automatically. VI. codart.smells : The codart.smells package implements the automatic detection of software code and design smells relevant to the refactoring operation supported by CodART. Each smell corresponds to one or more refactoring in the refactoring package. VII. codart.metrics : The codart.metrics packages contain several modules that implement the computation of the most well-known source code metrics. These metrics used to detect code smells and measuring the quality of software in terms of quality attributed. VIII. codart.sbse : The codart.sbse packages include scripts that implement the search-based refactoring processes. It mainly uses Pymoo multi-objective framework to find the best sequence of refactoring operations to maximize the source code and design quality. IX. tests : The test directory contains individual test data and test cases that are used for developing specific refactorings. Typically, each test case is a single Java file that contains one or more Java classes. X. benchmark_projects : This directory contains several open-source Java projects formerly used in automated refactoring researches by many researchers. Once the implementation of refactoring is completed, it will be executed and tested on all projects in this benchmark to ensure the generalization of functionality proposed by the implementation. XI. Other packages : The information of other packages will be announced in the future.","title":"5.1 CodART architecture"},{"location":"#52-refactoring-automation","text":"Each refactoring operation in Table 1 is implemented as an API, with the refactoring name. The API receives the involved entities with their refactoring roles and other required data as inputs, checks the feasibility of the refactoring using refactoring preconditions described in [2], performs the refactoring if it is feasible, and returns the refactored code or return null if the refactoring is not feasible. The core of our refactoring engine is a syntax-tree modification algorithm. Fundamentally, ANTLR is used to generate and modify the syntax-tree of a given program. Each refactoring API is an ANTLR Listener or visitor class, which required argument by its constructor and preform refactoring when call by parse-tree walker object. The refactoring target and input parameters must read from a configuration file, which can be expressed in JSON, XML, or YAML formats. The key to use ANTLR for refactoring tasks is the TokenStreamRewriter object that knows how to give altered views of a token stream without actually modifying the stream. It treats all of the manipulation methods as \"instructions\" and queues them up for lazy execution when traversing the token stream to render it back as text. The rewriter executes those instructions every time we call getText() . This strategy is very effective for the general problem of source code instrumentation or refactoring. The TokenStreamRewriter is a powerful and extremely efficient means of manipulating a token stream.","title":"5.2 Refactoring automation"},{"location":"#53-refactoring-recommendation","text":"A solution consists of a sequence of n refactoring operations applied to different code elements in the source code to fix. In order to represent a candidate solution (individual/chromosome), we use a vector-based representation. Each vector\u2019s dimension represents a refactoring operation where the order of applying these refactoring operations corresponds to their positions in the vector. The initial population is generated by randomly assigning a sequence of refactorings to some code fragments. Each generated refactoring solution is executed on the software system S . Once all required data is computed, the solution is evaluated based on the quality of the resulting design.","title":"5.3 Refactoring recommendation"},{"location":"#6-benchmark-projects-and-testbed","text":"To ensure CodART works properly, we are running it on many real-life software projects. Refactorings are applied to the software systems listed in Table 3. Benchmark projects may update and extend in the future. For the time being, we use a set of well-known open-source Java projects that have been intensely studied in previous works. We have also added two new Java software programs, WEKA and ANTLR, to examine the versatility of CodART performance on real-life software projects. Table 3. Software systems refactored in this project System Release Previous releases Domain Reference Xerces-J v2.7.0 -- software packages for parsing XML [3], [6] Azureus v2.3.0.6 -- Java BitTorrent client for handling multiple torrents [3] ArgoUML v0.26 and v0.3 -- UML tool for object-oriented design [3] Apache Ant v1.5.0 and v1.7.0 -- Java build tool and library [3] GanttProject v1.10.2 and v1.11.1 -- project management [3], [6], [5] JHotDraw v6.1 and v6.0b1 and v5.3 -- graphics tool [6], [5], [4] JFreeChart v1.0.9 -- chart tool [6] Beaver v0.9.11 and v0.9.8 -- parser generator [5], [4] Apache XML-RPC v3.1.1 -- B2B communications [5], [4] JRDF v0.3.4.3 -- semantic web (resource management) [5] XOM v1.2.1 -- XML tool [5] JSON v1.1 -- software packages for parsing JSON [4] JFlex v1.4.1 -- lexical analyzer generator [4] Mango v2.0.1 -- -- [4] Weka v3.9 -- data mining tool New ANTLR v4.8.0 -- parser generator tool New","title":"6 Benchmark projects and testbed"},{"location":"#7-codart-in-iust","text":"Developing a comprehensive refactoring engine required thousand of hours of programming. Refactoring is not just understanding and updating the syntax tree. The tool also needs to figure out how to rerender the code into text back in the editor view. According to a quote by Fowler [2] in his well-known refactoring book: \u201cimplementing decent refactoring is a challenging programming exercise\u2014one that I\u2019m mostly unaware of as I gaily use the tools.\u201d We have defined the basic functionalities of the CodART system as several student projects with different proposals. Students who will take our computer science course, including compiler design and construction, advanced compilers, and advanced software engineering, must be worked on these proposals as part of their course fulfillments. These projects try to familiarize students with the practical usage of compilers from the software engineering point of view. The detailed information of our current proposals are available in the following links: Core refactoring operations development (Fall 2020) Core code smells development Current semester (Winter and Spring 2021) Core search-based development (Future semesters) Core refactoring to design patterns development (Future semesters) Note: Students whose final project is confirmed by the reverse engineering laboratory have an opportunity to work on CodART as an independent and advanced research project. The only prerequisite is to pass the compiler graduate course by Dr. Saeed Parsa.","title":"7 CodART in IUST"},{"location":"#8-conclusion-and-remarks","text":"Software refactoring is used to reduce the costs and risks of software evolution. Automated software refactoring tools can reduce risks caused by manual refactoring, improve efficiency, and reduce software refactoring difficulties. Researchers have made great efforts to research how to implement and improve automated software refactoring tools. However, the results of automated refactoring tools often deviate from the intentions of the implementer. The goal of this project is to propose an open-source refactoring engine and toolkit that can automatically find the best refactoring sequence required for a given software and apply this sequence. Since the tool is work based on compiler principles, it is reliable to be used in practice and has many benefits for software developer companies. Students who participate in the project will learn compiler techniques such as lexing, parsing, source code analysis, and source code transformation. They also learn about software refactoring, search-based software engineering, optimization, software quality, and object-orient metrics.","title":"8 Conclusion and remarks"},{"location":"#conflict-of-interest","text":"The project is supported by the IUST Reverse Engineering Research Laboratory . Interested students may continue working on this project to fulfill their final bachelor and master thesis or their internship.","title":"Conflict of interest"},{"location":"#references","text":"[1] T. Parr and K. Fisher, \u201cLL(*): the foundation of the ANTLR parser generator,\u201d Proc. 32nd ACM SIGPLAN Conf. Program. Lang. Des. Implement., pp. 425\u2013436, 2011. [2] M. K. B. Fowler, Refactoring: improving the design of existing code, Second Edi. Addison-Wesley, 2018. [3] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. O\u0301 Cinne\u0301ide, and K. Deb, \u201cOn the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,\u201d Empir. Softw. Eng., vol. 21, no. 6, pp. 2503\u20132545, Dec. 2016. [4] M. Mohan, D. Greer, and P. McMullan, \u201cTechnical debt reduction using search based automated refactoring,\u201d J. Syst. Softw., vol. 120, pp. 183\u2013194, Oct. 2016. [5] M. Mohan and D. Greer, \u201cUsing a many-objective approach to investigate automated refactoring,\u201d Inf. Softw. Technol., vol. 112, pp. 83\u2013101, Aug. 2019. [6] W. Mkaouer et al., \u201cMany-Objective Software Remodularization Using NSGA-III,\u201d ACM Trans. Softw. Eng. Methodol., vol. 24, no. 3, pp. 1\u201345, May 2015. [7] M. Mohan and D. Greer, \u201cMultiRefactor: automated refactoring to improve software quality,\u201d 2017, pp. 556\u2013572. [8] N. Tsantalis, T. Chaikalis, and A. Chatzigeorgiou, \u201cTen years of JDeodorant: lessons learned from the hunt for smells,\u201d in 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), 2018, pp. 4\u201314. [9] T. Mens and T. Tourwe, \u201cA survey of software refactoring,\u201d IEEE Trans. Softw. Eng., vol. 30, no. 2, pp. 126\u2013139, Feb. 2004.","title":"References"},{"location":"#related-links","text":"IUST compiler course official webpage ANTLR slides: PART 1: Introduction ANTLR slides: PART 2: Getting started in Java ANTLR slides: PART 3: Getting started in C#","title":"Related links"},{"location":"#endnotes","text":"[1] https://www.jetbrains.com/idea/ [2] http://www.eclipse.org [3] http://www.netbeans.org [4] https://github.com/mmohan01/MultiRefactor [5] http://sourceforge.net/projects/recoder [6] http://reverse.iust.ac.ir","title":"Endnotes"},{"location":"about/","text":"About Us Programming is the art of telling another human being what one wants the computer to do. \u2014 Donald Knuth Project Contributors The CodART Project is part of Morteza Zakeri\u2019s Ph.D. thesis to refactor Java source codes automatically and improve their testability. We have defined several sub-projects relevant to CodART to improve software quality. Project Owner Morteza ZAKERI , Ph.D. student at Iran University of Science and Technology Project Supervisors Dr. Saeed Parsa Associate professor at Iran University of Science and Technology Dr. Mehrdad Ashtiani Assistant professor at Iran University of Science and Technology Current Contributors Morteza Zakeri Former contributors Seyyed Ali Ayati, B.Sc. student at Iran University of Science and Technology Mina Tahaei, B.Sc. student at Iran University of Science and Technology IUST B.Sc. Students in compiler course (Spring 2021) IUST B.Sc. Students in compiler course (Fall 2020) IUST M.Sc. students in advanced Compiler course (Fall 2020) More For any question please contact m-zakeri@live.com or visit CodART repo on GitHub: https://github.com/m-zakeri/CodART","title":"About us"},{"location":"about/#about-us","text":"Programming is the art of telling another human being what one wants the computer to do. \u2014 Donald Knuth","title":"About Us"},{"location":"about/#project-contributors","text":"The CodART Project is part of Morteza Zakeri\u2019s Ph.D. thesis to refactor Java source codes automatically and improve their testability. We have defined several sub-projects relevant to CodART to improve software quality.","title":"Project Contributors"},{"location":"about/#project-owner","text":"Morteza ZAKERI , Ph.D. student at Iran University of Science and Technology","title":"Project Owner"},{"location":"about/#project-supervisors","text":"Dr. Saeed Parsa Associate professor at Iran University of Science and Technology Dr. Mehrdad Ashtiani Assistant professor at Iran University of Science and Technology","title":"Project Supervisors"},{"location":"about/#current-contributors","text":"Morteza Zakeri","title":"Current Contributors"},{"location":"about/#former-contributors","text":"Seyyed Ali Ayati, B.Sc. student at Iran University of Science and Technology Mina Tahaei, B.Sc. student at Iran University of Science and Technology IUST B.Sc. Students in compiler course (Spring 2021) IUST B.Sc. Students in compiler course (Fall 2020) IUST M.Sc. students in advanced Compiler course (Fall 2020)","title":"Former contributors"},{"location":"about/#more","text":"For any question please contact m-zakeri@live.com or visit CodART repo on GitHub: https://github.com/m-zakeri/CodART","title":"More"},{"location":"benchmarks/","text":"CodART benchmarks and testbed To ensure CodART works properly, we are running it on many real-life software projects. Refactorings are applied to the software systems listed in Table 3. Benchmark projects may update and extend in the future. For the time being, we use a set of well-known open-source Java projects that have been intensely studied in previous works. We have also added two new Java software programs, WEKA and ANTLR, to examine the versatility of CodART performance on real-life software projects. Table 3. Software systems used as benchmarks in CodeART System Release Previous releases Domain Reference Xerces-J v2.7.0 -- software packages for parsing XML [3], [6] Azureus v2.3.0.6 -- Java BitTorrent client for handling multiple torrents [3] ArgoUML v0.26 and v0.3 -- UML tool for object-oriented design [3] Apache Ant v1.5.0 and v1.7.0 -- Java build tool and library [3] GanttProject v1.10.2 and v1.11.1 -- project management [3], [6], [5] JHotDraw v6.1 and v6.0b1 and v5.3 -- graphics tool [6], [5], [4] JFreeChart v1.0.9 -- chart tool [6] Beaver v0.9.11 and v0.9.8 -- parser generator [5], [4] Apache XML-RPC v3.1.1 -- B2B communications [5], [4] JRDF v0.3.4.3 -- semantic web (resource management) [5] XOM v1.2.1 -- XML tool [5] JSON v1.1 -- software packages for parsing JSON [4] JFlex v1.4.1 -- lexical analyzer generator [4] Mango v2.0.1 -- -- [4] Weka v3.8 -- data mining tool New ANTLR v4.8.0 -- parser generator tool New New projects To be announced. References [3] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. O\u0301 Cinne\u0301ide, and K. Deb, \u201cOn the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,\u201d Empir. Softw. Eng., vol. 21, no. 6, pp. 2503\u20132545, Dec. 2016. [4] M. Mohan, D. Greer, and P. McMullan, \u201cTechnical debt reduction using search based automated refactoring,\u201d J. Syst. Softw., vol. 120, pp. 183\u2013194, Oct. 2016. [5] M. Mohan and D. Greer, \u201cUsing a many-objective approach to investigate automated refactoring,\u201d Inf. Softw. Technol., vol. 112, pp. 83\u2013101, Aug. 2019. [6] W. Mkaouer et al., \u201cMany-Objective Software Remodularization Using NSGA-III,\u201d ACM Trans. Softw. Eng. Methodol., vol. 24, no. 3, pp. 1\u201345, May 2015.","title":"Benchmarks"},{"location":"benchmarks/#codart-benchmarks-and-testbed","text":"To ensure CodART works properly, we are running it on many real-life software projects. Refactorings are applied to the software systems listed in Table 3. Benchmark projects may update and extend in the future. For the time being, we use a set of well-known open-source Java projects that have been intensely studied in previous works. We have also added two new Java software programs, WEKA and ANTLR, to examine the versatility of CodART performance on real-life software projects. Table 3. Software systems used as benchmarks in CodeART System Release Previous releases Domain Reference Xerces-J v2.7.0 -- software packages for parsing XML [3], [6] Azureus v2.3.0.6 -- Java BitTorrent client for handling multiple torrents [3] ArgoUML v0.26 and v0.3 -- UML tool for object-oriented design [3] Apache Ant v1.5.0 and v1.7.0 -- Java build tool and library [3] GanttProject v1.10.2 and v1.11.1 -- project management [3], [6], [5] JHotDraw v6.1 and v6.0b1 and v5.3 -- graphics tool [6], [5], [4] JFreeChart v1.0.9 -- chart tool [6] Beaver v0.9.11 and v0.9.8 -- parser generator [5], [4] Apache XML-RPC v3.1.1 -- B2B communications [5], [4] JRDF v0.3.4.3 -- semantic web (resource management) [5] XOM v1.2.1 -- XML tool [5] JSON v1.1 -- software packages for parsing JSON [4] JFlex v1.4.1 -- lexical analyzer generator [4] Mango v2.0.1 -- -- [4] Weka v3.8 -- data mining tool New ANTLR v4.8.0 -- parser generator tool New","title":"CodART benchmarks and testbed"},{"location":"benchmarks/#new-projects","text":"To be announced.","title":"New projects"},{"location":"benchmarks/#references","text":"[3] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. O\u0301 Cinne\u0301ide, and K. Deb, \u201cOn the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,\u201d Empir. Softw. Eng., vol. 21, no. 6, pp. 2503\u20132545, Dec. 2016. [4] M. Mohan, D. Greer, and P. McMullan, \u201cTechnical debt reduction using search based automated refactoring,\u201d J. Syst. Softw., vol. 120, pp. 183\u2013194, Oct. 2016. [5] M. Mohan and D. Greer, \u201cUsing a many-objective approach to investigate automated refactoring,\u201d Inf. Softw. Technol., vol. 112, pp. 83\u2013101, Aug. 2019. [6] W. Mkaouer et al., \u201cMany-Objective Software Remodularization Using NSGA-III,\u201d ACM Trans. Softw. Eng. Methodol., vol. 24, no. 3, pp. 1\u201345, May 2015.","title":"References"},{"location":"code_smells_list/","text":"Code smells list The following code smells are detected by CodART. Table 2. Code smells Code smell Descriptions and other names God class The class defines many data members (fields) and methods and exhibits low cohesion. The god class smell occurs when a huge class surrounded by many data classes acts as a controller (i.e., takes most of the decisions and monopolizes the software's functionality). Other names: Blob, large class, brain class. Long method This smell occurs when a method is too long to understand and most presumably perform more than one responsibility. Other names: God method, brain method, large method. Feature envy This smell occurs when a method seems more interested in a class other than the one it actually is in. Data class This smell occurs when a class contains only fields and possibly getters/setters without any behavior (methods). Shotgun surgery This smell characterizes the situation when one kind of change leads to many changes to multiple different classes. When the changes are all over the place, they are hard to find, and it is easy to miss a necessary change. Refused bequest This smell occurs when a subclass rejects some of the methods or properties offered by its superclass. Functional decomposition This smell occurs when the experienced developers coming from procedural languages background write highly procedural and non-object-oriented code in an object-oriented language. Long parameter list This smell occurs when a method accepts a long list of parameters. Such lists are hard to understand and difficult to use. Promiscuous package A package can be considered promiscuous if it contains classes implementing too many features, making it too hard to understand and maintain. As for god class and long method, this smell arises when the package has low cohesion since it manages different responsibilities. Misplaced class A Misplaced Class smell suggests a class that is in a package that contains other classes not related to it. Switch statement This smell occurs when switch statements that switch on type codes are spread across the software system instead of exploiting polymorphism. Spaghetti code This smell refers to an unmaintainable, incomprehensible code without any structure. The smell does not exploit and prevents the use of object-orientation mechanisms and concepts. Divergent change Divergent change occurs when one class is commonly changed in different ways for different reasons. Other names: Multifaceted abstraction Deficient encapsulation This smell occurs when the declared accessibility of one or more members of abstraction is more permissive than actually required. Swiss army knife This smell arises when the designer attempts to provide all possible uses of the class and ends up in an excessively complex class interface. Lazy class Unnecessary abstraction Cyclically-dependent modularization This smell arises when two or more abstractions depend on each other directly or indirectly. Primitive obsession This smell occurs when primitive data types are used where an abstraction encapsulating the primitives could serve better. Speculative generality This smell occurs where abstraction is created based on speculated requirements. It is often unnecessary that makes things difficult to understand and maintain. Message chains A message chain occurs when a client requests another object, that object requests yet another one, and so on. These chains mean that the client is dependent on navigation along with the class structure. Any changes in these relationships require modifying the client. Total 20","title":"Code smell list"},{"location":"code_smells_list/#code-smells-list","text":"The following code smells are detected by CodART. Table 2. Code smells Code smell Descriptions and other names God class The class defines many data members (fields) and methods and exhibits low cohesion. The god class smell occurs when a huge class surrounded by many data classes acts as a controller (i.e., takes most of the decisions and monopolizes the software's functionality). Other names: Blob, large class, brain class. Long method This smell occurs when a method is too long to understand and most presumably perform more than one responsibility. Other names: God method, brain method, large method. Feature envy This smell occurs when a method seems more interested in a class other than the one it actually is in. Data class This smell occurs when a class contains only fields and possibly getters/setters without any behavior (methods). Shotgun surgery This smell characterizes the situation when one kind of change leads to many changes to multiple different classes. When the changes are all over the place, they are hard to find, and it is easy to miss a necessary change. Refused bequest This smell occurs when a subclass rejects some of the methods or properties offered by its superclass. Functional decomposition This smell occurs when the experienced developers coming from procedural languages background write highly procedural and non-object-oriented code in an object-oriented language. Long parameter list This smell occurs when a method accepts a long list of parameters. Such lists are hard to understand and difficult to use. Promiscuous package A package can be considered promiscuous if it contains classes implementing too many features, making it too hard to understand and maintain. As for god class and long method, this smell arises when the package has low cohesion since it manages different responsibilities. Misplaced class A Misplaced Class smell suggests a class that is in a package that contains other classes not related to it. Switch statement This smell occurs when switch statements that switch on type codes are spread across the software system instead of exploiting polymorphism. Spaghetti code This smell refers to an unmaintainable, incomprehensible code without any structure. The smell does not exploit and prevents the use of object-orientation mechanisms and concepts. Divergent change Divergent change occurs when one class is commonly changed in different ways for different reasons. Other names: Multifaceted abstraction Deficient encapsulation This smell occurs when the declared accessibility of one or more members of abstraction is more permissive than actually required. Swiss army knife This smell arises when the designer attempts to provide all possible uses of the class and ends up in an excessively complex class interface. Lazy class Unnecessary abstraction Cyclically-dependent modularization This smell arises when two or more abstractions depend on each other directly or indirectly. Primitive obsession This smell occurs when primitive data types are used where an abstraction encapsulating the primitives could serve better. Speculative generality This smell occurs where abstraction is created based on speculated requirements. It is often unnecessary that makes things difficult to understand and maintain. Message chains A message chain occurs when a client requests another object, that object requests yet another one, and so on. These chains mean that the client is dependent on navigation along with the class structure. Any changes in these relationships require modifying the client. Total 20","title":"Code smells list"},{"location":"faq/","text":"Frequently asked question Q1: What is CodART? A1: CodART is an automated source code refactoring toolkit. Q2: How can I contribute to the CodART project? A2: For any other question please contact us at m-zakeri@live.com","title":"FAQ"},{"location":"faq/#frequently-asked-question","text":"Q1: What is CodART? A1: CodART is an automated source code refactoring toolkit. Q2: How can I contribute to the CodART project? A2: For any other question please contact us at m-zakeri@live.com","title":"Frequently asked question"},{"location":"publications/","text":"Publications [1] Nasrabadi, M. Z., & Parsa, S. (2021). Learning to predict software testability. In 26th International Computer Conference, Computer Society of Iran. Tehran: IEEE. [2] [3]","title":"Publications"},{"location":"publications/#publications","text":"[1] Nasrabadi, M. Z., & Parsa, S. (2021). Learning to predict software testability. In 26th International Computer Conference, Computer Society of Iran. Tehran: IEEE. [2] [3]","title":"Publications"},{"location":"refactorings_list/","text":"Refactoring list The following refactoring operations have been automated in CodART. Click on refactoring name to see the API and code. Table 1. Refactoring operations Refactoring Definition Entities Roles Move class Move a class from a package to another package class source package, target package moved class Move method Move a method from a class to another. class method source class, target class moved method Merge packages Merge the elements of a set of packages in one of them package source package, target package Extract/Split package Add a package to compose the elements of another package package source package, target package Extract class Create a new class and move fields and methods from the old class to the new one class method source class, new class moved methods Extract method Extract a code fragment into a method method statement source method, new method moved statements Inline class Move all features of a class in another one and remove it class source class, target class Move field Move a field from a class to another class field source class, target class field Push down field Move a field of a superclass to a subclass class field super class, sub classes move field Push down method Move a method of a superclass to a subclass class method super class, sub classes moved method Pull up field Move a field from subclasses to the superclass class field sub classes, super class moved field Pull up method Move a method from subclasses to the superclass class method sub classes, super class moved method Increase field visibility Increase the visibility of a field from public to protected, protected to package or package to private class field source class source filed Decrease field visibility Decrease the visibility of a field from private to package, package to protected or protected to public class field source class source filed Make field final Make a non-final field final class field source class source filed Make field non-final Make a final field non-final class field source class source filed Make field static Make a non-static field static class field source class source filed Make field non-static Make a static field non-static class field source class source filed Remove field Remove a field from a class class field source class source filed Increase method visibility Increase the visibility of a method from public to protected, protected to package or package to private class method source class source method Decrease method visibility Decrease the visibility of a method from private to package, package to protected or protected to public class method source class source method Make method final Make a non-final method final class method source class source method Make method non-final Make a final method non-final class method source class source method Make method static Make a non-static method static class method source class source method Make method non-static Make a static method non-static class method source class source method Remove method Remove a method from a class class method source class source method Make class-final Make a non-final class final class source class Make class non-final Make a final class non-final class source class Make class abstract Change a concrete class to abstract class source class Make class concrete Change an abstract class to concrete class source class Extract subclass Create a subclass for a set of features class method source class, new subclass moved methods Extract interface Extract methods of a class into an interface class method source class, new interface interface methods Inline method Move the body of a method into its callers and remove the method method source method, callers method Collapse hierarchy Merge a superclass and a subclass class superclass, subclass Remove control flag Replace control flag with a break class method source class source method Replace nested conditional with guard clauses Replace nested conditional with guard clauses class method source class source method Replace constructor with a factory function Replace constructor with a factory function class source class Replace exception with test Replace exception with precheck class method source class source method Rename field Rename a field class field source class source filed Rename method Rename a method class method source class source method Rename class Rename a class class source class Rename package Rename a package package source package Encapsulate field Create setter/mutator and getter/accessor methods for a private field class field source class source filed Replace parameter with query Replace parameter with query class method source class source method Pull up constructor body Move the constructor class method subclass class, superclass constructor Replace control flag with break Replace control flag with break class method source class source method Remove flag argument Remove flag argument class method source class source method Total 47 \u2014 \u2014","title":"Refactoring list"},{"location":"refactorings_list/#refactoring-list","text":"The following refactoring operations have been automated in CodART. Click on refactoring name to see the API and code. Table 1. Refactoring operations Refactoring Definition Entities Roles Move class Move a class from a package to another package class source package, target package moved class Move method Move a method from a class to another. class method source class, target class moved method Merge packages Merge the elements of a set of packages in one of them package source package, target package Extract/Split package Add a package to compose the elements of another package package source package, target package Extract class Create a new class and move fields and methods from the old class to the new one class method source class, new class moved methods Extract method Extract a code fragment into a method method statement source method, new method moved statements Inline class Move all features of a class in another one and remove it class source class, target class Move field Move a field from a class to another class field source class, target class field Push down field Move a field of a superclass to a subclass class field super class, sub classes move field Push down method Move a method of a superclass to a subclass class method super class, sub classes moved method Pull up field Move a field from subclasses to the superclass class field sub classes, super class moved field Pull up method Move a method from subclasses to the superclass class method sub classes, super class moved method Increase field visibility Increase the visibility of a field from public to protected, protected to package or package to private class field source class source filed Decrease field visibility Decrease the visibility of a field from private to package, package to protected or protected to public class field source class source filed Make field final Make a non-final field final class field source class source filed Make field non-final Make a final field non-final class field source class source filed Make field static Make a non-static field static class field source class source filed Make field non-static Make a static field non-static class field source class source filed Remove field Remove a field from a class class field source class source filed Increase method visibility Increase the visibility of a method from public to protected, protected to package or package to private class method source class source method Decrease method visibility Decrease the visibility of a method from private to package, package to protected or protected to public class method source class source method Make method final Make a non-final method final class method source class source method Make method non-final Make a final method non-final class method source class source method Make method static Make a non-static method static class method source class source method Make method non-static Make a static method non-static class method source class source method Remove method Remove a method from a class class method source class source method Make class-final Make a non-final class final class source class Make class non-final Make a final class non-final class source class Make class abstract Change a concrete class to abstract class source class Make class concrete Change an abstract class to concrete class source class Extract subclass Create a subclass for a set of features class method source class, new subclass moved methods Extract interface Extract methods of a class into an interface class method source class, new interface interface methods Inline method Move the body of a method into its callers and remove the method method source method, callers method Collapse hierarchy Merge a superclass and a subclass class superclass, subclass Remove control flag Replace control flag with a break class method source class source method Replace nested conditional with guard clauses Replace nested conditional with guard clauses class method source class source method Replace constructor with a factory function Replace constructor with a factory function class source class Replace exception with test Replace exception with precheck class method source class source method Rename field Rename a field class field source class source filed Rename method Rename a method class method source class source method Rename class Rename a class class source class Rename package Rename a package package source package Encapsulate field Create setter/mutator and getter/accessor methods for a private field class field source class source filed Replace parameter with query Replace parameter with query class method source class source method Pull up constructor body Move the constructor class method subclass class, superclass constructor Replace control flag with break Replace control flag with break class method source class source method Remove flag argument Remove flag argument class method source class source method Total 47 \u2014 \u2014","title":"Refactoring list"},{"location":"code_smells/feature_envy/","text":"Feature envy To be constructed...","title":"Feature envy"},{"location":"code_smells/feature_envy/#feature-envy","text":"To be constructed...","title":"Feature envy"},{"location":"code_smells/large_class/","text":"Large class To be constructed...","title":"Large class"},{"location":"code_smells/large_class/#large-class","text":"To be constructed...","title":"Large class"},{"location":"code_smells/long_method/","text":"Long method To be constructed...","title":"Long method"},{"location":"code_smells/long_method/#long-method","text":"To be constructed...","title":"Long method"},{"location":"metrics/testability/","text":"Testability prediction Introduction This module contains light-weight version of testability prediction script (with 68 metrics) to be used in refactoring process in addition to QMOOD metrics. Changelog v0.2.3 Remove dependency to metrics_jcode_odor v0.2.2 Add scikit-learn 1 compatibility Reference [1] ADAFEST paper [2] TsDD paper PreProcess Writes all metrics in a csv file and performs preprocessing Source code in codart\\metrics\\testability_prediction2.py class PreProcess : \"\"\" Writes all metrics in a csv file and performs preprocessing \"\"\" @classmethod def compute_metrics_by_class_list ( cls , project_db_path , n_jobs ): \"\"\" \"\"\" # class_entities = cls.read_project_classes(db=db, classes_names_list=class_list, ) # print(project_db_path) db = und . open ( project_db_path ) class_list = UnderstandUtility . get_project_classes_longnames_java ( db = db ) db . close () # del db if n_jobs == 0 : # Sequential computing res = [ do ( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ] else : # Parallel computing res = Parallel ( n_jobs = n_jobs , )( delayed ( do )( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ) res = list ( filter ( None , res )) columns = [ 'Class' ] columns . extend ( TestabilityMetrics . get_all_primary_metrics_names ()) df = pd . DataFrame ( data = res , columns = columns ) # print('df for class {0} with shape {1}'.format(project_name, df.shape)) # df.to_csv(csv_path + project_name + '.csv', index=False) # print(df) return df compute_metrics_by_class_list ( project_db_path , n_jobs ) classmethod Source code in codart\\metrics\\testability_prediction2.py @classmethod def compute_metrics_by_class_list ( cls , project_db_path , n_jobs ): \"\"\" \"\"\" # class_entities = cls.read_project_classes(db=db, classes_names_list=class_list, ) # print(project_db_path) db = und . open ( project_db_path ) class_list = UnderstandUtility . get_project_classes_longnames_java ( db = db ) db . close () # del db if n_jobs == 0 : # Sequential computing res = [ do ( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ] else : # Parallel computing res = Parallel ( n_jobs = n_jobs , )( delayed ( do )( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ) res = list ( filter ( None , res )) columns = [ 'Class' ] columns . extend ( TestabilityMetrics . get_all_primary_metrics_names ()) df = pd . DataFrame ( data = res , columns = columns ) # print('df for class {0} with shape {1}'.format(project_name, df.shape)) # df.to_csv(csv_path + project_name + '.csv', index=False) # print(df) return df TestabilityMetrics Compute all required metrics for computing Coverageability and testability. Source code in codart\\metrics\\testability_prediction2.py class TestabilityMetrics : \"\"\" Compute all required metrics for computing Coverageability and testability. \"\"\" @classmethod def get_package_metrics_names ( cls ) -> list : return metrics_names . package_metrics_names_primary @classmethod def get_class_lexicon_metrics_names ( cls ) -> list : return metrics_names . class_lexicon_metrics_names @classmethod def get_class_ordinary_metrics_names ( cls ) -> list : return metrics_names . class_ordinary_metrics_names_primary @classmethod def get_all_metrics_names ( cls ) -> list : metrics = list () # print('project_metrics number: ', len(TestabilityMetrics.get_project_metrics_names())) # for metric_name in TestabilityMetrics.get_project_metrics_names(): # metrics.append('PJ_' + metric_name) # print('package_metrics number: ', len(TestabilityMetrics.get_package_metrics_names())) for metric_name in TestabilityMetrics . get_package_metrics_names (): metrics . append ( 'PK_' + metric_name ) # SOOTI is now corrected. # print('class_lexicon_metrics number: ', len(TestabilityMetrics.get_class_lexicon_metrics_names())) for metric_name in TestabilityMetrics . get_class_lexicon_metrics_names (): metrics . append ( 'CSLEX_' + metric_name ) # print('class_ordinary_metrics number: ', len(TestabilityMetrics.get_class_ordinary_metrics_names())) for metric_name in TestabilityMetrics . get_class_ordinary_metrics_names (): metrics . append ( 'CSORD_' + metric_name ) # print('All available metrics: {0}'.format(len(metrics))) return metrics @classmethod def get_all_primary_metrics_names ( cls ) -> list : primary_metrics_names = list () # for metric_name in metrics.metrics_names.project_metrics_names_primary: # primary_metrics_names.append('PJ_' + metric_name) for metric_name in metrics_names . package_metrics_names_primary : primary_metrics_names . append ( 'PK_' + metric_name ) for metric_name in metrics_names . class_lexicon_metrics_names : primary_metrics_names . append ( 'CSLEX_' + metric_name ) for metric_name in metrics_names . class_ordinary_metrics_names_primary : primary_metrics_names . append ( 'CSORD_' + metric_name ) return primary_metrics_names @classmethod def compute_java_package_metrics ( cls , db = None , entity = None ): \"\"\" Find package: strategy 2: Dominated strategy \"\"\" # class_name = entity . longname () class_name_list = class_name . split ( '.' )[: - 1 ] package_name = '.' . join ( class_name_list ) # print('package_name string', package_name) package_list = db . lookup ( package_name + '$' , 'Package' ) if package_list is None : return None if len ( package_list ) == 0 : # if len != 1 return None! return None package = package_list [ 0 ] # print('kind:', package.kind()) # print('Computing package metrics for class: \"{0}\" in package: \"{1}\"'.format(class_name, package.longname())) metric_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'CountDeclClass' , 'CountDeclFile' , 'SumCyclomatic' , 'MaxNesting' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , ] package_metrics = package . metric ( metric_list ) classes_and_interfaces_list = package . ents ( 'Contain' , 'Java Type ~Unknown ~Unresolved ~Jar ~Library' ) # PKNOMNAMM: Package number of not accessor or mutator methods pk_accessor_and_mutator_methods_list = list () for type_entity in classes_and_interfaces_list : pk_accessor_and_mutator_methods_list . append ( UnderstandUtility . NOMAMM ( type_entity )) pk_accessor_and_mutator_methods_list = list ( filter ( None , pk_accessor_and_mutator_methods_list )) package_metrics . update ({ 'PKNOAMM' : sum ( pk_accessor_and_mutator_methods_list )}) pknoi = len ( UnderstandUtility . get_package_interfaces_java ( package_entity = package )) pknoac = len ( UnderstandUtility . get_package_abstract_class_java ( package_entity = package )) package_metrics . update ({ 'PKNOI' : pknoi }) package_metrics . update ({ 'PKNOAC' : pknoac }) # print('package metrics', len(package_metrics), package_metrics) return package_metrics @classmethod def compute_java_class_metrics_lexicon ( cls , entity = None ): \"\"\" Args: entity (understand.Ent): Returns: dict: class-level metrics \"\"\" class_lexicon_metrics_dict = dict () tokens_list = list () identifiers_list = list () keywords_list = list () operators_list = list () return_and_print_count = 0 return_and_print_kw_list = [ 'return' , 'print' , 'printf' , 'println' , 'write' , 'writeln' ] condition_count = 0 condition_kw_list = [ 'if' , 'for' , 'while' , 'switch' , '?' , 'assert' , ] uncondition_count = 0 uncondition_kw_list = [ 'break' , 'continue' , ] exception_count = 0 exception_kw_list = [ 'try' , 'catch' , 'throw' , 'throws' , 'finally' , ] new_count = 0 new_count_kw_list = [ 'new' ] super_count = 0 super_count_kw_list = [ 'super' ] dots_count = 0 # print(entity.longname()) lexeme = entity . lexer ( show_inactive = False ) . first () while lexeme is not None : tokens_list . append ( lexeme . text ()) if lexeme . token () == 'Identifier' : identifiers_list . append ( lexeme . text ()) if lexeme . token () == 'Keyword' : keywords_list . append ( lexeme . text ()) if lexeme . token () == 'Operator' : operators_list . append ( lexeme . text ()) if lexeme . text () in return_and_print_kw_list : return_and_print_count += 1 if lexeme . text () in condition_kw_list : condition_count += 1 if lexeme . text () in uncondition_kw_list : uncondition_count += 1 if lexeme . text () in exception_kw_list : exception_count += 1 if lexeme . text () in new_count_kw_list : new_count += 1 if lexeme . text () in super_count_kw_list : super_count += 1 if lexeme . text () == '.' : dots_count += 1 lexeme = lexeme . next () number_of_assignments = operators_list . count ( '=' ) number_of_operators_without_assignments = len ( operators_list ) - number_of_assignments number_of_unique_operators = len ( set ( list ( filter ( '=' . __ne__ , operators_list )))) class_lexicon_metrics_dict . update ({ 'NumberOfTokens' : len ( tokens_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueTokens' : len ( set ( tokens_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfIdentifies' : len ( identifiers_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueIdentifiers' : len ( set ( identifiers_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfKeywords' : len ( keywords_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueKeywords' : len ( set ( keywords_list ))}) class_lexicon_metrics_dict . update ( { 'NumberOfOperatorsWithoutAssignments' : number_of_operators_without_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfAssignments' : number_of_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueOperators' : number_of_unique_operators }) class_lexicon_metrics_dict . update ({ 'NumberOfDots' : dots_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSemicolons' : entity . metric ([ 'CountSemicolon' ])[ 'CountSemicolon' ]}) class_lexicon_metrics_dict . update ({ 'NumberOfReturnAndPrintStatements' : return_and_print_count }) class_lexicon_metrics_dict . update ({ 'NumberOfConditionalJumpStatements' : condition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfUnConditionalJumpStatements' : uncondition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfExceptionStatements' : exception_count }) class_lexicon_metrics_dict . update ({ 'NumberOfNewStatements' : new_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSuperStatements' : super_count }) # print('class lexicon metrics dict', len(class_lexicon_metrics_dict), class_lexicon_metrics_dict) return class_lexicon_metrics_dict @classmethod def compute_java_class_metrics2 ( cls , db = None , entity = None ): \"\"\" Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Args: db (understand.Db): entity (understand.Ent): Returns: dict: Class-level metrics \"\"\" method_list = UnderstandUtility . get_method_of_class_java2 ( db = db , class_name = entity . longname ()) if method_list is None : # raise TypeError('method_list is none for class \"{}\"'.format(entity.longname())) print ( 'method_list is none for class \" {} \"' . format ( entity . longname ())) return None metrics_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'SumCyclomatic' , 'MaxNesting' , 'PercentLackOfCohesion' , 'CountClassCoupled' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , 'MaxInheritanceTree' , 'CountClassDerived' , 'CountClassBase' , ] class_metrics = entity . metric ( metrics_list ) parameters_length_list = list () for method in method_list : params = method . parameters () . split ( ',' ) if len ( params ) == 1 : if params [ 0 ] == ' ' or params [ 0 ] == '' or params [ 0 ] is None : parameters_length_list . append ( 0 ) else : parameters_length_list . append ( 1 ) else : parameters_length_list . append ( len ( params )) parameters_length_list = list ( filter ( None , parameters_length_list )) class_metrics . update ({ 'SumCSNOP' : sum ( parameters_length_list )}) class_metrics . update ({ 'RFC' : UnderstandUtility . RFC ( class_name = entity )}) class_metrics . update ({ 'FANIN' : UnderstandUtility . FANIN ( db = db , class_entity = entity )}) class_metrics . update ({ 'FANOUT' : UnderstandUtility . FANOUT ( db = db , class_entity = entity )}) class_metrics . update ({ 'ATFD' : UnderstandUtility . ATFD ( db = db , class_entity = entity )}) # Not implement class_metrics . update ({ 'CFNAMM' : UnderstandUtility . CFNAMM_Class ( class_name = entity )}) class_metrics . update ({ 'DAC' : UnderstandUtility . get_data_abstraction_coupling ( db = db , class_entity = entity )}) class_metrics . update ({ 'NumberOfMethodCalls' : UnderstandUtility . number_of_method_call ( class_entity = entity )}) # Visibility metrics # Understand built-in metrics plus one custom metric. class_metrics . update ({ 'CSNOAMM' : UnderstandUtility . NOMAMM ( class_entity = entity )}) # Inheritance metrics class_metrics . update ({ 'NIM' : UnderstandUtility . NIM ( class_name = entity )}) class_metrics . update ({ 'NMO' : UnderstandUtility . NMO ( class_name = entity )}) class_metrics . update ({ 'NOII' : UnderstandUtility . NOII ( db = db )}) # Not implemented class_count_path_list = list () class_knots_list = list () for method in method_list : class_count_path_list . append ( method . metric ([ 'CountPath' ])[ 'CountPath' ]) class_knots_list . append ( method . metric ([ 'Knots' ])[ 'Knots' ]) class_count_path_list = list ( filter ( None , class_count_path_list )) class_metrics . update ({ 'SumCountPath' : sum ( class_count_path_list )}) class_knots_list = list ( filter ( None , class_knots_list )) class_metrics . update ({ 'SumKnots' : sum ( class_knots_list )}) class_metrics . update ({ 'NumberOfDepends' : len ( entity . depends ())}) class_metrics . update ({ 'NumberOfDependsBy' : len ( entity . dependsby ())}) class_metrics . update ({ 'NumberOfMethods' : class_metrics [ 'CountDeclInstanceMethod' ] + class_metrics [ 'CountDeclClassMethod' ]}) # print('class metrics', len(class_metrics), class_metrics) return class_metrics compute_java_class_metrics2 ( db = None , entity = None ) classmethod Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Parameters: Name Type Description Default db understand.Db None entity understand.Ent None Returns: Type Description dict Class-level metrics Source code in codart\\metrics\\testability_prediction2.py @classmethod def compute_java_class_metrics2 ( cls , db = None , entity = None ): \"\"\" Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Args: db (understand.Db): entity (understand.Ent): Returns: dict: Class-level metrics \"\"\" method_list = UnderstandUtility . get_method_of_class_java2 ( db = db , class_name = entity . longname ()) if method_list is None : # raise TypeError('method_list is none for class \"{}\"'.format(entity.longname())) print ( 'method_list is none for class \" {} \"' . format ( entity . longname ())) return None metrics_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'SumCyclomatic' , 'MaxNesting' , 'PercentLackOfCohesion' , 'CountClassCoupled' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , 'MaxInheritanceTree' , 'CountClassDerived' , 'CountClassBase' , ] class_metrics = entity . metric ( metrics_list ) parameters_length_list = list () for method in method_list : params = method . parameters () . split ( ',' ) if len ( params ) == 1 : if params [ 0 ] == ' ' or params [ 0 ] == '' or params [ 0 ] is None : parameters_length_list . append ( 0 ) else : parameters_length_list . append ( 1 ) else : parameters_length_list . append ( len ( params )) parameters_length_list = list ( filter ( None , parameters_length_list )) class_metrics . update ({ 'SumCSNOP' : sum ( parameters_length_list )}) class_metrics . update ({ 'RFC' : UnderstandUtility . RFC ( class_name = entity )}) class_metrics . update ({ 'FANIN' : UnderstandUtility . FANIN ( db = db , class_entity = entity )}) class_metrics . update ({ 'FANOUT' : UnderstandUtility . FANOUT ( db = db , class_entity = entity )}) class_metrics . update ({ 'ATFD' : UnderstandUtility . ATFD ( db = db , class_entity = entity )}) # Not implement class_metrics . update ({ 'CFNAMM' : UnderstandUtility . CFNAMM_Class ( class_name = entity )}) class_metrics . update ({ 'DAC' : UnderstandUtility . get_data_abstraction_coupling ( db = db , class_entity = entity )}) class_metrics . update ({ 'NumberOfMethodCalls' : UnderstandUtility . number_of_method_call ( class_entity = entity )}) # Visibility metrics # Understand built-in metrics plus one custom metric. class_metrics . update ({ 'CSNOAMM' : UnderstandUtility . NOMAMM ( class_entity = entity )}) # Inheritance metrics class_metrics . update ({ 'NIM' : UnderstandUtility . NIM ( class_name = entity )}) class_metrics . update ({ 'NMO' : UnderstandUtility . NMO ( class_name = entity )}) class_metrics . update ({ 'NOII' : UnderstandUtility . NOII ( db = db )}) # Not implemented class_count_path_list = list () class_knots_list = list () for method in method_list : class_count_path_list . append ( method . metric ([ 'CountPath' ])[ 'CountPath' ]) class_knots_list . append ( method . metric ([ 'Knots' ])[ 'Knots' ]) class_count_path_list = list ( filter ( None , class_count_path_list )) class_metrics . update ({ 'SumCountPath' : sum ( class_count_path_list )}) class_knots_list = list ( filter ( None , class_knots_list )) class_metrics . update ({ 'SumKnots' : sum ( class_knots_list )}) class_metrics . update ({ 'NumberOfDepends' : len ( entity . depends ())}) class_metrics . update ({ 'NumberOfDependsBy' : len ( entity . dependsby ())}) class_metrics . update ({ 'NumberOfMethods' : class_metrics [ 'CountDeclInstanceMethod' ] + class_metrics [ 'CountDeclClassMethod' ]}) # print('class metrics', len(class_metrics), class_metrics) return class_metrics compute_java_class_metrics_lexicon ( entity = None ) classmethod Parameters: Name Type Description Default entity understand.Ent None Returns: Type Description dict class-level metrics Source code in codart\\metrics\\testability_prediction2.py @classmethod def compute_java_class_metrics_lexicon ( cls , entity = None ): \"\"\" Args: entity (understand.Ent): Returns: dict: class-level metrics \"\"\" class_lexicon_metrics_dict = dict () tokens_list = list () identifiers_list = list () keywords_list = list () operators_list = list () return_and_print_count = 0 return_and_print_kw_list = [ 'return' , 'print' , 'printf' , 'println' , 'write' , 'writeln' ] condition_count = 0 condition_kw_list = [ 'if' , 'for' , 'while' , 'switch' , '?' , 'assert' , ] uncondition_count = 0 uncondition_kw_list = [ 'break' , 'continue' , ] exception_count = 0 exception_kw_list = [ 'try' , 'catch' , 'throw' , 'throws' , 'finally' , ] new_count = 0 new_count_kw_list = [ 'new' ] super_count = 0 super_count_kw_list = [ 'super' ] dots_count = 0 # print(entity.longname()) lexeme = entity . lexer ( show_inactive = False ) . first () while lexeme is not None : tokens_list . append ( lexeme . text ()) if lexeme . token () == 'Identifier' : identifiers_list . append ( lexeme . text ()) if lexeme . token () == 'Keyword' : keywords_list . append ( lexeme . text ()) if lexeme . token () == 'Operator' : operators_list . append ( lexeme . text ()) if lexeme . text () in return_and_print_kw_list : return_and_print_count += 1 if lexeme . text () in condition_kw_list : condition_count += 1 if lexeme . text () in uncondition_kw_list : uncondition_count += 1 if lexeme . text () in exception_kw_list : exception_count += 1 if lexeme . text () in new_count_kw_list : new_count += 1 if lexeme . text () in super_count_kw_list : super_count += 1 if lexeme . text () == '.' : dots_count += 1 lexeme = lexeme . next () number_of_assignments = operators_list . count ( '=' ) number_of_operators_without_assignments = len ( operators_list ) - number_of_assignments number_of_unique_operators = len ( set ( list ( filter ( '=' . __ne__ , operators_list )))) class_lexicon_metrics_dict . update ({ 'NumberOfTokens' : len ( tokens_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueTokens' : len ( set ( tokens_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfIdentifies' : len ( identifiers_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueIdentifiers' : len ( set ( identifiers_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfKeywords' : len ( keywords_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueKeywords' : len ( set ( keywords_list ))}) class_lexicon_metrics_dict . update ( { 'NumberOfOperatorsWithoutAssignments' : number_of_operators_without_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfAssignments' : number_of_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueOperators' : number_of_unique_operators }) class_lexicon_metrics_dict . update ({ 'NumberOfDots' : dots_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSemicolons' : entity . metric ([ 'CountSemicolon' ])[ 'CountSemicolon' ]}) class_lexicon_metrics_dict . update ({ 'NumberOfReturnAndPrintStatements' : return_and_print_count }) class_lexicon_metrics_dict . update ({ 'NumberOfConditionalJumpStatements' : condition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfUnConditionalJumpStatements' : uncondition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfExceptionStatements' : exception_count }) class_lexicon_metrics_dict . update ({ 'NumberOfNewStatements' : new_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSuperStatements' : super_count }) # print('class lexicon metrics dict', len(class_lexicon_metrics_dict), class_lexicon_metrics_dict) return class_lexicon_metrics_dict compute_java_package_metrics ( db = None , entity = None ) classmethod Find package: strategy 2: Dominated strategy Source code in codart\\metrics\\testability_prediction2.py @classmethod def compute_java_package_metrics ( cls , db = None , entity = None ): \"\"\" Find package: strategy 2: Dominated strategy \"\"\" # class_name = entity . longname () class_name_list = class_name . split ( '.' )[: - 1 ] package_name = '.' . join ( class_name_list ) # print('package_name string', package_name) package_list = db . lookup ( package_name + '$' , 'Package' ) if package_list is None : return None if len ( package_list ) == 0 : # if len != 1 return None! return None package = package_list [ 0 ] # print('kind:', package.kind()) # print('Computing package metrics for class: \"{0}\" in package: \"{1}\"'.format(class_name, package.longname())) metric_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'CountDeclClass' , 'CountDeclFile' , 'SumCyclomatic' , 'MaxNesting' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , ] package_metrics = package . metric ( metric_list ) classes_and_interfaces_list = package . ents ( 'Contain' , 'Java Type ~Unknown ~Unresolved ~Jar ~Library' ) # PKNOMNAMM: Package number of not accessor or mutator methods pk_accessor_and_mutator_methods_list = list () for type_entity in classes_and_interfaces_list : pk_accessor_and_mutator_methods_list . append ( UnderstandUtility . NOMAMM ( type_entity )) pk_accessor_and_mutator_methods_list = list ( filter ( None , pk_accessor_and_mutator_methods_list )) package_metrics . update ({ 'PKNOAMM' : sum ( pk_accessor_and_mutator_methods_list )}) pknoi = len ( UnderstandUtility . get_package_interfaces_java ( package_entity = package )) pknoac = len ( UnderstandUtility . get_package_abstract_class_java ( package_entity = package )) package_metrics . update ({ 'PKNOI' : pknoi }) package_metrics . update ({ 'PKNOAC' : pknoac }) # print('package metrics', len(package_metrics), package_metrics) return package_metrics TestabilityModel Testability prediction model Source code in codart\\metrics\\testability_prediction2.py class TestabilityModel : \"\"\" Testability prediction model \"\"\" def __init__ ( self , ): self . scaler = scaler1 self . model = model5 self . model_branch = model_branch self . model_line = model_line def inference ( self , df_predict_data = None , verbose = False , log_path = None ): df_predict_data = df_predict_data . fillna ( 0 ) X_test1 = df_predict_data . iloc [:, 1 :] X_test = self . scaler . transform ( X_test1 ) y_pred = self . model . predict ( X_test ) y_pred_branch = self . model_branch . predict ( X_test ) y_pred_line = self . model_line . predict ( X_test ) df_new = pd . DataFrame ( df_predict_data . iloc [:, 0 ], columns = [ 'Class' ]) df_new [ 'PredictedTestability' ] = list ( y_pred ) df_new [ 'BranchCoverage' ] = list ( y_pred_branch ) df_new [ 'LineCoverage' ] = list ( y_pred_line ) if verbose : self . export_class_testability_values ( df = df_new , log_path = log_path ) return df_new [ 'PredictedTestability' ] . sum () # Return sum instead mean @classmethod def export_class_testability_values ( cls , df = None , log_path = None ): if log_path is None : log_path = os . path . join ( config . PROJECT_LOG_DIR , f 'classes_testability2_for_problem_ { config . PROBLEM } .csv' ) config . logger . info ( log_path ) config . logger . info ( f 'count classes testability2 \\t { df [ \"PredictedTestability\" ] . count () } ' ) config . logger . info ( f 'minimum testability2 \\t { df [ \"PredictedTestability\" ] . min () } ' ) config . logger . info ( f 'maximum testability2 \\t { df [ \"PredictedTestability\" ] . max () } ' ) config . logger . info ( f 'variance testability2 \\t { df [ \"PredictedTestability\" ] . var () } ' ) config . logger . info ( f 'sum classes testability2 \\t , { df [ \"PredictedTestability\" ] . sum () } ' ) config . logger . info ( '-' * 50 ) df . to_csv ( log_path , index = False ) main ( project_db_path , initial_value = 1.0 , verbose = False , log_path = None ) testability_prediction module API Source code in codart\\metrics\\testability_prediction2.py def main ( project_db_path , initial_value = 1.0 , verbose = False , log_path = None ): \"\"\" testability_prediction module API \"\"\" df = PreProcess () . compute_metrics_by_class_list ( project_db_path , n_jobs = 0 # n_job must be set to number of CPU cores, use zero for non-parallel computing of metrics ) testability_ = TestabilityModel () . inference ( df_predict_data = df , verbose = verbose , log_path = log_path ) # print('testability=', testability_) return round ( testability_ / initial_value , 5 )","title":"Testability prediction"},{"location":"metrics/testability/#testability-prediction","text":"","title":"Testability prediction"},{"location":"metrics/testability/#codart.metrics.testability_prediction2--introduction","text":"This module contains light-weight version of testability prediction script (with 68 metrics) to be used in refactoring process in addition to QMOOD metrics.","title":"Introduction"},{"location":"metrics/testability/#codart.metrics.testability_prediction2--changelog","text":"","title":"Changelog"},{"location":"metrics/testability/#codart.metrics.testability_prediction2--v023","text":"Remove dependency to metrics_jcode_odor","title":"v0.2.3"},{"location":"metrics/testability/#codart.metrics.testability_prediction2--v022","text":"Add scikit-learn 1 compatibility","title":"v0.2.2"},{"location":"metrics/testability/#codart.metrics.testability_prediction2--reference","text":"[1] ADAFEST paper [2] TsDD paper","title":"Reference"},{"location":"metrics/testability/#codart.metrics.testability_prediction2.PreProcess","text":"Writes all metrics in a csv file and performs preprocessing Source code in codart\\metrics\\testability_prediction2.py class PreProcess : \"\"\" Writes all metrics in a csv file and performs preprocessing \"\"\" @classmethod def compute_metrics_by_class_list ( cls , project_db_path , n_jobs ): \"\"\" \"\"\" # class_entities = cls.read_project_classes(db=db, classes_names_list=class_list, ) # print(project_db_path) db = und . open ( project_db_path ) class_list = UnderstandUtility . get_project_classes_longnames_java ( db = db ) db . close () # del db if n_jobs == 0 : # Sequential computing res = [ do ( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ] else : # Parallel computing res = Parallel ( n_jobs = n_jobs , )( delayed ( do )( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ) res = list ( filter ( None , res )) columns = [ 'Class' ] columns . extend ( TestabilityMetrics . get_all_primary_metrics_names ()) df = pd . DataFrame ( data = res , columns = columns ) # print('df for class {0} with shape {1}'.format(project_name, df.shape)) # df.to_csv(csv_path + project_name + '.csv', index=False) # print(df) return df","title":"PreProcess"},{"location":"metrics/testability/#codart.metrics.testability_prediction2.PreProcess.compute_metrics_by_class_list","text":"Source code in codart\\metrics\\testability_prediction2.py @classmethod def compute_metrics_by_class_list ( cls , project_db_path , n_jobs ): \"\"\" \"\"\" # class_entities = cls.read_project_classes(db=db, classes_names_list=class_list, ) # print(project_db_path) db = und . open ( project_db_path ) class_list = UnderstandUtility . get_project_classes_longnames_java ( db = db ) db . close () # del db if n_jobs == 0 : # Sequential computing res = [ do ( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ] else : # Parallel computing res = Parallel ( n_jobs = n_jobs , )( delayed ( do )( class_entity_long_name , project_db_path ) for class_entity_long_name in class_list ) res = list ( filter ( None , res )) columns = [ 'Class' ] columns . extend ( TestabilityMetrics . get_all_primary_metrics_names ()) df = pd . DataFrame ( data = res , columns = columns ) # print('df for class {0} with shape {1}'.format(project_name, df.shape)) # df.to_csv(csv_path + project_name + '.csv', index=False) # print(df) return df","title":"compute_metrics_by_class_list()"},{"location":"metrics/testability/#codart.metrics.testability_prediction2.TestabilityMetrics","text":"Compute all required metrics for computing Coverageability and testability. Source code in codart\\metrics\\testability_prediction2.py class TestabilityMetrics : \"\"\" Compute all required metrics for computing Coverageability and testability. \"\"\" @classmethod def get_package_metrics_names ( cls ) -> list : return metrics_names . package_metrics_names_primary @classmethod def get_class_lexicon_metrics_names ( cls ) -> list : return metrics_names . class_lexicon_metrics_names @classmethod def get_class_ordinary_metrics_names ( cls ) -> list : return metrics_names . class_ordinary_metrics_names_primary @classmethod def get_all_metrics_names ( cls ) -> list : metrics = list () # print('project_metrics number: ', len(TestabilityMetrics.get_project_metrics_names())) # for metric_name in TestabilityMetrics.get_project_metrics_names(): # metrics.append('PJ_' + metric_name) # print('package_metrics number: ', len(TestabilityMetrics.get_package_metrics_names())) for metric_name in TestabilityMetrics . get_package_metrics_names (): metrics . append ( 'PK_' + metric_name ) # SOOTI is now corrected. # print('class_lexicon_metrics number: ', len(TestabilityMetrics.get_class_lexicon_metrics_names())) for metric_name in TestabilityMetrics . get_class_lexicon_metrics_names (): metrics . append ( 'CSLEX_' + metric_name ) # print('class_ordinary_metrics number: ', len(TestabilityMetrics.get_class_ordinary_metrics_names())) for metric_name in TestabilityMetrics . get_class_ordinary_metrics_names (): metrics . append ( 'CSORD_' + metric_name ) # print('All available metrics: {0}'.format(len(metrics))) return metrics @classmethod def get_all_primary_metrics_names ( cls ) -> list : primary_metrics_names = list () # for metric_name in metrics.metrics_names.project_metrics_names_primary: # primary_metrics_names.append('PJ_' + metric_name) for metric_name in metrics_names . package_metrics_names_primary : primary_metrics_names . append ( 'PK_' + metric_name ) for metric_name in metrics_names . class_lexicon_metrics_names : primary_metrics_names . append ( 'CSLEX_' + metric_name ) for metric_name in metrics_names . class_ordinary_metrics_names_primary : primary_metrics_names . append ( 'CSORD_' + metric_name ) return primary_metrics_names @classmethod def compute_java_package_metrics ( cls , db = None , entity = None ): \"\"\" Find package: strategy 2: Dominated strategy \"\"\" # class_name = entity . longname () class_name_list = class_name . split ( '.' )[: - 1 ] package_name = '.' . join ( class_name_list ) # print('package_name string', package_name) package_list = db . lookup ( package_name + '$' , 'Package' ) if package_list is None : return None if len ( package_list ) == 0 : # if len != 1 return None! return None package = package_list [ 0 ] # print('kind:', package.kind()) # print('Computing package metrics for class: \"{0}\" in package: \"{1}\"'.format(class_name, package.longname())) metric_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'CountDeclClass' , 'CountDeclFile' , 'SumCyclomatic' , 'MaxNesting' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , ] package_metrics = package . metric ( metric_list ) classes_and_interfaces_list = package . ents ( 'Contain' , 'Java Type ~Unknown ~Unresolved ~Jar ~Library' ) # PKNOMNAMM: Package number of not accessor or mutator methods pk_accessor_and_mutator_methods_list = list () for type_entity in classes_and_interfaces_list : pk_accessor_and_mutator_methods_list . append ( UnderstandUtility . NOMAMM ( type_entity )) pk_accessor_and_mutator_methods_list = list ( filter ( None , pk_accessor_and_mutator_methods_list )) package_metrics . update ({ 'PKNOAMM' : sum ( pk_accessor_and_mutator_methods_list )}) pknoi = len ( UnderstandUtility . get_package_interfaces_java ( package_entity = package )) pknoac = len ( UnderstandUtility . get_package_abstract_class_java ( package_entity = package )) package_metrics . update ({ 'PKNOI' : pknoi }) package_metrics . update ({ 'PKNOAC' : pknoac }) # print('package metrics', len(package_metrics), package_metrics) return package_metrics @classmethod def compute_java_class_metrics_lexicon ( cls , entity = None ): \"\"\" Args: entity (understand.Ent): Returns: dict: class-level metrics \"\"\" class_lexicon_metrics_dict = dict () tokens_list = list () identifiers_list = list () keywords_list = list () operators_list = list () return_and_print_count = 0 return_and_print_kw_list = [ 'return' , 'print' , 'printf' , 'println' , 'write' , 'writeln' ] condition_count = 0 condition_kw_list = [ 'if' , 'for' , 'while' , 'switch' , '?' , 'assert' , ] uncondition_count = 0 uncondition_kw_list = [ 'break' , 'continue' , ] exception_count = 0 exception_kw_list = [ 'try' , 'catch' , 'throw' , 'throws' , 'finally' , ] new_count = 0 new_count_kw_list = [ 'new' ] super_count = 0 super_count_kw_list = [ 'super' ] dots_count = 0 # print(entity.longname()) lexeme = entity . lexer ( show_inactive = False ) . first () while lexeme is not None : tokens_list . append ( lexeme . text ()) if lexeme . token () == 'Identifier' : identifiers_list . append ( lexeme . text ()) if lexeme . token () == 'Keyword' : keywords_list . append ( lexeme . text ()) if lexeme . token () == 'Operator' : operators_list . append ( lexeme . text ()) if lexeme . text () in return_and_print_kw_list : return_and_print_count += 1 if lexeme . text () in condition_kw_list : condition_count += 1 if lexeme . text () in uncondition_kw_list : uncondition_count += 1 if lexeme . text () in exception_kw_list : exception_count += 1 if lexeme . text () in new_count_kw_list : new_count += 1 if lexeme . text () in super_count_kw_list : super_count += 1 if lexeme . text () == '.' : dots_count += 1 lexeme = lexeme . next () number_of_assignments = operators_list . count ( '=' ) number_of_operators_without_assignments = len ( operators_list ) - number_of_assignments number_of_unique_operators = len ( set ( list ( filter ( '=' . __ne__ , operators_list )))) class_lexicon_metrics_dict . update ({ 'NumberOfTokens' : len ( tokens_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueTokens' : len ( set ( tokens_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfIdentifies' : len ( identifiers_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueIdentifiers' : len ( set ( identifiers_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfKeywords' : len ( keywords_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueKeywords' : len ( set ( keywords_list ))}) class_lexicon_metrics_dict . update ( { 'NumberOfOperatorsWithoutAssignments' : number_of_operators_without_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfAssignments' : number_of_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueOperators' : number_of_unique_operators }) class_lexicon_metrics_dict . update ({ 'NumberOfDots' : dots_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSemicolons' : entity . metric ([ 'CountSemicolon' ])[ 'CountSemicolon' ]}) class_lexicon_metrics_dict . update ({ 'NumberOfReturnAndPrintStatements' : return_and_print_count }) class_lexicon_metrics_dict . update ({ 'NumberOfConditionalJumpStatements' : condition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfUnConditionalJumpStatements' : uncondition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfExceptionStatements' : exception_count }) class_lexicon_metrics_dict . update ({ 'NumberOfNewStatements' : new_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSuperStatements' : super_count }) # print('class lexicon metrics dict', len(class_lexicon_metrics_dict), class_lexicon_metrics_dict) return class_lexicon_metrics_dict @classmethod def compute_java_class_metrics2 ( cls , db = None , entity = None ): \"\"\" Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Args: db (understand.Db): entity (understand.Ent): Returns: dict: Class-level metrics \"\"\" method_list = UnderstandUtility . get_method_of_class_java2 ( db = db , class_name = entity . longname ()) if method_list is None : # raise TypeError('method_list is none for class \"{}\"'.format(entity.longname())) print ( 'method_list is none for class \" {} \"' . format ( entity . longname ())) return None metrics_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'SumCyclomatic' , 'MaxNesting' , 'PercentLackOfCohesion' , 'CountClassCoupled' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , 'MaxInheritanceTree' , 'CountClassDerived' , 'CountClassBase' , ] class_metrics = entity . metric ( metrics_list ) parameters_length_list = list () for method in method_list : params = method . parameters () . split ( ',' ) if len ( params ) == 1 : if params [ 0 ] == ' ' or params [ 0 ] == '' or params [ 0 ] is None : parameters_length_list . append ( 0 ) else : parameters_length_list . append ( 1 ) else : parameters_length_list . append ( len ( params )) parameters_length_list = list ( filter ( None , parameters_length_list )) class_metrics . update ({ 'SumCSNOP' : sum ( parameters_length_list )}) class_metrics . update ({ 'RFC' : UnderstandUtility . RFC ( class_name = entity )}) class_metrics . update ({ 'FANIN' : UnderstandUtility . FANIN ( db = db , class_entity = entity )}) class_metrics . update ({ 'FANOUT' : UnderstandUtility . FANOUT ( db = db , class_entity = entity )}) class_metrics . update ({ 'ATFD' : UnderstandUtility . ATFD ( db = db , class_entity = entity )}) # Not implement class_metrics . update ({ 'CFNAMM' : UnderstandUtility . CFNAMM_Class ( class_name = entity )}) class_metrics . update ({ 'DAC' : UnderstandUtility . get_data_abstraction_coupling ( db = db , class_entity = entity )}) class_metrics . update ({ 'NumberOfMethodCalls' : UnderstandUtility . number_of_method_call ( class_entity = entity )}) # Visibility metrics # Understand built-in metrics plus one custom metric. class_metrics . update ({ 'CSNOAMM' : UnderstandUtility . NOMAMM ( class_entity = entity )}) # Inheritance metrics class_metrics . update ({ 'NIM' : UnderstandUtility . NIM ( class_name = entity )}) class_metrics . update ({ 'NMO' : UnderstandUtility . NMO ( class_name = entity )}) class_metrics . update ({ 'NOII' : UnderstandUtility . NOII ( db = db )}) # Not implemented class_count_path_list = list () class_knots_list = list () for method in method_list : class_count_path_list . append ( method . metric ([ 'CountPath' ])[ 'CountPath' ]) class_knots_list . append ( method . metric ([ 'Knots' ])[ 'Knots' ]) class_count_path_list = list ( filter ( None , class_count_path_list )) class_metrics . update ({ 'SumCountPath' : sum ( class_count_path_list )}) class_knots_list = list ( filter ( None , class_knots_list )) class_metrics . update ({ 'SumKnots' : sum ( class_knots_list )}) class_metrics . update ({ 'NumberOfDepends' : len ( entity . depends ())}) class_metrics . update ({ 'NumberOfDependsBy' : len ( entity . dependsby ())}) class_metrics . update ({ 'NumberOfMethods' : class_metrics [ 'CountDeclInstanceMethod' ] + class_metrics [ 'CountDeclClassMethod' ]}) # print('class metrics', len(class_metrics), class_metrics) return class_metrics","title":"TestabilityMetrics"},{"location":"metrics/testability/#codart.metrics.testability_prediction2.TestabilityMetrics.compute_java_class_metrics2","text":"Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Parameters: Name Type Description Default db understand.Db None entity understand.Ent None Returns: Type Description dict Class-level metrics Source code in codart\\metrics\\testability_prediction2.py @classmethod def compute_java_class_metrics2 ( cls , db = None , entity = None ): \"\"\" Strategy #2: Take a list of all classes and search for target class Which strategy is used for our final setting? I do not know! Args: db (understand.Db): entity (understand.Ent): Returns: dict: Class-level metrics \"\"\" method_list = UnderstandUtility . get_method_of_class_java2 ( db = db , class_name = entity . longname ()) if method_list is None : # raise TypeError('method_list is none for class \"{}\"'.format(entity.longname())) print ( 'method_list is none for class \" {} \"' . format ( entity . longname ())) return None metrics_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'SumCyclomatic' , 'MaxNesting' , 'PercentLackOfCohesion' , 'CountClassCoupled' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , 'MaxInheritanceTree' , 'CountClassDerived' , 'CountClassBase' , ] class_metrics = entity . metric ( metrics_list ) parameters_length_list = list () for method in method_list : params = method . parameters () . split ( ',' ) if len ( params ) == 1 : if params [ 0 ] == ' ' or params [ 0 ] == '' or params [ 0 ] is None : parameters_length_list . append ( 0 ) else : parameters_length_list . append ( 1 ) else : parameters_length_list . append ( len ( params )) parameters_length_list = list ( filter ( None , parameters_length_list )) class_metrics . update ({ 'SumCSNOP' : sum ( parameters_length_list )}) class_metrics . update ({ 'RFC' : UnderstandUtility . RFC ( class_name = entity )}) class_metrics . update ({ 'FANIN' : UnderstandUtility . FANIN ( db = db , class_entity = entity )}) class_metrics . update ({ 'FANOUT' : UnderstandUtility . FANOUT ( db = db , class_entity = entity )}) class_metrics . update ({ 'ATFD' : UnderstandUtility . ATFD ( db = db , class_entity = entity )}) # Not implement class_metrics . update ({ 'CFNAMM' : UnderstandUtility . CFNAMM_Class ( class_name = entity )}) class_metrics . update ({ 'DAC' : UnderstandUtility . get_data_abstraction_coupling ( db = db , class_entity = entity )}) class_metrics . update ({ 'NumberOfMethodCalls' : UnderstandUtility . number_of_method_call ( class_entity = entity )}) # Visibility metrics # Understand built-in metrics plus one custom metric. class_metrics . update ({ 'CSNOAMM' : UnderstandUtility . NOMAMM ( class_entity = entity )}) # Inheritance metrics class_metrics . update ({ 'NIM' : UnderstandUtility . NIM ( class_name = entity )}) class_metrics . update ({ 'NMO' : UnderstandUtility . NMO ( class_name = entity )}) class_metrics . update ({ 'NOII' : UnderstandUtility . NOII ( db = db )}) # Not implemented class_count_path_list = list () class_knots_list = list () for method in method_list : class_count_path_list . append ( method . metric ([ 'CountPath' ])[ 'CountPath' ]) class_knots_list . append ( method . metric ([ 'Knots' ])[ 'Knots' ]) class_count_path_list = list ( filter ( None , class_count_path_list )) class_metrics . update ({ 'SumCountPath' : sum ( class_count_path_list )}) class_knots_list = list ( filter ( None , class_knots_list )) class_metrics . update ({ 'SumKnots' : sum ( class_knots_list )}) class_metrics . update ({ 'NumberOfDepends' : len ( entity . depends ())}) class_metrics . update ({ 'NumberOfDependsBy' : len ( entity . dependsby ())}) class_metrics . update ({ 'NumberOfMethods' : class_metrics [ 'CountDeclInstanceMethod' ] + class_metrics [ 'CountDeclClassMethod' ]}) # print('class metrics', len(class_metrics), class_metrics) return class_metrics","title":"compute_java_class_metrics2()"},{"location":"metrics/testability/#codart.metrics.testability_prediction2.TestabilityMetrics.compute_java_class_metrics_lexicon","text":"Parameters: Name Type Description Default entity understand.Ent None Returns: Type Description dict class-level metrics Source code in codart\\metrics\\testability_prediction2.py @classmethod def compute_java_class_metrics_lexicon ( cls , entity = None ): \"\"\" Args: entity (understand.Ent): Returns: dict: class-level metrics \"\"\" class_lexicon_metrics_dict = dict () tokens_list = list () identifiers_list = list () keywords_list = list () operators_list = list () return_and_print_count = 0 return_and_print_kw_list = [ 'return' , 'print' , 'printf' , 'println' , 'write' , 'writeln' ] condition_count = 0 condition_kw_list = [ 'if' , 'for' , 'while' , 'switch' , '?' , 'assert' , ] uncondition_count = 0 uncondition_kw_list = [ 'break' , 'continue' , ] exception_count = 0 exception_kw_list = [ 'try' , 'catch' , 'throw' , 'throws' , 'finally' , ] new_count = 0 new_count_kw_list = [ 'new' ] super_count = 0 super_count_kw_list = [ 'super' ] dots_count = 0 # print(entity.longname()) lexeme = entity . lexer ( show_inactive = False ) . first () while lexeme is not None : tokens_list . append ( lexeme . text ()) if lexeme . token () == 'Identifier' : identifiers_list . append ( lexeme . text ()) if lexeme . token () == 'Keyword' : keywords_list . append ( lexeme . text ()) if lexeme . token () == 'Operator' : operators_list . append ( lexeme . text ()) if lexeme . text () in return_and_print_kw_list : return_and_print_count += 1 if lexeme . text () in condition_kw_list : condition_count += 1 if lexeme . text () in uncondition_kw_list : uncondition_count += 1 if lexeme . text () in exception_kw_list : exception_count += 1 if lexeme . text () in new_count_kw_list : new_count += 1 if lexeme . text () in super_count_kw_list : super_count += 1 if lexeme . text () == '.' : dots_count += 1 lexeme = lexeme . next () number_of_assignments = operators_list . count ( '=' ) number_of_operators_without_assignments = len ( operators_list ) - number_of_assignments number_of_unique_operators = len ( set ( list ( filter ( '=' . __ne__ , operators_list )))) class_lexicon_metrics_dict . update ({ 'NumberOfTokens' : len ( tokens_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueTokens' : len ( set ( tokens_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfIdentifies' : len ( identifiers_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueIdentifiers' : len ( set ( identifiers_list ))}) class_lexicon_metrics_dict . update ({ 'NumberOfKeywords' : len ( keywords_list )}) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueKeywords' : len ( set ( keywords_list ))}) class_lexicon_metrics_dict . update ( { 'NumberOfOperatorsWithoutAssignments' : number_of_operators_without_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfAssignments' : number_of_assignments }) class_lexicon_metrics_dict . update ({ 'NumberOfUniqueOperators' : number_of_unique_operators }) class_lexicon_metrics_dict . update ({ 'NumberOfDots' : dots_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSemicolons' : entity . metric ([ 'CountSemicolon' ])[ 'CountSemicolon' ]}) class_lexicon_metrics_dict . update ({ 'NumberOfReturnAndPrintStatements' : return_and_print_count }) class_lexicon_metrics_dict . update ({ 'NumberOfConditionalJumpStatements' : condition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfUnConditionalJumpStatements' : uncondition_count }) class_lexicon_metrics_dict . update ({ 'NumberOfExceptionStatements' : exception_count }) class_lexicon_metrics_dict . update ({ 'NumberOfNewStatements' : new_count }) class_lexicon_metrics_dict . update ({ 'NumberOfSuperStatements' : super_count }) # print('class lexicon metrics dict', len(class_lexicon_metrics_dict), class_lexicon_metrics_dict) return class_lexicon_metrics_dict","title":"compute_java_class_metrics_lexicon()"},{"location":"metrics/testability/#codart.metrics.testability_prediction2.TestabilityMetrics.compute_java_package_metrics","text":"Find package: strategy 2: Dominated strategy Source code in codart\\metrics\\testability_prediction2.py @classmethod def compute_java_package_metrics ( cls , db = None , entity = None ): \"\"\" Find package: strategy 2: Dominated strategy \"\"\" # class_name = entity . longname () class_name_list = class_name . split ( '.' )[: - 1 ] package_name = '.' . join ( class_name_list ) # print('package_name string', package_name) package_list = db . lookup ( package_name + '$' , 'Package' ) if package_list is None : return None if len ( package_list ) == 0 : # if len != 1 return None! return None package = package_list [ 0 ] # print('kind:', package.kind()) # print('Computing package metrics for class: \"{0}\" in package: \"{1}\"'.format(class_name, package.longname())) metric_list = [ 'CountLineCode' , 'CountStmt' , 'CountDeclClassMethod' , 'CountDeclClassVariable' , 'CountDeclInstanceMethod' , 'CountDeclInstanceVariable' , 'CountDeclClass' , 'CountDeclFile' , 'SumCyclomatic' , 'MaxNesting' , 'CountDeclMethodDefault' , 'CountDeclMethodPrivate' , 'CountDeclMethodProtected' , 'CountDeclMethodPublic' , ] package_metrics = package . metric ( metric_list ) classes_and_interfaces_list = package . ents ( 'Contain' , 'Java Type ~Unknown ~Unresolved ~Jar ~Library' ) # PKNOMNAMM: Package number of not accessor or mutator methods pk_accessor_and_mutator_methods_list = list () for type_entity in classes_and_interfaces_list : pk_accessor_and_mutator_methods_list . append ( UnderstandUtility . NOMAMM ( type_entity )) pk_accessor_and_mutator_methods_list = list ( filter ( None , pk_accessor_and_mutator_methods_list )) package_metrics . update ({ 'PKNOAMM' : sum ( pk_accessor_and_mutator_methods_list )}) pknoi = len ( UnderstandUtility . get_package_interfaces_java ( package_entity = package )) pknoac = len ( UnderstandUtility . get_package_abstract_class_java ( package_entity = package )) package_metrics . update ({ 'PKNOI' : pknoi }) package_metrics . update ({ 'PKNOAC' : pknoac }) # print('package metrics', len(package_metrics), package_metrics) return package_metrics","title":"compute_java_package_metrics()"},{"location":"metrics/testability/#codart.metrics.testability_prediction2.TestabilityModel","text":"Testability prediction model Source code in codart\\metrics\\testability_prediction2.py class TestabilityModel : \"\"\" Testability prediction model \"\"\" def __init__ ( self , ): self . scaler = scaler1 self . model = model5 self . model_branch = model_branch self . model_line = model_line def inference ( self , df_predict_data = None , verbose = False , log_path = None ): df_predict_data = df_predict_data . fillna ( 0 ) X_test1 = df_predict_data . iloc [:, 1 :] X_test = self . scaler . transform ( X_test1 ) y_pred = self . model . predict ( X_test ) y_pred_branch = self . model_branch . predict ( X_test ) y_pred_line = self . model_line . predict ( X_test ) df_new = pd . DataFrame ( df_predict_data . iloc [:, 0 ], columns = [ 'Class' ]) df_new [ 'PredictedTestability' ] = list ( y_pred ) df_new [ 'BranchCoverage' ] = list ( y_pred_branch ) df_new [ 'LineCoverage' ] = list ( y_pred_line ) if verbose : self . export_class_testability_values ( df = df_new , log_path = log_path ) return df_new [ 'PredictedTestability' ] . sum () # Return sum instead mean @classmethod def export_class_testability_values ( cls , df = None , log_path = None ): if log_path is None : log_path = os . path . join ( config . PROJECT_LOG_DIR , f 'classes_testability2_for_problem_ { config . PROBLEM } .csv' ) config . logger . info ( log_path ) config . logger . info ( f 'count classes testability2 \\t { df [ \"PredictedTestability\" ] . count () } ' ) config . logger . info ( f 'minimum testability2 \\t { df [ \"PredictedTestability\" ] . min () } ' ) config . logger . info ( f 'maximum testability2 \\t { df [ \"PredictedTestability\" ] . max () } ' ) config . logger . info ( f 'variance testability2 \\t { df [ \"PredictedTestability\" ] . var () } ' ) config . logger . info ( f 'sum classes testability2 \\t , { df [ \"PredictedTestability\" ] . sum () } ' ) config . logger . info ( '-' * 50 ) df . to_csv ( log_path , index = False )","title":"TestabilityModel"},{"location":"metrics/testability/#codart.metrics.testability_prediction2.main","text":"testability_prediction module API Source code in codart\\metrics\\testability_prediction2.py def main ( project_db_path , initial_value = 1.0 , verbose = False , log_path = None ): \"\"\" testability_prediction module API \"\"\" df = PreProcess () . compute_metrics_by_class_list ( project_db_path , n_jobs = 0 # n_job must be set to number of CPU cores, use zero for non-parallel computing of metrics ) testability_ = TestabilityModel () . inference ( df_predict_data = df , verbose = verbose , log_path = log_path ) # print('testability=', testability_) return round ( testability_ / initial_value , 5 )","title":"main()"},{"location":"optimization/initialize/","text":"Search-based refactoring initialization Introduction This module implements finding refactoring candidates for the search-based algorithms Initialization: The abstract class and common utility functions. RandomInitialization: For initialling random candidates. Changelog Version 0.4.0 Enhances module's design. Version 0.3.2 Initialization The superclass of initialization contains init_refactoring methods Source code in codart\\sbse\\initialize.py class Initialization ( object ): \"\"\" The superclass of initialization contains init_refactoring methods \"\"\" def __init__ ( self , udb_path , population_size = 50 , lower_band = 10 , upper_band = 50 ): \"\"\" Args: udb_path (str): Path for understand database file. population_size (int): The length of population for GA. lower_band (int): The minimum length of individual for GA. upper_band (int): The maximum length of individual for GA. Returns: None \"\"\" random . seed ( None ) self . udb_path = udb_path self . population_size = population_size self . lower_band = lower_band self . upper_band = upper_band self . population = [] self . initializers = ( self . init_make_field_non_static , # 0 self . init_make_field_static , # 1 self . init_make_method_static , # 2 self . init_make_method_non_static , # 3 self . init_pullup_field , # 4 self . init_move_field , # 5 self . init_move_method , # 6 # self.init_move_method, # 6.2 self . init_move_class , # 7 # self.init_move_class, # 7.2 self . init_push_down_field , # 8 self . init_extract_class , # 9 # self.init_extract_class, # 9.2 self . init_pullup_method , # 10 self . init_push_down_method , # 11 self . init_pullup_constructor , # 12 self . init_decrease_field_visibility , # 13 self . init_increase_field_visibility , # 14 self . init_decrease_method_visibility , # 15 self . init_increase_method_visibility , # 16 self . init_extract_interface , # 17 # self.init_extract_interface, # 17.2 # self.init_extract_method, # 18 ) self . _variables = self . get_all_variables () self . _static_variables = self . get_all_variables ( static = True ) self . _methods = self . get_all_methods () self . _static_methods = self . get_all_methods ( static = True ) self . _pullup_field_candidates = self . find_pullup_field_candidates () self . _push_down_field_candidates = self . find_push_down_field_candidates () self . _pullup_method_candidates = self . find_pullup_method_candidates () self . _pullup_constructor_candidates = self . find_pullup_constructor_candidates () self . _push_down_method_candidates = self . find_push_down_method_candidates () self . _extract_interface_candidates = self . find_extract_interface_candidate () def __del__ ( self ): # logger.info(\"Understand database closed after initialization.\") # self._und.close() pass def get_all_methods ( self , static = False ): _db = und . open ( self . udb_path ) candidates = [] if static : query = _db . ents ( \"Static Method\" ) blacklist = ( 'abstract' , 'unknown' , 'constructor' ,) else : query = _db . ents ( \"Method\" ) blacklist = ( 'constructor' , 'static' , 'abstract' , 'unknown' ,) for ent in query : kind_name = ent . kindname () . lower () if any ( word in kind_name for word in blacklist ): continue parent = ent . parent () if parent is None : continue if not parent . kind () . check ( \"class\" ) or parent . kind () . check ( \"anonymous\" ): continue long_name = parent . longname () . split ( '.' ) method_name = ent . simplename () if len ( long_name ) == 1 : source_class = long_name [ - 1 ] source_package = None elif len ( long_name ) > 1 : source_class = long_name [ - 1 ] source_package = \".\" . join ( long_name [: - 1 ]) else : continue is_public = ent . kind () . check ( 'public' ) is_private = ent . kind () . check ( 'private' ) external_references = 0 for ref in ent . refs ( 'Callby, Overrideby' ): if '.' . join ( long_name [: - 1 ]) not in ref . ent () . longname (): external_references += 1 candidates . append ( { 'source_package' : source_package , 'source_class' : source_class , 'method_name' : method_name , 'is_public' : is_public , 'is_private' : is_private , 'external_references' : external_references } ) _db . close () return candidates def get_all_variables ( self , static = False ): _db = und . open ( self . udb_path ) candidates = [] if static : query = _db . ents ( \"Static Variable\" ) blacklist = () else : query = _db . ents ( \"Variable\" ) blacklist = ( 'static' ,) for ent in query : kind_name = ent . kindname () . lower () if any ( word in kind_name for word in blacklist ): continue parent = ent . parent () if parent is None : continue if not parent . kind () . check ( \"class\" ) or parent . kind () . check ( \"anonymous\" ): continue source_package = None long_name = ent . longname () . split ( \".\" ) if len ( long_name ) >= 3 : source_package = '.' . join ( long_name [: - 2 ]) source_class , field_name = long_name [ - 2 :] elif len ( long_name ) == 2 : source_class , field_name = long_name else : continue is_public = ent . kind () . check ( 'public' ) is_private = ent . kind () . check ( 'private' ) external_references = 0 for ref in ent . refs ( 'Setby, Useby' ): if '.' . join ( long_name [: - 1 ]) not in ref . ent () . longname (): external_references += 1 candidates . append ( { 'source_package' : source_package , 'source_class' : source_class , 'field_name' : field_name , 'is_public' : is_public , 'is_private' : is_private , 'external_references' : external_references } ) _db . close () return candidates # def get_all_class_entities(self, filter_=\"class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\"): # query = self._und.ents(filter_) # class_entities = [] # for ent in query: # class_entities.append(ent) # return class_entities # return query def find_pullup_field_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) for ent in class_entities : for ref in ent . refs ( \"Define\" , \"Variable\" ): candidate = { \"package_name\" : get_package_from_class ( ent . longname ()), \"children_class\" : ent . simplename (), \"field_name\" : ref . ent () . simplename () } candidates . append ( candidate ) _db . close () return candidates def find_push_down_field_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) for ent in class_entities : params = { \"source_class\" : \"\" , \"source_package\" : \"\" , \"field_name\" : \"\" , \"target_classes\" : [] } field_names = [] for ref in ent . refs ( \"ExtendBy ~Implicit\" ): params [ \"source_class\" ] = ent . simplename () params [ \"source_package\" ] = get_package_from_class ( ent . longname ()) if len ( params [ \"target_classes\" ]) >= 1 : rnd = random . randint ( 0 , 1 ) if rnd == 0 : params [ \"target_classes\" ] . append ( ref . ent () . simplename ()) else : params [ \"target_classes\" ] . append ( ref . ent () . simplename ()) for ref in ent . refs ( \"define\" , \"variable\" ): field_names . append ( ref . ent () . simplename ()) if field_names : params [ \"field_name\" ] = random . choice ( field_names ) else : continue if params [ \"source_class\" ] != \"\" : candidates . append ( params ) _db . close () return candidates def find_pullup_method_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) common_methods = [] for ent in class_entities : children = [] class_method_dict = {} father_methods = [] for met_ref in ent . refs ( \"Define\" , \"Method ~Override\" ): method = met_ref . ent () father_methods . append ( method . simplename ()) for ref in ent . refs ( \"Extendby\" ): child = ref . ent () if not child . kind () . check ( \"public class\" ): continue child_name = child . simplename () children . append ( child_name ) if child_name not in class_method_dict : class_method_dict [ child_name ] = [] for met_ref in child . refs ( \"Define\" , \"Method\" ): method = met_ref . ent () method_name = method . simplename () if method . ents ( \"Override\" ): continue if method_name not in father_methods : common_methods . append ( method_name ) class_method_dict [ child_name ] . append ( method_name ) counts = Counter ( common_methods ) common_methods = [ value for value , count in counts . items () if count > 1 ] if len ( common_methods ) > 0 : random_method = random . choice ( common_methods ) children = [ k for k , v in class_method_dict . items () if random_method in v ] if len ( children ) > 1 : candidates . append ({ \"method_name\" : random . choice ( common_methods ), \"children_classes\" : children }) _db . close () return candidates def find_pullup_constructor_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) for ent in class_entities : children = [] params = {} for ref in ent . refs ( \"Extendby\" ): child = ref . ent () if not child . kind () . check ( \"public class\" ): continue child_name = child . simplename () children . append ( child_name ) ln = ent . longname () . split ( \".\" ) params [ \"source_package\" ] = \".\" . join ( ln [: - 1 ]) if len ( ln ) > 1 else \"\" params [ \"target_class\" ] = ent . simplename () if len ( children ) >= 2 : params [ \"class_names\" ] = random . sample ( children , random . randint ( 2 , len ( children ))) candidates . append ( params ) _db . close () return candidates def find_push_down_method_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) for ent in class_entities : params = { \"source_class\" : \"\" , \"source_package\" : \"\" , \"method_name\" : \"\" , \"target_classes\" : [] } method_names = [] for ref in ent . refs ( \"Extendby ~Implicit\" , \"Public Class\" ): params [ \"source_class\" ] = ent . simplename () ln = ent . longname () . split ( \".\" ) params [ \"source_package\" ] = ln [ 0 ] if len ( ln ) > 1 else \"\" params [ \"target_classes\" ] . append ( ref . ent () . simplename ()) for ref in ent . refs ( \"Define\" , \"Method\" ): method_names . append ( ref . ent () . simplename ()) if method_names : params [ \"method_name\" ] = random . choice ( method_names ) else : continue if params [ \"target_classes\" ]: params [ \"target_classes\" ] = [ random . choice ( params [ \"target_classes\" ])] else : continue if params [ \"source_class\" ] != \"\" : candidates . append ( params ) _db . close () return candidates def find_extract_interface_candidate ( self ): _db = und . open ( config . UDB_PATH ) extract_interface_refactoring_candidates = [] classes = _db . ents ( \"Type Class Public ~Generic ~Interface ~Enum ~Unknown ~Anonymous ~TypeVariable\" ) for class_entity in classes : class_path = class_entity . parent () . longname () if os . path . exists ( class_path ): filter_inherited_attrs = 'Java Extend Couple ~Implicit, Java Implement Couple ~Implicit' filter_inherited_attrs = 'Java Implement Couple ~Implicit' inherited_entities = class_entity . ents ( filter_inherited_attrs ) if len ( inherited_entities ) == 0 : public_methods = len ( class_entity . ents ( \"Define\" , \"Java Method Member ~Private ~Static\" )) if public_methods > 0 : extract_interface_refactoring_candidates . append ( class_path ) _db . close () return extract_interface_refactoring_candidates def init_make_field_non_static ( self ): pass def init_make_field_static ( self ): pass def init_make_method_static ( self ): pass def init_make_method_non_static ( self ): pass def init_pullup_field ( self ): pass def init_push_down_field ( self ): pass def init_pullup_method ( self ): pass def init_pullup_constructor ( self ): pass def init_push_down_method ( self ): pass def init_move_field ( self ): pass def init_move_method ( self ): pass def init_move_class ( self ): pass def init_extract_class ( self ): pass def init_extract_method ( self ): pass def init_decrease_field_visibility ( self ): pass def init_decrease_method_visibility ( self ): pass def init_increase_field_visibility ( self ): pass def init_increase_method_visibility ( self ): pass def init_extract_interface ( self ): pass def generate_population ( self ): \"\"\" Generate population abstract method \"\"\" pass def select_random ( self ): \"\"\" Randomly selects a refactoring. If there are no candidates it tries again! Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" initializer = random . choice ( self . initializers ) logger . debug ( f '>>> Randomly selected refactoring: { initializer . __name__ } ' ) main_function , params , name = handle_index_error ( initializer )() if main_function is None : print ( f 'Inside the select_random method { name } ' ) return self . select_random () else : return main_function , params , name def dump_population ( self , path = None ): if self . population is None or len ( self . population ) == 0 : return population_trimmed = [] for chromosome in self . population : chromosome_new = [] for gene_ in chromosome : chromosome_new . append (( gene_ [ 2 ], gene_ [ 1 ])) population_trimmed . append ( chromosome_new ) # config.logger.debug(population_trimmed) with open ( path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) config . logger . debug ( f 'The initial population was saved into { path } ' ) def load_population ( self , path = None ): if len ( self . population ) > 0 : return with open ( path , 'r' , encoding = 'utf-8' ) as fp : population_trimmed = json . load ( fp ) for chromosome in population_trimmed : chromosome_new = [] for gene_ in chromosome : chromosome_new . append (( REFACTORING_MAIN_MAP [ gene_ [ 0 ]], gene_ [ 1 ], gene_ [ 0 ])) self . population . append ( chromosome_new ) # config.logger.debug(self.population) config . logger . debug ( f 'The initial population was loaded into \"population field\" from { path } ' ) __init__ ( self , udb_path , population_size = 50 , lower_band = 10 , upper_band = 50 ) special Parameters: Name Type Description Default udb_path str Path for understand database file. required population_size int The length of population for GA. 50 lower_band int The minimum length of individual for GA. 10 upper_band int The maximum length of individual for GA. 50 Returns: Type Description None Source code in codart\\sbse\\initialize.py def __init__ ( self , udb_path , population_size = 50 , lower_band = 10 , upper_band = 50 ): \"\"\" Args: udb_path (str): Path for understand database file. population_size (int): The length of population for GA. lower_band (int): The minimum length of individual for GA. upper_band (int): The maximum length of individual for GA. Returns: None \"\"\" random . seed ( None ) self . udb_path = udb_path self . population_size = population_size self . lower_band = lower_band self . upper_band = upper_band self . population = [] self . initializers = ( self . init_make_field_non_static , # 0 self . init_make_field_static , # 1 self . init_make_method_static , # 2 self . init_make_method_non_static , # 3 self . init_pullup_field , # 4 self . init_move_field , # 5 self . init_move_method , # 6 # self.init_move_method, # 6.2 self . init_move_class , # 7 # self.init_move_class, # 7.2 self . init_push_down_field , # 8 self . init_extract_class , # 9 # self.init_extract_class, # 9.2 self . init_pullup_method , # 10 self . init_push_down_method , # 11 self . init_pullup_constructor , # 12 self . init_decrease_field_visibility , # 13 self . init_increase_field_visibility , # 14 self . init_decrease_method_visibility , # 15 self . init_increase_method_visibility , # 16 self . init_extract_interface , # 17 # self.init_extract_interface, # 17.2 # self.init_extract_method, # 18 ) self . _variables = self . get_all_variables () self . _static_variables = self . get_all_variables ( static = True ) self . _methods = self . get_all_methods () self . _static_methods = self . get_all_methods ( static = True ) self . _pullup_field_candidates = self . find_pullup_field_candidates () self . _push_down_field_candidates = self . find_push_down_field_candidates () self . _pullup_method_candidates = self . find_pullup_method_candidates () self . _pullup_constructor_candidates = self . find_pullup_constructor_candidates () self . _push_down_method_candidates = self . find_push_down_method_candidates () self . _extract_interface_candidates = self . find_extract_interface_candidate () generate_population ( self ) Generate population abstract method Source code in codart\\sbse\\initialize.py def generate_population ( self ): \"\"\" Generate population abstract method \"\"\" pass select_random ( self ) Randomly selects a refactoring. If there are no candidates it tries again! Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def select_random ( self ): \"\"\" Randomly selects a refactoring. If there are no candidates it tries again! Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" initializer = random . choice ( self . initializers ) logger . debug ( f '>>> Randomly selected refactoring: { initializer . __name__ } ' ) main_function , params , name = handle_index_error ( initializer )() if main_function is None : print ( f 'Inside the select_random method { name } ' ) return self . select_random () else : return main_function , params , name RandomInitialization ( Initialization ) Use to randomly initialize the refactoring population in search-based algorithms Source code in codart\\sbse\\initialize.py class RandomInitialization ( Initialization ): \"\"\" Use to randomly initialize the refactoring population in search-based algorithms \"\"\" def __init__ ( self , * args , ** kwargs ): super ( RandomInitialization , self ) . __init__ ( * args , ** kwargs ) def generate_population ( self ): \"\"\" Generate randomly (unbiased) initialized refactoring population Returns: list: List of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a random initial population ...' ) # population = [] for _ in range ( self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a random initial population was finished.' ) return self . population def init_make_field_non_static ( self ): \"\"\" Finds all static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_non_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Non-Static' def init_make_field_static ( self ): \"\"\" Finds all non-static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Static' def init_make_method_static ( self ): \"\"\" Finds all non-static methods and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Static' def init_make_method_non_static ( self ): \"\"\" Finds all static methods and randomly chooses one of them Returns: tuple: refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_non_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Non-Static' def init_pullup_field ( self ): \"\"\" Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_field . main # params = {\"project_dir\": str(Path(self.udb_path).parent)} params = { \"project_dir\" : config . PROJECT_PATH } candidates = self . _pullup_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Field' def init_push_down_field ( self ): \"\"\" Finds fields to be push-down Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_field2 . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Field' def init_pullup_method ( self ): \"\"\" Finds methods to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Method' def init_pullup_constructor ( self ): \"\"\" Finds statements in class constructors to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_constructor . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_constructor_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Constructor' def init_push_down_method ( self ): \"\"\" Finds methods to be pushed-downs Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Method' def init_move_field ( self ): \"\"\" Finds fields with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_field = random . choice ( self . _variables ) params . update ( random_field ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Field' def init_move_field2 ( self ): \"\"\" Finds fields with a class to move (version 2) Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes_fields = [] random_field = random . choice ( classes_fields ) params . update ( random_field ) related_entities = random_field . ents ( \"Set, Setby, Contain, Containin, Use, Useby, Create, Createby, DotRef, DotRefby, Define, Definein\" , \"Type ~Unknown ~Anonymous\" # \"Package\" ) print ( 'Parameters' , params ) print ( \"related_entities\" , related_entities ) for e in related_entities : print ( e . longname (), e . kind ()) if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) def init_move_method ( self ): \"\"\" Finds methods with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_method = random . choice ( self . _methods ) params . update ( random_method ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Method' def init_move_class ( self ): \"\"\" Finds a class which should be moved to another existing package Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Java Class Public ~TypeVariable ~Anonymous ~Unknown ~Unresolved ~Private ~Static\" ) selected_class = random . choice ( classes ) package_list = selected_class . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_class . parent () is not None : package_list = selected_class . parent () . ents ( 'Containin' , 'Java Package' ) selected_class = selected_class . parent () # print(package_list) params . update ({ \"class_name\" : selected_class . simplename ()}) if len ( package_list ) < 1 : params . update ({ \"source_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"source_package\" : package_list [ 0 ] . longname ()}) entity_filter = \"Import, Importby, Contain, Containin, Couple, Coupleby, \" entity_filter += \"Create, Createby, DotRef, DotRefby, Declare, Declarein, Define, Definein\" related_entities = selected_class . ents ( entity_filter , \"Type ~Unknown ~Anonymous\" # \"Package\" ) # print('Parameters', params) # print(\"related_entities\", related_entities) # for e in related_entities: # print(e.longname(), e.kind()) trials = 0 while trials < 25 : if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) else : packages = _db . ents ( \"Package ~Unknown ~Unresolved ~Unnamed\" ) if packages is not None and len ( packages ) > 0 : selected_package = random . choice ( packages ) params . update ({ \"target_package\" : selected_package . longname ()}) else : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) # print(params['source_package'], params['target_package']) if params [ 'source_package' ] != params [ 'target_package' ] and params [ 'target_package' ] != '(Unnamed_Package)' : break trials += 1 _db . close () return refactoring_main , params , 'Move Class' def init_extract_class ( self ): \"\"\" Finds a set of methods and fields which should be extracted as a new class Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Type Class ~Unknown ~Anonymous\" ) random_class = random . choice ( classes ) params . update ( { \"source_class\" : random_class . simplename (), \"file_path\" : random_class . parent () . longname () } ) class_fields = [] class_methods = [] for ref in random_class . refs ( \"define\" , \"variable\" ): class_fields . append ( ref . ent ()) for ref in random_class . refs ( \"define\" , \"method\" ): class_methods . append ( ref . ent ()) params . update ( { \"moved_fields\" : [ ent . simplename () for ent in random . sample ( class_fields , random . randint ( 0 , len ( class_fields )))], \"moved_methods\" : [ ent . simplename () for ent in random . sample ( class_methods , random . randint ( 0 , len ( class_methods )))], } ) _db . close () return refactoring_main , params , 'Extract Class' def init_extract_method ( self ): pass def init_extract_interface ( self ): \"\"\" Finds a class which should have an interface Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_interface2 . main # params = {\"udb_path\": str(Path(self.udb_path))} random_class = random . choice ( self . _extract_interface_candidates ) params = { 'class_path' : random_class } return refactoring_main , params , 'Extract Interface' def init_increase_field_visibility ( self ): \"\"\" Finds a private field to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _variables )) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Increase Field Visibility' def init_decrease_field_visibility ( self ): \"\"\" Finds a none-external-reference-public field to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _variables )) # print(candidates) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Decrease Field Visibility' def init_increase_method_visibility ( self ): \"\"\" Finds a private method to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Increase Method Visibility' def init_decrease_method_visibility ( self ): \"\"\" Finds a none-external-reference-public method to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Decrease Method Visibility' generate_population ( self ) Generate randomly (unbiased) initialized refactoring population Returns: Type Description list List of refactoring sequences (list of refactoring operations) Source code in codart\\sbse\\initialize.py def generate_population ( self ): \"\"\" Generate randomly (unbiased) initialized refactoring population Returns: list: List of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a random initial population ...' ) # population = [] for _ in range ( self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a random initial population was finished.' ) return self . population init_decrease_field_visibility ( self ) Finds a none-external-reference-public field to decrease its visibility to private. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_decrease_field_visibility ( self ): \"\"\" Finds a none-external-reference-public field to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _variables )) # print(candidates) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Decrease Field Visibility' init_decrease_method_visibility ( self ) Finds a none-external-reference-public method to decrease its visibility to private. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_decrease_method_visibility ( self ): \"\"\" Finds a none-external-reference-public method to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Decrease Method Visibility' init_extract_class ( self ) Finds a set of methods and fields which should be extracted as a new class Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_extract_class ( self ): \"\"\" Finds a set of methods and fields which should be extracted as a new class Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Type Class ~Unknown ~Anonymous\" ) random_class = random . choice ( classes ) params . update ( { \"source_class\" : random_class . simplename (), \"file_path\" : random_class . parent () . longname () } ) class_fields = [] class_methods = [] for ref in random_class . refs ( \"define\" , \"variable\" ): class_fields . append ( ref . ent ()) for ref in random_class . refs ( \"define\" , \"method\" ): class_methods . append ( ref . ent ()) params . update ( { \"moved_fields\" : [ ent . simplename () for ent in random . sample ( class_fields , random . randint ( 0 , len ( class_fields )))], \"moved_methods\" : [ ent . simplename () for ent in random . sample ( class_methods , random . randint ( 0 , len ( class_methods )))], } ) _db . close () return refactoring_main , params , 'Extract Class' init_extract_interface ( self ) Finds a class which should have an interface Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_extract_interface ( self ): \"\"\" Finds a class which should have an interface Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_interface2 . main # params = {\"udb_path\": str(Path(self.udb_path))} random_class = random . choice ( self . _extract_interface_candidates ) params = { 'class_path' : random_class } return refactoring_main , params , 'Extract Interface' init_increase_field_visibility ( self ) Finds a private field to increase its visibility to public. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_increase_field_visibility ( self ): \"\"\" Finds a private field to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _variables )) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Increase Field Visibility' init_increase_method_visibility ( self ) Finds a private method to increase its visibility to public. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_increase_method_visibility ( self ): \"\"\" Finds a private method to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Increase Method Visibility' init_make_field_non_static ( self ) Finds all static fields and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_make_field_non_static ( self ): \"\"\" Finds all static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_non_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Non-Static' init_make_field_static ( self ) Finds all non-static fields and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_make_field_static ( self ): \"\"\" Finds all non-static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Static' init_make_method_non_static ( self ) Finds all static methods and randomly chooses one of them Returns: Type Description tuple refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_make_method_non_static ( self ): \"\"\" Finds all static methods and randomly chooses one of them Returns: tuple: refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_non_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Non-Static' init_make_method_static ( self ) Finds all non-static methods and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_make_method_static ( self ): \"\"\" Finds all non-static methods and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Static' init_move_class ( self ) Finds a class which should be moved to another existing package Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_class ( self ): \"\"\" Finds a class which should be moved to another existing package Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Java Class Public ~TypeVariable ~Anonymous ~Unknown ~Unresolved ~Private ~Static\" ) selected_class = random . choice ( classes ) package_list = selected_class . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_class . parent () is not None : package_list = selected_class . parent () . ents ( 'Containin' , 'Java Package' ) selected_class = selected_class . parent () # print(package_list) params . update ({ \"class_name\" : selected_class . simplename ()}) if len ( package_list ) < 1 : params . update ({ \"source_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"source_package\" : package_list [ 0 ] . longname ()}) entity_filter = \"Import, Importby, Contain, Containin, Couple, Coupleby, \" entity_filter += \"Create, Createby, DotRef, DotRefby, Declare, Declarein, Define, Definein\" related_entities = selected_class . ents ( entity_filter , \"Type ~Unknown ~Anonymous\" # \"Package\" ) # print('Parameters', params) # print(\"related_entities\", related_entities) # for e in related_entities: # print(e.longname(), e.kind()) trials = 0 while trials < 25 : if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) else : packages = _db . ents ( \"Package ~Unknown ~Unresolved ~Unnamed\" ) if packages is not None and len ( packages ) > 0 : selected_package = random . choice ( packages ) params . update ({ \"target_package\" : selected_package . longname ()}) else : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) # print(params['source_package'], params['target_package']) if params [ 'source_package' ] != params [ 'target_package' ] and params [ 'target_package' ] != '(Unnamed_Package)' : break trials += 1 _db . close () return refactoring_main , params , 'Move Class' init_move_field ( self ) Finds fields with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_field ( self ): \"\"\" Finds fields with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_field = random . choice ( self . _variables ) params . update ( random_field ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Field' init_move_field2 ( self ) Finds fields with a class to move (version 2) Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_field2 ( self ): \"\"\" Finds fields with a class to move (version 2) Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes_fields = [] random_field = random . choice ( classes_fields ) params . update ( random_field ) related_entities = random_field . ents ( \"Set, Setby, Contain, Containin, Use, Useby, Create, Createby, DotRef, DotRefby, Define, Definein\" , \"Type ~Unknown ~Anonymous\" # \"Package\" ) print ( 'Parameters' , params ) print ( \"related_entities\" , related_entities ) for e in related_entities : print ( e . longname (), e . kind ()) if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) init_move_method ( self ) Finds methods with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_method ( self ): \"\"\" Finds methods with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_method = random . choice ( self . _methods ) params . update ( random_method ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Method' init_pullup_constructor ( self ) Finds statements in class constructors to be pulled-up Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_pullup_constructor ( self ): \"\"\" Finds statements in class constructors to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_constructor . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_constructor_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Constructor' init_pullup_field ( self ) Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Type Description Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_pullup_field ( self ): \"\"\" Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_field . main # params = {\"project_dir\": str(Path(self.udb_path).parent)} params = { \"project_dir\" : config . PROJECT_PATH } candidates = self . _pullup_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Field' init_pullup_method ( self ) Finds methods to be pulled-up Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_pullup_method ( self ): \"\"\" Finds methods to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Method' init_push_down_field ( self ) Finds fields to be push-down Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_push_down_field ( self ): \"\"\" Finds fields to be push-down Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_field2 . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Field' init_push_down_method ( self ) Finds methods to be pushed-downs Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_push_down_method ( self ): \"\"\" Finds methods to be pushed-downs Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Method' SmellInitialization ( RandomInitialization ) Use to initialize refactoring population based on refactoring opportunities Source code in codart\\sbse\\initialize.py class SmellInitialization ( RandomInitialization ): \"\"\" Use to initialize refactoring population based on refactoring opportunities \"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\" Returns: SmellInitialization: An instance of SmellInitialization class \"\"\" super ( SmellInitialization , self ) . __init__ ( * args , ** kwargs ) # Load csv files self . move_method_candidates = self . load_move_method_candidates () self . extract_class_candidates = self . load_extract_class_candidates () # self.extract_method_candidates = self.load_extract_method_candidates() # We leave extract method for now. def generate_population ( self ): \"\"\" Generate a biased initial population consists of first-time validated refactorings Return: list: list of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a biased initial population ...' ) for _ in range ( 0 , self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) while is_correct_refactoring is False : reset_project () main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) #### # update_understand_database(self.udb_path) # quit() #### individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) reset_project () logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a biased initial population was finished.' ) return self . population def load_extract_class_candidates ( self ): _db = und . open ( self . udb_path ) god_classes = pandas . read_csv ( config . GOD_CLASS_PATH , sep = \" \\t \" ) candidates = [] for index , row in god_classes . iterrows (): moved_fields , moved_methods = [], [] # print(row[0].strip()) try : class_file = _db . lookup ( re . compile ( row [ 0 ] . strip () + r '$' ), \"Class\" )[ 0 ] . parent () . longname () # print(class_file) except : # print('Class file not found') continue source_class = row [ 0 ] . split ( \".\" )[ - 1 ] data = row [ 1 ][ 1 : - 1 ] # skip [ and ] data = data . split ( \",\" ) for field_or_method in data : field_or_method = field_or_method . strip () if \"(\" in field_or_method : # Method moved_methods . append ( field_or_method . split ( \"::\" )[ 1 ] . split ( \"(\" )[ 0 ] ) elif len ( field_or_method . split ( \" \" )) == 2 : # Field moved_fields . append ( field_or_method . split ( \" \" )[ - 1 ] ) candidates . append ( { \"source_class\" : source_class , \"moved_fields\" : moved_fields , \"moved_methods\" : moved_methods , \"file_path\" : class_file } ) # print(candidates) # quit() _db . close () return candidates def load_move_method_candidates ( self ): feature_envies = pandas . read_csv ( config . FEATURE_ENVY_PATH , sep = None , engine = 'python' ) candidates = [] for index , row in feature_envies . iterrows (): source_package , source_class , method_name = get_move_method_location ( row [ 1 ]) target_info = row [ 2 ] . split ( \".\" ) target_package = \".\" . join ( target_info [: - 1 ]) target_class = target_info [ - 1 ] candidates . append ({ \"source_package\" : source_package , \"source_class\" : source_class , \"method_name\" : method_name , \"target_package\" : target_package , \"target_class\" : target_class }) return candidates def load_extract_method_candidates ( self ): _db = und . open ( self . udb_path ) long_methods = pandas . read_csv ( config . LONG_METHOD_PATH , sep = ' \\t ' , engine = 'python' ) candidates = [] for index , row in long_methods . iterrows (): lines = {} class_info = row [ 0 ] . strip () . split ( \".\" )[ - 1 ] class_file = _db . lookup ( class_info + \".java\" , \"File\" ) if class_file : class_file = class_file [ 0 ] . longname () else : continue _bytes = open ( class_file , mode = 'rb' ) . read () file_content = codecs . decode ( _bytes , errors = 'strict' ) lines_info = row [ 5 ] for i in lines_info . split ( \")\" ): if i == '' : continue values = i . split ( \",\" ) char_number = values [ 0 ][ 1 :] . strip () length = values [ 1 ] . strip () should_copy = False if values [ 2 ] . strip () == 'F' else True if char_number and length : char_number = int ( char_number ) length = char_number + int ( length ) start = len ( file_content [: char_number ] . split ( \" \\n \" )) stop = len ( file_content [: length ] . split ( \" \\n \" )) for line in range ( start , stop + 1 ): lines [ line ] = should_copy candidates . append ({ \"file_path\" : class_file , \"lines\" : lines }) _db . close () return candidates def init_move_method ( self ): params = random . choice ( self . move_method_candidates ) params [ \"udb_path\" ] = self . udb_path main = move_method . main # print(params) return main , params , \"Move Method\" def init_extract_class ( self ): main = extract_class . main params = random . choice ( self . extract_class_candidates ) params [ \"udb_path\" ] = self . udb_path return main , params , \"Extract Class\" def init_extract_method ( self ): main = extract_method . main params = random . choice ( self . extract_method_candidates ) params [ \"udb_path\" ] = self . udb_path return main , params , \"Extract Method\" __init__ ( self , * args , ** kwargs ) special Returns: Type Description SmellInitialization An instance of SmellInitialization class Source code in codart\\sbse\\initialize.py def __init__ ( self , * args , ** kwargs ): \"\"\" Returns: SmellInitialization: An instance of SmellInitialization class \"\"\" super ( SmellInitialization , self ) . __init__ ( * args , ** kwargs ) # Load csv files self . move_method_candidates = self . load_move_method_candidates () self . extract_class_candidates = self . load_extract_class_candidates () # self.extract_method_candidates = self.load_extract_method_candidates() # We leave extract method for now. generate_population ( self ) Generate a biased initial population consists of first-time validated refactorings Returns: Type Description list list of refactoring sequences (list of refactoring operations) Source code in codart\\sbse\\initialize.py def generate_population ( self ): \"\"\" Generate a biased initial population consists of first-time validated refactorings Return: list: list of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a biased initial population ...' ) for _ in range ( 0 , self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) while is_correct_refactoring is False : reset_project () main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) #### # update_understand_database(self.udb_path) # quit() #### individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) reset_project () logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a biased initial population was finished.' ) return self . population init_extract_class ( self ) Finds a set of methods and fields which should be extracted as a new class Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_extract_class ( self ): main = extract_class . main params = random . choice ( self . extract_class_candidates ) params [ \"udb_path\" ] = self . udb_path return main , params , \"Extract Class\" init_move_method ( self ) Finds methods with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_method ( self ): params = random . choice ( self . move_method_candidates ) params [ \"udb_path\" ] = self . udb_path main = move_method . main # print(params) return main , params , \"Move Method\"","title":"Population initialization"},{"location":"optimization/initialize/#search-based-refactoring-initialization","text":"","title":"Search-based refactoring initialization"},{"location":"optimization/initialize/#codart.sbse.initialize--introduction","text":"This module implements finding refactoring candidates for the search-based algorithms Initialization: The abstract class and common utility functions. RandomInitialization: For initialling random candidates.","title":"Introduction"},{"location":"optimization/initialize/#codart.sbse.initialize--changelog","text":"","title":"Changelog"},{"location":"optimization/initialize/#codart.sbse.initialize--version-040","text":"Enhances module's design.","title":"Version 0.4.0"},{"location":"optimization/initialize/#codart.sbse.initialize--version-032","text":"","title":"Version 0.3.2"},{"location":"optimization/initialize/#codart.sbse.initialize.Initialization","text":"The superclass of initialization contains init_refactoring methods Source code in codart\\sbse\\initialize.py class Initialization ( object ): \"\"\" The superclass of initialization contains init_refactoring methods \"\"\" def __init__ ( self , udb_path , population_size = 50 , lower_band = 10 , upper_band = 50 ): \"\"\" Args: udb_path (str): Path for understand database file. population_size (int): The length of population for GA. lower_band (int): The minimum length of individual for GA. upper_band (int): The maximum length of individual for GA. Returns: None \"\"\" random . seed ( None ) self . udb_path = udb_path self . population_size = population_size self . lower_band = lower_band self . upper_band = upper_band self . population = [] self . initializers = ( self . init_make_field_non_static , # 0 self . init_make_field_static , # 1 self . init_make_method_static , # 2 self . init_make_method_non_static , # 3 self . init_pullup_field , # 4 self . init_move_field , # 5 self . init_move_method , # 6 # self.init_move_method, # 6.2 self . init_move_class , # 7 # self.init_move_class, # 7.2 self . init_push_down_field , # 8 self . init_extract_class , # 9 # self.init_extract_class, # 9.2 self . init_pullup_method , # 10 self . init_push_down_method , # 11 self . init_pullup_constructor , # 12 self . init_decrease_field_visibility , # 13 self . init_increase_field_visibility , # 14 self . init_decrease_method_visibility , # 15 self . init_increase_method_visibility , # 16 self . init_extract_interface , # 17 # self.init_extract_interface, # 17.2 # self.init_extract_method, # 18 ) self . _variables = self . get_all_variables () self . _static_variables = self . get_all_variables ( static = True ) self . _methods = self . get_all_methods () self . _static_methods = self . get_all_methods ( static = True ) self . _pullup_field_candidates = self . find_pullup_field_candidates () self . _push_down_field_candidates = self . find_push_down_field_candidates () self . _pullup_method_candidates = self . find_pullup_method_candidates () self . _pullup_constructor_candidates = self . find_pullup_constructor_candidates () self . _push_down_method_candidates = self . find_push_down_method_candidates () self . _extract_interface_candidates = self . find_extract_interface_candidate () def __del__ ( self ): # logger.info(\"Understand database closed after initialization.\") # self._und.close() pass def get_all_methods ( self , static = False ): _db = und . open ( self . udb_path ) candidates = [] if static : query = _db . ents ( \"Static Method\" ) blacklist = ( 'abstract' , 'unknown' , 'constructor' ,) else : query = _db . ents ( \"Method\" ) blacklist = ( 'constructor' , 'static' , 'abstract' , 'unknown' ,) for ent in query : kind_name = ent . kindname () . lower () if any ( word in kind_name for word in blacklist ): continue parent = ent . parent () if parent is None : continue if not parent . kind () . check ( \"class\" ) or parent . kind () . check ( \"anonymous\" ): continue long_name = parent . longname () . split ( '.' ) method_name = ent . simplename () if len ( long_name ) == 1 : source_class = long_name [ - 1 ] source_package = None elif len ( long_name ) > 1 : source_class = long_name [ - 1 ] source_package = \".\" . join ( long_name [: - 1 ]) else : continue is_public = ent . kind () . check ( 'public' ) is_private = ent . kind () . check ( 'private' ) external_references = 0 for ref in ent . refs ( 'Callby, Overrideby' ): if '.' . join ( long_name [: - 1 ]) not in ref . ent () . longname (): external_references += 1 candidates . append ( { 'source_package' : source_package , 'source_class' : source_class , 'method_name' : method_name , 'is_public' : is_public , 'is_private' : is_private , 'external_references' : external_references } ) _db . close () return candidates def get_all_variables ( self , static = False ): _db = und . open ( self . udb_path ) candidates = [] if static : query = _db . ents ( \"Static Variable\" ) blacklist = () else : query = _db . ents ( \"Variable\" ) blacklist = ( 'static' ,) for ent in query : kind_name = ent . kindname () . lower () if any ( word in kind_name for word in blacklist ): continue parent = ent . parent () if parent is None : continue if not parent . kind () . check ( \"class\" ) or parent . kind () . check ( \"anonymous\" ): continue source_package = None long_name = ent . longname () . split ( \".\" ) if len ( long_name ) >= 3 : source_package = '.' . join ( long_name [: - 2 ]) source_class , field_name = long_name [ - 2 :] elif len ( long_name ) == 2 : source_class , field_name = long_name else : continue is_public = ent . kind () . check ( 'public' ) is_private = ent . kind () . check ( 'private' ) external_references = 0 for ref in ent . refs ( 'Setby, Useby' ): if '.' . join ( long_name [: - 1 ]) not in ref . ent () . longname (): external_references += 1 candidates . append ( { 'source_package' : source_package , 'source_class' : source_class , 'field_name' : field_name , 'is_public' : is_public , 'is_private' : is_private , 'external_references' : external_references } ) _db . close () return candidates # def get_all_class_entities(self, filter_=\"class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\"): # query = self._und.ents(filter_) # class_entities = [] # for ent in query: # class_entities.append(ent) # return class_entities # return query def find_pullup_field_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) for ent in class_entities : for ref in ent . refs ( \"Define\" , \"Variable\" ): candidate = { \"package_name\" : get_package_from_class ( ent . longname ()), \"children_class\" : ent . simplename (), \"field_name\" : ref . ent () . simplename () } candidates . append ( candidate ) _db . close () return candidates def find_push_down_field_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) for ent in class_entities : params = { \"source_class\" : \"\" , \"source_package\" : \"\" , \"field_name\" : \"\" , \"target_classes\" : [] } field_names = [] for ref in ent . refs ( \"ExtendBy ~Implicit\" ): params [ \"source_class\" ] = ent . simplename () params [ \"source_package\" ] = get_package_from_class ( ent . longname ()) if len ( params [ \"target_classes\" ]) >= 1 : rnd = random . randint ( 0 , 1 ) if rnd == 0 : params [ \"target_classes\" ] . append ( ref . ent () . simplename ()) else : params [ \"target_classes\" ] . append ( ref . ent () . simplename ()) for ref in ent . refs ( \"define\" , \"variable\" ): field_names . append ( ref . ent () . simplename ()) if field_names : params [ \"field_name\" ] = random . choice ( field_names ) else : continue if params [ \"source_class\" ] != \"\" : candidates . append ( params ) _db . close () return candidates def find_pullup_method_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) common_methods = [] for ent in class_entities : children = [] class_method_dict = {} father_methods = [] for met_ref in ent . refs ( \"Define\" , \"Method ~Override\" ): method = met_ref . ent () father_methods . append ( method . simplename ()) for ref in ent . refs ( \"Extendby\" ): child = ref . ent () if not child . kind () . check ( \"public class\" ): continue child_name = child . simplename () children . append ( child_name ) if child_name not in class_method_dict : class_method_dict [ child_name ] = [] for met_ref in child . refs ( \"Define\" , \"Method\" ): method = met_ref . ent () method_name = method . simplename () if method . ents ( \"Override\" ): continue if method_name not in father_methods : common_methods . append ( method_name ) class_method_dict [ child_name ] . append ( method_name ) counts = Counter ( common_methods ) common_methods = [ value for value , count in counts . items () if count > 1 ] if len ( common_methods ) > 0 : random_method = random . choice ( common_methods ) children = [ k for k , v in class_method_dict . items () if random_method in v ] if len ( children ) > 1 : candidates . append ({ \"method_name\" : random . choice ( common_methods ), \"children_classes\" : children }) _db . close () return candidates def find_pullup_constructor_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) for ent in class_entities : children = [] params = {} for ref in ent . refs ( \"Extendby\" ): child = ref . ent () if not child . kind () . check ( \"public class\" ): continue child_name = child . simplename () children . append ( child_name ) ln = ent . longname () . split ( \".\" ) params [ \"source_package\" ] = \".\" . join ( ln [: - 1 ]) if len ( ln ) > 1 else \"\" params [ \"target_class\" ] = ent . simplename () if len ( children ) >= 2 : params [ \"class_names\" ] = random . sample ( children , random . randint ( 2 , len ( children ))) candidates . append ( params ) _db . close () return candidates def find_push_down_method_candidates ( self ): _db = und . open ( self . udb_path ) candidates = [] class_entities = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) for ent in class_entities : params = { \"source_class\" : \"\" , \"source_package\" : \"\" , \"method_name\" : \"\" , \"target_classes\" : [] } method_names = [] for ref in ent . refs ( \"Extendby ~Implicit\" , \"Public Class\" ): params [ \"source_class\" ] = ent . simplename () ln = ent . longname () . split ( \".\" ) params [ \"source_package\" ] = ln [ 0 ] if len ( ln ) > 1 else \"\" params [ \"target_classes\" ] . append ( ref . ent () . simplename ()) for ref in ent . refs ( \"Define\" , \"Method\" ): method_names . append ( ref . ent () . simplename ()) if method_names : params [ \"method_name\" ] = random . choice ( method_names ) else : continue if params [ \"target_classes\" ]: params [ \"target_classes\" ] = [ random . choice ( params [ \"target_classes\" ])] else : continue if params [ \"source_class\" ] != \"\" : candidates . append ( params ) _db . close () return candidates def find_extract_interface_candidate ( self ): _db = und . open ( config . UDB_PATH ) extract_interface_refactoring_candidates = [] classes = _db . ents ( \"Type Class Public ~Generic ~Interface ~Enum ~Unknown ~Anonymous ~TypeVariable\" ) for class_entity in classes : class_path = class_entity . parent () . longname () if os . path . exists ( class_path ): filter_inherited_attrs = 'Java Extend Couple ~Implicit, Java Implement Couple ~Implicit' filter_inherited_attrs = 'Java Implement Couple ~Implicit' inherited_entities = class_entity . ents ( filter_inherited_attrs ) if len ( inherited_entities ) == 0 : public_methods = len ( class_entity . ents ( \"Define\" , \"Java Method Member ~Private ~Static\" )) if public_methods > 0 : extract_interface_refactoring_candidates . append ( class_path ) _db . close () return extract_interface_refactoring_candidates def init_make_field_non_static ( self ): pass def init_make_field_static ( self ): pass def init_make_method_static ( self ): pass def init_make_method_non_static ( self ): pass def init_pullup_field ( self ): pass def init_push_down_field ( self ): pass def init_pullup_method ( self ): pass def init_pullup_constructor ( self ): pass def init_push_down_method ( self ): pass def init_move_field ( self ): pass def init_move_method ( self ): pass def init_move_class ( self ): pass def init_extract_class ( self ): pass def init_extract_method ( self ): pass def init_decrease_field_visibility ( self ): pass def init_decrease_method_visibility ( self ): pass def init_increase_field_visibility ( self ): pass def init_increase_method_visibility ( self ): pass def init_extract_interface ( self ): pass def generate_population ( self ): \"\"\" Generate population abstract method \"\"\" pass def select_random ( self ): \"\"\" Randomly selects a refactoring. If there are no candidates it tries again! Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" initializer = random . choice ( self . initializers ) logger . debug ( f '>>> Randomly selected refactoring: { initializer . __name__ } ' ) main_function , params , name = handle_index_error ( initializer )() if main_function is None : print ( f 'Inside the select_random method { name } ' ) return self . select_random () else : return main_function , params , name def dump_population ( self , path = None ): if self . population is None or len ( self . population ) == 0 : return population_trimmed = [] for chromosome in self . population : chromosome_new = [] for gene_ in chromosome : chromosome_new . append (( gene_ [ 2 ], gene_ [ 1 ])) population_trimmed . append ( chromosome_new ) # config.logger.debug(population_trimmed) with open ( path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) config . logger . debug ( f 'The initial population was saved into { path } ' ) def load_population ( self , path = None ): if len ( self . population ) > 0 : return with open ( path , 'r' , encoding = 'utf-8' ) as fp : population_trimmed = json . load ( fp ) for chromosome in population_trimmed : chromosome_new = [] for gene_ in chromosome : chromosome_new . append (( REFACTORING_MAIN_MAP [ gene_ [ 0 ]], gene_ [ 1 ], gene_ [ 0 ])) self . population . append ( chromosome_new ) # config.logger.debug(self.population) config . logger . debug ( f 'The initial population was loaded into \"population field\" from { path } ' )","title":"Initialization"},{"location":"optimization/initialize/#codart.sbse.initialize.Initialization.__init__","text":"Parameters: Name Type Description Default udb_path str Path for understand database file. required population_size int The length of population for GA. 50 lower_band int The minimum length of individual for GA. 10 upper_band int The maximum length of individual for GA. 50 Returns: Type Description None Source code in codart\\sbse\\initialize.py def __init__ ( self , udb_path , population_size = 50 , lower_band = 10 , upper_band = 50 ): \"\"\" Args: udb_path (str): Path for understand database file. population_size (int): The length of population for GA. lower_band (int): The minimum length of individual for GA. upper_band (int): The maximum length of individual for GA. Returns: None \"\"\" random . seed ( None ) self . udb_path = udb_path self . population_size = population_size self . lower_band = lower_band self . upper_band = upper_band self . population = [] self . initializers = ( self . init_make_field_non_static , # 0 self . init_make_field_static , # 1 self . init_make_method_static , # 2 self . init_make_method_non_static , # 3 self . init_pullup_field , # 4 self . init_move_field , # 5 self . init_move_method , # 6 # self.init_move_method, # 6.2 self . init_move_class , # 7 # self.init_move_class, # 7.2 self . init_push_down_field , # 8 self . init_extract_class , # 9 # self.init_extract_class, # 9.2 self . init_pullup_method , # 10 self . init_push_down_method , # 11 self . init_pullup_constructor , # 12 self . init_decrease_field_visibility , # 13 self . init_increase_field_visibility , # 14 self . init_decrease_method_visibility , # 15 self . init_increase_method_visibility , # 16 self . init_extract_interface , # 17 # self.init_extract_interface, # 17.2 # self.init_extract_method, # 18 ) self . _variables = self . get_all_variables () self . _static_variables = self . get_all_variables ( static = True ) self . _methods = self . get_all_methods () self . _static_methods = self . get_all_methods ( static = True ) self . _pullup_field_candidates = self . find_pullup_field_candidates () self . _push_down_field_candidates = self . find_push_down_field_candidates () self . _pullup_method_candidates = self . find_pullup_method_candidates () self . _pullup_constructor_candidates = self . find_pullup_constructor_candidates () self . _push_down_method_candidates = self . find_push_down_method_candidates () self . _extract_interface_candidates = self . find_extract_interface_candidate ()","title":"__init__()"},{"location":"optimization/initialize/#codart.sbse.initialize.Initialization.generate_population","text":"Generate population abstract method Source code in codart\\sbse\\initialize.py def generate_population ( self ): \"\"\" Generate population abstract method \"\"\" pass","title":"generate_population()"},{"location":"optimization/initialize/#codart.sbse.initialize.Initialization.select_random","text":"Randomly selects a refactoring. If there are no candidates it tries again! Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def select_random ( self ): \"\"\" Randomly selects a refactoring. If there are no candidates it tries again! Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" initializer = random . choice ( self . initializers ) logger . debug ( f '>>> Randomly selected refactoring: { initializer . __name__ } ' ) main_function , params , name = handle_index_error ( initializer )() if main_function is None : print ( f 'Inside the select_random method { name } ' ) return self . select_random () else : return main_function , params , name","title":"select_random()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization","text":"Use to randomly initialize the refactoring population in search-based algorithms Source code in codart\\sbse\\initialize.py class RandomInitialization ( Initialization ): \"\"\" Use to randomly initialize the refactoring population in search-based algorithms \"\"\" def __init__ ( self , * args , ** kwargs ): super ( RandomInitialization , self ) . __init__ ( * args , ** kwargs ) def generate_population ( self ): \"\"\" Generate randomly (unbiased) initialized refactoring population Returns: list: List of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a random initial population ...' ) # population = [] for _ in range ( self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a random initial population was finished.' ) return self . population def init_make_field_non_static ( self ): \"\"\" Finds all static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_non_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Non-Static' def init_make_field_static ( self ): \"\"\" Finds all non-static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Static' def init_make_method_static ( self ): \"\"\" Finds all non-static methods and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Static' def init_make_method_non_static ( self ): \"\"\" Finds all static methods and randomly chooses one of them Returns: tuple: refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_non_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Non-Static' def init_pullup_field ( self ): \"\"\" Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_field . main # params = {\"project_dir\": str(Path(self.udb_path).parent)} params = { \"project_dir\" : config . PROJECT_PATH } candidates = self . _pullup_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Field' def init_push_down_field ( self ): \"\"\" Finds fields to be push-down Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_field2 . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Field' def init_pullup_method ( self ): \"\"\" Finds methods to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Method' def init_pullup_constructor ( self ): \"\"\" Finds statements in class constructors to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_constructor . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_constructor_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Constructor' def init_push_down_method ( self ): \"\"\" Finds methods to be pushed-downs Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Method' def init_move_field ( self ): \"\"\" Finds fields with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_field = random . choice ( self . _variables ) params . update ( random_field ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Field' def init_move_field2 ( self ): \"\"\" Finds fields with a class to move (version 2) Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes_fields = [] random_field = random . choice ( classes_fields ) params . update ( random_field ) related_entities = random_field . ents ( \"Set, Setby, Contain, Containin, Use, Useby, Create, Createby, DotRef, DotRefby, Define, Definein\" , \"Type ~Unknown ~Anonymous\" # \"Package\" ) print ( 'Parameters' , params ) print ( \"related_entities\" , related_entities ) for e in related_entities : print ( e . longname (), e . kind ()) if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) def init_move_method ( self ): \"\"\" Finds methods with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_method = random . choice ( self . _methods ) params . update ( random_method ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Method' def init_move_class ( self ): \"\"\" Finds a class which should be moved to another existing package Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Java Class Public ~TypeVariable ~Anonymous ~Unknown ~Unresolved ~Private ~Static\" ) selected_class = random . choice ( classes ) package_list = selected_class . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_class . parent () is not None : package_list = selected_class . parent () . ents ( 'Containin' , 'Java Package' ) selected_class = selected_class . parent () # print(package_list) params . update ({ \"class_name\" : selected_class . simplename ()}) if len ( package_list ) < 1 : params . update ({ \"source_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"source_package\" : package_list [ 0 ] . longname ()}) entity_filter = \"Import, Importby, Contain, Containin, Couple, Coupleby, \" entity_filter += \"Create, Createby, DotRef, DotRefby, Declare, Declarein, Define, Definein\" related_entities = selected_class . ents ( entity_filter , \"Type ~Unknown ~Anonymous\" # \"Package\" ) # print('Parameters', params) # print(\"related_entities\", related_entities) # for e in related_entities: # print(e.longname(), e.kind()) trials = 0 while trials < 25 : if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) else : packages = _db . ents ( \"Package ~Unknown ~Unresolved ~Unnamed\" ) if packages is not None and len ( packages ) > 0 : selected_package = random . choice ( packages ) params . update ({ \"target_package\" : selected_package . longname ()}) else : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) # print(params['source_package'], params['target_package']) if params [ 'source_package' ] != params [ 'target_package' ] and params [ 'target_package' ] != '(Unnamed_Package)' : break trials += 1 _db . close () return refactoring_main , params , 'Move Class' def init_extract_class ( self ): \"\"\" Finds a set of methods and fields which should be extracted as a new class Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Type Class ~Unknown ~Anonymous\" ) random_class = random . choice ( classes ) params . update ( { \"source_class\" : random_class . simplename (), \"file_path\" : random_class . parent () . longname () } ) class_fields = [] class_methods = [] for ref in random_class . refs ( \"define\" , \"variable\" ): class_fields . append ( ref . ent ()) for ref in random_class . refs ( \"define\" , \"method\" ): class_methods . append ( ref . ent ()) params . update ( { \"moved_fields\" : [ ent . simplename () for ent in random . sample ( class_fields , random . randint ( 0 , len ( class_fields )))], \"moved_methods\" : [ ent . simplename () for ent in random . sample ( class_methods , random . randint ( 0 , len ( class_methods )))], } ) _db . close () return refactoring_main , params , 'Extract Class' def init_extract_method ( self ): pass def init_extract_interface ( self ): \"\"\" Finds a class which should have an interface Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_interface2 . main # params = {\"udb_path\": str(Path(self.udb_path))} random_class = random . choice ( self . _extract_interface_candidates ) params = { 'class_path' : random_class } return refactoring_main , params , 'Extract Interface' def init_increase_field_visibility ( self ): \"\"\" Finds a private field to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _variables )) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Increase Field Visibility' def init_decrease_field_visibility ( self ): \"\"\" Finds a none-external-reference-public field to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _variables )) # print(candidates) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Decrease Field Visibility' def init_increase_method_visibility ( self ): \"\"\" Finds a private method to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Increase Method Visibility' def init_decrease_method_visibility ( self ): \"\"\" Finds a none-external-reference-public method to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Decrease Method Visibility'","title":"RandomInitialization"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.generate_population","text":"Generate randomly (unbiased) initialized refactoring population Returns: Type Description list List of refactoring sequences (list of refactoring operations) Source code in codart\\sbse\\initialize.py def generate_population ( self ): \"\"\" Generate randomly (unbiased) initialized refactoring population Returns: list: List of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a random initial population ...' ) # population = [] for _ in range ( self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a random initial population was finished.' ) return self . population","title":"generate_population()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_decrease_field_visibility","text":"Finds a none-external-reference-public field to decrease its visibility to private. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_decrease_field_visibility ( self ): \"\"\" Finds a none-external-reference-public field to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _variables )) # print(candidates) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Decrease Field Visibility'","title":"init_decrease_field_visibility()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_decrease_method_visibility","text":"Finds a none-external-reference-public method to decrease its visibility to private. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_decrease_method_visibility ( self ): \"\"\" Finds a none-external-reference-public method to decrease its visibility to private. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = decrease_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_private' ] is False and d [ 'external_references' ] == 0 , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Decrease Method Visibility'","title":"init_decrease_method_visibility()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_extract_class","text":"Finds a set of methods and fields which should be extracted as a new class Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_extract_class ( self ): \"\"\" Finds a set of methods and fields which should be extracted as a new class Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Type Class ~Unknown ~Anonymous\" ) random_class = random . choice ( classes ) params . update ( { \"source_class\" : random_class . simplename (), \"file_path\" : random_class . parent () . longname () } ) class_fields = [] class_methods = [] for ref in random_class . refs ( \"define\" , \"variable\" ): class_fields . append ( ref . ent ()) for ref in random_class . refs ( \"define\" , \"method\" ): class_methods . append ( ref . ent ()) params . update ( { \"moved_fields\" : [ ent . simplename () for ent in random . sample ( class_fields , random . randint ( 0 , len ( class_fields )))], \"moved_methods\" : [ ent . simplename () for ent in random . sample ( class_methods , random . randint ( 0 , len ( class_methods )))], } ) _db . close () return refactoring_main , params , 'Extract Class'","title":"init_extract_class()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_extract_interface","text":"Finds a class which should have an interface Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_extract_interface ( self ): \"\"\" Finds a class which should have an interface Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = extract_interface2 . main # params = {\"udb_path\": str(Path(self.udb_path))} random_class = random . choice ( self . _extract_interface_candidates ) params = { 'class_path' : random_class } return refactoring_main , params , 'Extract Interface'","title":"init_extract_interface()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_increase_field_visibility","text":"Finds a private field to increase its visibility to public. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_increase_field_visibility ( self ): \"\"\" Finds a private field to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_field_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _variables )) field = random . choice ( candidates ) params . update ({ \"source_package\" : field [ \"source_package\" ], \"source_class\" : field [ \"source_class\" ], \"source_field\" : field [ \"field_name\" ], }) return refactoring_main , params , 'Increase Field Visibility'","title":"init_increase_field_visibility()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_increase_method_visibility","text":"Finds a private method to increase its visibility to public. Returns: Type Description tuple Refactoring main func, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_increase_method_visibility ( self ): \"\"\" Finds a private method to increase its visibility to public. Returns: tuple: Refactoring main func, its parameters, and its human-readable name. \"\"\" refactoring_main = increase_method_visibility . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = list ( filter ( lambda d : d [ 'is_public' ] is False , self . _methods )) method = random . choice ( candidates ) params . update ({ \"source_package\" : method [ \"source_package\" ], \"source_class\" : method [ \"source_class\" ], \"source_method\" : method [ \"method_name\" ], }) return refactoring_main , params , 'Increase Method Visibility'","title":"init_increase_method_visibility()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_make_field_non_static","text":"Finds all static fields and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_make_field_non_static ( self ): \"\"\" Finds all static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_non_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Non-Static'","title":"init_make_field_non_static()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_make_field_static","text":"Finds all non-static fields and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_make_field_static ( self ): \"\"\" Finds all non-static fields and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_field_static . main params = { \"udb_path\" : self . udb_path } candidates = self . _variables params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Field Static'","title":"init_make_field_static()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_make_method_non_static","text":"Finds all static methods and randomly chooses one of them Returns: Type Description tuple refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_make_method_non_static ( self ): \"\"\" Finds all static methods and randomly chooses one of them Returns: tuple: refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_non_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _static_methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Non-Static'","title":"init_make_method_non_static()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_make_method_static","text":"Finds all non-static methods and randomly chooses one of them Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_make_method_static ( self ): \"\"\" Finds all non-static methods and randomly chooses one of them Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = make_method_static2 . main params = { \"udb_path\" : self . udb_path } candidates = self . _methods params . update ( random . choice ( candidates )) params . pop ( \"source_package\" ) return refactoring_main , params , 'Make Method Static'","title":"init_make_method_static()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_move_class","text":"Finds a class which should be moved to another existing package Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_class ( self ): \"\"\" Finds a class which should be moved to another existing package Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_class . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes = _db . ents ( \"Java Class Public ~TypeVariable ~Anonymous ~Unknown ~Unresolved ~Private ~Static\" ) selected_class = random . choice ( classes ) package_list = selected_class . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_class . parent () is not None : package_list = selected_class . parent () . ents ( 'Containin' , 'Java Package' ) selected_class = selected_class . parent () # print(package_list) params . update ({ \"class_name\" : selected_class . simplename ()}) if len ( package_list ) < 1 : params . update ({ \"source_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"source_package\" : package_list [ 0 ] . longname ()}) entity_filter = \"Import, Importby, Contain, Containin, Couple, Coupleby, \" entity_filter += \"Create, Createby, DotRef, DotRefby, Declare, Declarein, Define, Definein\" related_entities = selected_class . ents ( entity_filter , \"Type ~Unknown ~Anonymous\" # \"Package\" ) # print('Parameters', params) # print(\"related_entities\", related_entities) # for e in related_entities: # print(e.longname(), e.kind()) trials = 0 while trials < 25 : if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()}) else : packages = _db . ents ( \"Package ~Unknown ~Unresolved ~Unnamed\" ) if packages is not None and len ( packages ) > 0 : selected_package = random . choice ( packages ) params . update ({ \"target_package\" : selected_package . longname ()}) else : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) # print(params['source_package'], params['target_package']) if params [ 'source_package' ] != params [ 'target_package' ] and params [ 'target_package' ] != '(Unnamed_Package)' : break trials += 1 _db . close () return refactoring_main , params , 'Move Class'","title":"init_move_class()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_move_field","text":"Finds fields with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_field ( self ): \"\"\" Finds fields with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_field = random . choice ( self . _variables ) params . update ( random_field ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Field'","title":"init_move_field()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_move_field2","text":"Finds fields with a class to move (version 2) Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_field2 ( self ): \"\"\" Finds fields with a class to move (version 2) Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = move_field . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} classes_fields = [] random_field = random . choice ( classes_fields ) params . update ( random_field ) related_entities = random_field . ents ( \"Set, Setby, Contain, Containin, Use, Useby, Create, Createby, DotRef, DotRefby, Define, Definein\" , \"Type ~Unknown ~Anonymous\" # \"Package\" ) print ( 'Parameters' , params ) print ( \"related_entities\" , related_entities ) for e in related_entities : print ( e . longname (), e . kind ()) if related_entities is not None and len ( related_entities ) > 0 : selected_entity = random . choice ( related_entities ) package_list = selected_entity . ents ( 'Containin' , 'Java Package' ) while not package_list and selected_entity . parent () is not None : package_list = selected_entity . parent () . ents ( 'Containin' , 'Java Package' ) selected_entity = selected_entity . parent () if len ( package_list ) < 1 : params . update ({ \"target_package\" : \"(Unnamed_Package)\" }) else : params . update ({ \"target_package\" : package_list [ 0 ] . longname ()})","title":"init_move_field2()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_move_method","text":"Finds methods with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_method ( self ): \"\"\" Finds methods with a class to move Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" _db = und . open ( self . udb_path ) refactoring_main = move_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} random_method = random . choice ( self . _methods ) params . update ( random_method ) classes = _db . ents ( \"Class ~Unknown ~Anonymous ~TypeVariable ~Private ~Static\" ) random_class = ( random . choice ( classes )) . longname () . split ( \".\" ) target_package = None \"\"\" target_class: str, target_package: str, \"\"\" if len ( random_class ) == 1 : target_class = random_class [ 0 ] elif len ( random_class ) > 1 : target_package = '.' . join ( random_class [: - 1 ]) target_class = random_class [ - 1 ] else : return self . init_move_field () params . update ({ \"target_class\" : target_class , \"target_package\" : target_package }) _db . close () return refactoring_main , params , 'Move Method'","title":"init_move_method()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_pullup_constructor","text":"Finds statements in class constructors to be pulled-up Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_pullup_constructor ( self ): \"\"\" Finds statements in class constructors to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_constructor . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_constructor_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Constructor'","title":"init_pullup_constructor()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_pullup_field","text":"Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Type Description Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_pullup_field ( self ): \"\"\" Find all classes with their attributes and package names, then chooses randomly one of them! Returns: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_field . main # params = {\"project_dir\": str(Path(self.udb_path).parent)} params = { \"project_dir\" : config . PROJECT_PATH } candidates = self . _pullup_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Field'","title":"init_pullup_field()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_pullup_method","text":"Finds methods to be pulled-up Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_pullup_method ( self ): \"\"\" Finds methods to be pulled-up Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pullup_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _pullup_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Pull Up Method'","title":"init_pullup_method()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_push_down_field","text":"Finds fields to be push-down Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_push_down_field ( self ): \"\"\" Finds fields to be push-down Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_field2 . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_field_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Field'","title":"init_push_down_field()"},{"location":"optimization/initialize/#codart.sbse.initialize.RandomInitialization.init_push_down_method","text":"Finds methods to be pushed-downs Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_push_down_method ( self ): \"\"\" Finds methods to be pushed-downs Returns: tuple: Refactoring main method, its parameters, and its human-readable name. \"\"\" refactoring_main = pushdown_method . main params = { \"udb_path\" : str ( Path ( self . udb_path ))} candidates = self . _push_down_method_candidates params . update ( random . choice ( candidates )) return refactoring_main , params , 'Push Down Method'","title":"init_push_down_method()"},{"location":"optimization/initialize/#codart.sbse.initialize.SmellInitialization","text":"Use to initialize refactoring population based on refactoring opportunities Source code in codart\\sbse\\initialize.py class SmellInitialization ( RandomInitialization ): \"\"\" Use to initialize refactoring population based on refactoring opportunities \"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\" Returns: SmellInitialization: An instance of SmellInitialization class \"\"\" super ( SmellInitialization , self ) . __init__ ( * args , ** kwargs ) # Load csv files self . move_method_candidates = self . load_move_method_candidates () self . extract_class_candidates = self . load_extract_class_candidates () # self.extract_method_candidates = self.load_extract_method_candidates() # We leave extract method for now. def generate_population ( self ): \"\"\" Generate a biased initial population consists of first-time validated refactorings Return: list: list of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a biased initial population ...' ) for _ in range ( 0 , self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) while is_correct_refactoring is False : reset_project () main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) #### # update_understand_database(self.udb_path) # quit() #### individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) reset_project () logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a biased initial population was finished.' ) return self . population def load_extract_class_candidates ( self ): _db = und . open ( self . udb_path ) god_classes = pandas . read_csv ( config . GOD_CLASS_PATH , sep = \" \\t \" ) candidates = [] for index , row in god_classes . iterrows (): moved_fields , moved_methods = [], [] # print(row[0].strip()) try : class_file = _db . lookup ( re . compile ( row [ 0 ] . strip () + r '$' ), \"Class\" )[ 0 ] . parent () . longname () # print(class_file) except : # print('Class file not found') continue source_class = row [ 0 ] . split ( \".\" )[ - 1 ] data = row [ 1 ][ 1 : - 1 ] # skip [ and ] data = data . split ( \",\" ) for field_or_method in data : field_or_method = field_or_method . strip () if \"(\" in field_or_method : # Method moved_methods . append ( field_or_method . split ( \"::\" )[ 1 ] . split ( \"(\" )[ 0 ] ) elif len ( field_or_method . split ( \" \" )) == 2 : # Field moved_fields . append ( field_or_method . split ( \" \" )[ - 1 ] ) candidates . append ( { \"source_class\" : source_class , \"moved_fields\" : moved_fields , \"moved_methods\" : moved_methods , \"file_path\" : class_file } ) # print(candidates) # quit() _db . close () return candidates def load_move_method_candidates ( self ): feature_envies = pandas . read_csv ( config . FEATURE_ENVY_PATH , sep = None , engine = 'python' ) candidates = [] for index , row in feature_envies . iterrows (): source_package , source_class , method_name = get_move_method_location ( row [ 1 ]) target_info = row [ 2 ] . split ( \".\" ) target_package = \".\" . join ( target_info [: - 1 ]) target_class = target_info [ - 1 ] candidates . append ({ \"source_package\" : source_package , \"source_class\" : source_class , \"method_name\" : method_name , \"target_package\" : target_package , \"target_class\" : target_class }) return candidates def load_extract_method_candidates ( self ): _db = und . open ( self . udb_path ) long_methods = pandas . read_csv ( config . LONG_METHOD_PATH , sep = ' \\t ' , engine = 'python' ) candidates = [] for index , row in long_methods . iterrows (): lines = {} class_info = row [ 0 ] . strip () . split ( \".\" )[ - 1 ] class_file = _db . lookup ( class_info + \".java\" , \"File\" ) if class_file : class_file = class_file [ 0 ] . longname () else : continue _bytes = open ( class_file , mode = 'rb' ) . read () file_content = codecs . decode ( _bytes , errors = 'strict' ) lines_info = row [ 5 ] for i in lines_info . split ( \")\" ): if i == '' : continue values = i . split ( \",\" ) char_number = values [ 0 ][ 1 :] . strip () length = values [ 1 ] . strip () should_copy = False if values [ 2 ] . strip () == 'F' else True if char_number and length : char_number = int ( char_number ) length = char_number + int ( length ) start = len ( file_content [: char_number ] . split ( \" \\n \" )) stop = len ( file_content [: length ] . split ( \" \\n \" )) for line in range ( start , stop + 1 ): lines [ line ] = should_copy candidates . append ({ \"file_path\" : class_file , \"lines\" : lines }) _db . close () return candidates def init_move_method ( self ): params = random . choice ( self . move_method_candidates ) params [ \"udb_path\" ] = self . udb_path main = move_method . main # print(params) return main , params , \"Move Method\" def init_extract_class ( self ): main = extract_class . main params = random . choice ( self . extract_class_candidates ) params [ \"udb_path\" ] = self . udb_path return main , params , \"Extract Class\" def init_extract_method ( self ): main = extract_method . main params = random . choice ( self . extract_method_candidates ) params [ \"udb_path\" ] = self . udb_path return main , params , \"Extract Method\"","title":"SmellInitialization"},{"location":"optimization/initialize/#codart.sbse.initialize.SmellInitialization.__init__","text":"Returns: Type Description SmellInitialization An instance of SmellInitialization class Source code in codart\\sbse\\initialize.py def __init__ ( self , * args , ** kwargs ): \"\"\" Returns: SmellInitialization: An instance of SmellInitialization class \"\"\" super ( SmellInitialization , self ) . __init__ ( * args , ** kwargs ) # Load csv files self . move_method_candidates = self . load_move_method_candidates () self . extract_class_candidates = self . load_extract_class_candidates () # self.extract_method_candidates = self.load_extract_method_candidates() # We leave extract method for now.","title":"__init__()"},{"location":"optimization/initialize/#codart.sbse.initialize.SmellInitialization.generate_population","text":"Generate a biased initial population consists of first-time validated refactorings Returns: Type Description list list of refactoring sequences (list of refactoring operations) Source code in codart\\sbse\\initialize.py def generate_population ( self ): \"\"\" Generate a biased initial population consists of first-time validated refactorings Return: list: list of refactoring sequences (list of refactoring operations) \"\"\" config . logger . debug ( f 'Generating a biased initial population ...' ) for _ in range ( 0 , self . population_size ): individual = [] individual_size = random . randint ( self . lower_band , self . upper_band ) for j in range ( individual_size ): main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) while is_correct_refactoring is False : reset_project () main , params , name = self . select_random () logger . debug ( f 'Refactoring name: { name } ' ) logger . debug ( f 'Refactoring params: { params } ' ) is_correct_refactoring = main ( ** params ) #### # update_understand_database(self.udb_path) # quit() #### individual . append (( main , params , name )) logger . debug ( f 'Append a refactoring \" { name } \" to \" { j } th\" gene of the individual { _ } .' ) reset_project () logger . debug ( '-' * 100 ) self . population . append ( individual ) logger . debug ( f 'Append individual { _ } to population, s' ) logger . debug ( '=' * 100 ) initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' self . dump_population ( path = initial_pop_path ) config . logger . debug ( f 'Generating a biased initial population was finished.' ) return self . population","title":"generate_population()"},{"location":"optimization/initialize/#codart.sbse.initialize.SmellInitialization.init_extract_class","text":"Finds a set of methods and fields which should be extracted as a new class Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_extract_class ( self ): main = extract_class . main params = random . choice ( self . extract_class_candidates ) params [ \"udb_path\" ] = self . udb_path return main , params , \"Extract Class\"","title":"init_extract_class()"},{"location":"optimization/initialize/#codart.sbse.initialize.SmellInitialization.init_move_method","text":"Finds methods with a class to move Returns: Type Description tuple Refactoring main method, its parameters, and its human-readable name. Source code in codart\\sbse\\initialize.py def init_move_method ( self ): params = random . choice ( self . move_method_candidates ) params [ \"udb_path\" ] = self . udb_path main = move_method . main # print(params) return main , params , \"Move Method\"","title":"init_move_method()"},{"location":"optimization/search-based_refactoring/","text":"Search-based refactoring module Module description This module implements the search-based refactoring with various search strategy using pymoo framework. Classes Gene, RefactoringOperation: One refactoring with params Individual: A list of RefactoringOperation PureRandomInitialization: Population, list of Individual References [1] https://pymoo.org/customization/custom.html [2] https://pymoo.org/misc/reference_directions.html Changelog version 0.2.4 1. Fix objective parameters of the problem classes version 0.2.3 1. Fix PEP 8 warnings version 0.2.2 1. Add a separate log directory for each execution 2. Add possibility to resume algorithm version 0.2.1 1. minor updates 2. fix bugs 3. rename variables names version 0.2.0 1. Crossover function is added. 2. Termination criteria are added. 3. Computation of highly trade-off points is added. 4. Tournament-selection is added. 5. _evaluate function in NSGA-III is now works on population instead of an individual (population-based versus element-wise). 6. Other setting for NSGA-III including adding energy-references point instead of Das and Dennis approach. === AdaptiveSinglePointCrossover ( Crossover ) This class implements solution variation, the adaptive one-point or single-point crossover operator. The crossover operator combines parents to create offsprings. It starts by selecting and splitting at random two parent solutions or individuals. Then, this operator creates two child solutions by putting, for the first child, the first part of the first parent with the second part of the second parent, and vice versa for the second child. Note 1: In the pymoo framework, the crossover operator retrieves the input already with predefined matings. The default parent selection algorithm is TournamentSelection. Note 2: It is better to create children that are close to their parents to have a more efficient search process, a so-called adaptive crossover , specifically in many-objective optimization. Therefore, the cutting point of the one-point crossover operator are controlled by restricting its position to be either belonging to the first tier of the refactoring sequence or belonging to the last tier. Source code in codart\\sbse\\search_based_refactoring2.py class AdaptiveSinglePointCrossover ( Crossover ): \"\"\" This class implements solution variation, the adaptive one-point or single-point crossover operator. The crossover operator combines parents to create offsprings. It starts by selecting and splitting at random two parent solutions or individuals. Then, this operator creates two child solutions by putting, for the first child, the first part of the first parent with the second part of the second parent, and vice versa for the second child. * Note 1: In the pymoo framework, the crossover operator retrieves the input already with predefined matings. The default parent selection algorithm is TournamentSelection. * Note 2: It is better to create children that are close to their parents to have a more efficient search process, a so-called __adaptive crossover__, specifically in many-objective optimization. Therefore, the cutting point of the one-point crossover operator are controlled by restricting its position to be either belonging to the first tier of the refactoring sequence or belonging to the last tier. \"\"\" def __init__ ( self , prob = 0.9 ): \"\"\" Args: prob (float): crossover probability \"\"\" # Define the crossover: number of parents, number of offsprings, and cross-over probability super () . __init__ ( n_parents = 2 , n_offsprings = 2 , prob = prob ) def _do ( self , problem , X , ** kwargs ): \"\"\" For population X Args: problem (Problem): An instance of pymoo Problem class to be optimized. X (np.array): Population \"\"\" # The input of has the following shape (n_parents, n_matings, n_var) _ , n_matings , n_var = X . shape # The output will be with the shape (n_offsprings, n_matings, n_var) # Because there the number of parents and offsprings are equal it keeps the shape of X Y = np . full_like ( X , None , dtype = object ) # print(X.shape) # print(X) # for each mating provided for k in range ( n_matings ): # get the first and the second parent (a and b are instance of individuals) a , b = X [ 0 , k , 0 ], X [ 1 , k , 0 ] # print('### a', a) # print('### b', b) # print('len a', len(a)) # print('len b', len(b)) len_min = min ( len ( a ), len ( b )) cross_point_1 = random . randint ( 1 , int ( len_min * 0.30 )) cross_point_2 = random . randint ( int ( len_min * 0.70 ), len_min - 1 ) if random . random () < 0.5 : cross_point_final = cross_point_1 else : cross_point_final = cross_point_2 logger . info ( f 'cross_point_final: { cross_point_final } ' ) offspring_a = [] offspring_b = [] for i in range ( 0 , cross_point_final ): offspring_a . append ( deepcopy ( a [ i ])) offspring_b . append ( deepcopy ( b [ i ])) for i in range ( cross_point_final , len_min ): offspring_a . append ( deepcopy ( b [ i ])) offspring_b . append ( deepcopy ( a [ i ])) if len ( b ) > len ( a ): for i in range ( len ( a ), len ( b )): offspring_a . append ( deepcopy ( b [ i ])) else : for i in range ( len ( b ), len ( a )): offspring_b . append ( deepcopy ( a [ i ])) # print('$$$ offspring_a', offspring_a) # print('$$$ offspring_b', offspring_b) # print('len offspring_a', len(offspring_a)) # print('len offspring_b', len(offspring_b)) # Join offsprings to offspring population Y Y [ 0 , k , 0 ], Y [ 1 , k , 0 ] = offspring_a , offspring_b # quit() return Y __init__ ( self , prob = 0.9 ) special prob (float): crossover probability Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.9 ): \"\"\" Args: prob (float): crossover probability \"\"\" # Define the crossover: number of parents, number of offsprings, and cross-over probability super () . __init__ ( n_parents = 2 , n_offsprings = 2 , prob = prob ) BitStringMutation ( Mutation ) This class implements solution variation, a bit-string mutation operator. The bit-string mutation operator that picks probabilistically one or more refactoring operations from its or their associated sequence and replaces them by other ones from the initial list of possible refactorings. Each chromosome dimension would be changed according to the mutation probability. For example, for a mutation probability of 0.2, for each dimension, we generate randomly a number x between 0 and 1, if x < mutation_probability (e.g., 0.2) we change the refactoring operation in that dimension, otherwise no changes are taken into account. Source code in codart\\sbse\\search_based_refactoring2.py class BitStringMutation ( Mutation ): \"\"\" This class implements solution variation, a bit-string mutation operator. The bit-string mutation operator that picks probabilistically one or more refactoring operations from its or their associated sequence and replaces them by other ones from the initial list of possible refactorings. Each chromosome dimension would be changed according to the mutation probability. For example, for a mutation probability of 0.2, for each dimension, we generate randomly a number x between 0 and 1, if `x < mutation_probability` (e.g., 0.2) we change the refactoring operation in that dimension, otherwise no changes are taken into account. \"\"\" def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer def _do ( self , problem , X , ** kwargs ): for i , individual in enumerate ( X ): for j , ro in enumerate ( individual ): r = np . random . random () # with a probability of `mutation_probability` replace the refactoring operation with new one if r < self . mutation_probability : random_chromosome = random . choice ( self . _initializer . population ) item = random . choice ( random_chromosome ) X [ i ][ 0 ][ j ] = deepcopy ( RefactoringOperation ( name = item [ 2 ], params = item [ 1 ], main = item [ 0 ])) return X __init__ ( self , prob = 0.2 , initializer = None ) special Parameters: Name Type Description Default prob float mutation probability 0.2 Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer BitStringMutation2 ( Mutation ) Select an individual to mutate with mutation probability. Only flip one refactoring operation in the selected individual. Source code in codart\\sbse\\search_based_refactoring2.py class BitStringMutation2 ( Mutation ): \"\"\" Select an individual to mutate with mutation probability. Only flip one refactoring operation in the selected individual. \"\"\" def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer self . _initializer . load_population () def _do ( self , problem , X , ** kwargs ): for i , individual in enumerate ( X ): r = np . random . random () # with a probability of `mutation_probability` replace the refactoring operation with new one if r < self . mutation_probability : # j is a random index in individual j = random . randint ( 0 , len ( individual [ 0 ]) - 1 ) random_chromosome = random . choice ( self . _initializer . population ) item = random . choice ( random_chromosome ) X [ i ][ 0 ][ j ] = deepcopy ( RefactoringOperation ( name = item [ 2 ], params = item [ 1 ], main = item [ 0 ])) return X __init__ ( self , prob = 0.2 , initializer = None ) special Parameters: Name Type Description Default prob float mutation probability 0.2 Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer self . _initializer . load_population () Gene The base class for the Gene in genetic algorithms. Source code in codart\\sbse\\search_based_refactoring2.py class Gene : \"\"\" The base class for the Gene in genetic algorithms. \"\"\" def __init__ ( self , ** kwargs ): \"\"\" Args: name (str): Refactoring operation name params (dict): Refactoring operation parameters main (function): Refactoring operation main function (API) \"\"\" self . name = kwargs . get ( 'name' ) self . params = kwargs . get ( 'params' ) self . main = kwargs . get ( 'main' ) def __str__ ( self ): parameters = '(' for param in self . params : parameters += str ( param ) + ', ' return self . name + parameters [: - 2 ] + ')' __init__ ( self , ** kwargs ) special Parameters: Name Type Description Default name str Refactoring operation name required params dict Refactoring operation parameters required main function Refactoring operation main function (API) required Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , ** kwargs ): \"\"\" Args: name (str): Refactoring operation name params (dict): Refactoring operation parameters main (function): Refactoring operation main function (API) \"\"\" self . name = kwargs . get ( 'name' ) self . params = kwargs . get ( 'params' ) self . main = kwargs . get ( 'main' ) Individual ( list , Generic ) The class define a data structure (list) to hold an individual during the search process. Each individual (also called, chromosome or solution in the context of genetic programming) is an array of refactoring operations where the order of their execution is accorded by their positions in the array. Source code in codart\\sbse\\search_based_refactoring2.py class Individual ( List ): \"\"\" The class define a data structure (list) to hold an individual during the search process. Each individual (also called, chromosome or solution in the context of genetic programming) is an array of refactoring operations where the order of their execution is accorded by their positions in the array. \"\"\" def __init__ ( self ): \"\"\" Args: \"\"\" super ( Individual , self ) . __init__ () self . refactoring_operations = [] def __iter__ ( self ): for ref in self . refactoring_operations : yield ref def __len__ ( self ): return len ( self . refactoring_operations ) def __getitem__ ( self , item ): return self . refactoring_operations [ item ] def __delitem__ ( self , key ): del self . refactoring_operations [ key ] def __setitem__ ( self , key , value ): self . refactoring_operations [ key ] = value def __str__ ( self ): return str ( self . refactoring_operations ) def insert ( self , __index : int , __object : RefactoringOperation ) -> None : self . refactoring_operations . insert ( __index , __object ) def append ( self , __object : RefactoringOperation ) -> None : self . insert ( len ( self . refactoring_operations ), __object ) __init__ ( self ) special Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self ): \"\"\" Args: \"\"\" super ( Individual , self ) . __init__ () self . refactoring_operations = [] append ( self , _Individual__object ) Append object to the end of the list. Source code in codart\\sbse\\search_based_refactoring2.py def append ( self , __object : RefactoringOperation ) -> None : self . insert ( len ( self . refactoring_operations ), __object ) insert ( self , _Individual__index , _Individual__object ) Insert object before index. Source code in codart\\sbse\\search_based_refactoring2.py def insert ( self , __index : int , __object : RefactoringOperation ) -> None : self . refactoring_operations . insert ( __index , __object ) LogCallback ( Callback ) Logging useful information after each iteration of the search algorithms Source code in codart\\sbse\\search_based_refactoring2.py class LogCallback ( Callback ): \"\"\" Logging useful information after each iteration of the search algorithms \"\"\" def __init__ ( self ) -> None : super () . __init__ () # self.data[\"best\"] = [] def notify ( self , algorithm , ** kwargs ): # self.data[\"best\"].append(algorithm.pop.get(\"F\").min()) logger . info ( f 'Generation # { algorithm . n_gen + config . NGEN } was finished:' ) # logger.info(f'Best solution:') # logger.info(f'{algorithm.pop.get(\"F\")}') # logger.info(f'Pareto-front solutions:') # logger.info(f'{algorithm.pf}') X , F , CV , G = algorithm . opt . get ( \"X\" , \"F\" , \"CV\" , \"G\" ) logger . info ( f 'Optimum solutions:' ) logger . info ( f ' { F } ' ) # Log evolved population at end of each generation generation_log_path = f ' { config . PROJECT_LOG_DIR } generations_logs/' if not os . path . exists ( generation_log_path ): os . makedirs ( generation_log_path ) generation_endof_date_time = config . dt . datetime . now () . strftime ( '%Y-%m- %d _%H-%M-%S' ) population_log_file_path = os . path . join ( generation_log_path , f 'pop_gen { algorithm . n_gen + config . NGEN } _ { generation_endof_date_time } .json' ) pop_opt_log_file_path = os . path . join ( generation_log_path , f 'pop_opt_gen { algorithm . n_gen + config . NGEN } _ { generation_endof_date_time } .json' ) pop_opt_objective_value_log = os . path . join ( config . PROJECT_LOG_DIR , f ' { config . PROJECT_NAME } _objectives_log_ { config . global_execution_start_time } .csv' ) population_trimmed = [] for chromosome in algorithm . pop : chromosome_new = [] for gene_ in chromosome . X [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) with open ( population_log_file_path , 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) population_trimmed = [] objective_values_content = '' for chromosome in algorithm . opt : chromosome_new = [] for gene_ in chromosome . X [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) objective_values_content += f ' { algorithm . n_gen + config . NGEN } ,' for gene_objective_ in chromosome . F : objective_values_content += f ' { gene_objective_ } ,' objective_values_content += ' \\n ' with open ( pop_opt_log_file_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) if not os . path . exists ( pop_opt_objective_value_log ): writing_mode = 'w' else : writing_mode = 'a' with open ( pop_opt_objective_value_log , mode = writing_mode , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) logger . info ( '-' * 100 ) logger . info ( ' ' ) # quit() PopulationInitialization ( Sampling ) This class create the initial population, x, consists of n_samples, pop_size. For each refactoring operation, a set of controlling parameters (e.g., actors and roles) is picked based on existing code smells in the program to be refactored. The selected refactoring operations are randomly arranged in each individual. Assigning randomly a sequence of refactorings to certain code fragments generates the initial population Source code in codart\\sbse\\search_based_refactoring2.py class PopulationInitialization ( Sampling ): \"\"\" This class create the initial population, x, consists of n_samples, pop_size. For each refactoring operation, a set of controlling parameters (e.g., actors and roles) is picked based on existing code smells in the program to be refactored. The selected refactoring operations are randomly arranged in each individual. Assigning randomly a sequence of refactorings to certain code fragments generates the initial population \"\"\" def __init__ ( self , initializer : Initialization = None ): \"\"\" Args: initializer (Initialization): An initializer object to be used for generating initial population \"\"\" super ( PopulationInitialization , self ) . __init__ () self . _initializer = initializer def _do ( self , problem , n_samples , ** kwargs ): \"\"\" Since the problem having only one variable, we return a matrix with the shape (n,1) Args: problem (Problem): An instance of pymoo Problem class to be optimized. n_samples (int): The same population size, pop_size. \"\"\" if os . path . exists ( config . INIT_POP_FILE ): self . _initializer . load_population ( path = config . INIT_POP_FILE ) population = self . _initializer . population initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' if config . NGEN == 0 : self . _initializer . dump_population ( path = initial_pop_path ) else : population = self . _initializer . generate_population () x = np . full (( n_samples , 1 ), None , dtype = Individual ) for i in range ( n_samples ): individual_object = [] # list of refactoring operations (Temporarily used instead of Individual class) for ref in population [ i ]: individual_object . append ( RefactoringOperation ( name = ref [ 2 ], params = ref [ 1 ], main = ref [ 0 ])) x [ i , 0 ] = deepcopy ( individual_object ) return x __init__ ( self , initializer = None ) special Parameters: Name Type Description Default initializer Initialization An initializer object to be used for generating initial population None Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , initializer : Initialization = None ): \"\"\" Args: initializer (Initialization): An initializer object to be used for generating initial population \"\"\" super ( PopulationInitialization , self ) . __init__ () self . _initializer = initializer ProblemManyObjective ( Problem ) The CodART many-objective optimization work with eight objective: Objective 1 to 6: QMOOD design quality attributes Objective 7: Testability prediction model Objective 8: Modularity complex network Source code in codart\\sbse\\search_based_refactoring2.py class ProblemManyObjective ( Problem ): \"\"\" The CodART many-objective optimization work with eight objective: * Objective 1 to 6: QMOOD design quality attributes * Objective 7: Testability prediction model * Objective 8: Modularity complex network \"\"\" def __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , verbose_design_metrics = False , ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives computed in parallel or not verbose_design_metrics (bool): Whether log the design metrics for each refactoring sequences or not \"\"\" super ( ProblemManyObjective , self ) . __init__ ( n_var = 1 , n_obj = n_objectives , n_constr = 0 , ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . verbose_design_metrics = verbose_design_metrics def _evaluate ( self , x , out , * args , ** kwargs ): \"\"\" This method iterate over a population, execute the refactoring operations in each individual sequentially, and compute quality attributes for the refactored version of the program, as objectives of the search. By default, elementwise_evaluation is set to False, which implies the _evaluate retrieves a set of solutions. Args: x (Population): x is a matrix where each row is an individual, and each column a variable.\\ We have one variable of type list (Individual) ==> x.shape = (len(Population), 1) \"\"\" objective_values = [] for k , individual_ in enumerate ( x ): # Stage 0: Git restore logger . debug ( \"Executing git restore.\" ) git_restore ( config . PROJECT_PATH ) logger . debug ( \"Updating understand database after git restore.\" ) update_understand_database ( config . UDB_PATH ) # Stage 1: Execute all refactoring operations in the sequence x logger . debug ( f \"Reached an Individual with size { len ( individual_ [ 0 ]) } \" ) for refactoring_operation in individual_ [ 0 ]: res = refactoring_operation . do_refactoring () # Update Understand DB logger . debug ( f \"Updating understand database after { refactoring_operation . name } .\" ) update_understand_database ( config . UDB_PATH ) # Stage 2: arr = Array ( 'd' , range ( self . n_obj )) if self . evaluate_in_parallel : # Stage 2 (parallel mood): Computing quality attributes p1 = Process ( target = calc_qmood_objectives , args = ( arr ,)) if self . n_obj == 8 : p2 = Process ( target = calc_testability_objective , args = ( config . UDB_PATH , arr ,)) p3 = Process ( target = calc_modularity_objective , args = ( config . UDB_PATH , arr ,)) p1 . start (), p2 . start (), p3 . start () p1 . join (), p2 . join (), p3 . join () else : p1 . start () p1 . join () else : # Stage 2 (sequential mood): Computing quality attributes qmood_quality_attributes = DesignQualityAttributes ( udb_path = config . UDB_PATH ) arr [ 0 ] = qmood_quality_attributes . reusability arr [ 1 ] = qmood_quality_attributes . understandability arr [ 2 ] = qmood_quality_attributes . flexibility arr [ 3 ] = qmood_quality_attributes . functionality arr [ 4 ] = qmood_quality_attributes . effectiveness arr [ 5 ] = qmood_quality_attributes . extendability if self . n_obj == 8 : arr [ 6 ] = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 )) arr [ 7 ] = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 )) if self . verbose_design_metrics : design_metrics = { \"DSC\" : [ qmood_quality_attributes . DSC ], \"NOH\" : [ qmood_quality_attributes . NOH ], \"ANA\" : [ qmood_quality_attributes . ANA ], \"MOA\" : [ qmood_quality_attributes . MOA ], \"DAM\" : [ qmood_quality_attributes . DAM ], \"CAMC\" : [ qmood_quality_attributes . CAMC ], \"CIS\" : [ qmood_quality_attributes . CIS ], \"NOM\" : [ qmood_quality_attributes . NOM ], \"DCC\" : [ qmood_quality_attributes . DCC ], \"MFA\" : [ qmood_quality_attributes . MFA ], \"NOP\" : [ qmood_quality_attributes . NOP ] } self . log_design_metrics ( design_metrics ) del qmood_quality_attributes # Stage 3: Marshal objectives into vector objective_values . append ([ - 1 * i for i in arr ]) logger . info ( f \"Objective values for individual { k } : { [ i for i in arr ] } \" ) # Stage 4: Marshal all objectives into out dictionary out [ 'F' ] = np . array ( objective_values , dtype = float ) # print('OUT', out['F']) def log_design_metrics ( self , design_metrics ): design_metrics_path = os . path . join ( config . PROJECT_LOG_DIR , f ' { config . PROJECT_NAME } _design_metrics_log_ { config . global_execution_start_time } .csv' ) df_design_metrics = pd . DataFrame ( data = design_metrics ) if os . path . exists ( design_metrics_path ): df = pd . read_csv ( design_metrics_path , index_col = False ) df_result = pd . concat ([ df , df_design_metrics ], ignore_index = True ) df_result . to_csv ( design_metrics_path , index = False ) else : df_design_metrics . to_csv ( design_metrics_path , index = False ) __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , verbose_design_metrics = False ) special Parameters: Name Type Description Default n_objectives int Number of objectives 8 n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 evaluate_in_parallel bool Whether the objectives computed in parallel or not False verbose_design_metrics bool Whether log the design metrics for each refactoring sequences or not False Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , verbose_design_metrics = False , ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives computed in parallel or not verbose_design_metrics (bool): Whether log the design metrics for each refactoring sequences or not \"\"\" super ( ProblemManyObjective , self ) . __init__ ( n_var = 1 , n_obj = n_objectives , n_constr = 0 , ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . verbose_design_metrics = verbose_design_metrics ProblemMultiObjective ( Problem ) The CodART multi-objective optimization work with three objective: Objective 1: Mean value of QMOOD metrics Objective 2: Testability Objective 3: Modularity Source code in codart\\sbse\\search_based_refactoring2.py class ProblemMultiObjective ( Problem ): \"\"\" The CodART multi-objective optimization work with three objective: * Objective 1: Mean value of QMOOD metrics * Objective 2: Testability * Objective 3: Modularity \"\"\" def __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives evaluate in parallel \"\"\" super ( ProblemMultiObjective , self ) . __init__ ( n_var = 1 , n_obj = 3 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . n_obj_virtual = n_objectives def _evaluate ( self , x , # out , * args , ** kwargs ): \"\"\" This method iterate over a population, execute the refactoring operations in each individual sequentially, and compute quality attributes for the refactored version of the program, as objectives of the search Args: x (Population): x is a matrix where each row is an individual, and each column a variable. \\ We have one variable of type list (Individual) ==> x.shape = (len(Population), 1) \"\"\" objective_values = [] for k , individual_ in enumerate ( x ): # Stage 0: Git restore logger . debug ( \"Executing git restore.\" ) git_restore ( config . PROJECT_PATH ) logger . debug ( \"Updating understand database after git restore.\" ) update_understand_database ( config . UDB_PATH ) # Stage 1: Execute all refactoring operations in the sequence x logger . debug ( f \"Reached Individual with Size { len ( individual_ [ 0 ]) } \" ) for refactoring_operation in individual_ [ 0 ]: refactoring_operation . do_refactoring () # Update Understand DB logger . debug ( f \"Updating understand database after { refactoring_operation . name } .\" ) update_understand_database ( config . UDB_PATH ) # Stage 2: arr = Array ( 'd' , range ( self . n_obj_virtual )) if self . evaluate_in_parallel : # Stage 2 (parallel mood): Computing quality attributes p1 = Process ( target = calc_qmood_objectives , args = ( arr ,)) p2 = Process ( target = calc_testability_objective , args = ( config . UDB_PATH , arr ,)) p3 = Process ( target = calc_modularity_objective , args = ( config . UDB_PATH , arr ,)) p1 . start (), p2 . start (), p3 . start () p1 . join (), p2 . join (), p3 . join () o1 = sum ([ i for i in arr [: 6 ]]) / 6. o2 = arr [ 6 ] o3 = arr [ 7 ] else : # Stage 2 (sequential mood): Computing quality attributes qmood_quality_attributes = DesignQualityAttributes ( udb_path = config . UDB_PATH ) o1 = qmood_quality_attributes . average_sum o2 = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 )) o3 = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 )) del qmood_quality_attributes # Stage 3: Marshal objectives into vector objective_values . append ([ - 1 * o1 , - 1 * o2 , - 1 * o3 ]) logger . info ( f \"Objective values for individual { k } : { [ - 1 * o1 , - 1 * o2 , - 1 * o3 ] } \" ) # Stage 4: Marshal all objectives into out dictionary out [ 'F' ] = np . array ( objective_values , dtype = float ) __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False ) special Parameters: Name Type Description Default n_objectives int Number of objectives 8 n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 evaluate_in_parallel bool Whether the objectives evaluate in parallel False Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives evaluate in parallel \"\"\" super ( ProblemMultiObjective , self ) . __init__ ( n_var = 1 , n_obj = 3 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . n_obj_virtual = n_objectives ProblemSingleObjective ( Problem ) The CodART single-objective optimization work with only one objective, testability: Source code in codart\\sbse\\search_based_refactoring2.py class ProblemSingleObjective ( Problem ): \"\"\" The CodART single-objective optimization work with only one objective, testability: \"\"\" def __init__ ( self , n_objectives = 1 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , mode = 'single' # 'multi' ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences mode (str): 'single' or 'multi' \"\"\" super ( ProblemSingleObjective , self ) . __init__ ( n_var = 1 , n_obj = 1 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . mode = mode self . n_obj_virtual = n_objectives def _evaluate ( self , x , # out , * args , ** kwargs ): \"\"\" This method iterate over a population, execute the refactoring operations in each individual sequentially, and compute quality attributes for the refactored version of the program, as objectives of the search Args: x (Population): x is a matrix where each row is an individual, and each column a variable.\\ We have one variable of type list (Individual) ==> x.shape = (len(Population), 1) \"\"\" objective_values = [] for k , individual_ in enumerate ( x ): # Stage 0: Git restore logger . debug ( \"Executing git restore.\" ) git_restore ( config . PROJECT_PATH ) logger . debug ( \"Updating understand database after git restore.\" ) update_understand_database ( config . UDB_PATH ) # Stage 1: Execute all refactoring operations in the sequence x logger . debug ( f \"Reached Individual with Size { len ( individual_ [ 0 ]) } \" ) for refactoring_operation in individual_ [ 0 ]: refactoring_operation . do_refactoring () # Update Understand DB logger . debug ( f \"Updating understand database after { refactoring_operation . name } .\" ) update_understand_database ( config . UDB_PATH ) # Stage 2: if self . mode == 'single' : # Stage 2 (Single objective mode): Considering only one quality attribute, e.g., testability score = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 )) else : # Stage 2 (Multi-objective mode): Considering one objective based on average of 8 objective arr = Array ( 'd' , range ( self . n_obj_virtual )) if self . evaluate_in_parallel : # Stage 2 (Multi-objective mode, parallel): Computing quality attributes p1 = Process ( target = calc_qmood_objectives , args = ( arr ,)) if self . n_obj_virtual == 8 : p2 = Process ( target = calc_testability_objective , args = ( config . UDB_PATH , arr ,)) p3 = Process ( target = calc_modularity_objective , args = ( config . UDB_PATH , arr ,)) p1 . start (), p2 . start (), p3 . start () p1 . join (), p2 . join (), p3 . join () else : p1 . start () p1 . join () score = sum ([ i for i in arr ]) / self . n_obj_virtual else : # Stage 2 (Multi-objective mode, sequential): Computing quality attributes qmood_quality_attributes = DesignQualityAttributes ( udb_path = config . UDB_PATH ) o1 = qmood_quality_attributes . average_sum if self . n_obj_virtual == 8 : o2 = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 )) o3 = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 )) else : o2 = 0 o3 = 0 del qmood_quality_attributes score = ( o1 * 6. + o2 + o3 ) / self . n_obj_virtual # Stage 3: Marshal objectives into vector objective_values . append ([ - 1 * score ]) logger . info ( f \"Objective values for individual { k } in mode { self . mode } : { [ - 1 * score ] } \" ) # Stage 4: Marshal all objectives into out dictionary out [ 'F' ] = np . array ( objective_values , dtype = float ) __init__ ( self , n_objectives = 1 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , mode = 'single' ) special Parameters: Name Type Description Default n_objectives int Number of objectives 1 n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 mode str 'single' or 'multi' 'single' Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , n_objectives = 1 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , mode = 'single' # 'multi' ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences mode (str): 'single' or 'multi' \"\"\" super ( ProblemSingleObjective , self ) . __init__ ( n_var = 1 , n_obj = 1 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . mode = mode self . n_obj_virtual = n_objectives RefactoringOperation ( Gene ) The class define a data structure (dictionary) to hold a refactoring operation Each refactoring operation hold as a dictionary contains the required parameters. Example: ``` make_field_static refactoring is marshaled as the following dict: params = { 'refactoring_name': 'make_field_static' 'api': 'main_function' 'source_class': 'name_of_source_class' 'field_name': 'name_of_the_field_to_be_static' } ``` Source code in codart\\sbse\\search_based_refactoring2.py class RefactoringOperation ( Gene ): \"\"\" The class define a data structure (dictionary) to hold a refactoring operation Each refactoring operation hold as a dictionary contains the required parameters. Example: ``` make_field_static refactoring is marshaled as the following dict: params = { 'refactoring_name': 'make_field_static' 'api': 'main_function' 'source_class': 'name_of_source_class' 'field_name': 'name_of_the_field_to_be_static' } ``` \"\"\" def __init__ ( self , ** kwargs ): \"\"\" Args: name (str): Refactoring operation name params (dict): Refactoring operation parameters main (function): Refactoring operation main function (API) \"\"\" super ( RefactoringOperation , self ) . __init__ ( ** kwargs ) def __str__ ( self ): return f ' { self . name } ( { self . params } ) \\n ' def __repr__ ( self ): return self . __str__ () def do_refactoring ( self ): \"\"\" Check preconditions and apply refactoring operation to source code Returns: result (boolean): The result statues of the applied refactoring \"\"\" logger . info ( f \"Running { self . name } \" ) logger . info ( f \"Parameters { self . params } \" ) try : res = self . main ( ** self . params ) logger . debug ( f \"Executed refactoring with result { res } \" ) return res except Exception as e : logger . error ( f \"Unexpected error in executing refactoring: \\n { e } \" ) return False do_refactoring ( self ) Check preconditions and apply refactoring operation to source code Returns: Type Description result (boolean) The result statues of the applied refactoring Source code in codart\\sbse\\search_based_refactoring2.py def do_refactoring ( self ): \"\"\" Check preconditions and apply refactoring operation to source code Returns: result (boolean): The result statues of the applied refactoring \"\"\" logger . info ( f \"Running { self . name } \" ) logger . info ( f \"Parameters { self . params } \" ) try : res = self . main ( ** self . params ) logger . debug ( f \"Executed refactoring with result { res } \" ) return res except Exception as e : logger . error ( f \"Unexpected error in executing refactoring: \\n { e } \" ) return False binary_tournament ( pop , P , ** kwargs ) Implements the binary tournament selection algorithm Source code in codart\\sbse\\search_based_refactoring2.py def binary_tournament ( pop , P , ** kwargs ): \"\"\" Implements the binary tournament selection algorithm \"\"\" # The P input defines the tournaments and competitors n_tournaments , n_competitors = P . shape if n_competitors != 2 : raise Exception ( \"Only pressure=2 allowed for binary tournament!\" ) S = np . full ( n_tournaments , - 1 , dtype = np . int64 ) # Now do all the tournaments for i in range ( n_tournaments ): a , b = P [ i ] # If the first individual is better, choose it if pop [ a ] . F . all () <= pop [ a ] . F . all (): S [ i ] = a # Otherwise, take the other individual else : S [ i ] = b return S is_equal_2_refactorings_list ( a , b ) This method implement is_equal method which should return True if two instances of Individual class are equal. Otherwise, it returns False. The duplicate instances are removed from population at each generation. Only one instance is held to speed up the search algorithm Source code in codart\\sbse\\search_based_refactoring2.py def is_equal_2_refactorings_list ( a , b ): \"\"\" This method implement is_equal method which should return True if two instances of Individual class are equal. Otherwise, it returns False. The duplicate instances are removed from population at each generation. Only one instance is held to speed up the search algorithm \"\"\" if len ( a . X [ 0 ]) != len ( b . X [ 0 ]): return False for i , ro in enumerate ( a . X [ 0 ]): if ro . name != b . X [ 0 ][ i ] . name : return False if ro . params != b . X [ 0 ][ i ] . params : return False return True log_project_info ( reset_ = True , design_metrics_path = None , quality_attributes_path = None , generation = 0 , testability_verbose = True , testability_log_path = None ) Logging project metrics and information Source code in codart\\sbse\\search_based_refactoring2.py def log_project_info ( reset_ = True , design_metrics_path = None , quality_attributes_path = None , generation = 0 , testability_verbose = True , testability_log_path = None ): \"\"\" Logging project metrics and information \"\"\" if reset_ : reset_project () if quality_attributes_path is None : quality_attributes_path = os . path . join ( config . PROJECT_LOG_DIR , 'quality_attrs_initial_values.csv' ) if design_metrics_path is None : design_metrics_path = os . path . join ( config . PROJECT_LOG_DIR , 'design_metrics.csv' ) design_quality_attribute = DesignQualityAttributes ( config . UDB_PATH ) avg_ , sum_ = design_quality_attribute . average_sum predicted_testability = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 ), verbose = testability_verbose , log_path = testability_log_path ) mdg_modularity = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 ) ) design_metrics = { \"DSC\" : [ design_quality_attribute . DSC ], \"NOH\" : [ design_quality_attribute . NOH ], \"ANA\" : [ design_quality_attribute . ANA ], \"MOA\" : [ design_quality_attribute . MOA ], \"DAM\" : [ design_quality_attribute . DAM ], \"CAMC\" : [ design_quality_attribute . CAMC ], \"CIS\" : [ design_quality_attribute . CIS ], \"NOM\" : [ design_quality_attribute . NOM ], \"DCC\" : [ design_quality_attribute . DCC ], \"MFA\" : [ design_quality_attribute . MFA ], \"NOP\" : [ design_quality_attribute . NOP ] } quality_objectives = { \"generation\" : [ generation ], \"reusability\" : [ design_quality_attribute . reusability ], \"understandability\" : [ design_quality_attribute . understandability ], \"flexibility\" : [ design_quality_attribute . flexibility ], \"functionality\" : [ design_quality_attribute . functionality ], \"effectiveness\" : [ design_quality_attribute . effectiveness ], \"extendability\" : [ design_quality_attribute . extendability ], \"testability\" : [ predicted_testability ], \"modularity\" : [ mdg_modularity ], } logger . info ( 'QMOOD design metrics (N):' ) logger . info ( design_metrics ) logger . info ( 'Objectives:' ) logger . info ( quality_objectives ) logger . info ( 'QMOOD quality attributes sum:' ) logger . info ( sum_ ) logger . info ( 'QMOOD quality attributes mean:' ) logger . info ( avg_ ) df_quality_attributes = pd . DataFrame ( data = quality_objectives ) if os . path . exists ( quality_attributes_path ): df = pd . read_csv ( quality_attributes_path , index_col = False ) df_result = pd . concat ([ df , df_quality_attributes ], ignore_index = True ) df_result . to_csv ( quality_attributes_path , index = False ) else : df_quality_attributes . to_csv ( quality_attributes_path , index = False ) df_design_metrics = pd . DataFrame ( data = design_metrics ) if os . path . exists ( design_metrics_path ): df = pd . read_csv ( design_metrics_path , index_col = False ) df_results = pd . concat ([ df , df_design_metrics ], ignore_index = True ) # df = df.append(df_design_metrics, ignore_index=True) df_results . to_csv ( design_metrics_path , index = False ) else : df_design_metrics . to_csv ( design_metrics_path , index = False ) main () Optimization module main driver Source code in codart\\sbse\\search_based_refactoring2.py def main (): \"\"\" Optimization module main driver \"\"\" # Define initialization objects initializer_class = SmellInitialization if config . WARM_START else RandomInitialization initializer_object = initializer_class ( udb_path = config . UDB_PATH , population_size = config . POPULATION_SIZE , lower_band = config . LOWER_BAND , upper_band = config . UPPER_BAND ) # ------------------------------------------- # Define optimization problems problems = list () # 0: Genetic (Single), 1: NSGA-II (Multi), 2: NSGA-III (Many) objectives problems problems . append ( ProblemSingleObjective ( n_objectives = config . NUMBER_OBJECTIVES , n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , ) ) problems . append ( ProblemMultiObjective ( n_objectives = config . NUMBER_OBJECTIVES , n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , ) ) problems . append ( ProblemManyObjective ( n_objectives = config . NUMBER_OBJECTIVES , n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , verbose_design_metrics = True , ) ) # Define search algorithms algorithms = list () # 1: GA alg1 = GA ( pop_size = config . POPULATION_SIZE , sampling = PopulationInitialization ( initializer_object ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg1 ) # 2: NSGA-II alg2 = NSGA2 ( pop_size = config . POPULATION_SIZE , sampling = PopulationInitialization ( initializer_object ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg2 ) # 3: NSGA-III # pop_size must be equal or larger than the number of reference directions number_of_references_points = config . POPULATION_SIZE - int ( config . POPULATION_SIZE * 0.20 ) ref_dirs = get_reference_directions ( 'energy' , # algorithm config . NUMBER_OBJECTIVES , # number of objectives number_of_references_points , # number of reference directions seed = 1 ) alg3 = NSGA3 ( ref_dirs = ref_dirs , pop_size = config . POPULATION_SIZE , # 200 sampling = PopulationInitialization ( initializer_object ), selection = TournamentSelection ( func_comp = binary_tournament ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY , ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg3 ) # Termination of algorithms my_termination = MultiObjectiveDefaultTermination ( x_tol = None , cv_tol = None , f_tol = 0.0015 , nth_gen = 5 , n_last = 5 , n_max_gen = config . MAX_ITERATIONS , # about 1000 - 1400 n_max_evals = 1e6 ) # Do optimization for various problems with various algorithms res = minimize ( problem = problems [ config . PROBLEM ], algorithm = algorithms [ config . PROBLEM ], termination = my_termination , seed = 1 , verbose = False , copy_algorithm = True , copy_termination = True , save_history = False , callback = LogCallback (), ) # np.save('checkpoint', res.algorithm) # Log results logger . info ( f \"***** Algorithm was finished in { res . algorithm . n_gen + config . NGEN } generations *****\" ) logger . info ( \" \" ) logger . info ( \"============ time information ============\" ) logger . info ( f \"Start time: { datetime . fromtimestamp ( res . start_time ) . strftime ( '%Y-%m- %d %H:%M:%S' ) } \" ) logger . info ( f \"End time: { datetime . fromtimestamp ( res . end_time ) . strftime ( '%Y-%m- %d %H:%M:%S' ) } \" ) logger . info ( f \"Execution time in seconds: { res . exec_time } \" ) logger . info ( f \"Execution time in minutes: { res . exec_time / 60 } \" ) logger . info ( f \"Execution time in hours: { res . exec_time / ( 60 * 60 ) } \" ) # logger.info(f\"Number of generations: {res.algorithm.n_gen}\") # logger.info(f\"Number of generations\", res.algorithm.termination) # Log optimum solutions logger . info ( \"============ All opt solutions ============\" ) for i , ind in enumerate ( res . opt ): logger . info ( f 'Opt refactoring sequence { i } :' ) logger . info ( ind . X ) logger . info ( f 'Opt refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind . F ) logger . info ( \"-\" * 75 ) # Log best refactorings logger . info ( \"============ Best refactoring sequences (a set of non-dominated solutions) ============\" ) for i , ind in enumerate ( res . X ): logger . info ( f 'Best refactoring sequence { i } :' ) logger . info ( ind ) logger . info ( \"-\" * 75 ) logger . info ( \"============ Best objective values (a set of non-dominated solutions) ============\" ) for i , ind_objective in enumerate ( res . F ): logger . info ( f 'Best refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind_objective ) logger . info ( \"-\" * 75 ) # Save best refactorings population_trimmed = [] objective_values_content = '' for chromosome in res . X : chromosome_new = [] if config . PROBLEM == 0 : # i.e., single objective problem for gene_ in chromosome : chromosome_new . append (( gene_ . name , gene_ . params )) else : for gene_ in chromosome [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) for objective_vector in res . F : objective_values_content += f ' { res . algorithm . n_gen + config . NGEN } ,' if config . PROBLEM == 0 : objective_values_content += f ' { objective_vector } ,' else : for objective_ in objective_vector : objective_values_content += f ' { objective_ } ,' objective_values_content += ' \\n ' best_refactoring_sequences_path = os . path . join ( config . PROJECT_LOG_DIR , f 'best_refactoring_sequences_after_ { res . algorithm . n_gen + config . NGEN } gens.json' ) with open ( best_refactoring_sequences_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) best_refactoring_sequences_objectives_path = os . path . join ( config . PROJECT_LOG_DIR , f 'best_refactoring_sequences_objectives_after_ { res . algorithm . n_gen + config . NGEN } gens.csv' ) with open ( best_refactoring_sequences_objectives_path , mode = 'w' , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) try : pf = res . F # dm = HighTradeoffPoints() dm = get_decision_making ( \"high-tradeoff\" ) I = dm . do ( pf ) logger . info ( \"============ High-tradeoff points refactoring sequences ============\" ) for i , ind in enumerate ( res . X [ I ]): logger . info ( f 'High tradeoff points refactoring sequence { i } :' ) logger . info ( ind ) logger . info ( \"-\" * 75 ) logger . info ( \"============ High-tradeoff points objective values ============\" ) for i , ind_objective in enumerate ( pf [ I ]): logger . info ( f 'High-tradeoff points refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind_objective ) logger . info ( \"-\" * 75 ) logger . info ( \"High-tradeoff points mean:\" ) logger . info ( np . mean ( pf [ I ], axis = 0 )) logger . info ( \"High-tradeoff points median:\" ) logger . info ( np . median ( pf [ I ], axis = 0 )) # Save high-tradeoff refactorings population_trimmed = [] objective_values_content = '' for chromosome in res . X [ I ]: chromosome_new = [] if config . PROBLEM == 0 : # i.e., single objective problem for gene_ in chromosome : chromosome_new . append (( gene_ . name , gene_ . params )) else : for gene_ in chromosome [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) for objective_vector in pf [ I ]: objective_values_content += f ' { res . algorithm . n_gen + config . NGEN } ,' if config . PROBLEM == 0 : objective_values_content += f ' { objective_vector } ,' else : for objective_ in objective_vector : objective_values_content += f ' { objective_ } ,' objective_values_content += ' \\n ' high_tradeoff_path = os . path . join ( config . PROJECT_LOG_DIR , f 'high_tradeoff_points_refactoring_after_ { res . algorithm . n_gen + config . NGEN } gens.json' ) with open ( high_tradeoff_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) high_tradeoff_path_objectives_path = os . path . join ( config . PROJECT_LOG_DIR , f 'high_tradeoff_points_after_ { res . algorithm . n_gen + config . NGEN } gens.csv' ) with open ( high_tradeoff_path_objectives_path , mode = 'w' , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) except : logger . error ( \"No multi-optimal solutions (error in computing high tradeoff points)!\" )","title":"Search-based refactoring"},{"location":"optimization/search-based_refactoring/#search-based-refactoring-module","text":"","title":"Search-based refactoring module"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--module-description","text":"This module implements the search-based refactoring with various search strategy using pymoo framework.","title":"Module description"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--classes","text":"Gene, RefactoringOperation: One refactoring with params Individual: A list of RefactoringOperation PureRandomInitialization: Population, list of Individual","title":"Classes"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--references","text":"[1] https://pymoo.org/customization/custom.html [2] https://pymoo.org/misc/reference_directions.html","title":"References"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--changelog","text":"","title":"Changelog"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--version-024","text":"1. Fix objective parameters of the problem classes","title":"version 0.2.4"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--version-023","text":"1. Fix PEP 8 warnings","title":"version 0.2.3"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--version-022","text":"1. Add a separate log directory for each execution 2. Add possibility to resume algorithm","title":"version 0.2.2"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--version-021","text":"1. minor updates 2. fix bugs 3. rename variables names","title":"version 0.2.1"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2--version-020","text":"1. Crossover function is added. 2. Termination criteria are added. 3. Computation of highly trade-off points is added. 4. Tournament-selection is added. 5. _evaluate function in NSGA-III is now works on population instead of an individual (population-based versus element-wise). 6. Other setting for NSGA-III including adding energy-references point instead of Das and Dennis approach. ===","title":"version 0.2.0"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.AdaptiveSinglePointCrossover","text":"This class implements solution variation, the adaptive one-point or single-point crossover operator. The crossover operator combines parents to create offsprings. It starts by selecting and splitting at random two parent solutions or individuals. Then, this operator creates two child solutions by putting, for the first child, the first part of the first parent with the second part of the second parent, and vice versa for the second child. Note 1: In the pymoo framework, the crossover operator retrieves the input already with predefined matings. The default parent selection algorithm is TournamentSelection. Note 2: It is better to create children that are close to their parents to have a more efficient search process, a so-called adaptive crossover , specifically in many-objective optimization. Therefore, the cutting point of the one-point crossover operator are controlled by restricting its position to be either belonging to the first tier of the refactoring sequence or belonging to the last tier. Source code in codart\\sbse\\search_based_refactoring2.py class AdaptiveSinglePointCrossover ( Crossover ): \"\"\" This class implements solution variation, the adaptive one-point or single-point crossover operator. The crossover operator combines parents to create offsprings. It starts by selecting and splitting at random two parent solutions or individuals. Then, this operator creates two child solutions by putting, for the first child, the first part of the first parent with the second part of the second parent, and vice versa for the second child. * Note 1: In the pymoo framework, the crossover operator retrieves the input already with predefined matings. The default parent selection algorithm is TournamentSelection. * Note 2: It is better to create children that are close to their parents to have a more efficient search process, a so-called __adaptive crossover__, specifically in many-objective optimization. Therefore, the cutting point of the one-point crossover operator are controlled by restricting its position to be either belonging to the first tier of the refactoring sequence or belonging to the last tier. \"\"\" def __init__ ( self , prob = 0.9 ): \"\"\" Args: prob (float): crossover probability \"\"\" # Define the crossover: number of parents, number of offsprings, and cross-over probability super () . __init__ ( n_parents = 2 , n_offsprings = 2 , prob = prob ) def _do ( self , problem , X , ** kwargs ): \"\"\" For population X Args: problem (Problem): An instance of pymoo Problem class to be optimized. X (np.array): Population \"\"\" # The input of has the following shape (n_parents, n_matings, n_var) _ , n_matings , n_var = X . shape # The output will be with the shape (n_offsprings, n_matings, n_var) # Because there the number of parents and offsprings are equal it keeps the shape of X Y = np . full_like ( X , None , dtype = object ) # print(X.shape) # print(X) # for each mating provided for k in range ( n_matings ): # get the first and the second parent (a and b are instance of individuals) a , b = X [ 0 , k , 0 ], X [ 1 , k , 0 ] # print('### a', a) # print('### b', b) # print('len a', len(a)) # print('len b', len(b)) len_min = min ( len ( a ), len ( b )) cross_point_1 = random . randint ( 1 , int ( len_min * 0.30 )) cross_point_2 = random . randint ( int ( len_min * 0.70 ), len_min - 1 ) if random . random () < 0.5 : cross_point_final = cross_point_1 else : cross_point_final = cross_point_2 logger . info ( f 'cross_point_final: { cross_point_final } ' ) offspring_a = [] offspring_b = [] for i in range ( 0 , cross_point_final ): offspring_a . append ( deepcopy ( a [ i ])) offspring_b . append ( deepcopy ( b [ i ])) for i in range ( cross_point_final , len_min ): offspring_a . append ( deepcopy ( b [ i ])) offspring_b . append ( deepcopy ( a [ i ])) if len ( b ) > len ( a ): for i in range ( len ( a ), len ( b )): offspring_a . append ( deepcopy ( b [ i ])) else : for i in range ( len ( b ), len ( a )): offspring_b . append ( deepcopy ( a [ i ])) # print('$$$ offspring_a', offspring_a) # print('$$$ offspring_b', offspring_b) # print('len offspring_a', len(offspring_a)) # print('len offspring_b', len(offspring_b)) # Join offsprings to offspring population Y Y [ 0 , k , 0 ], Y [ 1 , k , 0 ] = offspring_a , offspring_b # quit() return Y","title":"AdaptiveSinglePointCrossover"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.AdaptiveSinglePointCrossover.__init__","text":"prob (float): crossover probability Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.9 ): \"\"\" Args: prob (float): crossover probability \"\"\" # Define the crossover: number of parents, number of offsprings, and cross-over probability super () . __init__ ( n_parents = 2 , n_offsprings = 2 , prob = prob )","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.BitStringMutation","text":"This class implements solution variation, a bit-string mutation operator. The bit-string mutation operator that picks probabilistically one or more refactoring operations from its or their associated sequence and replaces them by other ones from the initial list of possible refactorings. Each chromosome dimension would be changed according to the mutation probability. For example, for a mutation probability of 0.2, for each dimension, we generate randomly a number x between 0 and 1, if x < mutation_probability (e.g., 0.2) we change the refactoring operation in that dimension, otherwise no changes are taken into account. Source code in codart\\sbse\\search_based_refactoring2.py class BitStringMutation ( Mutation ): \"\"\" This class implements solution variation, a bit-string mutation operator. The bit-string mutation operator that picks probabilistically one or more refactoring operations from its or their associated sequence and replaces them by other ones from the initial list of possible refactorings. Each chromosome dimension would be changed according to the mutation probability. For example, for a mutation probability of 0.2, for each dimension, we generate randomly a number x between 0 and 1, if `x < mutation_probability` (e.g., 0.2) we change the refactoring operation in that dimension, otherwise no changes are taken into account. \"\"\" def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer def _do ( self , problem , X , ** kwargs ): for i , individual in enumerate ( X ): for j , ro in enumerate ( individual ): r = np . random . random () # with a probability of `mutation_probability` replace the refactoring operation with new one if r < self . mutation_probability : random_chromosome = random . choice ( self . _initializer . population ) item = random . choice ( random_chromosome ) X [ i ][ 0 ][ j ] = deepcopy ( RefactoringOperation ( name = item [ 2 ], params = item [ 1 ], main = item [ 0 ])) return X","title":"BitStringMutation"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.BitStringMutation.__init__","text":"Parameters: Name Type Description Default prob float mutation probability 0.2 Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.BitStringMutation2","text":"Select an individual to mutate with mutation probability. Only flip one refactoring operation in the selected individual. Source code in codart\\sbse\\search_based_refactoring2.py class BitStringMutation2 ( Mutation ): \"\"\" Select an individual to mutate with mutation probability. Only flip one refactoring operation in the selected individual. \"\"\" def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer self . _initializer . load_population () def _do ( self , problem , X , ** kwargs ): for i , individual in enumerate ( X ): r = np . random . random () # with a probability of `mutation_probability` replace the refactoring operation with new one if r < self . mutation_probability : # j is a random index in individual j = random . randint ( 0 , len ( individual [ 0 ]) - 1 ) random_chromosome = random . choice ( self . _initializer . population ) item = random . choice ( random_chromosome ) X [ i ][ 0 ][ j ] = deepcopy ( RefactoringOperation ( name = item [ 2 ], params = item [ 1 ], main = item [ 0 ])) return X","title":"BitStringMutation2"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.BitStringMutation2.__init__","text":"Parameters: Name Type Description Default prob float mutation probability 0.2 Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , prob = 0.2 , initializer : Initialization = None ): \"\"\" Args: prob (float): mutation probability \"\"\" super () . __init__ () self . mutation_probability = prob self . _initializer = initializer self . _initializer . load_population ()","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.Gene","text":"The base class for the Gene in genetic algorithms. Source code in codart\\sbse\\search_based_refactoring2.py class Gene : \"\"\" The base class for the Gene in genetic algorithms. \"\"\" def __init__ ( self , ** kwargs ): \"\"\" Args: name (str): Refactoring operation name params (dict): Refactoring operation parameters main (function): Refactoring operation main function (API) \"\"\" self . name = kwargs . get ( 'name' ) self . params = kwargs . get ( 'params' ) self . main = kwargs . get ( 'main' ) def __str__ ( self ): parameters = '(' for param in self . params : parameters += str ( param ) + ', ' return self . name + parameters [: - 2 ] + ')'","title":"Gene"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.Gene.__init__","text":"Parameters: Name Type Description Default name str Refactoring operation name required params dict Refactoring operation parameters required main function Refactoring operation main function (API) required Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , ** kwargs ): \"\"\" Args: name (str): Refactoring operation name params (dict): Refactoring operation parameters main (function): Refactoring operation main function (API) \"\"\" self . name = kwargs . get ( 'name' ) self . params = kwargs . get ( 'params' ) self . main = kwargs . get ( 'main' )","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.Individual","text":"The class define a data structure (list) to hold an individual during the search process. Each individual (also called, chromosome or solution in the context of genetic programming) is an array of refactoring operations where the order of their execution is accorded by their positions in the array. Source code in codart\\sbse\\search_based_refactoring2.py class Individual ( List ): \"\"\" The class define a data structure (list) to hold an individual during the search process. Each individual (also called, chromosome or solution in the context of genetic programming) is an array of refactoring operations where the order of their execution is accorded by their positions in the array. \"\"\" def __init__ ( self ): \"\"\" Args: \"\"\" super ( Individual , self ) . __init__ () self . refactoring_operations = [] def __iter__ ( self ): for ref in self . refactoring_operations : yield ref def __len__ ( self ): return len ( self . refactoring_operations ) def __getitem__ ( self , item ): return self . refactoring_operations [ item ] def __delitem__ ( self , key ): del self . refactoring_operations [ key ] def __setitem__ ( self , key , value ): self . refactoring_operations [ key ] = value def __str__ ( self ): return str ( self . refactoring_operations ) def insert ( self , __index : int , __object : RefactoringOperation ) -> None : self . refactoring_operations . insert ( __index , __object ) def append ( self , __object : RefactoringOperation ) -> None : self . insert ( len ( self . refactoring_operations ), __object )","title":"Individual"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.Individual.__init__","text":"Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self ): \"\"\" Args: \"\"\" super ( Individual , self ) . __init__ () self . refactoring_operations = []","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.Individual.append","text":"Append object to the end of the list. Source code in codart\\sbse\\search_based_refactoring2.py def append ( self , __object : RefactoringOperation ) -> None : self . insert ( len ( self . refactoring_operations ), __object )","title":"append()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.Individual.insert","text":"Insert object before index. Source code in codart\\sbse\\search_based_refactoring2.py def insert ( self , __index : int , __object : RefactoringOperation ) -> None : self . refactoring_operations . insert ( __index , __object )","title":"insert()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.LogCallback","text":"Logging useful information after each iteration of the search algorithms Source code in codart\\sbse\\search_based_refactoring2.py class LogCallback ( Callback ): \"\"\" Logging useful information after each iteration of the search algorithms \"\"\" def __init__ ( self ) -> None : super () . __init__ () # self.data[\"best\"] = [] def notify ( self , algorithm , ** kwargs ): # self.data[\"best\"].append(algorithm.pop.get(\"F\").min()) logger . info ( f 'Generation # { algorithm . n_gen + config . NGEN } was finished:' ) # logger.info(f'Best solution:') # logger.info(f'{algorithm.pop.get(\"F\")}') # logger.info(f'Pareto-front solutions:') # logger.info(f'{algorithm.pf}') X , F , CV , G = algorithm . opt . get ( \"X\" , \"F\" , \"CV\" , \"G\" ) logger . info ( f 'Optimum solutions:' ) logger . info ( f ' { F } ' ) # Log evolved population at end of each generation generation_log_path = f ' { config . PROJECT_LOG_DIR } generations_logs/' if not os . path . exists ( generation_log_path ): os . makedirs ( generation_log_path ) generation_endof_date_time = config . dt . datetime . now () . strftime ( '%Y-%m- %d _%H-%M-%S' ) population_log_file_path = os . path . join ( generation_log_path , f 'pop_gen { algorithm . n_gen + config . NGEN } _ { generation_endof_date_time } .json' ) pop_opt_log_file_path = os . path . join ( generation_log_path , f 'pop_opt_gen { algorithm . n_gen + config . NGEN } _ { generation_endof_date_time } .json' ) pop_opt_objective_value_log = os . path . join ( config . PROJECT_LOG_DIR , f ' { config . PROJECT_NAME } _objectives_log_ { config . global_execution_start_time } .csv' ) population_trimmed = [] for chromosome in algorithm . pop : chromosome_new = [] for gene_ in chromosome . X [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) with open ( population_log_file_path , 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) population_trimmed = [] objective_values_content = '' for chromosome in algorithm . opt : chromosome_new = [] for gene_ in chromosome . X [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) objective_values_content += f ' { algorithm . n_gen + config . NGEN } ,' for gene_objective_ in chromosome . F : objective_values_content += f ' { gene_objective_ } ,' objective_values_content += ' \\n ' with open ( pop_opt_log_file_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) if not os . path . exists ( pop_opt_objective_value_log ): writing_mode = 'w' else : writing_mode = 'a' with open ( pop_opt_objective_value_log , mode = writing_mode , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) logger . info ( '-' * 100 ) logger . info ( ' ' ) # quit()","title":"LogCallback"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.PopulationInitialization","text":"This class create the initial population, x, consists of n_samples, pop_size. For each refactoring operation, a set of controlling parameters (e.g., actors and roles) is picked based on existing code smells in the program to be refactored. The selected refactoring operations are randomly arranged in each individual. Assigning randomly a sequence of refactorings to certain code fragments generates the initial population Source code in codart\\sbse\\search_based_refactoring2.py class PopulationInitialization ( Sampling ): \"\"\" This class create the initial population, x, consists of n_samples, pop_size. For each refactoring operation, a set of controlling parameters (e.g., actors and roles) is picked based on existing code smells in the program to be refactored. The selected refactoring operations are randomly arranged in each individual. Assigning randomly a sequence of refactorings to certain code fragments generates the initial population \"\"\" def __init__ ( self , initializer : Initialization = None ): \"\"\" Args: initializer (Initialization): An initializer object to be used for generating initial population \"\"\" super ( PopulationInitialization , self ) . __init__ () self . _initializer = initializer def _do ( self , problem , n_samples , ** kwargs ): \"\"\" Since the problem having only one variable, we return a matrix with the shape (n,1) Args: problem (Problem): An instance of pymoo Problem class to be optimized. n_samples (int): The same population size, pop_size. \"\"\" if os . path . exists ( config . INIT_POP_FILE ): self . _initializer . load_population ( path = config . INIT_POP_FILE ) population = self . _initializer . population initial_pop_path = f ' { config . PROJECT_LOG_DIR } initial_population_ { config . global_execution_start_time } .json' if config . NGEN == 0 : self . _initializer . dump_population ( path = initial_pop_path ) else : population = self . _initializer . generate_population () x = np . full (( n_samples , 1 ), None , dtype = Individual ) for i in range ( n_samples ): individual_object = [] # list of refactoring operations (Temporarily used instead of Individual class) for ref in population [ i ]: individual_object . append ( RefactoringOperation ( name = ref [ 2 ], params = ref [ 1 ], main = ref [ 0 ])) x [ i , 0 ] = deepcopy ( individual_object ) return x","title":"PopulationInitialization"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.PopulationInitialization.__init__","text":"Parameters: Name Type Description Default initializer Initialization An initializer object to be used for generating initial population None Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , initializer : Initialization = None ): \"\"\" Args: initializer (Initialization): An initializer object to be used for generating initial population \"\"\" super ( PopulationInitialization , self ) . __init__ () self . _initializer = initializer","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.ProblemManyObjective","text":"The CodART many-objective optimization work with eight objective: Objective 1 to 6: QMOOD design quality attributes Objective 7: Testability prediction model Objective 8: Modularity complex network Source code in codart\\sbse\\search_based_refactoring2.py class ProblemManyObjective ( Problem ): \"\"\" The CodART many-objective optimization work with eight objective: * Objective 1 to 6: QMOOD design quality attributes * Objective 7: Testability prediction model * Objective 8: Modularity complex network \"\"\" def __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , verbose_design_metrics = False , ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives computed in parallel or not verbose_design_metrics (bool): Whether log the design metrics for each refactoring sequences or not \"\"\" super ( ProblemManyObjective , self ) . __init__ ( n_var = 1 , n_obj = n_objectives , n_constr = 0 , ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . verbose_design_metrics = verbose_design_metrics def _evaluate ( self , x , out , * args , ** kwargs ): \"\"\" This method iterate over a population, execute the refactoring operations in each individual sequentially, and compute quality attributes for the refactored version of the program, as objectives of the search. By default, elementwise_evaluation is set to False, which implies the _evaluate retrieves a set of solutions. Args: x (Population): x is a matrix where each row is an individual, and each column a variable.\\ We have one variable of type list (Individual) ==> x.shape = (len(Population), 1) \"\"\" objective_values = [] for k , individual_ in enumerate ( x ): # Stage 0: Git restore logger . debug ( \"Executing git restore.\" ) git_restore ( config . PROJECT_PATH ) logger . debug ( \"Updating understand database after git restore.\" ) update_understand_database ( config . UDB_PATH ) # Stage 1: Execute all refactoring operations in the sequence x logger . debug ( f \"Reached an Individual with size { len ( individual_ [ 0 ]) } \" ) for refactoring_operation in individual_ [ 0 ]: res = refactoring_operation . do_refactoring () # Update Understand DB logger . debug ( f \"Updating understand database after { refactoring_operation . name } .\" ) update_understand_database ( config . UDB_PATH ) # Stage 2: arr = Array ( 'd' , range ( self . n_obj )) if self . evaluate_in_parallel : # Stage 2 (parallel mood): Computing quality attributes p1 = Process ( target = calc_qmood_objectives , args = ( arr ,)) if self . n_obj == 8 : p2 = Process ( target = calc_testability_objective , args = ( config . UDB_PATH , arr ,)) p3 = Process ( target = calc_modularity_objective , args = ( config . UDB_PATH , arr ,)) p1 . start (), p2 . start (), p3 . start () p1 . join (), p2 . join (), p3 . join () else : p1 . start () p1 . join () else : # Stage 2 (sequential mood): Computing quality attributes qmood_quality_attributes = DesignQualityAttributes ( udb_path = config . UDB_PATH ) arr [ 0 ] = qmood_quality_attributes . reusability arr [ 1 ] = qmood_quality_attributes . understandability arr [ 2 ] = qmood_quality_attributes . flexibility arr [ 3 ] = qmood_quality_attributes . functionality arr [ 4 ] = qmood_quality_attributes . effectiveness arr [ 5 ] = qmood_quality_attributes . extendability if self . n_obj == 8 : arr [ 6 ] = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 )) arr [ 7 ] = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 )) if self . verbose_design_metrics : design_metrics = { \"DSC\" : [ qmood_quality_attributes . DSC ], \"NOH\" : [ qmood_quality_attributes . NOH ], \"ANA\" : [ qmood_quality_attributes . ANA ], \"MOA\" : [ qmood_quality_attributes . MOA ], \"DAM\" : [ qmood_quality_attributes . DAM ], \"CAMC\" : [ qmood_quality_attributes . CAMC ], \"CIS\" : [ qmood_quality_attributes . CIS ], \"NOM\" : [ qmood_quality_attributes . NOM ], \"DCC\" : [ qmood_quality_attributes . DCC ], \"MFA\" : [ qmood_quality_attributes . MFA ], \"NOP\" : [ qmood_quality_attributes . NOP ] } self . log_design_metrics ( design_metrics ) del qmood_quality_attributes # Stage 3: Marshal objectives into vector objective_values . append ([ - 1 * i for i in arr ]) logger . info ( f \"Objective values for individual { k } : { [ i for i in arr ] } \" ) # Stage 4: Marshal all objectives into out dictionary out [ 'F' ] = np . array ( objective_values , dtype = float ) # print('OUT', out['F']) def log_design_metrics ( self , design_metrics ): design_metrics_path = os . path . join ( config . PROJECT_LOG_DIR , f ' { config . PROJECT_NAME } _design_metrics_log_ { config . global_execution_start_time } .csv' ) df_design_metrics = pd . DataFrame ( data = design_metrics ) if os . path . exists ( design_metrics_path ): df = pd . read_csv ( design_metrics_path , index_col = False ) df_result = pd . concat ([ df , df_design_metrics ], ignore_index = True ) df_result . to_csv ( design_metrics_path , index = False ) else : df_design_metrics . to_csv ( design_metrics_path , index = False )","title":"ProblemManyObjective"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.ProblemManyObjective.__init__","text":"Parameters: Name Type Description Default n_objectives int Number of objectives 8 n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 evaluate_in_parallel bool Whether the objectives computed in parallel or not False verbose_design_metrics bool Whether log the design metrics for each refactoring sequences or not False Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , verbose_design_metrics = False , ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives computed in parallel or not verbose_design_metrics (bool): Whether log the design metrics for each refactoring sequences or not \"\"\" super ( ProblemManyObjective , self ) . __init__ ( n_var = 1 , n_obj = n_objectives , n_constr = 0 , ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . verbose_design_metrics = verbose_design_metrics","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.ProblemMultiObjective","text":"The CodART multi-objective optimization work with three objective: Objective 1: Mean value of QMOOD metrics Objective 2: Testability Objective 3: Modularity Source code in codart\\sbse\\search_based_refactoring2.py class ProblemMultiObjective ( Problem ): \"\"\" The CodART multi-objective optimization work with three objective: * Objective 1: Mean value of QMOOD metrics * Objective 2: Testability * Objective 3: Modularity \"\"\" def __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives evaluate in parallel \"\"\" super ( ProblemMultiObjective , self ) . __init__ ( n_var = 1 , n_obj = 3 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . n_obj_virtual = n_objectives def _evaluate ( self , x , # out , * args , ** kwargs ): \"\"\" This method iterate over a population, execute the refactoring operations in each individual sequentially, and compute quality attributes for the refactored version of the program, as objectives of the search Args: x (Population): x is a matrix where each row is an individual, and each column a variable. \\ We have one variable of type list (Individual) ==> x.shape = (len(Population), 1) \"\"\" objective_values = [] for k , individual_ in enumerate ( x ): # Stage 0: Git restore logger . debug ( \"Executing git restore.\" ) git_restore ( config . PROJECT_PATH ) logger . debug ( \"Updating understand database after git restore.\" ) update_understand_database ( config . UDB_PATH ) # Stage 1: Execute all refactoring operations in the sequence x logger . debug ( f \"Reached Individual with Size { len ( individual_ [ 0 ]) } \" ) for refactoring_operation in individual_ [ 0 ]: refactoring_operation . do_refactoring () # Update Understand DB logger . debug ( f \"Updating understand database after { refactoring_operation . name } .\" ) update_understand_database ( config . UDB_PATH ) # Stage 2: arr = Array ( 'd' , range ( self . n_obj_virtual )) if self . evaluate_in_parallel : # Stage 2 (parallel mood): Computing quality attributes p1 = Process ( target = calc_qmood_objectives , args = ( arr ,)) p2 = Process ( target = calc_testability_objective , args = ( config . UDB_PATH , arr ,)) p3 = Process ( target = calc_modularity_objective , args = ( config . UDB_PATH , arr ,)) p1 . start (), p2 . start (), p3 . start () p1 . join (), p2 . join (), p3 . join () o1 = sum ([ i for i in arr [: 6 ]]) / 6. o2 = arr [ 6 ] o3 = arr [ 7 ] else : # Stage 2 (sequential mood): Computing quality attributes qmood_quality_attributes = DesignQualityAttributes ( udb_path = config . UDB_PATH ) o1 = qmood_quality_attributes . average_sum o2 = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 )) o3 = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 )) del qmood_quality_attributes # Stage 3: Marshal objectives into vector objective_values . append ([ - 1 * o1 , - 1 * o2 , - 1 * o3 ]) logger . info ( f \"Objective values for individual { k } : { [ - 1 * o1 , - 1 * o2 , - 1 * o3 ] } \" ) # Stage 4: Marshal all objectives into out dictionary out [ 'F' ] = np . array ( objective_values , dtype = float )","title":"ProblemMultiObjective"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.ProblemMultiObjective.__init__","text":"Parameters: Name Type Description Default n_objectives int Number of objectives 8 n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 evaluate_in_parallel bool Whether the objectives evaluate in parallel False Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , n_objectives = 8 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences evaluate_in_parallel (bool): Whether the objectives evaluate in parallel \"\"\" super ( ProblemMultiObjective , self ) . __init__ ( n_var = 1 , n_obj = 3 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . n_obj_virtual = n_objectives","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.ProblemSingleObjective","text":"The CodART single-objective optimization work with only one objective, testability: Source code in codart\\sbse\\search_based_refactoring2.py class ProblemSingleObjective ( Problem ): \"\"\" The CodART single-objective optimization work with only one objective, testability: \"\"\" def __init__ ( self , n_objectives = 1 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , mode = 'single' # 'multi' ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences mode (str): 'single' or 'multi' \"\"\" super ( ProblemSingleObjective , self ) . __init__ ( n_var = 1 , n_obj = 1 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . mode = mode self . n_obj_virtual = n_objectives def _evaluate ( self , x , # out , * args , ** kwargs ): \"\"\" This method iterate over a population, execute the refactoring operations in each individual sequentially, and compute quality attributes for the refactored version of the program, as objectives of the search Args: x (Population): x is a matrix where each row is an individual, and each column a variable.\\ We have one variable of type list (Individual) ==> x.shape = (len(Population), 1) \"\"\" objective_values = [] for k , individual_ in enumerate ( x ): # Stage 0: Git restore logger . debug ( \"Executing git restore.\" ) git_restore ( config . PROJECT_PATH ) logger . debug ( \"Updating understand database after git restore.\" ) update_understand_database ( config . UDB_PATH ) # Stage 1: Execute all refactoring operations in the sequence x logger . debug ( f \"Reached Individual with Size { len ( individual_ [ 0 ]) } \" ) for refactoring_operation in individual_ [ 0 ]: refactoring_operation . do_refactoring () # Update Understand DB logger . debug ( f \"Updating understand database after { refactoring_operation . name } .\" ) update_understand_database ( config . UDB_PATH ) # Stage 2: if self . mode == 'single' : # Stage 2 (Single objective mode): Considering only one quality attribute, e.g., testability score = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 )) else : # Stage 2 (Multi-objective mode): Considering one objective based on average of 8 objective arr = Array ( 'd' , range ( self . n_obj_virtual )) if self . evaluate_in_parallel : # Stage 2 (Multi-objective mode, parallel): Computing quality attributes p1 = Process ( target = calc_qmood_objectives , args = ( arr ,)) if self . n_obj_virtual == 8 : p2 = Process ( target = calc_testability_objective , args = ( config . UDB_PATH , arr ,)) p3 = Process ( target = calc_modularity_objective , args = ( config . UDB_PATH , arr ,)) p1 . start (), p2 . start (), p3 . start () p1 . join (), p2 . join (), p3 . join () else : p1 . start () p1 . join () score = sum ([ i for i in arr ]) / self . n_obj_virtual else : # Stage 2 (Multi-objective mode, sequential): Computing quality attributes qmood_quality_attributes = DesignQualityAttributes ( udb_path = config . UDB_PATH ) o1 = qmood_quality_attributes . average_sum if self . n_obj_virtual == 8 : o2 = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 )) o3 = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 )) else : o2 = 0 o3 = 0 del qmood_quality_attributes score = ( o1 * 6. + o2 + o3 ) / self . n_obj_virtual # Stage 3: Marshal objectives into vector objective_values . append ([ - 1 * score ]) logger . info ( f \"Objective values for individual { k } in mode { self . mode } : { [ - 1 * score ] } \" ) # Stage 4: Marshal all objectives into out dictionary out [ 'F' ] = np . array ( objective_values , dtype = float )","title":"ProblemSingleObjective"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.ProblemSingleObjective.__init__","text":"Parameters: Name Type Description Default n_objectives int Number of objectives 1 n_refactorings_lowerbound int The lower bound of the refactoring sequences 10 n_refactorings_upperbound int The upper bound of the refactoring sequences 50 mode str 'single' or 'multi' 'single' Source code in codart\\sbse\\search_based_refactoring2.py def __init__ ( self , n_objectives = 1 , n_refactorings_lowerbound = 10 , n_refactorings_upperbound = 50 , evaluate_in_parallel = False , mode = 'single' # 'multi' ): \"\"\" Args: n_objectives (int): Number of objectives n_refactorings_lowerbound (int): The lower bound of the refactoring sequences n_refactorings_upperbound (int): The upper bound of the refactoring sequences mode (str): 'single' or 'multi' \"\"\" super ( ProblemSingleObjective , self ) . __init__ ( n_var = 1 , n_obj = 1 , n_constr = 0 ) self . n_refactorings_lowerbound = n_refactorings_lowerbound self . n_refactorings_upperbound = n_refactorings_upperbound self . evaluate_in_parallel = evaluate_in_parallel self . mode = mode self . n_obj_virtual = n_objectives","title":"__init__()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.RefactoringOperation","text":"The class define a data structure (dictionary) to hold a refactoring operation Each refactoring operation hold as a dictionary contains the required parameters. Example: ``` make_field_static refactoring is marshaled as the following dict: params = { 'refactoring_name': 'make_field_static' 'api': 'main_function' 'source_class': 'name_of_source_class' 'field_name': 'name_of_the_field_to_be_static' } ``` Source code in codart\\sbse\\search_based_refactoring2.py class RefactoringOperation ( Gene ): \"\"\" The class define a data structure (dictionary) to hold a refactoring operation Each refactoring operation hold as a dictionary contains the required parameters. Example: ``` make_field_static refactoring is marshaled as the following dict: params = { 'refactoring_name': 'make_field_static' 'api': 'main_function' 'source_class': 'name_of_source_class' 'field_name': 'name_of_the_field_to_be_static' } ``` \"\"\" def __init__ ( self , ** kwargs ): \"\"\" Args: name (str): Refactoring operation name params (dict): Refactoring operation parameters main (function): Refactoring operation main function (API) \"\"\" super ( RefactoringOperation , self ) . __init__ ( ** kwargs ) def __str__ ( self ): return f ' { self . name } ( { self . params } ) \\n ' def __repr__ ( self ): return self . __str__ () def do_refactoring ( self ): \"\"\" Check preconditions and apply refactoring operation to source code Returns: result (boolean): The result statues of the applied refactoring \"\"\" logger . info ( f \"Running { self . name } \" ) logger . info ( f \"Parameters { self . params } \" ) try : res = self . main ( ** self . params ) logger . debug ( f \"Executed refactoring with result { res } \" ) return res except Exception as e : logger . error ( f \"Unexpected error in executing refactoring: \\n { e } \" ) return False","title":"RefactoringOperation"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.RefactoringOperation.do_refactoring","text":"Check preconditions and apply refactoring operation to source code Returns: Type Description result (boolean) The result statues of the applied refactoring Source code in codart\\sbse\\search_based_refactoring2.py def do_refactoring ( self ): \"\"\" Check preconditions and apply refactoring operation to source code Returns: result (boolean): The result statues of the applied refactoring \"\"\" logger . info ( f \"Running { self . name } \" ) logger . info ( f \"Parameters { self . params } \" ) try : res = self . main ( ** self . params ) logger . debug ( f \"Executed refactoring with result { res } \" ) return res except Exception as e : logger . error ( f \"Unexpected error in executing refactoring: \\n { e } \" ) return False","title":"do_refactoring()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.binary_tournament","text":"Implements the binary tournament selection algorithm Source code in codart\\sbse\\search_based_refactoring2.py def binary_tournament ( pop , P , ** kwargs ): \"\"\" Implements the binary tournament selection algorithm \"\"\" # The P input defines the tournaments and competitors n_tournaments , n_competitors = P . shape if n_competitors != 2 : raise Exception ( \"Only pressure=2 allowed for binary tournament!\" ) S = np . full ( n_tournaments , - 1 , dtype = np . int64 ) # Now do all the tournaments for i in range ( n_tournaments ): a , b = P [ i ] # If the first individual is better, choose it if pop [ a ] . F . all () <= pop [ a ] . F . all (): S [ i ] = a # Otherwise, take the other individual else : S [ i ] = b return S","title":"binary_tournament()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.is_equal_2_refactorings_list","text":"This method implement is_equal method which should return True if two instances of Individual class are equal. Otherwise, it returns False. The duplicate instances are removed from population at each generation. Only one instance is held to speed up the search algorithm Source code in codart\\sbse\\search_based_refactoring2.py def is_equal_2_refactorings_list ( a , b ): \"\"\" This method implement is_equal method which should return True if two instances of Individual class are equal. Otherwise, it returns False. The duplicate instances are removed from population at each generation. Only one instance is held to speed up the search algorithm \"\"\" if len ( a . X [ 0 ]) != len ( b . X [ 0 ]): return False for i , ro in enumerate ( a . X [ 0 ]): if ro . name != b . X [ 0 ][ i ] . name : return False if ro . params != b . X [ 0 ][ i ] . params : return False return True","title":"is_equal_2_refactorings_list()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.log_project_info","text":"Logging project metrics and information Source code in codart\\sbse\\search_based_refactoring2.py def log_project_info ( reset_ = True , design_metrics_path = None , quality_attributes_path = None , generation = 0 , testability_verbose = True , testability_log_path = None ): \"\"\" Logging project metrics and information \"\"\" if reset_ : reset_project () if quality_attributes_path is None : quality_attributes_path = os . path . join ( config . PROJECT_LOG_DIR , 'quality_attrs_initial_values.csv' ) if design_metrics_path is None : design_metrics_path = os . path . join ( config . PROJECT_LOG_DIR , 'design_metrics.csv' ) design_quality_attribute = DesignQualityAttributes ( config . UDB_PATH ) avg_ , sum_ = design_quality_attribute . average_sum predicted_testability = testability_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"TEST\" , 1.0 ), verbose = testability_verbose , log_path = testability_log_path ) mdg_modularity = modularity_main ( config . UDB_PATH , initial_value = config . CURRENT_METRICS . get ( \"MODULE\" , 1.0 ) ) design_metrics = { \"DSC\" : [ design_quality_attribute . DSC ], \"NOH\" : [ design_quality_attribute . NOH ], \"ANA\" : [ design_quality_attribute . ANA ], \"MOA\" : [ design_quality_attribute . MOA ], \"DAM\" : [ design_quality_attribute . DAM ], \"CAMC\" : [ design_quality_attribute . CAMC ], \"CIS\" : [ design_quality_attribute . CIS ], \"NOM\" : [ design_quality_attribute . NOM ], \"DCC\" : [ design_quality_attribute . DCC ], \"MFA\" : [ design_quality_attribute . MFA ], \"NOP\" : [ design_quality_attribute . NOP ] } quality_objectives = { \"generation\" : [ generation ], \"reusability\" : [ design_quality_attribute . reusability ], \"understandability\" : [ design_quality_attribute . understandability ], \"flexibility\" : [ design_quality_attribute . flexibility ], \"functionality\" : [ design_quality_attribute . functionality ], \"effectiveness\" : [ design_quality_attribute . effectiveness ], \"extendability\" : [ design_quality_attribute . extendability ], \"testability\" : [ predicted_testability ], \"modularity\" : [ mdg_modularity ], } logger . info ( 'QMOOD design metrics (N):' ) logger . info ( design_metrics ) logger . info ( 'Objectives:' ) logger . info ( quality_objectives ) logger . info ( 'QMOOD quality attributes sum:' ) logger . info ( sum_ ) logger . info ( 'QMOOD quality attributes mean:' ) logger . info ( avg_ ) df_quality_attributes = pd . DataFrame ( data = quality_objectives ) if os . path . exists ( quality_attributes_path ): df = pd . read_csv ( quality_attributes_path , index_col = False ) df_result = pd . concat ([ df , df_quality_attributes ], ignore_index = True ) df_result . to_csv ( quality_attributes_path , index = False ) else : df_quality_attributes . to_csv ( quality_attributes_path , index = False ) df_design_metrics = pd . DataFrame ( data = design_metrics ) if os . path . exists ( design_metrics_path ): df = pd . read_csv ( design_metrics_path , index_col = False ) df_results = pd . concat ([ df , df_design_metrics ], ignore_index = True ) # df = df.append(df_design_metrics, ignore_index=True) df_results . to_csv ( design_metrics_path , index = False ) else : df_design_metrics . to_csv ( design_metrics_path , index = False )","title":"log_project_info()"},{"location":"optimization/search-based_refactoring/#codart.sbse.search_based_refactoring2.main","text":"Optimization module main driver Source code in codart\\sbse\\search_based_refactoring2.py def main (): \"\"\" Optimization module main driver \"\"\" # Define initialization objects initializer_class = SmellInitialization if config . WARM_START else RandomInitialization initializer_object = initializer_class ( udb_path = config . UDB_PATH , population_size = config . POPULATION_SIZE , lower_band = config . LOWER_BAND , upper_band = config . UPPER_BAND ) # ------------------------------------------- # Define optimization problems problems = list () # 0: Genetic (Single), 1: NSGA-II (Multi), 2: NSGA-III (Many) objectives problems problems . append ( ProblemSingleObjective ( n_objectives = config . NUMBER_OBJECTIVES , n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , ) ) problems . append ( ProblemMultiObjective ( n_objectives = config . NUMBER_OBJECTIVES , n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , ) ) problems . append ( ProblemManyObjective ( n_objectives = config . NUMBER_OBJECTIVES , n_refactorings_lowerbound = config . LOWER_BAND , n_refactorings_upperbound = config . UPPER_BAND , evaluate_in_parallel = False , verbose_design_metrics = True , ) ) # Define search algorithms algorithms = list () # 1: GA alg1 = GA ( pop_size = config . POPULATION_SIZE , sampling = PopulationInitialization ( initializer_object ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg1 ) # 2: NSGA-II alg2 = NSGA2 ( pop_size = config . POPULATION_SIZE , sampling = PopulationInitialization ( initializer_object ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg2 ) # 3: NSGA-III # pop_size must be equal or larger than the number of reference directions number_of_references_points = config . POPULATION_SIZE - int ( config . POPULATION_SIZE * 0.20 ) ref_dirs = get_reference_directions ( 'energy' , # algorithm config . NUMBER_OBJECTIVES , # number of objectives number_of_references_points , # number of reference directions seed = 1 ) alg3 = NSGA3 ( ref_dirs = ref_dirs , pop_size = config . POPULATION_SIZE , # 200 sampling = PopulationInitialization ( initializer_object ), selection = TournamentSelection ( func_comp = binary_tournament ), crossover = AdaptiveSinglePointCrossover ( prob = config . CROSSOVER_PROBABILITY , ), # crossover=get_crossover(\"real_k_point\", n_points=2), mutation = BitStringMutation ( prob = config . MUTATION_PROBABILITY , initializer = initializer_object ), eliminate_duplicates = ElementwiseDuplicateElimination ( cmp_func = is_equal_2_refactorings_list ), n_gen = config . NGEN , ) algorithms . append ( alg3 ) # Termination of algorithms my_termination = MultiObjectiveDefaultTermination ( x_tol = None , cv_tol = None , f_tol = 0.0015 , nth_gen = 5 , n_last = 5 , n_max_gen = config . MAX_ITERATIONS , # about 1000 - 1400 n_max_evals = 1e6 ) # Do optimization for various problems with various algorithms res = minimize ( problem = problems [ config . PROBLEM ], algorithm = algorithms [ config . PROBLEM ], termination = my_termination , seed = 1 , verbose = False , copy_algorithm = True , copy_termination = True , save_history = False , callback = LogCallback (), ) # np.save('checkpoint', res.algorithm) # Log results logger . info ( f \"***** Algorithm was finished in { res . algorithm . n_gen + config . NGEN } generations *****\" ) logger . info ( \" \" ) logger . info ( \"============ time information ============\" ) logger . info ( f \"Start time: { datetime . fromtimestamp ( res . start_time ) . strftime ( '%Y-%m- %d %H:%M:%S' ) } \" ) logger . info ( f \"End time: { datetime . fromtimestamp ( res . end_time ) . strftime ( '%Y-%m- %d %H:%M:%S' ) } \" ) logger . info ( f \"Execution time in seconds: { res . exec_time } \" ) logger . info ( f \"Execution time in minutes: { res . exec_time / 60 } \" ) logger . info ( f \"Execution time in hours: { res . exec_time / ( 60 * 60 ) } \" ) # logger.info(f\"Number of generations: {res.algorithm.n_gen}\") # logger.info(f\"Number of generations\", res.algorithm.termination) # Log optimum solutions logger . info ( \"============ All opt solutions ============\" ) for i , ind in enumerate ( res . opt ): logger . info ( f 'Opt refactoring sequence { i } :' ) logger . info ( ind . X ) logger . info ( f 'Opt refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind . F ) logger . info ( \"-\" * 75 ) # Log best refactorings logger . info ( \"============ Best refactoring sequences (a set of non-dominated solutions) ============\" ) for i , ind in enumerate ( res . X ): logger . info ( f 'Best refactoring sequence { i } :' ) logger . info ( ind ) logger . info ( \"-\" * 75 ) logger . info ( \"============ Best objective values (a set of non-dominated solutions) ============\" ) for i , ind_objective in enumerate ( res . F ): logger . info ( f 'Best refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind_objective ) logger . info ( \"-\" * 75 ) # Save best refactorings population_trimmed = [] objective_values_content = '' for chromosome in res . X : chromosome_new = [] if config . PROBLEM == 0 : # i.e., single objective problem for gene_ in chromosome : chromosome_new . append (( gene_ . name , gene_ . params )) else : for gene_ in chromosome [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) for objective_vector in res . F : objective_values_content += f ' { res . algorithm . n_gen + config . NGEN } ,' if config . PROBLEM == 0 : objective_values_content += f ' { objective_vector } ,' else : for objective_ in objective_vector : objective_values_content += f ' { objective_ } ,' objective_values_content += ' \\n ' best_refactoring_sequences_path = os . path . join ( config . PROJECT_LOG_DIR , f 'best_refactoring_sequences_after_ { res . algorithm . n_gen + config . NGEN } gens.json' ) with open ( best_refactoring_sequences_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) best_refactoring_sequences_objectives_path = os . path . join ( config . PROJECT_LOG_DIR , f 'best_refactoring_sequences_objectives_after_ { res . algorithm . n_gen + config . NGEN } gens.csv' ) with open ( best_refactoring_sequences_objectives_path , mode = 'w' , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) try : pf = res . F # dm = HighTradeoffPoints() dm = get_decision_making ( \"high-tradeoff\" ) I = dm . do ( pf ) logger . info ( \"============ High-tradeoff points refactoring sequences ============\" ) for i , ind in enumerate ( res . X [ I ]): logger . info ( f 'High tradeoff points refactoring sequence { i } :' ) logger . info ( ind ) logger . info ( \"-\" * 75 ) logger . info ( \"============ High-tradeoff points objective values ============\" ) for i , ind_objective in enumerate ( pf [ I ]): logger . info ( f 'High-tradeoff points refactoring sequence corresponding objectives vector { i } :' ) logger . info ( ind_objective ) logger . info ( \"-\" * 75 ) logger . info ( \"High-tradeoff points mean:\" ) logger . info ( np . mean ( pf [ I ], axis = 0 )) logger . info ( \"High-tradeoff points median:\" ) logger . info ( np . median ( pf [ I ], axis = 0 )) # Save high-tradeoff refactorings population_trimmed = [] objective_values_content = '' for chromosome in res . X [ I ]: chromosome_new = [] if config . PROBLEM == 0 : # i.e., single objective problem for gene_ in chromosome : chromosome_new . append (( gene_ . name , gene_ . params )) else : for gene_ in chromosome [ 0 ]: chromosome_new . append (( gene_ . name , gene_ . params )) population_trimmed . append ( chromosome_new ) for objective_vector in pf [ I ]: objective_values_content += f ' { res . algorithm . n_gen + config . NGEN } ,' if config . PROBLEM == 0 : objective_values_content += f ' { objective_vector } ,' else : for objective_ in objective_vector : objective_values_content += f ' { objective_ } ,' objective_values_content += ' \\n ' high_tradeoff_path = os . path . join ( config . PROJECT_LOG_DIR , f 'high_tradeoff_points_refactoring_after_ { res . algorithm . n_gen + config . NGEN } gens.json' ) with open ( high_tradeoff_path , mode = 'w' , encoding = 'utf-8' ) as fp : json . dump ( population_trimmed , fp , indent = 4 ) high_tradeoff_path_objectives_path = os . path . join ( config . PROJECT_LOG_DIR , f 'high_tradeoff_points_after_ { res . algorithm . n_gen + config . NGEN } gens.csv' ) with open ( high_tradeoff_path_objectives_path , mode = 'w' , encoding = 'utf-8' ) as fp : fp . write ( objective_values_content ) except : logger . error ( \"No multi-optimal solutions (error in computing high tradeoff points)!\" )","title":"main()"},{"location":"proposals/core_code_smell_development/","text":"Core code smell development The following proposal has been initially prepared for the IUST Compiler and Advanced Software Engineering courses in Winter and Spring 2021 . Note: Before reading this proposal ensure that you have read and understood the CodART white-paper . Students may form groups of up to three persons. Each group must develop mechanisms for a subset of code smells listed in Table 2 . The exact list of code smells will be assigned to each group subsequently. The refactoring operations in Table 1 and code smells in Table 2 may update during the semester. To facilitate and organized the development process, this proposal defines the project in various phases. The project is divided into three separate phases. In the first phase, students must read about refactoring and code smells and understand the current state of the CodART completely. As a practice, they are asked to fix the existing issues on the project repository about refactoring operations developed in the first proposal. In the second phase, each group is asked to develop algorithms to automatically detect one or more code smells in a given Java project using ANTLR tool and other compiler techniques. TA team frequently helps the students at this phase to develop their algorithms. In the third phase, each group is asked to connect the code smells detection scripts to the corresponding refactoring and automate the overall quality improvement process. Grading policy for BSc students Table 6 shows the grading policy for the BSc students. It may change in the future. Table 6. grading policy for BSc students Activity Score (100) Understanding the CodART project and Fix the existing issues 30 Implementing smell detection approaches 40 Connecting code smells to refactoring and harnessing the overall process 20 Documenting the new source codes and pushing them to GitHub 10 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) Grading policy for MSc students Table 7 shows the grading policy for the MSc students. It may change in the future. Table 7. grading policy for MSc students Activity Score (100) Understanding the paper and presenting it 20 Implementing the paper 30 Evaluating the implementation 30 Documenting the project 20 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) To follow project's future phases, meet our next proposal: Core search-based development.","title":"Core code smell development"},{"location":"proposals/core_code_smell_development/#core-code-smell-development","text":"The following proposal has been initially prepared for the IUST Compiler and Advanced Software Engineering courses in Winter and Spring 2021 . Note: Before reading this proposal ensure that you have read and understood the CodART white-paper . Students may form groups of up to three persons. Each group must develop mechanisms for a subset of code smells listed in Table 2 . The exact list of code smells will be assigned to each group subsequently. The refactoring operations in Table 1 and code smells in Table 2 may update during the semester. To facilitate and organized the development process, this proposal defines the project in various phases. The project is divided into three separate phases. In the first phase, students must read about refactoring and code smells and understand the current state of the CodART completely. As a practice, they are asked to fix the existing issues on the project repository about refactoring operations developed in the first proposal. In the second phase, each group is asked to develop algorithms to automatically detect one or more code smells in a given Java project using ANTLR tool and other compiler techniques. TA team frequently helps the students at this phase to develop their algorithms. In the third phase, each group is asked to connect the code smells detection scripts to the corresponding refactoring and automate the overall quality improvement process.","title":"Core code smell development"},{"location":"proposals/core_code_smell_development/#grading-policy-for-bsc-students","text":"Table 6 shows the grading policy for the BSc students. It may change in the future. Table 6. grading policy for BSc students Activity Score (100) Understanding the CodART project and Fix the existing issues 30 Implementing smell detection approaches 40 Connecting code smells to refactoring and harnessing the overall process 20 Documenting the new source codes and pushing them to GitHub 10 Testing project on all projects available in CodART benchmarks 20+ (extra bonus)","title":"Grading policy for BSc students"},{"location":"proposals/core_code_smell_development/#grading-policy-for-msc-students","text":"Table 7 shows the grading policy for the MSc students. It may change in the future. Table 7. grading policy for MSc students Activity Score (100) Understanding the paper and presenting it 20 Implementing the paper 30 Evaluating the implementation 30 Documenting the project 20 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) To follow project's future phases, meet our next proposal: Core search-based development.","title":"Grading policy for MSc students"},{"location":"proposals/core_refactoring_to_design_patterns_development/","text":"Core refactoring to design patterns development To be announced.","title":"Core refactoring to patterns development"},{"location":"proposals/core_refactoring_to_design_patterns_development/#core-refactoring-to-design-patterns-development","text":"To be announced.","title":"Core refactoring to design patterns development"},{"location":"proposals/core_refactorings_development/","text":"Core refactoring development The following proposal was initially prepared for the IUST Compiler and Advanced compiler courses in Fall 2020. Students must form groups of up to three persons, and each group must implement several refactoring operations. The exact list of refactoring will be assigned to each group subsequently. The refactoring operations in Table 1 may update during the semester. As an example of refactoring automation, we have implemented the EncapsulateField refactoring, illustrated in Figure 1. A na\u00efve implementation is available on the project official Github page at https://m-zakeri.github.io/CodART . In addition, 26 refactoring operations in Table 1 have been implemented by MultiRefactor [7] based on RECODER , three of them have been implemented by JDeodrant [8], and other operations have been automated in [3], [6]. RECODER extracts a model of the code that can be used to analyze and modify the code before the changes are applied and written to file. The tool takes Java source code as input and will output the modified source code to a specified folder. The input must be fully compilable and must be accompanied by any necessary library files as compressed jar files. Grading policy for BSc students Table 4 shows the grading policy for the BSc students. It may change in the future. Table 4. grading policy for BSc students Activity Score (100) Refactoring operations implementation (moderate level) 50 Evaluation of the tool on the benchmark projects 30 Documentations 20 Search-based refactoring recommendation 30+ (extra bonus) Grading policy for MSc students Table 5 shows the grading policy for the MSc students. It may change in the future. Table 5. grading policy for MSc students Activity Score (100) Refactoring operations implementation (advanced level) 40 Search-based refactoring recommendation 30 Evaluation of the tool on the benchmark projects 20 Documentations 10 Improving the state-of-the-arts papers 30+ (extra bonus) To follow project's phases, refer to our next proposal: Core code smell development.","title":"Core refactoring development"},{"location":"proposals/core_refactorings_development/#core-refactoring-development","text":"The following proposal was initially prepared for the IUST Compiler and Advanced compiler courses in Fall 2020. Students must form groups of up to three persons, and each group must implement several refactoring operations. The exact list of refactoring will be assigned to each group subsequently. The refactoring operations in Table 1 may update during the semester. As an example of refactoring automation, we have implemented the EncapsulateField refactoring, illustrated in Figure 1. A na\u00efve implementation is available on the project official Github page at https://m-zakeri.github.io/CodART . In addition, 26 refactoring operations in Table 1 have been implemented by MultiRefactor [7] based on RECODER , three of them have been implemented by JDeodrant [8], and other operations have been automated in [3], [6]. RECODER extracts a model of the code that can be used to analyze and modify the code before the changes are applied and written to file. The tool takes Java source code as input and will output the modified source code to a specified folder. The input must be fully compilable and must be accompanied by any necessary library files as compressed jar files.","title":"Core refactoring development"},{"location":"proposals/core_refactorings_development/#grading-policy-for-bsc-students","text":"Table 4 shows the grading policy for the BSc students. It may change in the future. Table 4. grading policy for BSc students Activity Score (100) Refactoring operations implementation (moderate level) 50 Evaluation of the tool on the benchmark projects 30 Documentations 20 Search-based refactoring recommendation 30+ (extra bonus)","title":"Grading policy for BSc students"},{"location":"proposals/core_refactorings_development/#grading-policy-for-msc-students","text":"Table 5 shows the grading policy for the MSc students. It may change in the future. Table 5. grading policy for MSc students Activity Score (100) Refactoring operations implementation (advanced level) 40 Search-based refactoring recommendation 30 Evaluation of the tool on the benchmark projects 20 Documentations 10 Improving the state-of-the-arts papers 30+ (extra bonus) To follow project's phases, refer to our next proposal: Core code smell development.","title":"Grading policy for MSc students"},{"location":"proposals/core_search_based_development/","text":"Core search-based development To be announced.","title":"Core search-based development"},{"location":"proposals/core_search_based_development/#core-search-based-development","text":"To be announced.","title":"Core search-based development"},{"location":"refactorings/decrease_field_visibility/","text":"Decrease field visibility Introduction Decrease field visibility refactoring Decrease the visibility of a field from public to protected, protected to package or package to private. Pre and post-conditions Pre-conditions: User must enter the field's name, and the source class's name for the refactoring in order to decrease the target field's visibility. Post-conditions: No specific post-condition DecreaseFieldVisibilityListener ( JavaParserLabeledListener ) To implement \u0650Decrease Field Visibility refactoring based on its actors. Detects the required field and decreases/changes its visibility status. Source code in codart\\refactorings\\decrease_field_visibility.py class DecreaseFieldVisibilityListener ( JavaParserLabeledListener ): \"\"\" To implement \u0650Decrease Field Visibility refactoring based on its actors. Detects the required field and decreases/changes its visibility status. \"\"\" def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseFieldVisibilityListener): An instance of DecreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = False def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): self . in_field = True def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): self . in_field = False def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): if ctx . IDENTIFIER () . getText () == self . source_field and self . in_field : self . detected_field = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_field : # print(ctx.getText()) if ctx . modifier ( 0 ) is not None : if \"@\" in ctx . modifier ( 0 ) . getText (): if ctx . modifier ( 1 ) is not None : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 1 ) . start , text = \"private \" ) else : self . rewriter . replaceSingleToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"private \" + ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . getText () ) else : if ctx . modifier ( 0 ) . getText () == 'public' or ctx . modifier ( 0 ) . getText () == 'protected' : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 0 ) . start , text = \"private \" ) else : self . rewriter . insertBeforeToken ( token = ctx . modifier ( 0 ) . start , text = \"private \" ) else : if ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) is not None : self . rewriter . insertBeforeToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"private \" ) # print(\"private \" + ctx.memberDeclaration().getText()) self . detected_field = False __init__ ( self , source_class , source_field , rewriter ) special Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_field str Name of the field whose visibility status has to be changed required rewriter CommonTokenStream An instance of TokenStreamRewriter required Returns: Type Description object (DecreaseFieldVisibilityListener) An instance of DecreaseFieldVisibilityListener Source code in codart\\refactorings\\decrease_field_visibility.py def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseFieldVisibilityListener): An instance of DecreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ) Source code in codart\\refactorings\\decrease_field_visibility.py def main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) field_ent = db . lookup ( f \" { source_package } . { source_class } . { source_field } \" , \"Variable\" ) if len ( field_ent ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False field_ent = field_ent [ 0 ] if field_ent . simplename () != source_field : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not field_ent.kind().check(\"Public\"): # logger.error(\"Field is not public.\") # db.close() # return False for ref in field_ent . refs ( \"Useby,Setby\" ): ent = ref . ent () if f \" { source_package } . { source_class } \" not in ent . longname (): logger . debug ( f \" { source_package } . { source_class } not in { ent . longname () } \" ) logger . error ( \"Field cannot set to private.\" ) db . close () return False parent = field_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () db . close () parse_and_walk ( file_path = main_file , listener_class = DecreaseFieldVisibilityListener , has_write = True , source_class = source_class , source_field = source_field ) return True","title":"Decrease field visibility"},{"location":"refactorings/decrease_field_visibility/#decrease-field-visibility","text":"","title":"Decrease field visibility"},{"location":"refactorings/decrease_field_visibility/#codart.refactorings.decrease_field_visibility--introduction","text":"Decrease field visibility refactoring Decrease the visibility of a field from public to protected, protected to package or package to private.","title":"Introduction"},{"location":"refactorings/decrease_field_visibility/#codart.refactorings.decrease_field_visibility--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/decrease_field_visibility/#codart.refactorings.decrease_field_visibility--pre-conditions","text":"User must enter the field's name, and the source class's name for the refactoring in order to decrease the target field's visibility.","title":"Pre-conditions:"},{"location":"refactorings/decrease_field_visibility/#codart.refactorings.decrease_field_visibility--post-conditions","text":"No specific post-condition","title":"Post-conditions:"},{"location":"refactorings/decrease_field_visibility/#codart.refactorings.decrease_field_visibility.DecreaseFieldVisibilityListener","text":"To implement \u0650Decrease Field Visibility refactoring based on its actors. Detects the required field and decreases/changes its visibility status. Source code in codart\\refactorings\\decrease_field_visibility.py class DecreaseFieldVisibilityListener ( JavaParserLabeledListener ): \"\"\" To implement \u0650Decrease Field Visibility refactoring based on its actors. Detects the required field and decreases/changes its visibility status. \"\"\" def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseFieldVisibilityListener): An instance of DecreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = False def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): self . in_field = True def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): self . in_field = False def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): if ctx . IDENTIFIER () . getText () == self . source_field and self . in_field : self . detected_field = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_field : # print(ctx.getText()) if ctx . modifier ( 0 ) is not None : if \"@\" in ctx . modifier ( 0 ) . getText (): if ctx . modifier ( 1 ) is not None : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 1 ) . start , text = \"private \" ) else : self . rewriter . replaceSingleToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"private \" + ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . getText () ) else : if ctx . modifier ( 0 ) . getText () == 'public' or ctx . modifier ( 0 ) . getText () == 'protected' : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 0 ) . start , text = \"private \" ) else : self . rewriter . insertBeforeToken ( token = ctx . modifier ( 0 ) . start , text = \"private \" ) else : if ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) is not None : self . rewriter . insertBeforeToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"private \" ) # print(\"private \" + ctx.memberDeclaration().getText()) self . detected_field = False","title":"DecreaseFieldVisibilityListener"},{"location":"refactorings/decrease_field_visibility/#codart.refactorings.decrease_field_visibility.DecreaseFieldVisibilityListener.__init__","text":"Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_field str Name of the field whose visibility status has to be changed required rewriter CommonTokenStream An instance of TokenStreamRewriter required Returns: Type Description object (DecreaseFieldVisibilityListener) An instance of DecreaseFieldVisibilityListener Source code in codart\\refactorings\\decrease_field_visibility.py def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseFieldVisibilityListener): An instance of DecreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter","title":"__init__()"},{"location":"refactorings/decrease_field_visibility/#codart.refactorings.decrease_field_visibility.main","text":"Source code in codart\\refactorings\\decrease_field_visibility.py def main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) field_ent = db . lookup ( f \" { source_package } . { source_class } . { source_field } \" , \"Variable\" ) if len ( field_ent ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False field_ent = field_ent [ 0 ] if field_ent . simplename () != source_field : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not field_ent.kind().check(\"Public\"): # logger.error(\"Field is not public.\") # db.close() # return False for ref in field_ent . refs ( \"Useby,Setby\" ): ent = ref . ent () if f \" { source_package } . { source_class } \" not in ent . longname (): logger . debug ( f \" { source_package } . { source_class } not in { ent . longname () } \" ) logger . error ( \"Field cannot set to private.\" ) db . close () return False parent = field_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () db . close () parse_and_walk ( file_path = main_file , listener_class = DecreaseFieldVisibilityListener , has_write = True , source_class = source_class , source_field = source_field ) return True","title":"main()"},{"location":"refactorings/decrease_method_visibility/","text":"Decrease method visibility Introduction Decrease method visibility refactoring Decrease the visibility of a method from public to protected, protected to package or package to private. DecreaseMethodVisibilityListener ( JavaParserLabeledListener ) To implement \u0650Decrease Method Visibility refactoring based on its actors. Detects the required method and decreases/changes its visibility status. Source code in codart\\refactorings\\decrease_method_visibility.py class DecreaseMethodVisibilityListener ( JavaParserLabeledListener ): \"\"\" To implement \u0650Decrease Method Visibility refactoring based on its actors. Detects the required method and decreases/changes its visibility status. \"\"\" def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseMethodVisibilityListener): An instance of DecreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_method : self . detected_method = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_method : if ctx . modifier ( 0 ) is not None : if \"@\" in ctx . modifier ( 0 ) . getText (): if ctx . modifier ( 1 ) is not None : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 1 ) . start , text = \"private \" ) else : self . rewriter . replaceSingleToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"private \" + ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . getText () ) else : if ctx . modifier ( 0 ) . getText () == 'public' or ctx . modifier ( 0 ) . getText () == 'protected' : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 0 ) . start , text = \"private \" ) else : self . rewriter . insertBeforeToken ( token = ctx . modifier ( 0 ) . start , text = \"private \" ) else : if ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) is not None : self . rewriter . insertBeforeToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"private \" ) self . detected_method = False __init__ ( self , source_class , source_method , rewriter ) special Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_method str Name of the field whose visibility status has to be changed required rewriter CommonTokenStream An instance of TokenStreamRewriter required Returns: Type Description object (DecreaseMethodVisibilityListener) An instance of DecreaseMethodVisibilityListener Source code in codart\\refactorings\\decrease_method_visibility.py def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseMethodVisibilityListener): An instance of DecreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ) Source code in codart\\refactorings\\decrease_method_visibility.py def main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) method_ent = db . lookup ( f \" { source_package } . { source_class } . { source_method } \" , \"Method\" ) if len ( method_ent ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False method_ent = method_ent [ 0 ] if method_ent . simplename () != source_method : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not method_ent.kind().check(\"Public\"): # logger.error(\"Method is not public.\") # db.close() # return False for ent in method_ent . ents ( \"CallBy\" ): if f \" { source_package } . { source_class } \" not in ent . longname (): logger . error ( \"Method cannot set to private.\" ) db . close () return False parent = method_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () db . close () parse_and_walk ( file_path = main_file , listener_class = DecreaseMethodVisibilityListener , has_write = True , source_class = source_class , source_method = source_method ) return True","title":"Decrease method visibility"},{"location":"refactorings/decrease_method_visibility/#decrease-method-visibility","text":"","title":"Decrease method visibility"},{"location":"refactorings/decrease_method_visibility/#codart.refactorings.decrease_method_visibility--introduction","text":"Decrease method visibility refactoring Decrease the visibility of a method from public to protected, protected to package or package to private.","title":"Introduction"},{"location":"refactorings/decrease_method_visibility/#codart.refactorings.decrease_method_visibility.DecreaseMethodVisibilityListener","text":"To implement \u0650Decrease Method Visibility refactoring based on its actors. Detects the required method and decreases/changes its visibility status. Source code in codart\\refactorings\\decrease_method_visibility.py class DecreaseMethodVisibilityListener ( JavaParserLabeledListener ): \"\"\" To implement \u0650Decrease Method Visibility refactoring based on its actors. Detects the required method and decreases/changes its visibility status. \"\"\" def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseMethodVisibilityListener): An instance of DecreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_method : self . detected_method = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_method : if ctx . modifier ( 0 ) is not None : if \"@\" in ctx . modifier ( 0 ) . getText (): if ctx . modifier ( 1 ) is not None : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 1 ) . start , text = \"private \" ) else : self . rewriter . replaceSingleToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"private \" + ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . getText () ) else : if ctx . modifier ( 0 ) . getText () == 'public' or ctx . modifier ( 0 ) . getText () == 'protected' : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 0 ) . start , text = \"private \" ) else : self . rewriter . insertBeforeToken ( token = ctx . modifier ( 0 ) . start , text = \"private \" ) else : if ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) is not None : self . rewriter . insertBeforeToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"private \" ) self . detected_method = False","title":"DecreaseMethodVisibilityListener"},{"location":"refactorings/decrease_method_visibility/#codart.refactorings.decrease_method_visibility.DecreaseMethodVisibilityListener.__init__","text":"Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_method str Name of the field whose visibility status has to be changed required rewriter CommonTokenStream An instance of TokenStreamRewriter required Returns: Type Description object (DecreaseMethodVisibilityListener) An instance of DecreaseMethodVisibilityListener Source code in codart\\refactorings\\decrease_method_visibility.py def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (DecreaseMethodVisibilityListener): An instance of DecreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter","title":"__init__()"},{"location":"refactorings/decrease_method_visibility/#codart.refactorings.decrease_method_visibility.main","text":"Source code in codart\\refactorings\\decrease_method_visibility.py def main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) method_ent = db . lookup ( f \" { source_package } . { source_class } . { source_method } \" , \"Method\" ) if len ( method_ent ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False method_ent = method_ent [ 0 ] if method_ent . simplename () != source_method : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not method_ent.kind().check(\"Public\"): # logger.error(\"Method is not public.\") # db.close() # return False for ent in method_ent . ents ( \"CallBy\" ): if f \" { source_package } . { source_class } \" not in ent . longname (): logger . error ( \"Method cannot set to private.\" ) db . close () return False parent = method_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () db . close () parse_and_walk ( file_path = main_file , listener_class = DecreaseMethodVisibilityListener , has_write = True , source_class = source_class , source_method = source_method ) return True","title":"main()"},{"location":"refactorings/encapsulate_field/","text":"Encapsulate field Introduction The module implements encapsulate field refactoring in response to Deficient Encapsulation design smell. References [1] G. Suryanarayana, G. Samarthyam, and T. Sharma, Refactoring for software design smells: managing technical debt, 1st ed. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 2014. EncapsulateFiledRefactoringListener ( JavaParserLabeledListener ) To implement encapsulate field refactoring. Makes a public field private and provide accessors and mutator methods. Source code in codart\\refactorings\\encapsulate_field.py class EncapsulateFiledRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement encapsulate field refactoring. Makes a public field private and provide accessors and mutator methods. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , source_class_name : str = None , field_identifier : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): contains the program tokens package_name (str): The enclosing package of the field source_class_name (str): The enclosing class of the field field_identifier (str): The field name to be encapsulated Returns: object (DecreaseMethodVisibilityListener): An instance of EncapsulateFiledRefactoringListener \"\"\" self . token_stream = common_token_stream if package_name is None : self . package_name = '' else : self . package_name = package_name self . source_class_name = source_class_name self . field_identifier = field_identifier self . getter_exist = False self . setter_exist = False self . in_source_class = False self . in_selected_package = True if self . package_name == '' else False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = \\ TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . package_name == ctx . qualifiedName () . getText (): self . in_selected_package = True else : self . in_selected_package = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class_name : self . in_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . in_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . in_source_class and self . in_selected_package : if ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . getText () == self . field_identifier : if not ctx . parentCtx . parentCtx . modifier ( 0 ): self . token_stream_rewriter . insertBeforeIndex ( index = ctx . typeType () . stop . tokenIndex , text = 'private ' ) elif ctx . parentCtx . parentCtx . modifier ( 0 ) . getText () == 'public' : self . token_stream_rewriter . replaceRange ( from_idx = ctx . parentCtx . parentCtx . modifier ( 0 ) . start . tokenIndex , to_idx = ctx . parentCtx . parentCtx . modifier ( 0 ) . stop . tokenIndex , text = 'private' ) else : return for c in ctx . parentCtx . parentCtx . parentCtx . classBodyDeclaration (): try : print ( 'method name: ' + c . memberDeclaration () . methodDeclaration () . IDENTIFIER () . getText ()) if c . memberDeclaration () . methodDeclaration () . IDENTIFIER () \\ . getText () == 'get' + str . capitalize ( self . field_identifier ): self . getter_exist = True if c . memberDeclaration () . methodDeclaration () . IDENTIFIER () \\ . getText () == 'set' + str . capitalize ( self . field_identifier ): self . setter_exist = True except : logger . error ( \"not method !!!\" ) logger . debug ( \"setter find: \" + str ( self . setter_exist )) logger . debug ( \"getter find: \" + str ( self . getter_exist )) # generate accessor and mutator methods # Accessor body new_code = '' if not self . getter_exist : new_code = ' \\n\\t // new getter method \\n\\t ' new_code += 'public ' + ctx . typeType () . getText () + \\ ' get' + str . capitalize ( self . field_identifier ) new_code += '() { \\n\\t\\t return this.' + self . field_identifier \\ + ';' + ' \\n\\t } \\n ' # Mutator body if not self . setter_exist : new_code += ' \\n\\t // new setter method \\n\\t ' new_code += 'public void set' + str . capitalize ( self . field_identifier ) new_code += '(' + ctx . typeType () . getText () + ' ' \\ + self . field_identifier + ') { \\n\\t\\t ' new_code += 'this.' + self . field_identifier + ' = ' \\ + self . field_identifier + ';' + ' \\n\\t } \\n ' self . token_stream_rewriter . insertAfter ( ctx . stop . tokenIndex , new_code ) hidden = self . token_stream . getHiddenTokensToRight ( ctx . stop . tokenIndex ) # self.token_stream_rewriter.replaceRange(from_idx=hidden[0].tokenIndex, # to_idx=hidden[-1].tokenIndex, # text='\\n\\t/*End of accessor and mutator methods!*/\\n\\n') def exitExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . in_source_class and self . in_selected_package : if ctx . expression ( 0 ) . getText () == self . field_identifier or \\ ctx . expression ( 0 ) . getText () == 'this.' + self . field_identifier : expr_code = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . expression ( 1 ) . start . tokenIndex , stop = ctx . expression ( 1 ) . stop . tokenIndex ) new_code = 'this.set' + str . capitalize ( self . field_identifier ) + '(' + expr_code + ')' self . token_stream_rewriter . replaceRange ( ctx . start . tokenIndex , ctx . stop . tokenIndex , new_code ) def exitExpression0 ( self , ctx : JavaParserLabeled . Expression0Context ): if self . in_source_class and self . in_selected_package : try : if ctx . parentCtx . getChild ( 1 ) . getText () in ( '=' , '+=' , '-=' , '*=' , '/=' , '&=' , '|=' , '^=' , '>>=' , '>>>=' , '<<=' , '%=' ) and \\ ctx . parentCtx . getChild ( 0 ) == ctx : return except : pass if ctx . getText () == self . field_identifier : new_code = 'this.get' + str . capitalize ( self . field_identifier ) + '()' self . token_stream_rewriter . replaceRange ( ctx . start . tokenIndex , ctx . stop . tokenIndex , new_code ) def exitExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): if self . in_source_class and self . in_selected_package : try : if ctx . parentCtx . getChild ( 1 ) . getText () in ( '=' , '+=' , '-=' , '*=' , '/=' , '&=' , '|=' , '^=' , '>>=' , '>>>=' , '<<=' , '%=' ) and \\ ctx . parentCtx . getChild ( 0 ) == ctx : return except : pass if ctx . getText () == 'this.' + self . field_identifier : new_code = 'this.get' + str . capitalize ( self . field_identifier ) + '()' self . token_stream_rewriter . replaceRange ( ctx . start . tokenIndex , ctx . stop . tokenIndex , new_code ) def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): try : hidden = self . token_stream . getHiddenTokensToLeft ( ctx . start . tokenIndex ) self . token_stream_rewriter . replaceRange ( from_idx = hidden [ 0 ] . tokenIndex , to_idx = hidden [ - 1 ] . tokenIndex , text = '/*After refactoring (Refactored version)*/ \\n ' ) except : pass __init__ ( self , common_token_stream = None , package_name = None , source_class_name = None , field_identifier = None ) special Parameters: Name Type Description Default common_token_stream CommonTokenStream contains the program tokens None package_name str The enclosing package of the field None source_class_name str The enclosing class of the field None field_identifier str The field name to be encapsulated None Returns: Type Description object (DecreaseMethodVisibilityListener) An instance of EncapsulateFiledRefactoringListener Source code in codart\\refactorings\\encapsulate_field.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , source_class_name : str = None , field_identifier : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): contains the program tokens package_name (str): The enclosing package of the field source_class_name (str): The enclosing class of the field field_identifier (str): The field name to be encapsulated Returns: object (DecreaseMethodVisibilityListener): An instance of EncapsulateFiledRefactoringListener \"\"\" self . token_stream = common_token_stream if package_name is None : self . package_name = '' else : self . package_name = package_name self . source_class_name = source_class_name self . field_identifier = field_identifier self . getter_exist = False self . setter_exist = False self . in_source_class = False self . in_selected_package = True if self . package_name == '' else False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = \\ TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"Encapsulate field"},{"location":"refactorings/encapsulate_field/#encapsulate-field","text":"","title":"Encapsulate field"},{"location":"refactorings/encapsulate_field/#codart.refactorings.encapsulate_field--introduction","text":"The module implements encapsulate field refactoring in response to Deficient Encapsulation design smell.","title":"Introduction"},{"location":"refactorings/encapsulate_field/#codart.refactorings.encapsulate_field--references","text":"[1] G. Suryanarayana, G. Samarthyam, and T. Sharma, Refactoring for software design smells: managing technical debt, 1st ed. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 2014.","title":"References"},{"location":"refactorings/encapsulate_field/#codart.refactorings.encapsulate_field.EncapsulateFiledRefactoringListener","text":"To implement encapsulate field refactoring. Makes a public field private and provide accessors and mutator methods. Source code in codart\\refactorings\\encapsulate_field.py class EncapsulateFiledRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement encapsulate field refactoring. Makes a public field private and provide accessors and mutator methods. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , source_class_name : str = None , field_identifier : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): contains the program tokens package_name (str): The enclosing package of the field source_class_name (str): The enclosing class of the field field_identifier (str): The field name to be encapsulated Returns: object (DecreaseMethodVisibilityListener): An instance of EncapsulateFiledRefactoringListener \"\"\" self . token_stream = common_token_stream if package_name is None : self . package_name = '' else : self . package_name = package_name self . source_class_name = source_class_name self . field_identifier = field_identifier self . getter_exist = False self . setter_exist = False self . in_source_class = False self . in_selected_package = True if self . package_name == '' else False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = \\ TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . package_name == ctx . qualifiedName () . getText (): self . in_selected_package = True else : self . in_selected_package = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class_name : self . in_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . in_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . in_source_class and self . in_selected_package : if ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . getText () == self . field_identifier : if not ctx . parentCtx . parentCtx . modifier ( 0 ): self . token_stream_rewriter . insertBeforeIndex ( index = ctx . typeType () . stop . tokenIndex , text = 'private ' ) elif ctx . parentCtx . parentCtx . modifier ( 0 ) . getText () == 'public' : self . token_stream_rewriter . replaceRange ( from_idx = ctx . parentCtx . parentCtx . modifier ( 0 ) . start . tokenIndex , to_idx = ctx . parentCtx . parentCtx . modifier ( 0 ) . stop . tokenIndex , text = 'private' ) else : return for c in ctx . parentCtx . parentCtx . parentCtx . classBodyDeclaration (): try : print ( 'method name: ' + c . memberDeclaration () . methodDeclaration () . IDENTIFIER () . getText ()) if c . memberDeclaration () . methodDeclaration () . IDENTIFIER () \\ . getText () == 'get' + str . capitalize ( self . field_identifier ): self . getter_exist = True if c . memberDeclaration () . methodDeclaration () . IDENTIFIER () \\ . getText () == 'set' + str . capitalize ( self . field_identifier ): self . setter_exist = True except : logger . error ( \"not method !!!\" ) logger . debug ( \"setter find: \" + str ( self . setter_exist )) logger . debug ( \"getter find: \" + str ( self . getter_exist )) # generate accessor and mutator methods # Accessor body new_code = '' if not self . getter_exist : new_code = ' \\n\\t // new getter method \\n\\t ' new_code += 'public ' + ctx . typeType () . getText () + \\ ' get' + str . capitalize ( self . field_identifier ) new_code += '() { \\n\\t\\t return this.' + self . field_identifier \\ + ';' + ' \\n\\t } \\n ' # Mutator body if not self . setter_exist : new_code += ' \\n\\t // new setter method \\n\\t ' new_code += 'public void set' + str . capitalize ( self . field_identifier ) new_code += '(' + ctx . typeType () . getText () + ' ' \\ + self . field_identifier + ') { \\n\\t\\t ' new_code += 'this.' + self . field_identifier + ' = ' \\ + self . field_identifier + ';' + ' \\n\\t } \\n ' self . token_stream_rewriter . insertAfter ( ctx . stop . tokenIndex , new_code ) hidden = self . token_stream . getHiddenTokensToRight ( ctx . stop . tokenIndex ) # self.token_stream_rewriter.replaceRange(from_idx=hidden[0].tokenIndex, # to_idx=hidden[-1].tokenIndex, # text='\\n\\t/*End of accessor and mutator methods!*/\\n\\n') def exitExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . in_source_class and self . in_selected_package : if ctx . expression ( 0 ) . getText () == self . field_identifier or \\ ctx . expression ( 0 ) . getText () == 'this.' + self . field_identifier : expr_code = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . expression ( 1 ) . start . tokenIndex , stop = ctx . expression ( 1 ) . stop . tokenIndex ) new_code = 'this.set' + str . capitalize ( self . field_identifier ) + '(' + expr_code + ')' self . token_stream_rewriter . replaceRange ( ctx . start . tokenIndex , ctx . stop . tokenIndex , new_code ) def exitExpression0 ( self , ctx : JavaParserLabeled . Expression0Context ): if self . in_source_class and self . in_selected_package : try : if ctx . parentCtx . getChild ( 1 ) . getText () in ( '=' , '+=' , '-=' , '*=' , '/=' , '&=' , '|=' , '^=' , '>>=' , '>>>=' , '<<=' , '%=' ) and \\ ctx . parentCtx . getChild ( 0 ) == ctx : return except : pass if ctx . getText () == self . field_identifier : new_code = 'this.get' + str . capitalize ( self . field_identifier ) + '()' self . token_stream_rewriter . replaceRange ( ctx . start . tokenIndex , ctx . stop . tokenIndex , new_code ) def exitExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): if self . in_source_class and self . in_selected_package : try : if ctx . parentCtx . getChild ( 1 ) . getText () in ( '=' , '+=' , '-=' , '*=' , '/=' , '&=' , '|=' , '^=' , '>>=' , '>>>=' , '<<=' , '%=' ) and \\ ctx . parentCtx . getChild ( 0 ) == ctx : return except : pass if ctx . getText () == 'this.' + self . field_identifier : new_code = 'this.get' + str . capitalize ( self . field_identifier ) + '()' self . token_stream_rewriter . replaceRange ( ctx . start . tokenIndex , ctx . stop . tokenIndex , new_code ) def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): try : hidden = self . token_stream . getHiddenTokensToLeft ( ctx . start . tokenIndex ) self . token_stream_rewriter . replaceRange ( from_idx = hidden [ 0 ] . tokenIndex , to_idx = hidden [ - 1 ] . tokenIndex , text = '/*After refactoring (Refactored version)*/ \\n ' ) except : pass","title":"EncapsulateFiledRefactoringListener"},{"location":"refactorings/encapsulate_field/#codart.refactorings.encapsulate_field.EncapsulateFiledRefactoringListener.__init__","text":"Parameters: Name Type Description Default common_token_stream CommonTokenStream contains the program tokens None package_name str The enclosing package of the field None source_class_name str The enclosing class of the field None field_identifier str The field name to be encapsulated None Returns: Type Description object (DecreaseMethodVisibilityListener) An instance of EncapsulateFiledRefactoringListener Source code in codart\\refactorings\\encapsulate_field.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , source_class_name : str = None , field_identifier : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): contains the program tokens package_name (str): The enclosing package of the field source_class_name (str): The enclosing class of the field field_identifier (str): The field name to be encapsulated Returns: object (DecreaseMethodVisibilityListener): An instance of EncapsulateFiledRefactoringListener \"\"\" self . token_stream = common_token_stream if package_name is None : self . package_name = '' else : self . package_name = package_name self . source_class_name = source_class_name self . field_identifier = field_identifier self . getter_exist = False self . setter_exist = False self . in_source_class = False self . in_selected_package = True if self . package_name == '' else False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = \\ TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"refactorings/extract_class/","text":"Extract class Introduction The module implements the extract class refactoring to fix God/Large/Blob class code smell. Extract a set of filed and methods from the class to a new class. Pre and Post Conditions Pre Conditions: Post Conditions: Changelog v0.2.1 Fix bugs in getting entity.parent() None DependencyPreConditionListener ( JavaParserLabeledListener ) Source code in codart\\refactorings\\extract_class.py class DependencyPreConditionListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , class_identifier : str = None ): self . enter_class = False self . token_stream = common_token_stream self . class_identifier = class_identifier # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( \"common_token_stream is None\" ) self . field_dict = {} self . method_name = [] # self . method_no = 0 self . connected_components = [] # Groups methods in terms of their dependncies on the class attributes and one another def split_class ( self ): # 1- move the dictionary of fields into a new dictionary of methods operating on fields method_dict = {} for key , value in self . field_dict . items (): for method in value : if not str ( method ) in method_dict : method_dict [ str ( method )] = [ key ] else : method_dict [ str ( method )] . append ( key ) # 2- Group methods in terms of their dependencies on one another method_group = dict () # 3- Group methods in terms of their dependencies on the class attributes # Todo: To be modified for key , value in method_dict . items (): if not str ( value ) in method_group : method_group [ str ( value )] = [ key ] else : method_group [ str ( value )] . append ( key ) # -------------------------------------- # 4- Create graph G = nx . DiGraph () for field , methods in self . field_dict . items (): for method in methods : G . add_node ( method [ 1 ], method_name = method [ 0 ]) G . add_edge ( field , method [ 1 ]) # graph_visualization.draw(g=G) S = [ G . subgraph ( c ) . copy () for c in nx . weakly_connected_components ( G )] for class_ in S : class_fields = [ node for node in class_ . nodes if class_ . in_degree ( node ) == 0 ] class_methods = [ class_ . nodes [ node ][ \"method_name\" ] for node in class_ . nodes if class_ . in_degree ( node ) > 0 ] self . connected_components . append ( class_fields + class_methods ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () != self . class_identifier : return self . enter_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . enter_class = False self . split_class () def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . enter_class : return field_id = ctx . variableDeclarators () . variableDeclarator ( i = 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () self . field_dict [ field_id ] = [] def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . enter_class : return m = [] m_name = ctx . IDENTIFIER () . getText () self . method_no = self . method_no + 1 m . append ( m_name ) m . append ( self . method_no ) self . method_name . append ( m ) def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . enter_class : return def exitExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): try : if not self . enter_class : return if self . method_no == 0 : return current_method = self . method_name [ - 1 ] variable_name = ctx . IDENTIFIER () . getText () if variable_name not in self . field_dict : return if not current_method in self . field_dict [ variable_name ]: self . field_dict [ variable_name ] . append ( current_method ) except : x = 0 ExtractClassRefactoringListener ( JavaParserLabeledListener ) To implement extract class refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one Source code in codart\\refactorings\\extract_class.py class ExtractClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement extract class refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , new_class : str = None , moved_fields = None , moved_methods = None , method_map : dict = None ): \"\"\" \"\"\" if method_map is None : self . method_map = {} else : self . method_map = method_map if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if moved_fields is None : self . moved_fields = [] else : self . moved_fields = moved_fields if common_token_stream is None : raise ValueError ( \"common_token_stream is None\" ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if new_class is None : raise ValueError ( \"new_class is None\" ) else : self . new_class = new_class self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . package_name = \"\" self . parameters = [] self . object_name = self . new_class . replace ( self . new_class , self . new_class [ 0 ] . lower () + self . new_class [ 1 :]) self . modifiers = \"\" self . do_increase_visibility = False temp = [] for method in moved_methods : if self . method_map . get ( method ) is not None and len ( self . method_map . get ( method )) > 0 : temp . append ( self . method_map . get ( method )) self . fields_to_increase_visibility = set () . union ( * temp ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if ctx . qualifiedName () and not self . package_name : self . package_name = ctx . qualifiedName () . getText () self . code += f \"package { self . package_name } ; { self . NEW_LINE } \" def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): i = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . code += f \" \\n { i } \\n \" def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = str ( ctx . children [ 1 ]) if class_identifier == self . source_class : self . is_source_class = True self . code += self . NEW_LINE * 2 self . code += f \"// New class( { self . new_class } ) generated by CodART\" + self . NEW_LINE self . code += f \"class { self . new_class }{ self . NEW_LINE } \" + \"{\" + self . NEW_LINE else : self . is_source_class = False def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_source_class : self . token_stream_rewriter . insertAfterToken ( token = ctx . start , text = \" \\n\\t \" + f \"public { self . new_class } { self . object_name } = new { self . new_class } ();\" , program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME ) def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = str ( ctx . children [ 1 ]) if class_identifier == self . source_class : self . code += \"}\" self . is_source_class = False else : self . is_source_class = True def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): pass def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): if not self . is_source_class : return None field_identifier = ctx . IDENTIFIER () . getText () if field_identifier in self . moved_fields : self . detected_field = field_identifier def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): field_names = ctx . variableDeclarators () . getText () . split ( \",\" ) for field in field_names : if field in self . fields_to_increase_visibility : for modifier in ctx . parentCtx . parentCtx . modifier (): if modifier . getText () == \"private\" : self . token_stream_rewriter . replaceSingleToken ( token = modifier . start , text = \"public \" ) def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None if not self . detected_field : return None field_names = ctx . variableDeclarators () . getText () field_names = field_names . split ( ',' ) grand_parent_ctx = ctx . parentCtx . parentCtx if any ([ self . detected_field in i for i in field_names ]): field_type = ctx . typeType () . getText () if len ( field_names ) == 1 : # Todo: Requires better handling st = f \"public { field_type } { field_names [ 0 ] } ; { self . NEW_LINE } \" if '=new' in st and '()' in st : st = st . replace ( 'new' , 'new ' ) self . code += st else : # Todo: Requires better handling st = f \"public { field_type } { self . detected_field } ; { self . NEW_LINE } \" if '=new' in st and '()' in st : st = st . replace ( 'new' , 'new ' ) self . code += st # delete field from source class for fi in field_names : if self . detected_field in fi : field_names . remove ( fi ) # Todo: Requires better handling if fi == '1))' or fi == ' 1))' : field_names . remove ( fi ) if field_names : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . start . tokenIndex , to_idx = grand_parent_ctx . stop . tokenIndex , text = f \"public { field_type } { ',' . join ( field_names ) } ; \\n \" ) else : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . start . tokenIndex , to_idx = grand_parent_ctx . stop . tokenIndex ) self . detected_field = None def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if method_identifier in self . moved_methods : self . detected_method = method_identifier def enterFormalParameter ( self , ctx : JavaParserLabeled . FormalParameterContext ): if self . detected_method : self . parameters . append ( ctx . variableDeclaratorId () . IDENTIFIER () . getText () ) def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if self . detected_method == method_identifier : start_index = ctx . start . tokenIndex stop_index = ctx . stop . tokenIndex method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . code += self . NEW_LINE + ( \"public \" + method_text + self . NEW_LINE ) # delegate method body in source class if self . method_map . get ( method_identifier ): self . parameters . append ( \"this\" ) self . token_stream_rewriter . replaceRange ( from_idx = ctx . methodBody () . start . tokenIndex , to_idx = stop_index , text = \"{\" + f \" \\n return this. { self . object_name } . { self . detected_method } (\" + \",\" . join ( self . parameters ) + \"); \\n \" + \"}\" ) self . parameters = [] self . detected_method = None def enterExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): identifier = ctx . IDENTIFIER () if identifier is not None : if identifier . getText () in self . moved_fields and self . detected_method not in self . moved_methods : # Found field usage! self . token_stream_rewriter . insertBeforeToken ( token = ctx . stop , text = self . object_name + \".\" , program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME ) __init__ ( self , common_token_stream = None , source_class = None , new_class = None , moved_fields = None , moved_methods = None , method_map = None ) special Source code in codart\\refactorings\\extract_class.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , new_class : str = None , moved_fields = None , moved_methods = None , method_map : dict = None ): \"\"\" \"\"\" if method_map is None : self . method_map = {} else : self . method_map = method_map if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if moved_fields is None : self . moved_fields = [] else : self . moved_fields = moved_fields if common_token_stream is None : raise ValueError ( \"common_token_stream is None\" ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if new_class is None : raise ValueError ( \"new_class is None\" ) else : self . new_class = new_class self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . package_name = \"\" self . parameters = [] self . object_name = self . new_class . replace ( self . new_class , self . new_class [ 0 ] . lower () + self . new_class [ 1 :]) self . modifiers = \"\" self . do_increase_visibility = False temp = [] for method in moved_methods : if self . method_map . get ( method ) is not None and len ( self . method_map . get ( method )) > 0 : temp . append ( self . method_map . get ( method )) self . fields_to_increase_visibility = set () . union ( * temp )","title":"Extract class"},{"location":"refactorings/extract_class/#extract-class","text":"","title":"Extract class"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class--introduction","text":"The module implements the extract class refactoring to fix God/Large/Blob class code smell. Extract a set of filed and methods from the class to a new class.","title":"Introduction"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class--pre-and-post-conditions","text":"","title":"Pre and Post Conditions"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class--pre-conditions","text":"","title":"Pre Conditions:"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class--post-conditions","text":"","title":"Post Conditions:"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class--changelog","text":"","title":"Changelog"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class--v021","text":"Fix bugs in getting entity.parent() None","title":"v0.2.1"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class.DependencyPreConditionListener","text":"Source code in codart\\refactorings\\extract_class.py class DependencyPreConditionListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , class_identifier : str = None ): self . enter_class = False self . token_stream = common_token_stream self . class_identifier = class_identifier # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( \"common_token_stream is None\" ) self . field_dict = {} self . method_name = [] # self . method_no = 0 self . connected_components = [] # Groups methods in terms of their dependncies on the class attributes and one another def split_class ( self ): # 1- move the dictionary of fields into a new dictionary of methods operating on fields method_dict = {} for key , value in self . field_dict . items (): for method in value : if not str ( method ) in method_dict : method_dict [ str ( method )] = [ key ] else : method_dict [ str ( method )] . append ( key ) # 2- Group methods in terms of their dependencies on one another method_group = dict () # 3- Group methods in terms of their dependencies on the class attributes # Todo: To be modified for key , value in method_dict . items (): if not str ( value ) in method_group : method_group [ str ( value )] = [ key ] else : method_group [ str ( value )] . append ( key ) # -------------------------------------- # 4- Create graph G = nx . DiGraph () for field , methods in self . field_dict . items (): for method in methods : G . add_node ( method [ 1 ], method_name = method [ 0 ]) G . add_edge ( field , method [ 1 ]) # graph_visualization.draw(g=G) S = [ G . subgraph ( c ) . copy () for c in nx . weakly_connected_components ( G )] for class_ in S : class_fields = [ node for node in class_ . nodes if class_ . in_degree ( node ) == 0 ] class_methods = [ class_ . nodes [ node ][ \"method_name\" ] for node in class_ . nodes if class_ . in_degree ( node ) > 0 ] self . connected_components . append ( class_fields + class_methods ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () != self . class_identifier : return self . enter_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . enter_class = False self . split_class () def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . enter_class : return field_id = ctx . variableDeclarators () . variableDeclarator ( i = 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () self . field_dict [ field_id ] = [] def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . enter_class : return m = [] m_name = ctx . IDENTIFIER () . getText () self . method_no = self . method_no + 1 m . append ( m_name ) m . append ( self . method_no ) self . method_name . append ( m ) def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . enter_class : return def exitExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): try : if not self . enter_class : return if self . method_no == 0 : return current_method = self . method_name [ - 1 ] variable_name = ctx . IDENTIFIER () . getText () if variable_name not in self . field_dict : return if not current_method in self . field_dict [ variable_name ]: self . field_dict [ variable_name ] . append ( current_method ) except : x = 0","title":"DependencyPreConditionListener"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class.ExtractClassRefactoringListener","text":"To implement extract class refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one Source code in codart\\refactorings\\extract_class.py class ExtractClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement extract class refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , new_class : str = None , moved_fields = None , moved_methods = None , method_map : dict = None ): \"\"\" \"\"\" if method_map is None : self . method_map = {} else : self . method_map = method_map if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if moved_fields is None : self . moved_fields = [] else : self . moved_fields = moved_fields if common_token_stream is None : raise ValueError ( \"common_token_stream is None\" ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if new_class is None : raise ValueError ( \"new_class is None\" ) else : self . new_class = new_class self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . package_name = \"\" self . parameters = [] self . object_name = self . new_class . replace ( self . new_class , self . new_class [ 0 ] . lower () + self . new_class [ 1 :]) self . modifiers = \"\" self . do_increase_visibility = False temp = [] for method in moved_methods : if self . method_map . get ( method ) is not None and len ( self . method_map . get ( method )) > 0 : temp . append ( self . method_map . get ( method )) self . fields_to_increase_visibility = set () . union ( * temp ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if ctx . qualifiedName () and not self . package_name : self . package_name = ctx . qualifiedName () . getText () self . code += f \"package { self . package_name } ; { self . NEW_LINE } \" def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): i = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . code += f \" \\n { i } \\n \" def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = str ( ctx . children [ 1 ]) if class_identifier == self . source_class : self . is_source_class = True self . code += self . NEW_LINE * 2 self . code += f \"// New class( { self . new_class } ) generated by CodART\" + self . NEW_LINE self . code += f \"class { self . new_class }{ self . NEW_LINE } \" + \"{\" + self . NEW_LINE else : self . is_source_class = False def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_source_class : self . token_stream_rewriter . insertAfterToken ( token = ctx . start , text = \" \\n\\t \" + f \"public { self . new_class } { self . object_name } = new { self . new_class } ();\" , program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME ) def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = str ( ctx . children [ 1 ]) if class_identifier == self . source_class : self . code += \"}\" self . is_source_class = False else : self . is_source_class = True def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): pass def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): if not self . is_source_class : return None field_identifier = ctx . IDENTIFIER () . getText () if field_identifier in self . moved_fields : self . detected_field = field_identifier def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): field_names = ctx . variableDeclarators () . getText () . split ( \",\" ) for field in field_names : if field in self . fields_to_increase_visibility : for modifier in ctx . parentCtx . parentCtx . modifier (): if modifier . getText () == \"private\" : self . token_stream_rewriter . replaceSingleToken ( token = modifier . start , text = \"public \" ) def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None if not self . detected_field : return None field_names = ctx . variableDeclarators () . getText () field_names = field_names . split ( ',' ) grand_parent_ctx = ctx . parentCtx . parentCtx if any ([ self . detected_field in i for i in field_names ]): field_type = ctx . typeType () . getText () if len ( field_names ) == 1 : # Todo: Requires better handling st = f \"public { field_type } { field_names [ 0 ] } ; { self . NEW_LINE } \" if '=new' in st and '()' in st : st = st . replace ( 'new' , 'new ' ) self . code += st else : # Todo: Requires better handling st = f \"public { field_type } { self . detected_field } ; { self . NEW_LINE } \" if '=new' in st and '()' in st : st = st . replace ( 'new' , 'new ' ) self . code += st # delete field from source class for fi in field_names : if self . detected_field in fi : field_names . remove ( fi ) # Todo: Requires better handling if fi == '1))' or fi == ' 1))' : field_names . remove ( fi ) if field_names : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . start . tokenIndex , to_idx = grand_parent_ctx . stop . tokenIndex , text = f \"public { field_type } { ',' . join ( field_names ) } ; \\n \" ) else : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . start . tokenIndex , to_idx = grand_parent_ctx . stop . tokenIndex ) self . detected_field = None def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if method_identifier in self . moved_methods : self . detected_method = method_identifier def enterFormalParameter ( self , ctx : JavaParserLabeled . FormalParameterContext ): if self . detected_method : self . parameters . append ( ctx . variableDeclaratorId () . IDENTIFIER () . getText () ) def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if self . detected_method == method_identifier : start_index = ctx . start . tokenIndex stop_index = ctx . stop . tokenIndex method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . code += self . NEW_LINE + ( \"public \" + method_text + self . NEW_LINE ) # delegate method body in source class if self . method_map . get ( method_identifier ): self . parameters . append ( \"this\" ) self . token_stream_rewriter . replaceRange ( from_idx = ctx . methodBody () . start . tokenIndex , to_idx = stop_index , text = \"{\" + f \" \\n return this. { self . object_name } . { self . detected_method } (\" + \",\" . join ( self . parameters ) + \"); \\n \" + \"}\" ) self . parameters = [] self . detected_method = None def enterExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): identifier = ctx . IDENTIFIER () if identifier is not None : if identifier . getText () in self . moved_fields and self . detected_method not in self . moved_methods : # Found field usage! self . token_stream_rewriter . insertBeforeToken ( token = ctx . stop , text = self . object_name + \".\" , program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME )","title":"ExtractClassRefactoringListener"},{"location":"refactorings/extract_class/#codart.refactorings.extract_class.ExtractClassRefactoringListener.__init__","text":"Source code in codart\\refactorings\\extract_class.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , new_class : str = None , moved_fields = None , moved_methods = None , method_map : dict = None ): \"\"\" \"\"\" if method_map is None : self . method_map = {} else : self . method_map = method_map if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if moved_fields is None : self . moved_fields = [] else : self . moved_fields = moved_fields if common_token_stream is None : raise ValueError ( \"common_token_stream is None\" ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if new_class is None : raise ValueError ( \"new_class is None\" ) else : self . new_class = new_class self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . package_name = \"\" self . parameters = [] self . object_name = self . new_class . replace ( self . new_class , self . new_class [ 0 ] . lower () + self . new_class [ 1 :]) self . modifiers = \"\" self . do_increase_visibility = False temp = [] for method in moved_methods : if self . method_map . get ( method ) is not None and len ( self . method_map . get ( method )) > 0 : temp . append ( self . method_map . get ( method )) self . fields_to_increase_visibility = set () . union ( * temp )","title":"__init__()"},{"location":"refactorings/extract_interface/","text":"Extract interface Introduction When multiple clients are using the same part of a class interface, or part of the interface in two classes is the same; Extract Interface Refactoring moves this identical portion to its own interface. Pre and post-conditions Pre-conditions: precondition is whether the package name, all the class names and method names in those classes exist. The parameter types and return types of each method should be the same across the classes. Post-conditions: No specific Post Condition ExtractInterfaceRefactoring The class that does the process of extract interface refactoring. Splits the identical,reused portion of the interface, creates a new interface, and moves the split portion to the new interface. Source code in codart\\refactorings\\extract_interface.py class ExtractInterfaceRefactoring : \"\"\" The class that does the process of extract interface refactoring. Splits the identical,reused portion of the interface, creates a new interface, and moves the split portion to the new interface. \"\"\" def __init__ ( self , source_filenames : list , package_name : str , class_names : list , method_keys : list , interface_name : str , interface_filename : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done (contains the classes) class_names (str): The classes which are going to implement the new interface method_keys (str): The methods which are going to be included in the interface filename_mapping (str): Mapping the file's name to the correct format so that it can be processed interface_name (str): The new interface name interface_filename (str): The new interface file name Returns: object (ExtractInterfaceRefactoring): An instance of ExtractInterfaceRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_names = class_names self . method_keys = method_keys self . interface_name = interface_name self . interface_filename = interface_filename self . filename_mapping = filename_mapping def do_refactor ( self ): program = symbol_table . get_program ( self . source_filenames , print_status = True ) if self . package_name not in program . packages or any ( class_name not in program . packages [ self . package_name ] . classes for class_name in self . class_names ) or \\ any ( method_key not in program . packages [ self . package_name ] . classes [ class_name ] . methods for class_name in self . class_names for method_key in self . method_keys ): return False method_returntypes = {} method_parameters = {} method_names = [] for method_key in self . method_keys : method_names . append ( method_key [: method_key . find ( '(' )]) rewriter = symbol_table . Rewriter ( program , self . filename_mapping ) for class_name in self . class_names : c : symbol_table . Class = program . packages [ self . package_name ] . classes [ class_name ] # Add implements to the class has_superinterface = False if c . parser_context . IMPLEMENTS () is not None : # old: c.parser_context.superinterfaces() t = symbol_table . TokensInfo ( c . parser_context . typeList ()) # old: c.parser_context.superinterfaces() has_superinterface = True elif c . parser_context . EXTENDS () is not None : # old: c.parser_context.superclass() t = symbol_table . TokensInfo ( c . parser_context . typeType ()) # old: c.parser_context.superclass() elif c . parser_context . typeParameters () is not None : t = symbol_table . TokensInfo ( c . parser_context . typeParameters ()) else : # old: TokensInfo(c.parser_context.identifier()) t = symbol_table . TokensInfo ( c . parser_context ) t . stop = c . parser_context . IDENTIFIER () . getSymbol () . tokenIndex rewriter . insert_after ( t , ( \", \" if has_superinterface else \" implements \" ) + self . interface_name ) for method_key in self . method_keys : m : symbol_table . Method = c . methods [ method_key ] # Check if the return types / parameter types are the same # Or add to dictionary if method_key in method_returntypes : if method_returntypes [ method_key ] != m . returntype : return False if len ( method_parameters [ method_key ]) != len ( m . parameters ): return False for i in range ( len ( m . parameters )): if method_parameters [ method_key ][ i ][ 0 ] != m . parameters [ i ][ 0 ]: return False else : method_returntypes [ method_key ] = m . returntype method_parameters [ method_key ] = m . parameters # Manage method modifiers if len ( m . modifiers_parser_contexts ) > 0 : t = symbol_table . TokensInfo ( m . modifiers_parser_contexts [ 0 ]) else : t = m . get_tokens_info () rewriter . insert_before_start ( t , # old: m.get_tokens_info() # without requiring t ( \"\" if \"@Override\" in m . modifiers else \"@Override \\n \" ) + ( \"\" if \"public\" in m . modifiers else \"public \" ) ) for i in range ( len ( m . modifiers )): mm = m . modifiers [ i ] if mm == \"private\" or mm == \"protected\" : t = symbol_table . TokensInfo ( m . modifiers_parser_contexts [ i ]) # old: m.parser_context.methodModifier(i) rewriter . replace ( t , \"\" ) # Change variable types to the interface if only interface methods are used. for package_name in program . packages : p : symbol_table . Package = program . packages [ package_name ] for class_name in p . classes : c : symbol_table . Class = p . classes [ class_name ] fields_of_interest = {} for fn in c . fields : f : symbol_table . Field = c . fields [ fn ] d = False for cn in self . class_names : if ( f . datatype == cn and f . file_info . has_imported_class ( package_name , cn )) \\ or ( package_name is not None and f . datatype == package_name + '.' + cn ): d = True break if d and \"private\" in f . modifiers : fields_of_interest [ f . name ] = f for method_key in c . methods : m : symbol_table . Method = c . methods [ method_key ] vars_of_interest = {} for item in m . body_local_vars_and_expr_names : if isinstance ( item , symbol_table . LocalVariable ): for cn in self . class_names : if ( item . datatype == cn and c . file_info . has_imported_class ( package_name , cn )) \\ or ( package_name is not None and item . datatype == package_name + '.' + cn ): vars_of_interest [ item . identifier ] = item break if isinstance ( item , symbol_table . MethodInvocation ): if len ( item . dot_separated_identifiers ) == 2 or \\ ( len ( item . dot_separated_identifiers ) == 3 and item . dot_separated_identifiers [ 0 ] == \"this\" ): if item . dot_separated_identifiers [ - 2 ] in vars_of_interest : if item . dot_separated_identifiers [ - 1 ] not in method_names : vars_of_interest . pop ( item . dot_separated_identifiers [ - 2 ]) elif item . dot_separated_identifiers [ - 2 ] in fields_of_interest \\ and item . dot_separated_identifiers [ - 1 ] not in method_names : fields_of_interest . pop ( item . dot_separated_identifiers [ - 2 ]) for var_name in vars_of_interest : var = vars_of_interest [ var_name ] if m . file_info . has_imported_package ( package_name ): # old: var.parser_context.unannType() rewriter . replace ( symbol_table . TokensInfo ( var . parser_context . typeType ()), self . interface_name ) else : if package_name is None : break # old: var.parser_context.unannType() rewriter . replace ( symbol_table . TokensInfo ( var . parser_context . typeType ()), package_name + '.' + self . interface_name ) for field_name in fields_of_interest : f = fields_of_interest [ field_name ] if c . file_info . has_imported_package ( package_name ): typename = self . interface_name else : if package_name is None : break typename = package_name + '.' + self . interface_name if len ( f . neighbor_names ) == 0 : rewriter . replace ( symbol_table . TokensInfo ( f . parser_context . typeType ()), typename ) # old: f.parser_context.unannType() else : if not any ( nn in fields_of_interest for nn in f . neighbor_names ): t = symbol_table . TokensInfo ( f . all_variable_declarator_contexts [ f . index_in_variable_declarators ]) if f . index_in_variable_declarators == 0 : t . stop = symbol_table . TokensInfo ( f . all_variable_declarator_contexts [ f . index_in_variable_declarators + 1 ]) . start - 1 else : t . start = symbol_table . TokensInfo ( f . all_variable_declarator_contexts [ f . index_in_variable_declarators - 1 ]) . start + 1 rewriter . replace ( t , \"\" ) rewriter . insert_after ( f . get_tokens_info (), \" \\n private \" + typename + \" \" + f . name + ( \" = \" + f . initializer + \";\" if f . initializer is not None else \";\" ) ) # Create the interface interface_file_content = ( \"package \" + package_name + \"; \\n\\n \" + \"public interface \" + self . interface_name + \" \\n \" + \"{ \\n \" ) for method_key in self . method_keys : method_name = method_key [: method_key . find ( '(' )] interface_file_content += \" \" + method_returntypes [ method_key ] + \" \" + method_name + \"(\" if len ( method_parameters [ method_key ]) > 0 : interface_file_content += method_parameters [ method_key ][ 0 ][ 0 ] + \" \" + method_parameters [ method_key ][ 0 ][ 1 ] for i in range ( 1 , len ( method_parameters [ method_key ])): param = method_parameters [ method_key ][ i ] interface_file_content += \", \" + param [ 0 ] + \" \" + param [ 1 ] interface_file_content += \"); \\n \" interface_file_content += \"} \\n \" if not os . path . exists ( self . interface_filename [: self . interface_filename . rfind ( '/' )]): os . makedirs ( self . interface_filename [: self . interface_filename . rfind ( '/' )]) file = open ( self . interface_filename , \"w+\" , encoding = 'utf8' , errors = 'ignore' ) file . write ( interface_file_content ) file . close () rewriter . apply () return True __init__ ( self , source_filenames , package_name , class_names , method_keys , interface_name , interface_filename , filename_mapping =< function ExtractInterfaceRefactoring .< lambda > at 0x000001616E31D280 > ) special Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the classes) required class_names str The classes which are going to implement the new interface required method_keys str The methods which are going to be included in the interface required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function ExtractInterfaceRefactoring.<lambda> at 0x000001616E31D280> interface_name str The new interface name required interface_filename str The new interface file name required Returns: Type Description object (ExtractInterfaceRefactoring) An instance of ExtractInterfaceRefactoring class Source code in codart\\refactorings\\extract_interface.py def __init__ ( self , source_filenames : list , package_name : str , class_names : list , method_keys : list , interface_name : str , interface_filename : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done (contains the classes) class_names (str): The classes which are going to implement the new interface method_keys (str): The methods which are going to be included in the interface filename_mapping (str): Mapping the file's name to the correct format so that it can be processed interface_name (str): The new interface name interface_filename (str): The new interface file name Returns: object (ExtractInterfaceRefactoring): An instance of ExtractInterfaceRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_names = class_names self . method_keys = method_keys self . interface_name = interface_name self . interface_filename = interface_filename self . filename_mapping = filename_mapping main ( source_filenames , package_name , class_names , method_keys , interface_name , interface_filename , ** kwargs ) The main API for extract interface refactoring Source code in codart\\refactorings\\extract_interface.py def main ( source_filenames , package_name , class_names , method_keys , interface_name , interface_filename , ** kwargs ): \"\"\" The main API for extract interface refactoring \"\"\" extract_interface_object = ExtractInterfaceRefactoring ( source_filenames = source_filenames , package_name = package_name , class_names = class_names , method_keys = method_keys , interface_name = interface_name , interface_filename = interface_filename , ) res = extract_interface_object . do_refactor () if not res : config . logger . error ( \"Cannot perform extract interface refactoring.\" ) return res","title":"Extract interface"},{"location":"refactorings/extract_interface/#extract-interface","text":"","title":"Extract interface"},{"location":"refactorings/extract_interface/#codart.refactorings.extract_interface--introduction","text":"When multiple clients are using the same part of a class interface, or part of the interface in two classes is the same; Extract Interface Refactoring moves this identical portion to its own interface.","title":"Introduction"},{"location":"refactorings/extract_interface/#codart.refactorings.extract_interface--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/extract_interface/#codart.refactorings.extract_interface--pre-conditions","text":"precondition is whether the package name, all the class names and method names in those classes exist. The parameter types and return types of each method should be the same across the classes.","title":"Pre-conditions:"},{"location":"refactorings/extract_interface/#codart.refactorings.extract_interface--post-conditions","text":"No specific Post Condition","title":"Post-conditions:"},{"location":"refactorings/extract_interface/#codart.refactorings.extract_interface.ExtractInterfaceRefactoring","text":"The class that does the process of extract interface refactoring. Splits the identical,reused portion of the interface, creates a new interface, and moves the split portion to the new interface. Source code in codart\\refactorings\\extract_interface.py class ExtractInterfaceRefactoring : \"\"\" The class that does the process of extract interface refactoring. Splits the identical,reused portion of the interface, creates a new interface, and moves the split portion to the new interface. \"\"\" def __init__ ( self , source_filenames : list , package_name : str , class_names : list , method_keys : list , interface_name : str , interface_filename : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done (contains the classes) class_names (str): The classes which are going to implement the new interface method_keys (str): The methods which are going to be included in the interface filename_mapping (str): Mapping the file's name to the correct format so that it can be processed interface_name (str): The new interface name interface_filename (str): The new interface file name Returns: object (ExtractInterfaceRefactoring): An instance of ExtractInterfaceRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_names = class_names self . method_keys = method_keys self . interface_name = interface_name self . interface_filename = interface_filename self . filename_mapping = filename_mapping def do_refactor ( self ): program = symbol_table . get_program ( self . source_filenames , print_status = True ) if self . package_name not in program . packages or any ( class_name not in program . packages [ self . package_name ] . classes for class_name in self . class_names ) or \\ any ( method_key not in program . packages [ self . package_name ] . classes [ class_name ] . methods for class_name in self . class_names for method_key in self . method_keys ): return False method_returntypes = {} method_parameters = {} method_names = [] for method_key in self . method_keys : method_names . append ( method_key [: method_key . find ( '(' )]) rewriter = symbol_table . Rewriter ( program , self . filename_mapping ) for class_name in self . class_names : c : symbol_table . Class = program . packages [ self . package_name ] . classes [ class_name ] # Add implements to the class has_superinterface = False if c . parser_context . IMPLEMENTS () is not None : # old: c.parser_context.superinterfaces() t = symbol_table . TokensInfo ( c . parser_context . typeList ()) # old: c.parser_context.superinterfaces() has_superinterface = True elif c . parser_context . EXTENDS () is not None : # old: c.parser_context.superclass() t = symbol_table . TokensInfo ( c . parser_context . typeType ()) # old: c.parser_context.superclass() elif c . parser_context . typeParameters () is not None : t = symbol_table . TokensInfo ( c . parser_context . typeParameters ()) else : # old: TokensInfo(c.parser_context.identifier()) t = symbol_table . TokensInfo ( c . parser_context ) t . stop = c . parser_context . IDENTIFIER () . getSymbol () . tokenIndex rewriter . insert_after ( t , ( \", \" if has_superinterface else \" implements \" ) + self . interface_name ) for method_key in self . method_keys : m : symbol_table . Method = c . methods [ method_key ] # Check if the return types / parameter types are the same # Or add to dictionary if method_key in method_returntypes : if method_returntypes [ method_key ] != m . returntype : return False if len ( method_parameters [ method_key ]) != len ( m . parameters ): return False for i in range ( len ( m . parameters )): if method_parameters [ method_key ][ i ][ 0 ] != m . parameters [ i ][ 0 ]: return False else : method_returntypes [ method_key ] = m . returntype method_parameters [ method_key ] = m . parameters # Manage method modifiers if len ( m . modifiers_parser_contexts ) > 0 : t = symbol_table . TokensInfo ( m . modifiers_parser_contexts [ 0 ]) else : t = m . get_tokens_info () rewriter . insert_before_start ( t , # old: m.get_tokens_info() # without requiring t ( \"\" if \"@Override\" in m . modifiers else \"@Override \\n \" ) + ( \"\" if \"public\" in m . modifiers else \"public \" ) ) for i in range ( len ( m . modifiers )): mm = m . modifiers [ i ] if mm == \"private\" or mm == \"protected\" : t = symbol_table . TokensInfo ( m . modifiers_parser_contexts [ i ]) # old: m.parser_context.methodModifier(i) rewriter . replace ( t , \"\" ) # Change variable types to the interface if only interface methods are used. for package_name in program . packages : p : symbol_table . Package = program . packages [ package_name ] for class_name in p . classes : c : symbol_table . Class = p . classes [ class_name ] fields_of_interest = {} for fn in c . fields : f : symbol_table . Field = c . fields [ fn ] d = False for cn in self . class_names : if ( f . datatype == cn and f . file_info . has_imported_class ( package_name , cn )) \\ or ( package_name is not None and f . datatype == package_name + '.' + cn ): d = True break if d and \"private\" in f . modifiers : fields_of_interest [ f . name ] = f for method_key in c . methods : m : symbol_table . Method = c . methods [ method_key ] vars_of_interest = {} for item in m . body_local_vars_and_expr_names : if isinstance ( item , symbol_table . LocalVariable ): for cn in self . class_names : if ( item . datatype == cn and c . file_info . has_imported_class ( package_name , cn )) \\ or ( package_name is not None and item . datatype == package_name + '.' + cn ): vars_of_interest [ item . identifier ] = item break if isinstance ( item , symbol_table . MethodInvocation ): if len ( item . dot_separated_identifiers ) == 2 or \\ ( len ( item . dot_separated_identifiers ) == 3 and item . dot_separated_identifiers [ 0 ] == \"this\" ): if item . dot_separated_identifiers [ - 2 ] in vars_of_interest : if item . dot_separated_identifiers [ - 1 ] not in method_names : vars_of_interest . pop ( item . dot_separated_identifiers [ - 2 ]) elif item . dot_separated_identifiers [ - 2 ] in fields_of_interest \\ and item . dot_separated_identifiers [ - 1 ] not in method_names : fields_of_interest . pop ( item . dot_separated_identifiers [ - 2 ]) for var_name in vars_of_interest : var = vars_of_interest [ var_name ] if m . file_info . has_imported_package ( package_name ): # old: var.parser_context.unannType() rewriter . replace ( symbol_table . TokensInfo ( var . parser_context . typeType ()), self . interface_name ) else : if package_name is None : break # old: var.parser_context.unannType() rewriter . replace ( symbol_table . TokensInfo ( var . parser_context . typeType ()), package_name + '.' + self . interface_name ) for field_name in fields_of_interest : f = fields_of_interest [ field_name ] if c . file_info . has_imported_package ( package_name ): typename = self . interface_name else : if package_name is None : break typename = package_name + '.' + self . interface_name if len ( f . neighbor_names ) == 0 : rewriter . replace ( symbol_table . TokensInfo ( f . parser_context . typeType ()), typename ) # old: f.parser_context.unannType() else : if not any ( nn in fields_of_interest for nn in f . neighbor_names ): t = symbol_table . TokensInfo ( f . all_variable_declarator_contexts [ f . index_in_variable_declarators ]) if f . index_in_variable_declarators == 0 : t . stop = symbol_table . TokensInfo ( f . all_variable_declarator_contexts [ f . index_in_variable_declarators + 1 ]) . start - 1 else : t . start = symbol_table . TokensInfo ( f . all_variable_declarator_contexts [ f . index_in_variable_declarators - 1 ]) . start + 1 rewriter . replace ( t , \"\" ) rewriter . insert_after ( f . get_tokens_info (), \" \\n private \" + typename + \" \" + f . name + ( \" = \" + f . initializer + \";\" if f . initializer is not None else \";\" ) ) # Create the interface interface_file_content = ( \"package \" + package_name + \"; \\n\\n \" + \"public interface \" + self . interface_name + \" \\n \" + \"{ \\n \" ) for method_key in self . method_keys : method_name = method_key [: method_key . find ( '(' )] interface_file_content += \" \" + method_returntypes [ method_key ] + \" \" + method_name + \"(\" if len ( method_parameters [ method_key ]) > 0 : interface_file_content += method_parameters [ method_key ][ 0 ][ 0 ] + \" \" + method_parameters [ method_key ][ 0 ][ 1 ] for i in range ( 1 , len ( method_parameters [ method_key ])): param = method_parameters [ method_key ][ i ] interface_file_content += \", \" + param [ 0 ] + \" \" + param [ 1 ] interface_file_content += \"); \\n \" interface_file_content += \"} \\n \" if not os . path . exists ( self . interface_filename [: self . interface_filename . rfind ( '/' )]): os . makedirs ( self . interface_filename [: self . interface_filename . rfind ( '/' )]) file = open ( self . interface_filename , \"w+\" , encoding = 'utf8' , errors = 'ignore' ) file . write ( interface_file_content ) file . close () rewriter . apply () return True","title":"ExtractInterfaceRefactoring"},{"location":"refactorings/extract_interface/#codart.refactorings.extract_interface.ExtractInterfaceRefactoring.__init__","text":"Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the classes) required class_names str The classes which are going to implement the new interface required method_keys str The methods which are going to be included in the interface required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function ExtractInterfaceRefactoring.<lambda> at 0x000001616E31D280> interface_name str The new interface name required interface_filename str The new interface file name required Returns: Type Description object (ExtractInterfaceRefactoring) An instance of ExtractInterfaceRefactoring class Source code in codart\\refactorings\\extract_interface.py def __init__ ( self , source_filenames : list , package_name : str , class_names : list , method_keys : list , interface_name : str , interface_filename : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done (contains the classes) class_names (str): The classes which are going to implement the new interface method_keys (str): The methods which are going to be included in the interface filename_mapping (str): Mapping the file's name to the correct format so that it can be processed interface_name (str): The new interface name interface_filename (str): The new interface file name Returns: object (ExtractInterfaceRefactoring): An instance of ExtractInterfaceRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_names = class_names self . method_keys = method_keys self . interface_name = interface_name self . interface_filename = interface_filename self . filename_mapping = filename_mapping","title":"__init__()"},{"location":"refactorings/extract_interface/#codart.refactorings.extract_interface.main","text":"The main API for extract interface refactoring Source code in codart\\refactorings\\extract_interface.py def main ( source_filenames , package_name , class_names , method_keys , interface_name , interface_filename , ** kwargs ): \"\"\" The main API for extract interface refactoring \"\"\" extract_interface_object = ExtractInterfaceRefactoring ( source_filenames = source_filenames , package_name = package_name , class_names = class_names , method_keys = method_keys , interface_name = interface_name , interface_filename = interface_filename , ) res = extract_interface_object . do_refactor () if not res : config . logger . error ( \"Cannot perform extract interface refactoring.\" ) return res","title":"main()"},{"location":"refactorings/extract_interface2/","text":"Extract interface 2 Introduction The module implements a light version of extract interface refactoring described in extract_interface.py Pre and post-conditions Pre-conditions: The interface should not be already exist. precondition is whether the package name, all the class names and method names in those classes exist. The parameter types and return types of each method should be the same across the classes. Post-conditions: No specific post-condition main ( class_path ) Parameters: Name Type Description Default class_path str The java file path containing the public class required Source code in codart\\refactorings\\extract_interface2.py def main ( class_path ): \"\"\" Args: class_path (str): The java file path containing the public class \"\"\" # Precondition 1: The interface should not be already exist. interface_path = os . path . join ( os . path . dirname ( class_path ), f 'I { os . path . splitext ( os . path . basename ( class_path ))[ 0 ] } .java' ) if os . path . exists ( interface_path ): return False stream = FileStream ( class_path , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = InterfaceInfoListener () walker = ParseTreeWalker () walker . walk ( listener = listener , t = tree ) interface_info_ = listener . get_interface_info () interface_info_ [ 'name' ] = 'I' + interface_info_ [ 'name' ] interface_info_ [ 'path' ] = os . path . dirname ( class_path ) ic = InterfaceCreator ( interface_info_ , class_path ) ic . add_implement_statement_to_class () ic . save () return True","title":"Extract interface 2"},{"location":"refactorings/extract_interface2/#extract-interface-2","text":"","title":"Extract interface 2"},{"location":"refactorings/extract_interface2/#codart.refactorings.extract_interface2--introduction","text":"The module implements a light version of extract interface refactoring described in extract_interface.py","title":"Introduction"},{"location":"refactorings/extract_interface2/#codart.refactorings.extract_interface2--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/extract_interface2/#codart.refactorings.extract_interface2--pre-conditions","text":"The interface should not be already exist. precondition is whether the package name, all the class names and method names in those classes exist. The parameter types and return types of each method should be the same across the classes.","title":"Pre-conditions:"},{"location":"refactorings/extract_interface2/#codart.refactorings.extract_interface2--post-conditions","text":"No specific post-condition","title":"Post-conditions:"},{"location":"refactorings/extract_interface2/#codart.refactorings.extract_interface2.main","text":"Parameters: Name Type Description Default class_path str The java file path containing the public class required Source code in codart\\refactorings\\extract_interface2.py def main ( class_path ): \"\"\" Args: class_path (str): The java file path containing the public class \"\"\" # Precondition 1: The interface should not be already exist. interface_path = os . path . join ( os . path . dirname ( class_path ), f 'I { os . path . splitext ( os . path . basename ( class_path ))[ 0 ] } .java' ) if os . path . exists ( interface_path ): return False stream = FileStream ( class_path , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = InterfaceInfoListener () walker = ParseTreeWalker () walker . walk ( listener = listener , t = tree ) interface_info_ = listener . get_interface_info () interface_info_ [ 'name' ] = 'I' + interface_info_ [ 'name' ] interface_info_ [ 'path' ] = os . path . dirname ( class_path ) ic = InterfaceCreator ( interface_info_ , class_path ) ic . add_implement_statement_to_class () ic . save () return True","title":"main()"},{"location":"refactorings/extract_method/","text":"Extract method Introduction An Extraction method refactoring class for using compiler listeners Description about the code: - statements are each line of code showing an act for example a = 5; is a statement. - exact each method of each class. Pre and post-conditions Pre-conditions: No specific pre-condition Post-conditions: No specific Post-condition Conf object help Lines are calculated from beginning the beginning of file starting from 1 . limitations Extracted lines must be a part of a method or a class constructor any other format simply would not work. (though we don't know java even supports any other format) ExtractMethodRefactoring ( JavaParserLabeledListener ) Extract method factoring class extending javaParserLabeledListener Source code in codart\\refactorings\\extract_method.py class ExtractMethodRefactoring ( JavaParserLabeledListener ): \"\"\" Extract method factoring class extending javaParserLabeledListener \"\"\" def __init__ ( self , lines : list ): \"\"\" Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: object (ExtractMethodRefactoring): An instance of ExtractMethodRefactoring \"\"\" # checks Target method and lines to be valid if lines is None or len ( lines ) == 0 : raise Exception ( 'target lines are not specified.' ) # setting variables self . lines = np . array ( lines ) self . lines . reshape (( len ( lines ), 1 )) self . last_line = self . lines . max () self . first_line = self . lines . min () self . post_variables = {} self . pre_variables = {} self . mid_variables = {} self . is_in_target_method = False self . is_target_method_static = False self . is_result_valid = False self . exception_thrown_in_target_method = None self . assigning_value_pre = False self . assigning_value_mid = False self . assigning_value_post = False self . method_stop_line = 0 self . return_variable = None self . return_variable_type = None self . methods_name = [] ###################################### # Overriding required methods to satisfy our extraction requirements ###################################### def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): self . methods_name . append ( ctx . IDENTIFIER () . getText ()) # checks if this is the method containing target lines if ctx . start . line <= self . first_line and ctx . stop . line >= self . last_line : print ( \"Found method containing target lines.\" ) self . is_in_target_method = True self . is_result_valid = True # checks if method is static for modifier in ctx . parentCtx . parentCtx . modifier (): if modifier . getText () == 'static' : self . is_target_method_static = True print ( \"Target Method is static.\" ) break # checks if method throws any exception if ctx . qualifiedNameList (): self . exception_thrown_in_target_method = ctx . qualifiedNameList () . getText () print ( \"Target Method throws exception.\" ) # TODO : check extracted lines for exception occurrence instead , # as they may not throw exception even though their parent method does # save method's last line number self . method_stop_line = ctx . stop . line def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): self . is_in_target_method = False def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): # checks if this Constructor contains target lines if ctx . start . line <= self . first_line and ctx . stop . line >= self . last_line : print ( \"Found Constructor containing target lines.\" ) self . is_in_target_method = True self . is_result_valid = True # checks if Constructor is static for modifier in ctx . parentCtx . parentCtx . modifier (): if modifier . getText () == 'static' : self . is_target_method_static = True print ( \"Target Method is static.\" ) break # checks if Constructor throws any exception if ctx . qualifiedNameList (): self . exception_thrown_in_target_method = ctx . qualifiedNameList () . getText () print ( \"Target Method throws exception.\" ) # TODO : check extracted lines for exception occurrence instead , # as they may not throw exception even though their parent method does # save method's last line number self . method_stop_line = ctx . stop . line def exitConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): self . is_in_target_method = False def enterLocalVariableDeclaration ( self , ctx : JavaParserLabeled . LocalVariableDeclarationContext ): # checks if we are in target method if self . is_in_target_method : # checks if this statement is not in extracting lines if not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( set ( self . lines )): # checks if this statement is before extracting lines if ctx . start . line < self . last_line : # adding all created variables for var in ctx . variableDeclarators () . variableDeclarator (): self . pre_variables [ var . variableDeclaratorId () . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : str ( var . getText ()) . __contains__ ( '=' ) } # this statement is after extracting lines else : pass # this statement is inside extracting lines else : # adding all created variables for var in ctx . variableDeclarators () . variableDeclarator (): self . mid_variables [ var . variableDeclaratorId () . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : str ( var . getText ()) . __contains__ ( '=' ) } def enterEnhancedForControl ( self , ctx : JavaParserLabeled . EnhancedForControlContext ): # checks if we are in target method if self . is_in_target_method : # checks if this statement is not in extracting lines if not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( set ( self . lines )): # checks if this statement is before extracting lines if ctx . start . line < self . last_line : # adding created variables var = ctx . variableDeclaratorId () self . pre_variables [ var . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : True } # this statement is after extracting lines else : pass # this statement is inside extracting lines else : # adding created variables var = ctx . variableDeclaratorId () self . mid_variables [ var . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : True } # adding target method parameters to pre_variables def enterFormalParameter ( self , ctx : JavaParserLabeled . FormalParameterContext ): # checks if we are in target method if self . is_in_target_method : # adding all created variables self . pre_variables [ ctx . variableDeclaratorId () . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : True } # detecting writing value to variables def enterExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): # checks if we are in target method if self . is_in_target_method : # checks if this statement is not in extracting lines if not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( set ( self . lines )): # checks if this statement is before extracting lines if ctx . start . line < self . last_line : self . assigning_value_pre = True # this statement is after extracting lines elif ctx . start . line > self . last_line : self . assigning_value_post = True # any other case is useless else : pass # this statement is inside extracting lines else : self . assigning_value_mid = True def enterEveryRule ( self , ctx : ParserRuleContext ): # checks if we are in target method if self . is_in_target_method : # checks if every statements are is either completely inside or outside of extracting lines if set ( range ( ctx . start . line , ctx . stop . line + 1 )) & set ( self . lines ): if not set ( self . lines ) . issubset ( set ( range ( ctx . start . line , ctx . stop . line + 1 ))) and \\ not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( self . lines ): self . is_result_valid = False def enterPrimary4 ( self , ctx : JavaParserLabeled . Primary4Context ): # checks if we are in target method if self . is_in_target_method : # print('entering:',ctx.getText()) # print(self.assigning_value_pre) # print(self.assigning_value_mid) # print(self.assigning_value_post) # writing value to a variable in mid if self . assigning_value_mid : # adding variable action = 'write' if ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression1Context ) and ctx . parentCtx . parentCtx . DOT ()) or \\ ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression2Context ) and ctx . parentCtx . parentCtx . LBRACK ()): # print(\"exiting:\", ctx.getText()) action = 'read' if self . mid_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . mid_variables [ str ( ctx . IDENTIFIER ())][ action ] = True else : self . mid_variables [ str ( ctx . IDENTIFIER ())] = { action : True } self . assigning_value_mid = False # writing value to a variable in pre elif self . assigning_value_pre : # adding variable action = 'write' if ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression1Context ) and ctx . parentCtx . parentCtx . DOT ()) or \\ ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression2Context ) and ctx . parentCtx . parentCtx . LBRACK ()): # print(\"exiting:\", ctx.getText()) action = 'read' if self . pre_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . pre_variables [ str ( ctx . IDENTIFIER ())][ action ] = True else : self . pre_variables [ str ( ctx . IDENTIFIER ())] = { action : True } self . assigning_value_pre = False # writing value to a variable in post elif self . assigning_value_post : # adding variable action = 'write' if ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression1Context ) and ctx . parentCtx . parentCtx . DOT ()) or \\ ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression2Context ) and ctx . parentCtx . parentCtx . LBRACK ()): # print(\"exiting:\", ctx.getText()) action = 'read' if self . post_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . post_variables [ str ( ctx . IDENTIFIER ())][ action ] = True else : self . post_variables [ str ( ctx . IDENTIFIER ())] = { action : True } self . assigning_value_post = False # reading a variable value not in extracting lines elif not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( set ( self . lines )): # checks if this statement is after extracting lines if ctx . start . line > self . last_line : # adding variable to post_variables if self . post_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . post_variables [ str ( ctx . IDENTIFIER ())][ 'read' ] = True else : self . post_variables [ str ( ctx . IDENTIFIER ())] = { 'read' : True } # this statement is before extracting lines else : pass # this statement is inside extracting lines else : if self . mid_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . mid_variables [ str ( ctx . IDENTIFIER ())][ 'read' ] = True else : self . mid_variables [ str ( ctx . IDENTIFIER ())] = { 'read' : True } # helper functions # get method arguments for function call def get_args ( self , include_type : bool ): print ( self . pre_variables ) result = '(' first = True for key in self . mid_variables . keys (): if self . mid_variables [ key ] . keys () . __contains__ ( 'type' ): continue if self . pre_variables . keys () . __contains__ ( key ) and \\ self . pre_variables [ key ] . keys () . __contains__ ( 'write' ) and \\ self . pre_variables [ key ][ 'write' ] and \\ self . pre_variables [ key ] . keys () . __contains__ ( 'type' ): if not first : result += ', ' else : first = False if include_type : result += self . pre_variables [ key ][ 'type' ] + ' ' + key else : result += key result += ')' + ( \"\" if include_type else \";\" ) return result def get_write_variable ( self ): result = None for key in self . post_variables . keys (): if self . mid_variables . __contains__ ( key ) and self . mid_variables [ key ] . __contains__ ( 'type' ) and \\ self . mid_variables [ key ][ 'type' ]: if result is None : self . return_variable = key self . return_variable_type = self . mid_variables [ key ][ 'type' ] result = self . mid_variables [ key ][ 'type' ] + ' ' + key + ' = ' else : print ( 'assignments on :' , self . return_variable , \",\" , key ) self . return_variable = None raise Exception ( 'only one assignment in extracting lines is acceptable!' ) elif self . pre_variables . __contains__ ( key ) and self . pre_variables [ key ] . __contains__ ( 'type' ) and \\ self . pre_variables [ key ][ 'type' ] and self . mid_variables . __contains__ ( key ) and self . mid_variables [ key ] . __contains__ ( 'write' ) and self . mid_variables [ key ][ 'write' ]: if result is None : result = key + ' = ' self . return_variable = key self . return_variable_type = self . pre_variables [ key ][ 'type' ] else : print ( 'assignments on :' , self . return_variable , \",\" , key ) self . return_variable = None raise Exception ( 'only one assignment in extracting lines is acceptable!' ) return '' if result is None else result __init__ ( self , lines ) special Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: Type Description object (ExtractMethodRefactoring) An instance of ExtractMethodRefactoring Source code in codart\\refactorings\\extract_method.py def __init__ ( self , lines : list ): \"\"\" Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: object (ExtractMethodRefactoring): An instance of ExtractMethodRefactoring \"\"\" # checks Target method and lines to be valid if lines is None or len ( lines ) == 0 : raise Exception ( 'target lines are not specified.' ) # setting variables self . lines = np . array ( lines ) self . lines . reshape (( len ( lines ), 1 )) self . last_line = self . lines . max () self . first_line = self . lines . min () self . post_variables = {} self . pre_variables = {} self . mid_variables = {} self . is_in_target_method = False self . is_target_method_static = False self . is_result_valid = False self . exception_thrown_in_target_method = None self . assigning_value_pre = False self . assigning_value_mid = False self . assigning_value_post = False self . method_stop_line = 0 self . return_variable = None self . return_variable_type = None self . methods_name = [] main ( file_path , lines ) The main API for Extract Method refactoring operation Source code in codart\\refactorings\\extract_method.py def main ( file_path , lines : dict ): \"\"\" The main API for Extract Method refactoring operation \"\"\" print ( \"Started Extract Method\" ) _conf = { 'target_file' : file_path , 'output_file' : file_path , 'lines' : lines , 'new_method_name' : 'newMethodByCodArt' , } extract_method ( _conf ) print ( \"Finished Extract Method\" )","title":"Extract method"},{"location":"refactorings/extract_method/#extract-method","text":"","title":"Extract method"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method--introduction","text":"An Extraction method refactoring class for using compiler listeners Description about the code: - statements are each line of code showing an act for example a = 5; is a statement. - exact each method of each class.","title":"Introduction"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method--pre-conditions","text":"No specific pre-condition","title":"Pre-conditions:"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method--post-conditions","text":"No specific Post-condition","title":"Post-conditions:"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method--conf-object-help","text":"Lines are calculated from beginning the beginning of file starting from 1 .","title":"Conf object help"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method--limitations","text":"Extracted lines must be a part of a method or a class constructor any other format simply would not work. (though we don't know java even supports any other format)","title":"limitations"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method.ExtractMethodRefactoring","text":"Extract method factoring class extending javaParserLabeledListener Source code in codart\\refactorings\\extract_method.py class ExtractMethodRefactoring ( JavaParserLabeledListener ): \"\"\" Extract method factoring class extending javaParserLabeledListener \"\"\" def __init__ ( self , lines : list ): \"\"\" Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: object (ExtractMethodRefactoring): An instance of ExtractMethodRefactoring \"\"\" # checks Target method and lines to be valid if lines is None or len ( lines ) == 0 : raise Exception ( 'target lines are not specified.' ) # setting variables self . lines = np . array ( lines ) self . lines . reshape (( len ( lines ), 1 )) self . last_line = self . lines . max () self . first_line = self . lines . min () self . post_variables = {} self . pre_variables = {} self . mid_variables = {} self . is_in_target_method = False self . is_target_method_static = False self . is_result_valid = False self . exception_thrown_in_target_method = None self . assigning_value_pre = False self . assigning_value_mid = False self . assigning_value_post = False self . method_stop_line = 0 self . return_variable = None self . return_variable_type = None self . methods_name = [] ###################################### # Overriding required methods to satisfy our extraction requirements ###################################### def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): self . methods_name . append ( ctx . IDENTIFIER () . getText ()) # checks if this is the method containing target lines if ctx . start . line <= self . first_line and ctx . stop . line >= self . last_line : print ( \"Found method containing target lines.\" ) self . is_in_target_method = True self . is_result_valid = True # checks if method is static for modifier in ctx . parentCtx . parentCtx . modifier (): if modifier . getText () == 'static' : self . is_target_method_static = True print ( \"Target Method is static.\" ) break # checks if method throws any exception if ctx . qualifiedNameList (): self . exception_thrown_in_target_method = ctx . qualifiedNameList () . getText () print ( \"Target Method throws exception.\" ) # TODO : check extracted lines for exception occurrence instead , # as they may not throw exception even though their parent method does # save method's last line number self . method_stop_line = ctx . stop . line def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): self . is_in_target_method = False def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): # checks if this Constructor contains target lines if ctx . start . line <= self . first_line and ctx . stop . line >= self . last_line : print ( \"Found Constructor containing target lines.\" ) self . is_in_target_method = True self . is_result_valid = True # checks if Constructor is static for modifier in ctx . parentCtx . parentCtx . modifier (): if modifier . getText () == 'static' : self . is_target_method_static = True print ( \"Target Method is static.\" ) break # checks if Constructor throws any exception if ctx . qualifiedNameList (): self . exception_thrown_in_target_method = ctx . qualifiedNameList () . getText () print ( \"Target Method throws exception.\" ) # TODO : check extracted lines for exception occurrence instead , # as they may not throw exception even though their parent method does # save method's last line number self . method_stop_line = ctx . stop . line def exitConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): self . is_in_target_method = False def enterLocalVariableDeclaration ( self , ctx : JavaParserLabeled . LocalVariableDeclarationContext ): # checks if we are in target method if self . is_in_target_method : # checks if this statement is not in extracting lines if not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( set ( self . lines )): # checks if this statement is before extracting lines if ctx . start . line < self . last_line : # adding all created variables for var in ctx . variableDeclarators () . variableDeclarator (): self . pre_variables [ var . variableDeclaratorId () . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : str ( var . getText ()) . __contains__ ( '=' ) } # this statement is after extracting lines else : pass # this statement is inside extracting lines else : # adding all created variables for var in ctx . variableDeclarators () . variableDeclarator (): self . mid_variables [ var . variableDeclaratorId () . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : str ( var . getText ()) . __contains__ ( '=' ) } def enterEnhancedForControl ( self , ctx : JavaParserLabeled . EnhancedForControlContext ): # checks if we are in target method if self . is_in_target_method : # checks if this statement is not in extracting lines if not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( set ( self . lines )): # checks if this statement is before extracting lines if ctx . start . line < self . last_line : # adding created variables var = ctx . variableDeclaratorId () self . pre_variables [ var . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : True } # this statement is after extracting lines else : pass # this statement is inside extracting lines else : # adding created variables var = ctx . variableDeclaratorId () self . mid_variables [ var . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : True } # adding target method parameters to pre_variables def enterFormalParameter ( self , ctx : JavaParserLabeled . FormalParameterContext ): # checks if we are in target method if self . is_in_target_method : # adding all created variables self . pre_variables [ ctx . variableDeclaratorId () . getText ()] = \\ { 'type' : ctx . typeType () . getText (), 'write' : True } # detecting writing value to variables def enterExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): # checks if we are in target method if self . is_in_target_method : # checks if this statement is not in extracting lines if not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( set ( self . lines )): # checks if this statement is before extracting lines if ctx . start . line < self . last_line : self . assigning_value_pre = True # this statement is after extracting lines elif ctx . start . line > self . last_line : self . assigning_value_post = True # any other case is useless else : pass # this statement is inside extracting lines else : self . assigning_value_mid = True def enterEveryRule ( self , ctx : ParserRuleContext ): # checks if we are in target method if self . is_in_target_method : # checks if every statements are is either completely inside or outside of extracting lines if set ( range ( ctx . start . line , ctx . stop . line + 1 )) & set ( self . lines ): if not set ( self . lines ) . issubset ( set ( range ( ctx . start . line , ctx . stop . line + 1 ))) and \\ not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( self . lines ): self . is_result_valid = False def enterPrimary4 ( self , ctx : JavaParserLabeled . Primary4Context ): # checks if we are in target method if self . is_in_target_method : # print('entering:',ctx.getText()) # print(self.assigning_value_pre) # print(self.assigning_value_mid) # print(self.assigning_value_post) # writing value to a variable in mid if self . assigning_value_mid : # adding variable action = 'write' if ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression1Context ) and ctx . parentCtx . parentCtx . DOT ()) or \\ ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression2Context ) and ctx . parentCtx . parentCtx . LBRACK ()): # print(\"exiting:\", ctx.getText()) action = 'read' if self . mid_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . mid_variables [ str ( ctx . IDENTIFIER ())][ action ] = True else : self . mid_variables [ str ( ctx . IDENTIFIER ())] = { action : True } self . assigning_value_mid = False # writing value to a variable in pre elif self . assigning_value_pre : # adding variable action = 'write' if ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression1Context ) and ctx . parentCtx . parentCtx . DOT ()) or \\ ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression2Context ) and ctx . parentCtx . parentCtx . LBRACK ()): # print(\"exiting:\", ctx.getText()) action = 'read' if self . pre_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . pre_variables [ str ( ctx . IDENTIFIER ())][ action ] = True else : self . pre_variables [ str ( ctx . IDENTIFIER ())] = { action : True } self . assigning_value_pre = False # writing value to a variable in post elif self . assigning_value_post : # adding variable action = 'write' if ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression1Context ) and ctx . parentCtx . parentCtx . DOT ()) or \\ ( isinstance ( ctx . parentCtx . parentCtx , JavaParserLabeled . Expression2Context ) and ctx . parentCtx . parentCtx . LBRACK ()): # print(\"exiting:\", ctx.getText()) action = 'read' if self . post_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . post_variables [ str ( ctx . IDENTIFIER ())][ action ] = True else : self . post_variables [ str ( ctx . IDENTIFIER ())] = { action : True } self . assigning_value_post = False # reading a variable value not in extracting lines elif not set ( range ( ctx . start . line , ctx . stop . line + 1 )) . issubset ( set ( self . lines )): # checks if this statement is after extracting lines if ctx . start . line > self . last_line : # adding variable to post_variables if self . post_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . post_variables [ str ( ctx . IDENTIFIER ())][ 'read' ] = True else : self . post_variables [ str ( ctx . IDENTIFIER ())] = { 'read' : True } # this statement is before extracting lines else : pass # this statement is inside extracting lines else : if self . mid_variables . keys () . __contains__ ( str ( ctx . IDENTIFIER ())): self . mid_variables [ str ( ctx . IDENTIFIER ())][ 'read' ] = True else : self . mid_variables [ str ( ctx . IDENTIFIER ())] = { 'read' : True } # helper functions # get method arguments for function call def get_args ( self , include_type : bool ): print ( self . pre_variables ) result = '(' first = True for key in self . mid_variables . keys (): if self . mid_variables [ key ] . keys () . __contains__ ( 'type' ): continue if self . pre_variables . keys () . __contains__ ( key ) and \\ self . pre_variables [ key ] . keys () . __contains__ ( 'write' ) and \\ self . pre_variables [ key ][ 'write' ] and \\ self . pre_variables [ key ] . keys () . __contains__ ( 'type' ): if not first : result += ', ' else : first = False if include_type : result += self . pre_variables [ key ][ 'type' ] + ' ' + key else : result += key result += ')' + ( \"\" if include_type else \";\" ) return result def get_write_variable ( self ): result = None for key in self . post_variables . keys (): if self . mid_variables . __contains__ ( key ) and self . mid_variables [ key ] . __contains__ ( 'type' ) and \\ self . mid_variables [ key ][ 'type' ]: if result is None : self . return_variable = key self . return_variable_type = self . mid_variables [ key ][ 'type' ] result = self . mid_variables [ key ][ 'type' ] + ' ' + key + ' = ' else : print ( 'assignments on :' , self . return_variable , \",\" , key ) self . return_variable = None raise Exception ( 'only one assignment in extracting lines is acceptable!' ) elif self . pre_variables . __contains__ ( key ) and self . pre_variables [ key ] . __contains__ ( 'type' ) and \\ self . pre_variables [ key ][ 'type' ] and self . mid_variables . __contains__ ( key ) and self . mid_variables [ key ] . __contains__ ( 'write' ) and self . mid_variables [ key ][ 'write' ]: if result is None : result = key + ' = ' self . return_variable = key self . return_variable_type = self . pre_variables [ key ][ 'type' ] else : print ( 'assignments on :' , self . return_variable , \",\" , key ) self . return_variable = None raise Exception ( 'only one assignment in extracting lines is acceptable!' ) return '' if result is None else result","title":"ExtractMethodRefactoring"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method.ExtractMethodRefactoring.__init__","text":"Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: Type Description object (ExtractMethodRefactoring) An instance of ExtractMethodRefactoring Source code in codart\\refactorings\\extract_method.py def __init__ ( self , lines : list ): \"\"\" Arges: Lines (list<int>): A list of statements line numbers to be extracted form the method body. Returns: object (ExtractMethodRefactoring): An instance of ExtractMethodRefactoring \"\"\" # checks Target method and lines to be valid if lines is None or len ( lines ) == 0 : raise Exception ( 'target lines are not specified.' ) # setting variables self . lines = np . array ( lines ) self . lines . reshape (( len ( lines ), 1 )) self . last_line = self . lines . max () self . first_line = self . lines . min () self . post_variables = {} self . pre_variables = {} self . mid_variables = {} self . is_in_target_method = False self . is_target_method_static = False self . is_result_valid = False self . exception_thrown_in_target_method = None self . assigning_value_pre = False self . assigning_value_mid = False self . assigning_value_post = False self . method_stop_line = 0 self . return_variable = None self . return_variable_type = None self . methods_name = []","title":"__init__()"},{"location":"refactorings/extract_method/#codart.refactorings.extract_method.main","text":"The main API for Extract Method refactoring operation Source code in codart\\refactorings\\extract_method.py def main ( file_path , lines : dict ): \"\"\" The main API for Extract Method refactoring operation \"\"\" print ( \"Started Extract Method\" ) _conf = { 'target_file' : file_path , 'output_file' : file_path , 'lines' : lines , 'new_method_name' : 'newMethodByCodArt' , } extract_method ( _conf ) print ( \"Finished Extract Method\" )","title":"main()"},{"location":"refactorings/extract_subclass/","text":"Extract subclass Introduction Extract subclass refactoring ExtractSubClassRefactoringListener ( JavaParserLabeledListener ) To implement extract subclass refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one Source code in codart\\refactorings\\extract_subclass.py class ExtractSubClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement extract subclass refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , new_class : str = None , moved_fields = None , moved_methods = None , output_path : str = \"\" ): if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if moved_fields is None : self . moved_fields = [] else : self . moved_fields = moved_fields if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if new_class is None : raise ValueError ( \"new_class is None\" ) else : self . new_class = new_class self . output_path = output_path self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . is_in_constructor = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. \"\"\" class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True self . code += self . NEW_LINE * 2 self . code += f \"// New class( { self . new_class } ) generated by CodART\" + self . NEW_LINE self . code += f \"class { self . new_class } extends { self . source_class }{ self . NEW_LINE } \" + \"{\" + self . NEW_LINE self . code += f \"public { self . new_class } ()\" + \"{ }\" + self . NEW_LINE else : self . is_source_class = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It closes the opened curly brackets If it is the source class. \"\"\" if self . is_source_class : self . code += \"}\" self . is_source_class = False def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): \"\"\" It writes self.code in the output path. \"\"\" child_file_name = self . new_class + \".java\" with open ( os . path . join ( self . output_path , child_file_name ), \"w+\" ) as f : f . write ( self . code . replace ( ' \\r\\n ' , ' \\n ' )) def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): \"\"\" It sets the detected field to the field if it is one of the moved fields. \"\"\" if not self . is_source_class : return None field_identifier = ctx . IDENTIFIER () . getText () if field_identifier in self . moved_fields : self . detected_field = field_identifier def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): \"\"\" It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. \"\"\" if not self . is_source_class : return None field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () field_names = list () field_names . append ( field_identifier ) # print(\"field_names=\", field_names) grand_parent_ctx = ctx . parentCtx . parentCtx if self . detected_field in field_names : if not grand_parent_ctx . modifier (): modifier = \"\" else : modifier = grand_parent_ctx . modifier ( 0 ) . getText () field_type = ctx . typeType () . getText () self . code += f \" { self . TAB }{ modifier } { field_type } { self . detected_field } ; { self . NEW_LINE } \" # delete field from source class ==>new start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . parentCtx . parentCtx . stop . tokenIndex self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_field = None def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It sets the detected field to the method if it is one of the moved methods. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if method_identifier in self . moved_methods : self . detected_method = method_identifier def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if self . detected_method == method_identifier : start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . stop . tokenIndex method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . code += ( self . NEW_LINE + self . TAB + method_text + self . NEW_LINE ) # delete method from source class self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_method = None def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_source_class : self . is_in_constructor = True self . fields_in_constructor = [] self . methods_in_constructor = [] self . constructor_body = ctx . block () children = self . constructor_body . children def exitConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_source_class and self . is_in_constructor : move_constructor_flag = False for field in self . fields_in_constructor : if field in self . moved_fields : move_constructor_flag = True for method in self . methods_in_constructor : if method in self . moved_methods : move_constructor_flag = True if move_constructor_flag : if ctx . formalParameters () . formalParameterList (): constructor_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : constructor_parameters = [] constructor_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): constructor_text += modifier . getText () + ' ' constructor_text += self . new_class constructor_text += ' ( ' for parameter in constructor_parameters : constructor_text += parameter . typeType () . getText () + ' ' constructor_text += parameter . variableDeclaratorId () . getText () + ', ' if constructor_parameters : constructor_text = constructor_text [: len ( constructor_text ) - 2 ] constructor_text += ') \\n\\t {' constructor_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ) constructor_text += '} \\n ' self . code += constructor_text start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . parentCtx . parentCtx . stop . tokenIndex self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . is_in_constructor = False def enterExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . is_source_class and self . is_in_constructor : if len ( ctx . children [ 0 ] . children ) == 1 : self . fields_in_constructor . append ( ctx . children [ 0 ] . getText ()) else : self . fields_in_constructor . append ( ctx . children [ 0 ] . children [ - 1 ] . getText ()) def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if self . is_source_class and self . is_in_constructor : self . methods_in_constructor . append ( ctx . IDENTIFIER ()) enterClassDeclaration ( self , ctx ) It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. Source code in codart\\refactorings\\extract_subclass.py def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. \"\"\" class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True self . code += self . NEW_LINE * 2 self . code += f \"// New class( { self . new_class } ) generated by CodART\" + self . NEW_LINE self . code += f \"class { self . new_class } extends { self . source_class }{ self . NEW_LINE } \" + \"{\" + self . NEW_LINE self . code += f \"public { self . new_class } ()\" + \"{ }\" + self . NEW_LINE else : self . is_source_class = False enterMethodDeclaration ( self , ctx ) It sets the detected field to the method if it is one of the moved methods. Source code in codart\\refactorings\\extract_subclass.py def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It sets the detected field to the method if it is one of the moved methods. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if method_identifier in self . moved_methods : self . detected_method = method_identifier enterVariableDeclaratorId ( self , ctx ) It sets the detected field to the field if it is one of the moved fields. Source code in codart\\refactorings\\extract_subclass.py def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): \"\"\" It sets the detected field to the field if it is one of the moved fields. \"\"\" if not self . is_source_class : return None field_identifier = ctx . IDENTIFIER () . getText () if field_identifier in self . moved_fields : self . detected_field = field_identifier exitClassDeclaration ( self , ctx ) It closes the opened curly brackets If it is the source class. Source code in codart\\refactorings\\extract_subclass.py def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It closes the opened curly brackets If it is the source class. \"\"\" if self . is_source_class : self . code += \"}\" self . is_source_class = False exitCompilationUnit ( self , ctx ) It writes self.code in the output path. Source code in codart\\refactorings\\extract_subclass.py def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): \"\"\" It writes self.code in the output path. \"\"\" child_file_name = self . new_class + \".java\" with open ( os . path . join ( self . output_path , child_file_name ), \"w+\" ) as f : f . write ( self . code . replace ( ' \\r\\n ' , ' \\n ' )) exitFieldDeclaration ( self , ctx ) It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. Source code in codart\\refactorings\\extract_subclass.py def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): \"\"\" It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. \"\"\" if not self . is_source_class : return None field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () field_names = list () field_names . append ( field_identifier ) # print(\"field_names=\", field_names) grand_parent_ctx = ctx . parentCtx . parentCtx if self . detected_field in field_names : if not grand_parent_ctx . modifier (): modifier = \"\" else : modifier = grand_parent_ctx . modifier ( 0 ) . getText () field_type = ctx . typeType () . getText () self . code += f \" { self . TAB }{ modifier } { field_type } { self . detected_field } ; { self . NEW_LINE } \" # delete field from source class ==>new start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . parentCtx . parentCtx . stop . tokenIndex self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_field = None exitMethodDeclaration ( self , ctx ) It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. Source code in codart\\refactorings\\extract_subclass.py def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if self . detected_method == method_identifier : start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . stop . tokenIndex method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . code += ( self . NEW_LINE + self . TAB + method_text + self . NEW_LINE ) # delete method from source class self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_method = None main () it builds the parse tree and walk its corresponding walker so that our overridden methods run. Source code in codart\\refactorings\\extract_subclass.py def main (): \"\"\" it builds the parse tree and walk its corresponding walker so that our overridden methods run. \"\"\" # udb_path = \"/home/ali/Desktop/code/TestProject/TestProject.udb\" # udb_path=create_understand_database(\"C:\\\\Users\\\\asus\\\\Desktop\\\\test_project\") # source_class = \"GodClass\" # moved_methods = ['method1', 'method3', ] # moved_fields = ['field1', 'field2', ] udb_path = \"C: \\\\ Users \\\\ asus \\\\ Desktop \\\\ test_project \\\\ test_project.udb\" # moved_methods = ['getValue', 'rowToJSONArray', 'getVal', ] # moved_fields = ['number_2', 'number_1', ] source_class = \"GodClass\" moved_methods = [ 'method1' , 'method3' ] moved_fields = [ 'field1' , 'field2' ] father_path_file = \"/data/Dev/JavaSample/src/GodClass.java\" father_path_directory = \"/data/Dev/JavaSample/src\" path_to_refactor = \"/data/Dev/JavaSample/src\" new_class_file = \"/data/Dev/JavaSample/src/GodSubClass.java\" # source_class = \"TaskNode\" # moved_methods = ['getUserObject'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\\\\TaskNode.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\\\\TaskNodeextracted.java\" # source_class = \"SecuritySupport\" # moved_methods = ['getSystemProperty'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\\\\SecuritySupport.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\\\\SecuritySupportextracted.java\" # source_class = \"BaseMarkupSerializer\" # moved_methods = ['setOutputCharStream'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\\\\BaseMarkupSerializer.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\\\\BaseMarkupSerializerextracted.java\" # source_class = \"Piece\" # moved_methods = ['setX'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\\\\Piece.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\\\\Pieceextracted.java\" stream = FileStream ( father_path_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = ExtractSubClassRefactoringListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( father_path_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) extractJavaFilesAndProcess ( path_to_refactor , father_path_file , new_class_file ) for file in files_to_refactor : stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = FindUsagesListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory ) # output_path=father_path_directory) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) tmp_aul = my_listener . aul with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # after find usages try : stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = PropagationListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory , aul = tmp_aul ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) except : print ( \"not utf8\" )","title":"Extract subclass"},{"location":"refactorings/extract_subclass/#extract-subclass","text":"","title":"Extract subclass"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass--introduction","text":"Extract subclass refactoring","title":"Introduction"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.ExtractSubClassRefactoringListener","text":"To implement extract subclass refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one Source code in codart\\refactorings\\extract_subclass.py class ExtractSubClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement extract subclass refactoring based on its actors. Creates a new class and move fields and methods from the old class to the new one \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , new_class : str = None , moved_fields = None , moved_methods = None , output_path : str = \"\" ): if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if moved_fields is None : self . moved_fields = [] else : self . moved_fields = moved_fields if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if new_class is None : raise ValueError ( \"new_class is None\" ) else : self . new_class = new_class self . output_path = output_path self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . is_in_constructor = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. \"\"\" class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True self . code += self . NEW_LINE * 2 self . code += f \"// New class( { self . new_class } ) generated by CodART\" + self . NEW_LINE self . code += f \"class { self . new_class } extends { self . source_class }{ self . NEW_LINE } \" + \"{\" + self . NEW_LINE self . code += f \"public { self . new_class } ()\" + \"{ }\" + self . NEW_LINE else : self . is_source_class = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It closes the opened curly brackets If it is the source class. \"\"\" if self . is_source_class : self . code += \"}\" self . is_source_class = False def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): \"\"\" It writes self.code in the output path. \"\"\" child_file_name = self . new_class + \".java\" with open ( os . path . join ( self . output_path , child_file_name ), \"w+\" ) as f : f . write ( self . code . replace ( ' \\r\\n ' , ' \\n ' )) def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): \"\"\" It sets the detected field to the field if it is one of the moved fields. \"\"\" if not self . is_source_class : return None field_identifier = ctx . IDENTIFIER () . getText () if field_identifier in self . moved_fields : self . detected_field = field_identifier def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): \"\"\" It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. \"\"\" if not self . is_source_class : return None field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () field_names = list () field_names . append ( field_identifier ) # print(\"field_names=\", field_names) grand_parent_ctx = ctx . parentCtx . parentCtx if self . detected_field in field_names : if not grand_parent_ctx . modifier (): modifier = \"\" else : modifier = grand_parent_ctx . modifier ( 0 ) . getText () field_type = ctx . typeType () . getText () self . code += f \" { self . TAB }{ modifier } { field_type } { self . detected_field } ; { self . NEW_LINE } \" # delete field from source class ==>new start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . parentCtx . parentCtx . stop . tokenIndex self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_field = None def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It sets the detected field to the method if it is one of the moved methods. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if method_identifier in self . moved_methods : self . detected_method = method_identifier def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if self . detected_method == method_identifier : start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . stop . tokenIndex method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . code += ( self . NEW_LINE + self . TAB + method_text + self . NEW_LINE ) # delete method from source class self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_method = None def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_source_class : self . is_in_constructor = True self . fields_in_constructor = [] self . methods_in_constructor = [] self . constructor_body = ctx . block () children = self . constructor_body . children def exitConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_source_class and self . is_in_constructor : move_constructor_flag = False for field in self . fields_in_constructor : if field in self . moved_fields : move_constructor_flag = True for method in self . methods_in_constructor : if method in self . moved_methods : move_constructor_flag = True if move_constructor_flag : if ctx . formalParameters () . formalParameterList (): constructor_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : constructor_parameters = [] constructor_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): constructor_text += modifier . getText () + ' ' constructor_text += self . new_class constructor_text += ' ( ' for parameter in constructor_parameters : constructor_text += parameter . typeType () . getText () + ' ' constructor_text += parameter . variableDeclaratorId () . getText () + ', ' if constructor_parameters : constructor_text = constructor_text [: len ( constructor_text ) - 2 ] constructor_text += ') \\n\\t {' constructor_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ) constructor_text += '} \\n ' self . code += constructor_text start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . parentCtx . parentCtx . stop . tokenIndex self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . is_in_constructor = False def enterExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . is_source_class and self . is_in_constructor : if len ( ctx . children [ 0 ] . children ) == 1 : self . fields_in_constructor . append ( ctx . children [ 0 ] . getText ()) else : self . fields_in_constructor . append ( ctx . children [ 0 ] . children [ - 1 ] . getText ()) def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if self . is_source_class and self . is_in_constructor : self . methods_in_constructor . append ( ctx . IDENTIFIER ())","title":"ExtractSubClassRefactoringListener"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.ExtractSubClassRefactoringListener.enterClassDeclaration","text":"It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. Source code in codart\\refactorings\\extract_subclass.py def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It checks if it is source class, we generate the declaration of the new class, by appending some text to self.code. \"\"\" class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True self . code += self . NEW_LINE * 2 self . code += f \"// New class( { self . new_class } ) generated by CodART\" + self . NEW_LINE self . code += f \"class { self . new_class } extends { self . source_class }{ self . NEW_LINE } \" + \"{\" + self . NEW_LINE self . code += f \"public { self . new_class } ()\" + \"{ }\" + self . NEW_LINE else : self . is_source_class = False","title":"enterClassDeclaration()"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.ExtractSubClassRefactoringListener.enterMethodDeclaration","text":"It sets the detected field to the method if it is one of the moved methods. Source code in codart\\refactorings\\extract_subclass.py def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It sets the detected field to the method if it is one of the moved methods. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if method_identifier in self . moved_methods : self . detected_method = method_identifier","title":"enterMethodDeclaration()"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.ExtractSubClassRefactoringListener.enterVariableDeclaratorId","text":"It sets the detected field to the field if it is one of the moved fields. Source code in codart\\refactorings\\extract_subclass.py def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): \"\"\" It sets the detected field to the field if it is one of the moved fields. \"\"\" if not self . is_source_class : return None field_identifier = ctx . IDENTIFIER () . getText () if field_identifier in self . moved_fields : self . detected_field = field_identifier","title":"enterVariableDeclaratorId()"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.ExtractSubClassRefactoringListener.exitClassDeclaration","text":"It closes the opened curly brackets If it is the source class. Source code in codart\\refactorings\\extract_subclass.py def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): \"\"\" It closes the opened curly brackets If it is the source class. \"\"\" if self . is_source_class : self . code += \"}\" self . is_source_class = False","title":"exitClassDeclaration()"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.ExtractSubClassRefactoringListener.exitCompilationUnit","text":"It writes self.code in the output path. Source code in codart\\refactorings\\extract_subclass.py def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): \"\"\" It writes self.code in the output path. \"\"\" child_file_name = self . new_class + \".java\" with open ( os . path . join ( self . output_path , child_file_name ), \"w+\" ) as f : f . write ( self . code . replace ( ' \\r\\n ' , ' \\n ' ))","title":"exitCompilationUnit()"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.ExtractSubClassRefactoringListener.exitFieldDeclaration","text":"It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. Source code in codart\\refactorings\\extract_subclass.py def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): \"\"\" It gets the field name, if the field is one of the moved fields, we move it and delete it from the source program. \"\"\" if not self . is_source_class : return None field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () field_names = list () field_names . append ( field_identifier ) # print(\"field_names=\", field_names) grand_parent_ctx = ctx . parentCtx . parentCtx if self . detected_field in field_names : if not grand_parent_ctx . modifier (): modifier = \"\" else : modifier = grand_parent_ctx . modifier ( 0 ) . getText () field_type = ctx . typeType () . getText () self . code += f \" { self . TAB }{ modifier } { field_type } { self . detected_field } ; { self . NEW_LINE } \" # delete field from source class ==>new start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . parentCtx . parentCtx . stop . tokenIndex self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_field = None","title":"exitFieldDeclaration()"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.ExtractSubClassRefactoringListener.exitMethodDeclaration","text":"It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. Source code in codart\\refactorings\\extract_subclass.py def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): \"\"\" It gets the method name, if the method is one of the moved methods, we move it to the subclass and delete it from the source program. \"\"\" if not self . is_source_class : return None method_identifier = ctx . IDENTIFIER () . getText () if self . detected_method == method_identifier : start_index = ctx . parentCtx . parentCtx . start . tokenIndex stop_index = ctx . stop . tokenIndex method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . code += ( self . NEW_LINE + self . TAB + method_text + self . NEW_LINE ) # delete method from source class self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = start_index , to_idx = stop_index ) self . detected_method = None","title":"exitMethodDeclaration()"},{"location":"refactorings/extract_subclass/#codart.refactorings.extract_subclass.main","text":"it builds the parse tree and walk its corresponding walker so that our overridden methods run. Source code in codart\\refactorings\\extract_subclass.py def main (): \"\"\" it builds the parse tree and walk its corresponding walker so that our overridden methods run. \"\"\" # udb_path = \"/home/ali/Desktop/code/TestProject/TestProject.udb\" # udb_path=create_understand_database(\"C:\\\\Users\\\\asus\\\\Desktop\\\\test_project\") # source_class = \"GodClass\" # moved_methods = ['method1', 'method3', ] # moved_fields = ['field1', 'field2', ] udb_path = \"C: \\\\ Users \\\\ asus \\\\ Desktop \\\\ test_project \\\\ test_project.udb\" # moved_methods = ['getValue', 'rowToJSONArray', 'getVal', ] # moved_fields = ['number_2', 'number_1', ] source_class = \"GodClass\" moved_methods = [ 'method1' , 'method3' ] moved_fields = [ 'field1' , 'field2' ] father_path_file = \"/data/Dev/JavaSample/src/GodClass.java\" father_path_directory = \"/data/Dev/JavaSample/src\" path_to_refactor = \"/data/Dev/JavaSample/src\" new_class_file = \"/data/Dev/JavaSample/src/GodSubClass.java\" # source_class = \"TaskNode\" # moved_methods = ['getUserObject'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\\\\TaskNode.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\ganttproject\\\\ganttproject\\\\src\\\\main\\\\java\\\\net\\\\sourceforge\\\\ganttproject\\\\task\\\\TaskNodeextracted.java\" # source_class = \"SecuritySupport\" # moved_methods = ['getSystemProperty'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\\\\SecuritySupport.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\html\\\\dom\\\\SecuritySupportextracted.java\" # source_class = \"BaseMarkupSerializer\" # moved_methods = ['setOutputCharStream'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\\\\BaseMarkupSerializer.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\xerces2-j\\\\src\\\\org\\\\apache\\\\xml\\\\serialize\\\\BaseMarkupSerializerextracted.java\" # source_class = \"Piece\" # moved_methods = ['setX'] # moved_fields = [] # father_path_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\\\\Piece.java\" # father_path_directory = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\" # path_to_refactor = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\" # new_class_file = \"C:\\\\Users\\\\asus\\\\Desktop\\\\benchmark_projects\\\\Chess_master\\\\src\\\\game\\\\Pieceextracted.java\" stream = FileStream ( father_path_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = ExtractSubClassRefactoringListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( father_path_file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) extractJavaFilesAndProcess ( path_to_refactor , father_path_file , new_class_file ) for file in files_to_refactor : stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = FindUsagesListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory ) # output_path=father_path_directory) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) tmp_aul = my_listener . aul with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # after find usages try : stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = PropagationListener ( common_token_stream = token_stream , source_class = source_class , new_class = source_class + \"extracted\" , moved_fields = moved_fields , moved_methods = moved_methods , output_path = father_path_directory , aul = tmp_aul ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( file , mode = 'w' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) except : print ( \"not utf8\" )","title":"main()"},{"location":"refactorings/increase_field_visibility/","text":"Increase field visibility Introduction Increase field visibility refactoring Increase the visibility of a field from private to package, package to protected or protected to public. Pre and post-conditions Pre-conditions: User must enter the field's name, and the source class's name for the refactoring in order to increase the target field's visibility. Post-conditions: No specific post-condition IncreaseFieldVisibilityListener ( JavaParserLabeledListener ) To implement \u0650Increase Field Visibility refactoring based on its actors. Detects the required field and increases/changes its visibility status. Source code in codart\\refactorings\\increase_field_visibility.py class IncreaseFieldVisibilityListener ( JavaParserLabeledListener ): \"\"\" To implement \u0650Increase Field Visibility refactoring based on its actors. Detects the required field and increases/changes its visibility status. \"\"\" def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseFieldVisibilityListener): An instance of IncreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = False def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): self . in_field = True def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): self . in_field = False def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): if ctx . IDENTIFIER () . getText () == self . source_field and self . in_field : self . detected_field = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_field : if ctx . modifier ( 0 ) is not None : if \"@\" in ctx . modifier ( 0 ) . getText (): if ctx . modifier ( 1 ) is not None : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 1 ) . start , text = \"public \" ) else : self . rewriter . replaceSingleToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"public \" + ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . getText () ) else : if ctx . modifier ( 0 ) . getText () == 'private' or ctx . modifier ( 0 ) . getText () == 'protected' : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 0 ) . start , text = \"public \" ) else : self . rewriter . insertBeforeToken ( token = ctx . modifier ( 0 ) . start , text = \"public \" ) else : if ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) is not None : self . rewriter . insertBeforeToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"public \" ) self . detected_field = False __init__ ( self , source_class , source_field , rewriter ) special Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_field str Name of the field whose visibility status has to be changed required rewriter CommonTokenStream An instance of TokenStreamRewriter required Returns: Type Description object (IncreaseFieldVisibilityListener) An instance of IncreaseFieldVisibilityListener Source code in codart\\refactorings\\increase_field_visibility.py def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseFieldVisibilityListener): An instance of IncreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ) Source code in codart\\refactorings\\increase_field_visibility.py def main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) fields = db . lookup ( f \" { source_package } . { source_class } . { source_field } \" , \"Variable\" ) if len ( fields ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False field_ent = fields [ 0 ] if field_ent . simplename () != source_field : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not field_ent.kind().check(\"private\"): # logger.error(\"Field is not private.\") # db.close() # return False parent = field_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = str ( parent . longname ()) db . close () parse_and_walk ( file_path = main_file , listener_class = IncreaseFieldVisibilityListener , has_write = True , source_class = source_class , source_field = source_field ) # db.close() return True","title":"Increase field visibility"},{"location":"refactorings/increase_field_visibility/#increase-field-visibility","text":"","title":"Increase field visibility"},{"location":"refactorings/increase_field_visibility/#codart.refactorings.increase_field_visibility--introduction","text":"Increase field visibility refactoring Increase the visibility of a field from private to package, package to protected or protected to public.","title":"Introduction"},{"location":"refactorings/increase_field_visibility/#codart.refactorings.increase_field_visibility--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/increase_field_visibility/#codart.refactorings.increase_field_visibility--pre-conditions","text":"User must enter the field's name, and the source class's name for the refactoring in order to increase the target field's visibility.","title":"Pre-conditions:"},{"location":"refactorings/increase_field_visibility/#codart.refactorings.increase_field_visibility--post-conditions","text":"No specific post-condition","title":"Post-conditions:"},{"location":"refactorings/increase_field_visibility/#codart.refactorings.increase_field_visibility.IncreaseFieldVisibilityListener","text":"To implement \u0650Increase Field Visibility refactoring based on its actors. Detects the required field and increases/changes its visibility status. Source code in codart\\refactorings\\increase_field_visibility.py class IncreaseFieldVisibilityListener ( JavaParserLabeledListener ): \"\"\" To implement \u0650Increase Field Visibility refactoring based on its actors. Detects the required field and increases/changes its visibility status. \"\"\" def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseFieldVisibilityListener): An instance of IncreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = False def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): self . in_field = True def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): self . in_field = False def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): if ctx . IDENTIFIER () . getText () == self . source_field and self . in_field : self . detected_field = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_field : if ctx . modifier ( 0 ) is not None : if \"@\" in ctx . modifier ( 0 ) . getText (): if ctx . modifier ( 1 ) is not None : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 1 ) . start , text = \"public \" ) else : self . rewriter . replaceSingleToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"public \" + ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . getText () ) else : if ctx . modifier ( 0 ) . getText () == 'private' or ctx . modifier ( 0 ) . getText () == 'protected' : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 0 ) . start , text = \"public \" ) else : self . rewriter . insertBeforeToken ( token = ctx . modifier ( 0 ) . start , text = \"public \" ) else : if ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) is not None : self . rewriter . insertBeforeToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"public \" ) self . detected_field = False","title":"IncreaseFieldVisibilityListener"},{"location":"refactorings/increase_field_visibility/#codart.refactorings.increase_field_visibility.IncreaseFieldVisibilityListener.__init__","text":"Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_field str Name of the field whose visibility status has to be changed required rewriter CommonTokenStream An instance of TokenStreamRewriter required Returns: Type Description object (IncreaseFieldVisibilityListener) An instance of IncreaseFieldVisibilityListener Source code in codart\\refactorings\\increase_field_visibility.py def __init__ ( self , source_class , source_field , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_field (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseFieldVisibilityListener): An instance of IncreaseFieldVisibilityListener \"\"\" self . source_class = source_class self . source_field = source_field self . in_class = False self . in_field = False self . detected_field = False self . rewriter = rewriter","title":"__init__()"},{"location":"refactorings/increase_field_visibility/#codart.refactorings.increase_field_visibility.main","text":"Source code in codart\\refactorings\\increase_field_visibility.py def main ( udb_path , source_package , source_class , source_field , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) fields = db . lookup ( f \" { source_package } . { source_class } . { source_field } \" , \"Variable\" ) if len ( fields ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False field_ent = fields [ 0 ] if field_ent . simplename () != source_field : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not field_ent.kind().check(\"private\"): # logger.error(\"Field is not private.\") # db.close() # return False parent = field_ent . parent () while parent . parent () is not None : parent = parent . parent () main_file = str ( parent . longname ()) db . close () parse_and_walk ( file_path = main_file , listener_class = IncreaseFieldVisibilityListener , has_write = True , source_class = source_class , source_field = source_field ) # db.close() return True","title":"main()"},{"location":"refactorings/increase_method_visibility/","text":"Increase method visibility Introduction Increase method visibility refactoring Increase the visibility of a method from private to package, package to protected or protected to public. Pre and post-conditions Pre-conditions: User must enter the method's name, and the source class's name for the refactoring in order to increase the target method's visibility. Post-conditions: No specific post-condition IncreaseMethodVisibilityListener ( JavaParserLabeledListener ) To implement \u0650Increase Method Visibility refactoring based on its actors. Detects the required method and increases/changes its visibility status. Source code in codart\\refactorings\\increase_method_visibility.py class IncreaseMethodVisibilityListener ( JavaParserLabeledListener ): \"\"\" To implement \u0650Increase Method Visibility refactoring based on its actors. Detects the required method and increases/changes its visibility status. \"\"\" def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseMethodVisibilityListener): An instance of IncreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_method : self . detected_method = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_method : if ctx . modifier ( 0 ) is not None : if \"@\" in ctx . modifier ( 0 ) . getText (): if ctx . modifier ( 1 ) is not None : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 1 ) . start , text = \"public \" ) else : self . rewriter . replaceSingleToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"public \" + ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . getText () ) else : if ctx . modifier ( 0 ) . getText () == 'private' or ctx . modifier ( 0 ) . getText () == 'protected' : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 0 ) . start , text = \"public \" ) else : self . rewriter . insertBeforeToken ( token = ctx . modifier ( 0 ) . start , text = \"public \" ) else : if ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) is not None : self . rewriter . insertBeforeToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"public \" ) self . detected_method = False __init__ ( self , source_class , source_method , rewriter ) special Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_method str Name of the field whose visibility status has to be changed required rewriter CommonTokenStream An instance of TokenStreamRewriter required Returns: Type Description object (IncreaseMethodVisibilityListener) An instance of IncreaseMethodVisibilityListener Source code in codart\\refactorings\\increase_method_visibility.py def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseMethodVisibilityListener): An instance of IncreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ) Source code in codart\\refactorings\\increase_method_visibility.py def main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) methods = db . lookup ( f \" { source_package } . { source_class } . { source_method } \" , \"Method\" ) if methods is None or len ( methods ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False method_entity = methods [ 0 ] if method_entity . simplename () != source_method : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not method_entity.kind().check(\"Private\"): # logger.error(\"Method is not private.\") # db.close() # return False parent = method_entity . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () # The file that contain the method db . close () parse_and_walk ( file_path = main_file , listener_class = IncreaseMethodVisibilityListener , has_write = True , source_class = source_class , source_method = source_method ) # db.close() return True","title":"Increase method visibility"},{"location":"refactorings/increase_method_visibility/#increase-method-visibility","text":"","title":"Increase method visibility"},{"location":"refactorings/increase_method_visibility/#codart.refactorings.increase_method_visibility--introduction","text":"Increase method visibility refactoring Increase the visibility of a method from private to package, package to protected or protected to public.","title":"Introduction"},{"location":"refactorings/increase_method_visibility/#codart.refactorings.increase_method_visibility--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/increase_method_visibility/#codart.refactorings.increase_method_visibility--pre-conditions","text":"User must enter the method's name, and the source class's name for the refactoring in order to increase the target method's visibility.","title":"Pre-conditions:"},{"location":"refactorings/increase_method_visibility/#codart.refactorings.increase_method_visibility--post-conditions","text":"No specific post-condition","title":"Post-conditions:"},{"location":"refactorings/increase_method_visibility/#codart.refactorings.increase_method_visibility.IncreaseMethodVisibilityListener","text":"To implement \u0650Increase Method Visibility refactoring based on its actors. Detects the required method and increases/changes its visibility status. Source code in codart\\refactorings\\increase_method_visibility.py class IncreaseMethodVisibilityListener ( JavaParserLabeledListener ): \"\"\" To implement \u0650Increase Method Visibility refactoring based on its actors. Detects the required method and increases/changes its visibility status. \"\"\" def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseMethodVisibilityListener): An instance of IncreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_class : self . in_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if ctx . IDENTIFIER () . getText () == self . source_method : self . detected_method = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_method : if ctx . modifier ( 0 ) is not None : if \"@\" in ctx . modifier ( 0 ) . getText (): if ctx . modifier ( 1 ) is not None : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 1 ) . start , text = \"public \" ) else : self . rewriter . replaceSingleToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"public \" + ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . getText () ) else : if ctx . modifier ( 0 ) . getText () == 'private' or ctx . modifier ( 0 ) . getText () == 'protected' : self . rewriter . replaceSingleToken ( token = ctx . modifier ( 0 ) . start , text = \"public \" ) else : self . rewriter . insertBeforeToken ( token = ctx . modifier ( 0 ) . start , text = \"public \" ) else : if ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) is not None : self . rewriter . insertBeforeToken ( ctx . memberDeclaration () . getChild ( 0 ) . getChild ( 0 ) . start , text = \"public \" ) self . detected_method = False","title":"IncreaseMethodVisibilityListener"},{"location":"refactorings/increase_method_visibility/#codart.refactorings.increase_method_visibility.IncreaseMethodVisibilityListener.__init__","text":"Parameters: Name Type Description Default source_class str Name of the class in which the refactoring has to be done required source_method str Name of the field whose visibility status has to be changed required rewriter CommonTokenStream An instance of TokenStreamRewriter required Returns: Type Description object (IncreaseMethodVisibilityListener) An instance of IncreaseMethodVisibilityListener Source code in codart\\refactorings\\increase_method_visibility.py def __init__ ( self , source_class , source_method , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Name of the class in which the refactoring has to be done source_method (str): Name of the field whose visibility status has to be changed rewriter (CommonTokenStream): An instance of TokenStreamRewriter Returns: object (IncreaseMethodVisibilityListener): An instance of IncreaseMethodVisibilityListener \"\"\" self . source_class = source_class self . source_method = source_method self . in_class = False self . detected_method = False self . rewriter = rewriter","title":"__init__()"},{"location":"refactorings/increase_method_visibility/#codart.refactorings.increase_method_visibility.main","text":"Source code in codart\\refactorings\\increase_method_visibility.py def main ( udb_path , source_package , source_class , source_method , * args , ** kwargs ): \"\"\" \"\"\" db = und . open ( udb_path ) methods = db . lookup ( f \" { source_package } . { source_class } . { source_method } \" , \"Method\" ) if methods is None or len ( methods ) == 0 : logger . error ( \"Invalid inputs.\" ) db . close () return False method_entity = methods [ 0 ] if method_entity . simplename () != source_method : logger . error ( \"Invalid entity.\" ) db . close () return False # Strong overlay precondition # if not method_entity.kind().check(\"Private\"): # logger.error(\"Method is not private.\") # db.close() # return False parent = method_entity . parent () while parent . parent () is not None : parent = parent . parent () main_file = parent . longname () # The file that contain the method db . close () parse_and_walk ( file_path = main_file , listener_class = IncreaseMethodVisibilityListener , has_write = True , source_class = source_class , source_method = source_method ) # db.close() return True","title":"main()"},{"location":"refactorings/inline_class/","text":"Increase method visibility Introduction The script implements inline class refactoring Merge to class into one class InlineClassRefactoringListener ( JavaParserLabeledListener ) To implement inline class refactoring based on its actors. Creates a new class and move fields and methods from two old class to the new one, then delete the two class Source code in codart\\refactorings\\inline_class.py class InlineClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement inline class refactoring based on its actors. Creates a new class and move fields and methods from two old class to the new one, then delete the two class \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , source_class_data : dict = None , target_class : str = None , target_class_data : dict = None , is_complete : bool = False ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if target_class is None : raise ValueError ( \"new_class is None\" ) else : self . target_class = target_class if target_class : self . target_class = target_class if source_class_data : self . source_class_data = source_class_data else : self . source_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} if target_class_data : self . target_class_data = target_class_data else : self . target_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} self . field_that_has_source = [] self . has_source_new = False self . is_complete = is_complete self . is_target_class = False self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True self . is_target_class = False elif class_identifier == self . target_class : self . is_target_class = True self . is_source_class = False else : self . is_target_class = False self . is_source_class = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_target_class and ( self . source_class_data [ 'fields' ] or self . source_class_data [ 'constructors' ] or self . source_class_data [ 'methods' ]): if not self . is_complete : final_fields = merge_fields ( self . source_class_data [ 'fields' ], self . target_class_data [ 'fields' ], self . target_class ) final_constructors = merge_constructors ( self . source_class_data [ 'constructors' ], self . target_class_data [ 'constructors' ]) final_methods = merge_methods ( self . source_class_data [ 'methods' ], self . target_class_data [ 'methods' ]) text = ' \\t ' for field in final_fields : text += field . text + ' \\n ' for constructor in final_constructors : text += constructor . text + ' \\n ' for method in final_methods : text += method . text + ' \\n ' self . token_stream_rewriter . insertBeforeIndex ( index = ctx . stop . tokenIndex , text = text ) self . is_complete = True else : self . is_target_class = False elif self . is_source_class : if ctx . parentCtx . classOrInterfaceModifier ( 0 ) is None : return self . is_source_class = False self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . parentCtx . classOrInterfaceModifier ( 0 ) . start . tokenIndex , to_idx = ctx . stop . tokenIndex ) def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_source_class : self . code += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex + 1 , stop = ctx . stop . tokenIndex - 1 ) self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . parentCtx . start . tokenIndex , to_idx = ctx . parentCtx . stop . tokenIndex ) else : return None def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . is_source_class or self . is_target_class : field_text = '' for child in ctx . children : if child . getText () == ';' : field_text = field_text [: len ( field_text ) - 1 ] + ';' break field_text += child . getText () + ' ' name = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () if ctx . typeType () . classOrInterfaceType () is not None and \\ ctx . typeType () . classOrInterfaceType () . getText () == self . source_class : self . field_that_has_source . append ( name ) return modifier_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): modifier_text += modifier . getText () + ' ' field_text = modifier_text + field_text if self . is_source_class : self . source_class_data [ 'fields' ] . append ( Field ( name = name , text = field_text )) else : self . target_class_data [ 'fields' ] . append ( Field ( name = name , text = field_text )) def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . is_target_class : if ctx . typeType () . classOrInterfaceType () . getText () == self . source_class : grand_parent_ctx = ctx . parentCtx . parentCtx self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . start . tokenIndex , to_idx = grand_parent_ctx . stop . tokenIndex ) def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_source_class or self . is_target_class : if ctx . formalParameters () . formalParameterList (): constructor_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : constructor_parameters = [] constructor_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): constructor_text += modifier . getText () + ' ' if self . is_source_class : constructor_text += self . target_class else : constructor_text += ctx . IDENTIFIER () . getText () constructor_text += ' ( ' for parameter in constructor_parameters : constructor_text += parameter . typeType () . getText () + ' ' constructor_text += parameter . variableDeclaratorId () . getText () + ', ' if constructor_parameters : constructor_text = constructor_text [: len ( constructor_text ) - 2 ] constructor_text += ') \\n\\t {' constructor_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ) constructor_text += '} \\n ' if self . is_source_class : self . source_class_data [ 'constructors' ] . append ( ConstructorOrMethod ( name = self . target_class , parameters = [ Parameter ( parameter_type = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in constructor_parameters ], text = constructor_text , constructor_body = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ))) else : self . target_class_data [ 'constructors' ] . append ( ConstructorOrMethod ( name = self . target_class , parameters = [ Parameter ( parameter_type = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in constructor_parameters ], text = constructor_text , constructor_body = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ))) proper_constructor = get_proper_constructor ( self . target_class_data [ 'constructors' ][ - 1 ], self . source_class_data [ 'constructors' ]) if proper_constructor is None : return self . token_stream_rewriter . insertBeforeIndex ( index = ctx . stop . tokenIndex , text = proper_constructor . constructorBody ) def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_source_class or self . is_target_class : if ctx . formalParameters () . formalParameterList (): method_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : method_parameters = [] method_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): method_text += modifier . getText () + ' ' type_text = ctx . typeTypeOrVoid () . getText () if type_text == self . source_class : type_text = self . target_class if self . is_target_class : self . token_stream_rewriter . replace ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . typeTypeOrVoid () . start . tokenIndex , to_idx = ctx . typeTypeOrVoid () . stop . tokenIndex , text = type_text ) method_text += type_text + ' ' + ctx . IDENTIFIER () . getText () method_text += ' ( ' for parameter in method_parameters : method_text += parameter . typeType () . getText () + ' ' method_text += parameter . variableDeclaratorId () . getText () + ', ' if method_parameters : method_text = method_text [: len ( method_text ) - 2 ] method_text += ') \\n\\t {' method_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . methodBody () . start . tokenIndex + 1 , stop = ctx . methodBody () . stop . tokenIndex - 1 ) method_text += '} \\n ' if self . is_source_class : self . source_class_data [ 'methods' ] . append ( ConstructorOrMethod ( name = ctx . IDENTIFIER () . getText (), parameters = [ Parameter ( parameter_type = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in method_parameters ], text = method_text )) else : self . target_class_data [ 'methods' ] . append ( ConstructorOrMethod ( name = ctx . IDENTIFIER () . getText (), parameters = [ Parameter ( parameter_type = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in method_parameters ], text = method_text )) def enterExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): if ctx . IDENTIFIER () is None and ctx . IDENTIFIER () . getText () in self . field_that_has_source : field_text = ctx . expression () . getText () self . token_stream_rewriter . replace ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex , text = field_text ) def exitExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . has_source_new : self . has_source_new = False self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex + 1 ) def enterExpression4 ( self , ctx : JavaParserLabeled . Expression4Context ): if ctx . children [ - 1 ] . children [ 0 ] . getText () == self . source_class : self . has_source_new = True def enterCreatedName0 ( self , ctx : JavaParserLabeled . CreatedName0Context ): if ctx . IDENTIFIER ( 0 ) . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . target_class ) def enterCreatedName1 ( self , ctx : JavaParserLabeled . CreatedName1Context ): if ctx . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . target_class ) def enterFormalParameter ( self , ctx : JavaParserLabeled . FormalParameterContext ): class_type = ctx . typeType () . classOrInterfaceType () if class_type : if class_type . IDENTIFIER ( 0 ) . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = class_type . start . tokenIndex , text = self . target_class ) def enterQualifiedName ( self , ctx : JavaParserLabeled . QualifiedNameContext ): if ctx . IDENTIFIER ( 0 ) . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . target_class ) def exitExpression0 ( self , ctx : JavaParserLabeled . Expression0Context ): if ctx . primary () . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . target_class ) def enterLocalVariableDeclaration ( self , ctx : JavaParserLabeled . LocalVariableDeclarationContext ): if ctx . typeType () . classOrInterfaceType (): if ctx . typeType () . classOrInterfaceType () . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replace ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . typeType () . start . tokenIndex , to_idx = ctx . typeType () . stop . tokenIndex , text = self . target_class ) __init__ ( self , common_token_stream = None , source_class = None , source_class_data = None , target_class = None , target_class_data = None , is_complete = False ) special Source code in codart\\refactorings\\inline_class.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , source_class_data : dict = None , target_class : str = None , target_class_data : dict = None , is_complete : bool = False ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if target_class is None : raise ValueError ( \"new_class is None\" ) else : self . target_class = target_class if target_class : self . target_class = target_class if source_class_data : self . source_class_data = source_class_data else : self . source_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} if target_class_data : self . target_class_data = target_class_data else : self . target_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} self . field_that_has_source = [] self . has_source_new = False self . is_complete = is_complete self . is_target_class = False self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\"","title":"Inline class"},{"location":"refactorings/inline_class/#increase-method-visibility","text":"","title":"Increase method visibility"},{"location":"refactorings/inline_class/#codart.refactorings.inline_class--introduction","text":"The script implements inline class refactoring Merge to class into one class","title":"Introduction"},{"location":"refactorings/inline_class/#codart.refactorings.inline_class.InlineClassRefactoringListener","text":"To implement inline class refactoring based on its actors. Creates a new class and move fields and methods from two old class to the new one, then delete the two class Source code in codart\\refactorings\\inline_class.py class InlineClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement inline class refactoring based on its actors. Creates a new class and move fields and methods from two old class to the new one, then delete the two class \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , source_class_data : dict = None , target_class : str = None , target_class_data : dict = None , is_complete : bool = False ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if target_class is None : raise ValueError ( \"new_class is None\" ) else : self . target_class = target_class if target_class : self . target_class = target_class if source_class_data : self . source_class_data = source_class_data else : self . source_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} if target_class_data : self . target_class_data = target_class_data else : self . target_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} self . field_that_has_source = [] self . has_source_new = False self . is_complete = is_complete self . is_target_class = False self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True self . is_target_class = False elif class_identifier == self . target_class : self . is_target_class = True self . is_source_class = False else : self . is_target_class = False self . is_source_class = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_target_class and ( self . source_class_data [ 'fields' ] or self . source_class_data [ 'constructors' ] or self . source_class_data [ 'methods' ]): if not self . is_complete : final_fields = merge_fields ( self . source_class_data [ 'fields' ], self . target_class_data [ 'fields' ], self . target_class ) final_constructors = merge_constructors ( self . source_class_data [ 'constructors' ], self . target_class_data [ 'constructors' ]) final_methods = merge_methods ( self . source_class_data [ 'methods' ], self . target_class_data [ 'methods' ]) text = ' \\t ' for field in final_fields : text += field . text + ' \\n ' for constructor in final_constructors : text += constructor . text + ' \\n ' for method in final_methods : text += method . text + ' \\n ' self . token_stream_rewriter . insertBeforeIndex ( index = ctx . stop . tokenIndex , text = text ) self . is_complete = True else : self . is_target_class = False elif self . is_source_class : if ctx . parentCtx . classOrInterfaceModifier ( 0 ) is None : return self . is_source_class = False self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . parentCtx . classOrInterfaceModifier ( 0 ) . start . tokenIndex , to_idx = ctx . stop . tokenIndex ) def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_source_class : self . code += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex + 1 , stop = ctx . stop . tokenIndex - 1 ) self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . parentCtx . start . tokenIndex , to_idx = ctx . parentCtx . stop . tokenIndex ) else : return None def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . is_source_class or self . is_target_class : field_text = '' for child in ctx . children : if child . getText () == ';' : field_text = field_text [: len ( field_text ) - 1 ] + ';' break field_text += child . getText () + ' ' name = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () if ctx . typeType () . classOrInterfaceType () is not None and \\ ctx . typeType () . classOrInterfaceType () . getText () == self . source_class : self . field_that_has_source . append ( name ) return modifier_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): modifier_text += modifier . getText () + ' ' field_text = modifier_text + field_text if self . is_source_class : self . source_class_data [ 'fields' ] . append ( Field ( name = name , text = field_text )) else : self . target_class_data [ 'fields' ] . append ( Field ( name = name , text = field_text )) def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . is_target_class : if ctx . typeType () . classOrInterfaceType () . getText () == self . source_class : grand_parent_ctx = ctx . parentCtx . parentCtx self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . start . tokenIndex , to_idx = grand_parent_ctx . stop . tokenIndex ) def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_source_class or self . is_target_class : if ctx . formalParameters () . formalParameterList (): constructor_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : constructor_parameters = [] constructor_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): constructor_text += modifier . getText () + ' ' if self . is_source_class : constructor_text += self . target_class else : constructor_text += ctx . IDENTIFIER () . getText () constructor_text += ' ( ' for parameter in constructor_parameters : constructor_text += parameter . typeType () . getText () + ' ' constructor_text += parameter . variableDeclaratorId () . getText () + ', ' if constructor_parameters : constructor_text = constructor_text [: len ( constructor_text ) - 2 ] constructor_text += ') \\n\\t {' constructor_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ) constructor_text += '} \\n ' if self . is_source_class : self . source_class_data [ 'constructors' ] . append ( ConstructorOrMethod ( name = self . target_class , parameters = [ Parameter ( parameter_type = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in constructor_parameters ], text = constructor_text , constructor_body = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ))) else : self . target_class_data [ 'constructors' ] . append ( ConstructorOrMethod ( name = self . target_class , parameters = [ Parameter ( parameter_type = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in constructor_parameters ], text = constructor_text , constructor_body = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ))) proper_constructor = get_proper_constructor ( self . target_class_data [ 'constructors' ][ - 1 ], self . source_class_data [ 'constructors' ]) if proper_constructor is None : return self . token_stream_rewriter . insertBeforeIndex ( index = ctx . stop . tokenIndex , text = proper_constructor . constructorBody ) def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_source_class or self . is_target_class : if ctx . formalParameters () . formalParameterList (): method_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : method_parameters = [] method_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): method_text += modifier . getText () + ' ' type_text = ctx . typeTypeOrVoid () . getText () if type_text == self . source_class : type_text = self . target_class if self . is_target_class : self . token_stream_rewriter . replace ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . typeTypeOrVoid () . start . tokenIndex , to_idx = ctx . typeTypeOrVoid () . stop . tokenIndex , text = type_text ) method_text += type_text + ' ' + ctx . IDENTIFIER () . getText () method_text += ' ( ' for parameter in method_parameters : method_text += parameter . typeType () . getText () + ' ' method_text += parameter . variableDeclaratorId () . getText () + ', ' if method_parameters : method_text = method_text [: len ( method_text ) - 2 ] method_text += ') \\n\\t {' method_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . methodBody () . start . tokenIndex + 1 , stop = ctx . methodBody () . stop . tokenIndex - 1 ) method_text += '} \\n ' if self . is_source_class : self . source_class_data [ 'methods' ] . append ( ConstructorOrMethod ( name = ctx . IDENTIFIER () . getText (), parameters = [ Parameter ( parameter_type = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in method_parameters ], text = method_text )) else : self . target_class_data [ 'methods' ] . append ( ConstructorOrMethod ( name = ctx . IDENTIFIER () . getText (), parameters = [ Parameter ( parameter_type = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in method_parameters ], text = method_text )) def enterExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): if ctx . IDENTIFIER () is None and ctx . IDENTIFIER () . getText () in self . field_that_has_source : field_text = ctx . expression () . getText () self . token_stream_rewriter . replace ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex , text = field_text ) def exitExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . has_source_new : self . has_source_new = False self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex + 1 ) def enterExpression4 ( self , ctx : JavaParserLabeled . Expression4Context ): if ctx . children [ - 1 ] . children [ 0 ] . getText () == self . source_class : self . has_source_new = True def enterCreatedName0 ( self , ctx : JavaParserLabeled . CreatedName0Context ): if ctx . IDENTIFIER ( 0 ) . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . target_class ) def enterCreatedName1 ( self , ctx : JavaParserLabeled . CreatedName1Context ): if ctx . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . target_class ) def enterFormalParameter ( self , ctx : JavaParserLabeled . FormalParameterContext ): class_type = ctx . typeType () . classOrInterfaceType () if class_type : if class_type . IDENTIFIER ( 0 ) . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = class_type . start . tokenIndex , text = self . target_class ) def enterQualifiedName ( self , ctx : JavaParserLabeled . QualifiedNameContext ): if ctx . IDENTIFIER ( 0 ) . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . target_class ) def exitExpression0 ( self , ctx : JavaParserLabeled . Expression0Context ): if ctx . primary () . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . target_class ) def enterLocalVariableDeclaration ( self , ctx : JavaParserLabeled . LocalVariableDeclarationContext ): if ctx . typeType () . classOrInterfaceType (): if ctx . typeType () . classOrInterfaceType () . getText () == self . source_class and self . target_class : self . token_stream_rewriter . replace ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . typeType () . start . tokenIndex , to_idx = ctx . typeType () . stop . tokenIndex , text = self . target_class )","title":"InlineClassRefactoringListener"},{"location":"refactorings/inline_class/#codart.refactorings.inline_class.InlineClassRefactoringListener.__init__","text":"Source code in codart\\refactorings\\inline_class.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class : str = None , source_class_data : dict = None , target_class : str = None , target_class_data : dict = None , is_complete : bool = False ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if source_class is None : raise ValueError ( \"source_class is None\" ) else : self . source_class = source_class if target_class is None : raise ValueError ( \"new_class is None\" ) else : self . target_class = target_class if target_class : self . target_class = target_class if source_class_data : self . source_class_data = source_class_data else : self . source_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} if target_class_data : self . target_class_data = target_class_data else : self . target_class_data = { 'fields' : [], 'methods' : [], 'constructors' : []} self . field_that_has_source = [] self . has_source_new = False self . is_complete = is_complete self . is_target_class = False self . is_source_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\"","title":"__init__()"},{"location":"refactorings/make_field_final/","text":"Make field final Introduction Add the \"final\" property / keyword to a field, so that it never changes once it is initialized. Pre and post-conditions Pre-conditions: User must enter the field's name and the name of the source class in order to make it final Check if the field exists, then make it final Post-conditions: The value of this field should never be changed in the project MakeFieldFinalRefactoringListener ( JavaParserLabeledListener ) The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and changes its status to final. Source code in codart\\refactorings\\make_field_final.py class MakeFieldFinalRefactoringListener ( JavaParserLabeledListener ): \"\"\" The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and changes its status to final. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using \\ the ANTLR parser generator. source_class (str): Name of the class in which the refactoring has to be done. field_name (str): Name of the field whose final status has to be changed. Returns: object (MakeFieldFinalRefactoringListener): An instance of MakeFieldFinalRefactoringListener. \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx # field_identifier = ctx.variableDeclarators().getText().split(\",\") field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () if self . field_name in field_identifier : if not grand_parent_ctx . modifier (): self . token_stream_rewriter . replaceRange ( from_idx = ctx . typeType () . start . tokenIndex , to_idx = ctx . typeType () . stop . tokenIndex , text = 'final ' + ctx . typeType () . getText () ) else : for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"final\" : self . is_final = True break if not self . is_final : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex , text = grand_parent_ctx . modifier ( 0 ) . getText () + ' final' ) __init__ ( self , common_token_stream = None , source_class = None , field_name = None ) special Parameters: Name Type Description Default common_token_stream CommonTokenStream A stream of tokens generated by parsing the main file using the ANTLR parser generator. None source_class str Name of the class in which the refactoring has to be done. None field_name str Name of the field whose final status has to be changed. None Returns: Type Description object (MakeFieldFinalRefactoringListener) An instance of MakeFieldFinalRefactoringListener. Source code in codart\\refactorings\\make_field_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using \\ the ANTLR parser generator. source_class (str): Name of the class in which the refactoring has to be done. field_name (str): Name of the field whose final status has to be changed. Returns: object (MakeFieldFinalRefactoringListener): An instance of MakeFieldFinalRefactoringListener. \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"Make field final"},{"location":"refactorings/make_field_final/#make-field-final","text":"","title":"Make field final"},{"location":"refactorings/make_field_final/#codart.refactorings.make_field_final--introduction","text":"Add the \"final\" property / keyword to a field, so that it never changes once it is initialized.","title":"Introduction"},{"location":"refactorings/make_field_final/#codart.refactorings.make_field_final--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_field_final/#codart.refactorings.make_field_final--pre-conditions","text":"User must enter the field's name and the name of the source class in order to make it final Check if the field exists, then make it final","title":"Pre-conditions:"},{"location":"refactorings/make_field_final/#codart.refactorings.make_field_final--post-conditions","text":"The value of this field should never be changed in the project","title":"Post-conditions:"},{"location":"refactorings/make_field_final/#codart.refactorings.make_field_final.MakeFieldFinalRefactoringListener","text":"The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and changes its status to final. Source code in codart\\refactorings\\make_field_final.py class MakeFieldFinalRefactoringListener ( JavaParserLabeledListener ): \"\"\" The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and changes its status to final. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using \\ the ANTLR parser generator. source_class (str): Name of the class in which the refactoring has to be done. field_name (str): Name of the field whose final status has to be changed. Returns: object (MakeFieldFinalRefactoringListener): An instance of MakeFieldFinalRefactoringListener. \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx # field_identifier = ctx.variableDeclarators().getText().split(\",\") field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () if self . field_name in field_identifier : if not grand_parent_ctx . modifier (): self . token_stream_rewriter . replaceRange ( from_idx = ctx . typeType () . start . tokenIndex , to_idx = ctx . typeType () . stop . tokenIndex , text = 'final ' + ctx . typeType () . getText () ) else : for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"final\" : self . is_final = True break if not self . is_final : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex , text = grand_parent_ctx . modifier ( 0 ) . getText () + ' final' )","title":"MakeFieldFinalRefactoringListener"},{"location":"refactorings/make_field_final/#codart.refactorings.make_field_final.MakeFieldFinalRefactoringListener.__init__","text":"Parameters: Name Type Description Default common_token_stream CommonTokenStream A stream of tokens generated by parsing the main file using the ANTLR parser generator. None source_class str Name of the class in which the refactoring has to be done. None field_name str Name of the field whose final status has to be changed. None Returns: Type Description object (MakeFieldFinalRefactoringListener) An instance of MakeFieldFinalRefactoringListener. Source code in codart\\refactorings\\make_field_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using \\ the ANTLR parser generator. source_class (str): Name of the class in which the refactoring has to be done. field_name (str): Name of the field whose final status has to be changed. Returns: object (MakeFieldFinalRefactoringListener): An instance of MakeFieldFinalRefactoringListener. \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"__init__()"},{"location":"refactorings/make_field_non_final/","text":"Make field non-final Introduction Remove the \"final\" property from a field, so that it can be changed after initialization. Pre and post-conditions Pre-conditions: User must enter the field's name and the name of the source class in order to make it non-final Check if the field exists, then make it non-final Post-conditions: No specific Post Condition MakeFieldNonFinalRefactoringListener ( JavaParserLabeledListener ) The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and removes the \"final\" keyword from its properties. Source code in codart\\refactorings\\make_field_non_final.py class MakeFieldNonFinalRefactoringListener ( JavaParserLabeledListener ): \"\"\" The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and removes the \"final\" keyword from its properties. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using the ANTLR parser generator source_class (str): Name of the class in which the refactoring has to be done field_name (str):Name of the field whose final status has to be changed Returns: object (MakeFieldNonFinalRefactoringListener): An instance of MakeFieldNonFinalRefactoringListener \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () print ( \"field_identifier :\" , field_identifier ) if self . field_name in field_identifier : if not ( grand_parent_ctx . modifier () == []): for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"final\" : self . is_final = True break print ( \"-----------------------\" , self . is_final ) if self . is_final : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( i ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( i ) . stop . tokenIndex , text = '' ) __init__ ( self , common_token_stream = None , source_class = None , field_name = None ) special Parameters: Name Type Description Default common_token_stream CommonTokenStream A stream of tokens generated by parsing the main file using the ANTLR parser generator None source_class str Name of the class in which the refactoring has to be done None field_name str Name of the field whose final status has to be changed None Returns: Type Description object (MakeFieldNonFinalRefactoringListener) An instance of MakeFieldNonFinalRefactoringListener Source code in codart\\refactorings\\make_field_non_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using the ANTLR parser generator source_class (str): Name of the class in which the refactoring has to be done field_name (str):Name of the field whose final status has to be changed Returns: object (MakeFieldNonFinalRefactoringListener): An instance of MakeFieldNonFinalRefactoringListener \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"Make field non-final"},{"location":"refactorings/make_field_non_final/#make-field-non-final","text":"","title":"Make field non-final"},{"location":"refactorings/make_field_non_final/#codart.refactorings.make_field_non_final--introduction","text":"Remove the \"final\" property from a field, so that it can be changed after initialization.","title":"Introduction"},{"location":"refactorings/make_field_non_final/#codart.refactorings.make_field_non_final--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_field_non_final/#codart.refactorings.make_field_non_final--pre-conditions","text":"User must enter the field's name and the name of the source class in order to make it non-final Check if the field exists, then make it non-final","title":"Pre-conditions:"},{"location":"refactorings/make_field_non_final/#codart.refactorings.make_field_non_final--post-conditions","text":"No specific Post Condition","title":"Post-conditions:"},{"location":"refactorings/make_field_non_final/#codart.refactorings.make_field_non_final.MakeFieldNonFinalRefactoringListener","text":"The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and removes the \"final\" keyword from its properties. Source code in codart\\refactorings\\make_field_non_final.py class MakeFieldNonFinalRefactoringListener ( JavaParserLabeledListener ): \"\"\" The Main listener which parses the file based on the provided information using ANTLR parser generator and tokenization methods. Detects the desired field and removes the \"final\" keyword from its properties. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using the ANTLR parser generator source_class (str): Name of the class in which the refactoring has to be done field_name (str):Name of the field whose final status has to be changed Returns: object (MakeFieldNonFinalRefactoringListener): An instance of MakeFieldNonFinalRefactoringListener \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () print ( \"field_identifier :\" , field_identifier ) if self . field_name in field_identifier : if not ( grand_parent_ctx . modifier () == []): for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"final\" : self . is_final = True break print ( \"-----------------------\" , self . is_final ) if self . is_final : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( i ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( i ) . stop . tokenIndex , text = '' )","title":"MakeFieldNonFinalRefactoringListener"},{"location":"refactorings/make_field_non_final/#codart.refactorings.make_field_non_final.MakeFieldNonFinalRefactoringListener.__init__","text":"Parameters: Name Type Description Default common_token_stream CommonTokenStream A stream of tokens generated by parsing the main file using the ANTLR parser generator None source_class str Name of the class in which the refactoring has to be done None field_name str Name of the field whose final status has to be changed None Returns: Type Description object (MakeFieldNonFinalRefactoringListener) An instance of MakeFieldNonFinalRefactoringListener Source code in codart\\refactorings\\make_field_non_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): A stream of tokens generated by parsing the main file using the ANTLR parser generator source_class (str): Name of the class in which the refactoring has to be done field_name (str):Name of the field whose final status has to be changed Returns: object (MakeFieldNonFinalRefactoringListener): An instance of MakeFieldNonFinalRefactoringListener \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"__init__()"},{"location":"refactorings/make_field_non_static/","text":"Make field non-static Introduction Make static field non-static refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeFieldNonStaticRefactoringListener ( JavaParserLabeledListener ) To implement Make static field non-static refactoring operation based on its actors. Source code in codart\\refactorings\\make_field_non_static.py class MakeFieldNonStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make static field non-static refactoring operation based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx # field_identifier = ctx.variableDeclarators().getText().split(\",\") field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () if self . field_name in field_identifier : i = 0 if not ( grand_parent_ctx . modifier () == []): for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"static\" : self . is_static = True break if self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( i ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( i ) . stop . tokenIndex , text = '' ) __init__ ( self , common_token_stream = None , source_class = None , field_name = None ) special Source code in codart\\refactorings\\make_field_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False main ( udb_path , source_class , field_name , * args , ** kwargs ) Main API for make field non-static Source code in codart\\refactorings\\make_field_non_static.py def main ( udb_path , source_class , field_name , * args , ** kwargs ): \"\"\" Main API for make field non-static \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeFieldNonStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , field_name = field_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"Make field non-static"},{"location":"refactorings/make_field_non_static/#make-field-non-static","text":"","title":"Make field non-static"},{"location":"refactorings/make_field_non_static/#codart.refactorings.make_field_non_static--introduction","text":"Make static field non-static refactoring operation","title":"Introduction"},{"location":"refactorings/make_field_non_static/#codart.refactorings.make_field_non_static--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_field_non_static/#codart.refactorings.make_field_non_static--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_field_non_static/#codart.refactorings.make_field_non_static--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_field_non_static/#codart.refactorings.make_field_non_static.MakeFieldNonStaticRefactoringListener","text":"To implement Make static field non-static refactoring operation based on its actors. Source code in codart\\refactorings\\make_field_non_static.py class MakeFieldNonStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make static field non-static refactoring operation based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx # field_identifier = ctx.variableDeclarators().getText().split(\",\") field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () if self . field_name in field_identifier : i = 0 if not ( grand_parent_ctx . modifier () == []): for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"static\" : self . is_static = True break if self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( i ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( i ) . stop . tokenIndex , text = '' )","title":"MakeFieldNonStaticRefactoringListener"},{"location":"refactorings/make_field_non_static/#codart.refactorings.make_field_non_static.MakeFieldNonStaticRefactoringListener.__init__","text":"Source code in codart\\refactorings\\make_field_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_field_non_static/#codart.refactorings.make_field_non_static.main","text":"Main API for make field non-static Source code in codart\\refactorings\\make_field_non_static.py def main ( udb_path , source_class , field_name , * args , ** kwargs ): \"\"\" Main API for make field non-static \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeFieldNonStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , field_name = field_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_field_static/","text":"Make field static Introduction Make static field static refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeFieldStaticRefactoringListener ( JavaParserLabeledListener ) To implement make field static refactoring based on its actors. Source code in codart\\refactorings\\make_field_static.py class MakeFieldStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement make field static refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx # field_identifier = ctx.variableDeclarators().getText().split(\",\") field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () if self . field_name in field_identifier : if grand_parent_ctx . modifier () == []: self . token_stream_rewriter . replaceRange ( from_idx = ctx . typeType () . start . tokenIndex , to_idx = ctx . typeType () . stop . tokenIndex , text = 'static ' + ctx . typeType () . getText () ) else : for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"static\" : self . is_static = True break if not self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex , text = grand_parent_ctx . modifier ( 0 ) . getText () + ' static' ) __init__ ( self , common_token_stream = None , source_class = None , field_name = None ) special Source code in codart\\refactorings\\make_field_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False main ( udb_path , source_class , field_name , * args , ** kwargs ) The main API for make field static Source code in codart\\refactorings\\make_field_static.py def main ( udb_path , source_class , field_name , * args , ** kwargs ): \"\"\" The main API for make field static \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeFieldStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , field_name = field_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"Make field static"},{"location":"refactorings/make_field_static/#make-field-static","text":"","title":"Make field static"},{"location":"refactorings/make_field_static/#codart.refactorings.make_field_static--introduction","text":"Make static field static refactoring operation","title":"Introduction"},{"location":"refactorings/make_field_static/#codart.refactorings.make_field_static--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_field_static/#codart.refactorings.make_field_static--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_field_static/#codart.refactorings.make_field_static--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_field_static/#codart.refactorings.make_field_static.MakeFieldStaticRefactoringListener","text":"To implement make field static refactoring based on its actors. Source code in codart\\refactorings\\make_field_static.py class MakeFieldStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement make field static refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx # field_identifier = ctx.variableDeclarators().getText().split(\",\") field_identifier = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . IDENTIFIER () . getText () if self . field_name in field_identifier : if grand_parent_ctx . modifier () == []: self . token_stream_rewriter . replaceRange ( from_idx = ctx . typeType () . start . tokenIndex , to_idx = ctx . typeType () . stop . tokenIndex , text = 'static ' + ctx . typeType () . getText () ) else : for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"static\" : self . is_static = True break if not self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex , text = grand_parent_ctx . modifier ( 0 ) . getText () + ' static' )","title":"MakeFieldStaticRefactoringListener"},{"location":"refactorings/make_field_static/#codart.refactorings.make_field_static.MakeFieldStaticRefactoringListener.__init__","text":"Source code in codart\\refactorings\\make_field_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , field_name : str = None ): \"\"\" \"\"\" if field_name is None : self . field_name = \"\" else : self . field_name = field_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_field_static/#codart.refactorings.make_field_static.main","text":"The main API for make field static Source code in codart\\refactorings\\make_field_static.py def main ( udb_path , source_class , field_name , * args , ** kwargs ): \"\"\" The main API for make field static \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeFieldStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , field_name = field_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_method_final/","text":"Make method final Introduction Make method final refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodFinalRefactoringListener ( JavaParserLabeledListener ) To implement Make method final refactoring based on its actors. Source code in codart\\refactorings\\make_method_final.py class MakeMethodFinalRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make method final refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx method_identifier = ctx . IDENTIFIER () . getText () if self . method_name in method_identifier : if grand_parent_ctx . modifier () == []: self . token_stream_rewriter . replaceRange ( from_idx = ctx . typeTypeOrVoid () . start . tokenIndex , to_idx = ctx . typeTypeOrVoid () . stop . tokenIndex , text = 'final ' + ctx . typeTypeOrVoid () . getText () ) else : for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"final\" : self . is_static = True break if not self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex , text = grand_parent_ctx . modifier ( 0 ) . getText () + ' final' ) __init__ ( self , common_token_stream = None , source_class = None , method_name = None ) special Source code in codart\\refactorings\\make_method_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"Make method final"},{"location":"refactorings/make_method_final/#make-method-final","text":"","title":"Make method final"},{"location":"refactorings/make_method_final/#codart.refactorings.make_method_final--introduction","text":"Make method final refactoring operation","title":"Introduction"},{"location":"refactorings/make_method_final/#codart.refactorings.make_method_final--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_final/#codart.refactorings.make_method_final--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_final/#codart.refactorings.make_method_final--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_final/#codart.refactorings.make_method_final.MakeMethodFinalRefactoringListener","text":"To implement Make method final refactoring based on its actors. Source code in codart\\refactorings\\make_method_final.py class MakeMethodFinalRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make method final refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx method_identifier = ctx . IDENTIFIER () . getText () if self . method_name in method_identifier : if grand_parent_ctx . modifier () == []: self . token_stream_rewriter . replaceRange ( from_idx = ctx . typeTypeOrVoid () . start . tokenIndex , to_idx = ctx . typeTypeOrVoid () . stop . tokenIndex , text = 'final ' + ctx . typeTypeOrVoid () . getText () ) else : for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"final\" : self . is_static = True break if not self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex , text = grand_parent_ctx . modifier ( 0 ) . getText () + ' final' )","title":"MakeMethodFinalRefactoringListener"},{"location":"refactorings/make_method_final/#codart.refactorings.make_method_final.MakeMethodFinalRefactoringListener.__init__","text":"Source code in codart\\refactorings\\make_method_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_method_non_final/","text":"Make method non-final Introduction Make method non-final refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodNonFinalRefactoringListener ( JavaParserLabeledListener ) To implement Make Method Non-Final refactoring based on its actors. Source code in codart\\refactorings\\make_method_non_final.py class MakeMethodNonFinalRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make Method Non-Final refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx method_identifier = ctx . IDENTIFIER () . getText () if self . method_name in method_identifier : if not ( grand_parent_ctx . modifier () == []): for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"final\" : self . is_final = True break if self . is_final : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( i ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( i ) . stop . tokenIndex , text = '' ) __init__ ( self , common_token_stream = None , source_class = None , method_name = None ) special Source code in codart\\refactorings\\make_method_non_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"Make method non-final"},{"location":"refactorings/make_method_non_final/#make-method-non-final","text":"","title":"Make method non-final"},{"location":"refactorings/make_method_non_final/#codart.refactorings.make_method_non_final--introduction","text":"Make method non-final refactoring operation","title":"Introduction"},{"location":"refactorings/make_method_non_final/#codart.refactorings.make_method_non_final--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_non_final/#codart.refactorings.make_method_non_final--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_non_final/#codart.refactorings.make_method_non_final--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_non_final/#codart.refactorings.make_method_non_final.MakeMethodNonFinalRefactoringListener","text":"To implement Make Method Non-Final refactoring based on its actors. Source code in codart\\refactorings\\make_method_non_final.py class MakeMethodNonFinalRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make Method Non-Final refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx method_identifier = ctx . IDENTIFIER () . getText () if self . method_name in method_identifier : if not ( grand_parent_ctx . modifier () == []): for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"final\" : self . is_final = True break if self . is_final : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( i ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( i ) . stop . tokenIndex , text = '' )","title":"MakeMethodNonFinalRefactoringListener"},{"location":"refactorings/make_method_non_final/#codart.refactorings.make_method_non_final.MakeMethodNonFinalRefactoringListener.__init__","text":"Source code in codart\\refactorings\\make_method_non_final.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_final = False","title":"__init__()"},{"location":"refactorings/make_method_non_static/","text":"Make method non-static Introduction The module implements make method non-static refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ) To implement Make Method None-Static refactoring based on its actors. Source code in codart\\refactorings\\make_method_non_static.py class MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make Method None-Static refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . target_class : self . is_target_class = True self . target_class_data = { 'constructors' : []} else : self . is_target_class = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_target_class : have_default_constructor = False for constructor in self . target_class_data [ 'constructor' ]: if len ( constructor . parameters ) == 0 : have_default_constructor = True break if not have_default_constructor : self . token_stream_rewriter . insertBeforeIndex ( index = ctx . stop . tokenIndex - 1 , text = f ' \\n\\t public { self . target_class_data [ \"constructors\" ][ 0 ] } () \\n\\t{{}}\\n ' ) self . is_target_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_target_class : if ctx . IDENTIFIER () . getText () in self . target_methods : grand_parent_ctx = ctx . parentCtx . parentCtx if grand_parent_ctx . modifier (): if len ( grand_parent_ctx . modifier ()) == 2 : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . modifier ( 1 ) . start . tokenIndex - 1 , to_idx = grand_parent_ctx . modifier ( 1 ) . stop . tokenIndex ) else : if grand_parent_ctx . modifier ( 0 ) . getText () == 'static' : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex - 1 , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex ) else : return None def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_target_class : if ctx . formalParameters () . formalParameterList (): constructor_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : constructor_parameters = [] constructor_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): constructor_text += modifier . getText () + ' ' constructor_text += ctx . IDENTIFIER () . getText () constructor_text += ' ( ' for parameter in constructor_parameters : constructor_text += parameter . typeType () . getText () + ' ' constructor_text += parameter . variableDeclaratorId () . getText () + ', ' if constructor_parameters : constructor_text = constructor_text [: len ( constructor_text ) - 2 ] constructor_text += ') \\n\\t {' constructor_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ) constructor_text += '} \\n ' self . target_class_data [ 'constructors' ] . append ( ConstructorOrMethod ( name = self . target_class , parameters = [ Parameter ( parameterType = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in constructor_parameters ], text = constructor_text )) __init__ ( self , common_token_stream = None , target_class = None , target_methods = None ) special Source code in codart\\refactorings\\make_method_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" main ( udb_path , target_class , target_methods ) Source code in codart\\refactorings\\make_method_non_static.py def main ( udb_path , target_class , target_methods ): \"\"\" \"\"\" main_file = None db = understand . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == target_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , target_class = target_class , target_methods = target_methods ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True Introduction The module implements a light-weight version of make method non-static refactoring operation described in make_method_non_static . Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ) To implement Make Method Non-Static refactoring based on its actors (version 2). Source code in codart\\refactorings\\make_method_non_static2.py class MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make Method Non-Static refactoring based on its actors (version 2). \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return grand_parent_ctx = ctx . parentCtx . parentCtx method_identifier = ctx . IDENTIFIER () . getText () if self . method_name in method_identifier : if not hasattr ( grand_parent_ctx , \"modifier\" ): return if not ( grand_parent_ctx . modifier () == []): i = 0 for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"static\" : self . is_static = True break if self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( i ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( i ) . stop . tokenIndex , text = '' ) __init__ ( self , common_token_stream = None , source_class = None , method_name = None ) special Source code in codart\\refactorings\\make_method_non_static2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False main ( udb_path = None , source_class = None , method_name = None , * args , ** kwargs ) Source code in codart\\refactorings\\make_method_non_static2.py def main ( udb_path = None , source_class = None , method_name = None , * args , ** kwargs ): \"\"\" \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . parent () is not None : if cls . simplename () == source_class : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , method_name = method_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"Make method non-static"},{"location":"refactorings/make_method_non_static/#make-method-non-static","text":"","title":"Make method non-static"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static--introduction","text":"The module implements make method non-static refactoring operation","title":"Introduction"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static.MakeMethodNonStaticRefactoringListener","text":"To implement Make Method None-Static refactoring based on its actors. Source code in codart\\refactorings\\make_method_non_static.py class MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make Method None-Static refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . target_class : self . is_target_class = True self . target_class_data = { 'constructors' : []} else : self . is_target_class = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_target_class : have_default_constructor = False for constructor in self . target_class_data [ 'constructor' ]: if len ( constructor . parameters ) == 0 : have_default_constructor = True break if not have_default_constructor : self . token_stream_rewriter . insertBeforeIndex ( index = ctx . stop . tokenIndex - 1 , text = f ' \\n\\t public { self . target_class_data [ \"constructors\" ][ 0 ] } () \\n\\t{{}}\\n ' ) self . is_target_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_target_class : if ctx . IDENTIFIER () . getText () in self . target_methods : grand_parent_ctx = ctx . parentCtx . parentCtx if grand_parent_ctx . modifier (): if len ( grand_parent_ctx . modifier ()) == 2 : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . modifier ( 1 ) . start . tokenIndex - 1 , to_idx = grand_parent_ctx . modifier ( 1 ) . stop . tokenIndex ) else : if grand_parent_ctx . modifier ( 0 ) . getText () == 'static' : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex - 1 , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex ) else : return None def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_target_class : if ctx . formalParameters () . formalParameterList (): constructor_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : constructor_parameters = [] constructor_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): constructor_text += modifier . getText () + ' ' constructor_text += ctx . IDENTIFIER () . getText () constructor_text += ' ( ' for parameter in constructor_parameters : constructor_text += parameter . typeType () . getText () + ' ' constructor_text += parameter . variableDeclaratorId () . getText () + ', ' if constructor_parameters : constructor_text = constructor_text [: len ( constructor_text ) - 2 ] constructor_text += ') \\n\\t {' constructor_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ) constructor_text += '} \\n ' self . target_class_data [ 'constructors' ] . append ( ConstructorOrMethod ( name = self . target_class , parameters = [ Parameter ( parameterType = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in constructor_parameters ], text = constructor_text ))","title":"MakeMethodNonStaticRefactoringListener"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static.MakeMethodNonStaticRefactoringListener.__init__","text":"Source code in codart\\refactorings\\make_method_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\"","title":"__init__()"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static.main","text":"Source code in codart\\refactorings\\make_method_non_static.py def main ( udb_path , target_class , target_methods ): \"\"\" \"\"\" main_file = None db = understand . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == target_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , target_class = target_class , target_methods = target_methods ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static2--introduction","text":"The module implements a light-weight version of make method non-static refactoring operation described in make_method_non_static .","title":"Introduction"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static2--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static2.MakeMethodNonStaticRefactoringListener","text":"To implement Make Method Non-Static refactoring based on its actors (version 2). Source code in codart\\refactorings\\make_method_non_static2.py class MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make Method Non-Static refactoring based on its actors (version 2). \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return grand_parent_ctx = ctx . parentCtx . parentCtx method_identifier = ctx . IDENTIFIER () . getText () if self . method_name in method_identifier : if not hasattr ( grand_parent_ctx , \"modifier\" ): return if not ( grand_parent_ctx . modifier () == []): i = 0 for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == \"static\" : self . is_static = True break if self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( i ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( i ) . stop . tokenIndex , text = '' )","title":"MakeMethodNonStaticRefactoringListener"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static2.MakeMethodNonStaticRefactoringListener.__init__","text":"Source code in codart\\refactorings\\make_method_non_static2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_method_non_static/#codart.refactorings.make_method_non_static2.main","text":"Source code in codart\\refactorings\\make_method_non_static2.py def main ( udb_path = None , source_class = None , method_name = None , * args , ** kwargs ): \"\"\" \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . parent () is not None : if cls . simplename () == source_class : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , method_name = method_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_method_static/","text":"Make method static Introduction The module implements make method non-static refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ) To implement Make Method None-Static refactoring based on its actors. Source code in codart\\refactorings\\make_method_non_static.py class MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make Method None-Static refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . target_class : self . is_target_class = True self . target_class_data = { 'constructors' : []} else : self . is_target_class = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_target_class : have_default_constructor = False for constructor in self . target_class_data [ 'constructor' ]: if len ( constructor . parameters ) == 0 : have_default_constructor = True break if not have_default_constructor : self . token_stream_rewriter . insertBeforeIndex ( index = ctx . stop . tokenIndex - 1 , text = f ' \\n\\t public { self . target_class_data [ \"constructors\" ][ 0 ] } () \\n\\t{{}}\\n ' ) self . is_target_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_target_class : if ctx . IDENTIFIER () . getText () in self . target_methods : grand_parent_ctx = ctx . parentCtx . parentCtx if grand_parent_ctx . modifier (): if len ( grand_parent_ctx . modifier ()) == 2 : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . modifier ( 1 ) . start . tokenIndex - 1 , to_idx = grand_parent_ctx . modifier ( 1 ) . stop . tokenIndex ) else : if grand_parent_ctx . modifier ( 0 ) . getText () == 'static' : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex - 1 , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex ) else : return None def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_target_class : if ctx . formalParameters () . formalParameterList (): constructor_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : constructor_parameters = [] constructor_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): constructor_text += modifier . getText () + ' ' constructor_text += ctx . IDENTIFIER () . getText () constructor_text += ' ( ' for parameter in constructor_parameters : constructor_text += parameter . typeType () . getText () + ' ' constructor_text += parameter . variableDeclaratorId () . getText () + ', ' if constructor_parameters : constructor_text = constructor_text [: len ( constructor_text ) - 2 ] constructor_text += ') \\n\\t {' constructor_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ) constructor_text += '} \\n ' self . target_class_data [ 'constructors' ] . append ( ConstructorOrMethod ( name = self . target_class , parameters = [ Parameter ( parameterType = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in constructor_parameters ], text = constructor_text )) __init__ ( self , common_token_stream = None , target_class = None , target_methods = None ) special Source code in codart\\refactorings\\make_method_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" main ( udb_path , target_class , target_methods ) Source code in codart\\refactorings\\make_method_non_static.py def main ( udb_path , target_class , target_methods ): \"\"\" \"\"\" main_file = None db = understand . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == target_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , target_class = target_class , target_methods = target_methods ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True Make method static 2 Introduction The module implements a light-weight version of make method static refactoring operation described in make_method_static . Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MakeMethodStaticRefactoringListener ( JavaParserLabeledListener ) To implement make method static (version 2). Source code in codart\\refactorings\\make_method_static2.py class MakeMethodStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement make method static (version 2). \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx method_identifier = ctx . IDENTIFIER () . getText () if self . method_name in method_identifier : if grand_parent_ctx . modifier () is None or len ( grand_parent_ctx . modifier ()) == 0 : self . token_stream_rewriter . replaceRange ( from_idx = ctx . typeTypeOrVoid () . start . tokenIndex , to_idx = ctx . typeTypeOrVoid () . stop . tokenIndex , text = 'static ' + ctx . typeTypeOrVoid () . getText () ) else : for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == 'static' : self . is_static = True break if not self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex , text = grand_parent_ctx . modifier ( 0 ) . getText () + ' static' ) __init__ ( self , common_token_stream = None , source_class = None , method_name = None ) special Source code in codart\\refactorings\\make_method_static2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False main ( udb_path , source_class , method_name , * args , ** kwargs ) Source code in codart\\refactorings\\make_method_static2.py def main ( udb_path , source_class , method_name , * args , ** kwargs ): \"\"\" \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , method_name = method_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"Make method static"},{"location":"refactorings/make_method_static/#make-method-static","text":"","title":"Make method static"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_non_static--introduction","text":"The module implements make method non-static refactoring operation","title":"Introduction"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_non_static--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_non_static--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_non_static--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_non_static.MakeMethodNonStaticRefactoringListener","text":"To implement Make Method None-Static refactoring based on its actors. Source code in codart\\refactorings\\make_method_non_static.py class MakeMethodNonStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement Make Method None-Static refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . target_class : self . is_target_class = True self . target_class_data = { 'constructors' : []} else : self . is_target_class = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_target_class : have_default_constructor = False for constructor in self . target_class_data [ 'constructor' ]: if len ( constructor . parameters ) == 0 : have_default_constructor = True break if not have_default_constructor : self . token_stream_rewriter . insertBeforeIndex ( index = ctx . stop . tokenIndex - 1 , text = f ' \\n\\t public { self . target_class_data [ \"constructors\" ][ 0 ] } () \\n\\t{{}}\\n ' ) self . is_target_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_target_class : if ctx . IDENTIFIER () . getText () in self . target_methods : grand_parent_ctx = ctx . parentCtx . parentCtx if grand_parent_ctx . modifier (): if len ( grand_parent_ctx . modifier ()) == 2 : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . modifier ( 1 ) . start . tokenIndex - 1 , to_idx = grand_parent_ctx . modifier ( 1 ) . stop . tokenIndex ) else : if grand_parent_ctx . modifier ( 0 ) . getText () == 'static' : self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex - 1 , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex ) else : return None def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_target_class : if ctx . formalParameters () . formalParameterList (): constructor_parameters = [ ctx . formalParameters () . formalParameterList () . children [ i ] for i in range ( len ( ctx . formalParameters () . formalParameterList () . children )) if i % 2 == 0 ] else : constructor_parameters = [] constructor_text = '' for modifier in ctx . parentCtx . parentCtx . modifier (): constructor_text += modifier . getText () + ' ' constructor_text += ctx . IDENTIFIER () . getText () constructor_text += ' ( ' for parameter in constructor_parameters : constructor_text += parameter . typeType () . getText () + ' ' constructor_text += parameter . variableDeclaratorId () . getText () + ', ' if constructor_parameters : constructor_text = constructor_text [: len ( constructor_text ) - 2 ] constructor_text += ') \\n\\t {' constructor_text += self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = ctx . block () . start . tokenIndex + 1 , stop = ctx . block () . stop . tokenIndex - 1 ) constructor_text += '} \\n ' self . target_class_data [ 'constructors' ] . append ( ConstructorOrMethod ( name = self . target_class , parameters = [ Parameter ( parameterType = p . typeType () . getText (), name = p . variableDeclaratorId () . IDENTIFIER () . getText ()) for p in constructor_parameters ], text = constructor_text ))","title":"MakeMethodNonStaticRefactoringListener"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_non_static.MakeMethodNonStaticRefactoringListener.__init__","text":"Source code in codart\\refactorings\\make_method_non_static.py def __init__ ( self , common_token_stream : CommonTokenStream = None , target_class : str = None , target_methods : list = None ): \"\"\" \"\"\" if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if target_class is None : raise ValueError ( \"source_class is None\" ) else : self . target_class = target_class if target_methods is None or len ( target_methods ) == 0 : raise ValueError ( \"target method must have one method name\" ) else : self . target_methods = target_methods self . target_class_data = None self . is_target_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\"","title":"__init__()"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_non_static.main","text":"Source code in codart\\refactorings\\make_method_non_static.py def main ( udb_path , target_class , target_methods ): \"\"\" \"\"\" main_file = None db = understand . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == target_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodNonStaticRefactoringListener ( common_token_stream = token_stream , target_class = target_class , target_methods = target_methods ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/make_method_static/#make-method-static-2","text":"","title":"Make method static 2"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_static2--introduction","text":"The module implements a light-weight version of make method static refactoring operation described in make_method_static .","title":"Introduction"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_static2--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_static2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_static2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_static2.MakeMethodStaticRefactoringListener","text":"To implement make method static (version 2). Source code in codart\\refactorings\\make_method_static2.py class MakeMethodStaticRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement make method static (version 2). \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier == self . source_class : self . is_source_class = True else : self . is_source_class = False def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if not self . is_source_class : return None grand_parent_ctx = ctx . parentCtx . parentCtx method_identifier = ctx . IDENTIFIER () . getText () if self . method_name in method_identifier : if grand_parent_ctx . modifier () is None or len ( grand_parent_ctx . modifier ()) == 0 : self . token_stream_rewriter . replaceRange ( from_idx = ctx . typeTypeOrVoid () . start . tokenIndex , to_idx = ctx . typeTypeOrVoid () . stop . tokenIndex , text = 'static ' + ctx . typeTypeOrVoid () . getText () ) else : for i in range ( 0 , len ( grand_parent_ctx . modifier ())): if grand_parent_ctx . modifier ( i ) . getText () == 'static' : self . is_static = True break if not self . is_static : self . token_stream_rewriter . replaceRange ( from_idx = grand_parent_ctx . modifier ( 0 ) . start . tokenIndex , to_idx = grand_parent_ctx . modifier ( 0 ) . stop . tokenIndex , text = grand_parent_ctx . modifier ( 0 ) . getText () + ' static' )","title":"MakeMethodStaticRefactoringListener"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_static2.MakeMethodStaticRefactoringListener.__init__","text":"Source code in codart\\refactorings\\make_method_static2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , source_class = None , method_name : str = None ): \"\"\" \"\"\" if method_name is None : self . method_name = \"\" else : self . method_name = method_name if source_class is None : self . source_class = \"\" else : self . source_class = source_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_source_class = False self . is_static = False","title":"__init__()"},{"location":"refactorings/make_method_static/#codart.refactorings.make_method_static2.main","text":"Source code in codart\\refactorings\\make_method_static2.py def main ( udb_path , source_class , method_name , * args , ** kwargs ): \"\"\" \"\"\" main_file = None db = und . open ( udb_path ) classes = db . ents ( \"Class\" ) for cls in classes : if cls . simplename () == source_class : if cls . parent () is not None : temp_file = str ( cls . parent () . longname ( True )) if os . path . isfile ( temp_file ): main_file = temp_file break if main_file is None : db . close () return False db . close () stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = MakeMethodStaticRefactoringListener ( common_token_stream = token_stream , source_class = source_class , method_name = method_name ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) with open ( main_file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/move_class/","text":"Move class Introduction The module implements Move Class refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions MoveClassAPI Source code in codart\\refactorings\\move_class.py class MoveClassAPI : \"\"\" \"\"\" def __init__ ( self , udb_path : str , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . udb_path = udb_path self . source_package = source_package self . target_package = target_package self . class_name = class_name self . source_package_dir = None self . target_package_dir = None self . _class_current_path = None self . class_content = None self . usages = None self . _class_new_path = None def check_preconditions ( self ) -> bool : if self . source_package == self . target_package : config . logger . error ( \"Source and target packages are same.\" ) return False if self . source_package == ROOT_PACKAGE or self . target_package == ROOT_PACKAGE : config . logger . error ( \"Can not move package to/from root package.\" ) return False # Get package directories source_package_dir , target_package_dir = self . get_package_directories () if source_package_dir is None or target_package_dir is None : config . logger . error ( \"Package entity does not exists.\" ) return False if config . PROJECT_PATH not in target_package_dir : config . logger . error ( f \"Target package address { target_package_dir } cannot be resolved.\" ) return False if config . PROJECT_PATH not in source_package_dir : config . logger . error ( f \"Source package address { source_package_dir } cannot be resolved.\" ) return False class_full_path = os . path . join ( source_package_dir , f \" { self . class_name } .java\" ) if not os . path . exists ( class_full_path ): config . logger . error ( f 'Class \" { self . class_name } \" does not exists in source package \" { source_package_dir } \" ' ) return False # Get class directory class_path , class_content , usages = self . get_class_info () if class_path is None or class_content is None : config . logger . error ( \"Class entity does not exists.\" ) return False class_new_path = os . path . join ( target_package_dir , f \" { self . class_name } .java\" ) if os . path . exists ( class_new_path ): config . logger . error ( \"Class already exists in target package.\" ) return False self . source_package_dir = source_package_dir self . target_package_dir = target_package_dir self . _class_current_path = class_path self . class_content = class_content self . usages = usages self . _class_new_path = class_new_path return True def get_package_directories ( self ): db = und . open ( self . udb_path ) source_package_path = None target_package_path = None packages = db . ents ( \"Java Package\" ) for ent_ in packages : if ent_ . longname () == self . source_package : if ent_ . parent () is not None : name_ = ent_ . parent () . longname () if os . path . exists ( name_ ): source_package_path = os . path . dirname ( name_ ) break for ent_ in packages : if ent_ . longname () == self . target_package : if ent_ . parent () is not None : name_ = ent_ . parent () . longname () if os . path . exists ( name_ ): target_package_path = os . path . dirname ( name_ ) break db . close () return source_package_path , target_package_path def get_class_info ( self ): db = und . open ( self . udb_path ) class_path = None class_contents = None usages = set () classes = db . ents ( \"Class ~Unresolved ~Unknown ~Anonymous\" ) for ent_ in classes : simple_name = ent_ . simplename () if simple_name == self . class_name and class_path is None and ent_ . parent () is not None : class_contents = ent_ . contents () class_path = ent_ . parent () . longname () for ref_ in ent_ . refs (): if ref_ . file () . simplename () != f \" { simple_name } .java\" : usages . add ( ref_ . file () . longname ()) break db . close () return class_path , class_contents , usages def do_refactor ( self ): if not self . check_preconditions (): config . logger . error ( \"Pre conditions failed.\" ) return False # Update usages for file_path in self . usages : parse_and_walk ( file_path = file_path , listener_class = UpdateImportsListener , has_write = True , source_package = self . source_package , target_package = self . target_package , class_name = self . class_name ) # Delete source class # config.logger.debug(f'Current class path to be removed: {self._class_current_path}') os . remove ( self . _class_current_path ) # Write the new class package = \"\" if self . target_package != ROOT_PACKAGE : package = f \"package { self . target_package } ; \\n \" imports = \"\" if self . source_package != ROOT_PACKAGE : imports = f \"import { self . source_package } .*; \\n \" # logger.debug(f'New class path to be added: {self._class_new_path}') with open ( self . _class_new_path , mode = 'w' , encoding = 'utf8' , errors = 'ignore' ) as f : f . write ( package + imports + self . class_content ) return True __init__ ( self , udb_path , source_package , target_package , class_name ) special Source code in codart\\refactorings\\move_class.py def __init__ ( self , udb_path : str , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . udb_path = udb_path self . source_package = source_package self . target_package = target_package self . class_name = class_name self . source_package_dir = None self . target_package_dir = None self . _class_current_path = None self . class_content = None self . usages = None self . _class_new_path = None UpdateImportsListener ( JavaParserLabeledListener ) Source code in codart\\refactorings\\move_class.py class UpdateImportsListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , rewriter : TokenStreamRewriter , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . rewriter = rewriter self . source_package = source_package self . target_package = target_package self . class_name = class_name self . current_package = None self . imported = False self . import_loc = None def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . current_package = ctx . qualifiedName () . getText () def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . import_loc = ctx . stop def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): # import source_package.Sample; if self . target_package in ctx . getText (): self . imported = True if self . class_name in ctx . getText (): if self . target_package == self . current_package : replace_text = \"\" else : replace_text = f \" \\n import { self . target_package } . { self . class_name } ; \\n \" self . rewriter . replaceRangeTokens ( from_token = ctx . start , to_token = ctx . stop , text = replace_text , program_name = self . rewriter . DEFAULT_PROGRAM_NAME ) elif f \" { self . source_package } . { self . class_name } \" in ctx . getText (): self . rewriter . delete ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex ) def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): if not self . imported and self . current_package != self . target_package : self . rewriter . insertAfterToken ( token = self . import_loc , text = f \" \\n import { self . target_package } . { self . class_name } ; \\n \" , program_name = self . rewriter . DEFAULT_PROGRAM_NAME ) __init__ ( self , rewriter , source_package , target_package , class_name ) special Source code in codart\\refactorings\\move_class.py def __init__ ( self , rewriter : TokenStreamRewriter , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . rewriter = rewriter self . source_package = source_package self . target_package = target_package self . class_name = class_name self . current_package = None self . imported = False self . import_loc = None main ( udb_path , source_package , target_package , class_name , * args , ** kwargs ) The main API for Move Class refactoring Source code in codart\\refactorings\\move_class.py def main ( udb_path : str , source_package : str , target_package : str , class_name : str , * args , ** kwargs ): \"\"\" The main API for Move Class refactoring \"\"\" move_class = MoveClassAPI ( udb_path , source_package , target_package , class_name ) res = move_class . do_refactor () return res","title":"Move class"},{"location":"refactorings/move_class/#move-class","text":"","title":"Move class"},{"location":"refactorings/move_class/#codart.refactorings.move_class--introduction","text":"The module implements Move Class refactoring operation","title":"Introduction"},{"location":"refactorings/move_class/#codart.refactorings.move_class--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/move_class/#codart.refactorings.move_class--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/move_class/#codart.refactorings.move_class--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/move_class/#codart.refactorings.move_class.MoveClassAPI","text":"Source code in codart\\refactorings\\move_class.py class MoveClassAPI : \"\"\" \"\"\" def __init__ ( self , udb_path : str , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . udb_path = udb_path self . source_package = source_package self . target_package = target_package self . class_name = class_name self . source_package_dir = None self . target_package_dir = None self . _class_current_path = None self . class_content = None self . usages = None self . _class_new_path = None def check_preconditions ( self ) -> bool : if self . source_package == self . target_package : config . logger . error ( \"Source and target packages are same.\" ) return False if self . source_package == ROOT_PACKAGE or self . target_package == ROOT_PACKAGE : config . logger . error ( \"Can not move package to/from root package.\" ) return False # Get package directories source_package_dir , target_package_dir = self . get_package_directories () if source_package_dir is None or target_package_dir is None : config . logger . error ( \"Package entity does not exists.\" ) return False if config . PROJECT_PATH not in target_package_dir : config . logger . error ( f \"Target package address { target_package_dir } cannot be resolved.\" ) return False if config . PROJECT_PATH not in source_package_dir : config . logger . error ( f \"Source package address { source_package_dir } cannot be resolved.\" ) return False class_full_path = os . path . join ( source_package_dir , f \" { self . class_name } .java\" ) if not os . path . exists ( class_full_path ): config . logger . error ( f 'Class \" { self . class_name } \" does not exists in source package \" { source_package_dir } \" ' ) return False # Get class directory class_path , class_content , usages = self . get_class_info () if class_path is None or class_content is None : config . logger . error ( \"Class entity does not exists.\" ) return False class_new_path = os . path . join ( target_package_dir , f \" { self . class_name } .java\" ) if os . path . exists ( class_new_path ): config . logger . error ( \"Class already exists in target package.\" ) return False self . source_package_dir = source_package_dir self . target_package_dir = target_package_dir self . _class_current_path = class_path self . class_content = class_content self . usages = usages self . _class_new_path = class_new_path return True def get_package_directories ( self ): db = und . open ( self . udb_path ) source_package_path = None target_package_path = None packages = db . ents ( \"Java Package\" ) for ent_ in packages : if ent_ . longname () == self . source_package : if ent_ . parent () is not None : name_ = ent_ . parent () . longname () if os . path . exists ( name_ ): source_package_path = os . path . dirname ( name_ ) break for ent_ in packages : if ent_ . longname () == self . target_package : if ent_ . parent () is not None : name_ = ent_ . parent () . longname () if os . path . exists ( name_ ): target_package_path = os . path . dirname ( name_ ) break db . close () return source_package_path , target_package_path def get_class_info ( self ): db = und . open ( self . udb_path ) class_path = None class_contents = None usages = set () classes = db . ents ( \"Class ~Unresolved ~Unknown ~Anonymous\" ) for ent_ in classes : simple_name = ent_ . simplename () if simple_name == self . class_name and class_path is None and ent_ . parent () is not None : class_contents = ent_ . contents () class_path = ent_ . parent () . longname () for ref_ in ent_ . refs (): if ref_ . file () . simplename () != f \" { simple_name } .java\" : usages . add ( ref_ . file () . longname ()) break db . close () return class_path , class_contents , usages def do_refactor ( self ): if not self . check_preconditions (): config . logger . error ( \"Pre conditions failed.\" ) return False # Update usages for file_path in self . usages : parse_and_walk ( file_path = file_path , listener_class = UpdateImportsListener , has_write = True , source_package = self . source_package , target_package = self . target_package , class_name = self . class_name ) # Delete source class # config.logger.debug(f'Current class path to be removed: {self._class_current_path}') os . remove ( self . _class_current_path ) # Write the new class package = \"\" if self . target_package != ROOT_PACKAGE : package = f \"package { self . target_package } ; \\n \" imports = \"\" if self . source_package != ROOT_PACKAGE : imports = f \"import { self . source_package } .*; \\n \" # logger.debug(f'New class path to be added: {self._class_new_path}') with open ( self . _class_new_path , mode = 'w' , encoding = 'utf8' , errors = 'ignore' ) as f : f . write ( package + imports + self . class_content ) return True","title":"MoveClassAPI"},{"location":"refactorings/move_class/#codart.refactorings.move_class.MoveClassAPI.__init__","text":"Source code in codart\\refactorings\\move_class.py def __init__ ( self , udb_path : str , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . udb_path = udb_path self . source_package = source_package self . target_package = target_package self . class_name = class_name self . source_package_dir = None self . target_package_dir = None self . _class_current_path = None self . class_content = None self . usages = None self . _class_new_path = None","title":"__init__()"},{"location":"refactorings/move_class/#codart.refactorings.move_class.UpdateImportsListener","text":"Source code in codart\\refactorings\\move_class.py class UpdateImportsListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , rewriter : TokenStreamRewriter , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . rewriter = rewriter self . source_package = source_package self . target_package = target_package self . class_name = class_name self . current_package = None self . imported = False self . import_loc = None def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . current_package = ctx . qualifiedName () . getText () def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . import_loc = ctx . stop def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): # import source_package.Sample; if self . target_package in ctx . getText (): self . imported = True if self . class_name in ctx . getText (): if self . target_package == self . current_package : replace_text = \"\" else : replace_text = f \" \\n import { self . target_package } . { self . class_name } ; \\n \" self . rewriter . replaceRangeTokens ( from_token = ctx . start , to_token = ctx . stop , text = replace_text , program_name = self . rewriter . DEFAULT_PROGRAM_NAME ) elif f \" { self . source_package } . { self . class_name } \" in ctx . getText (): self . rewriter . delete ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex ) def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): if not self . imported and self . current_package != self . target_package : self . rewriter . insertAfterToken ( token = self . import_loc , text = f \" \\n import { self . target_package } . { self . class_name } ; \\n \" , program_name = self . rewriter . DEFAULT_PROGRAM_NAME )","title":"UpdateImportsListener"},{"location":"refactorings/move_class/#codart.refactorings.move_class.UpdateImportsListener.__init__","text":"Source code in codart\\refactorings\\move_class.py def __init__ ( self , rewriter : TokenStreamRewriter , source_package : str , target_package : str , class_name : str ): \"\"\" \"\"\" self . rewriter = rewriter self . source_package = source_package self . target_package = target_package self . class_name = class_name self . current_package = None self . imported = False self . import_loc = None","title":"__init__()"},{"location":"refactorings/move_class/#codart.refactorings.move_class.main","text":"The main API for Move Class refactoring Source code in codart\\refactorings\\move_class.py def main ( udb_path : str , source_package : str , target_package : str , class_name : str , * args , ** kwargs ): \"\"\" The main API for Move Class refactoring \"\"\" move_class = MoveClassAPI ( udb_path , source_package , target_package , class_name ) res = move_class . do_refactor () return res","title":"main()"},{"location":"refactorings/move_field/","text":"Move field Introduction The module implements Move Field refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions CutFieldListener ( JavaParserLabeledListener ) Source code in codart\\refactorings\\move_field.py class CutFieldListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , class_name : str , instance_name : str , field_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . field_name = field_name self . is_static = is_static self . import_statement = import_statement self . rewriter = rewriter self . instance_name = instance_name self . instance_name = class_name . lower () + \"ByCodArt\" self . is_member = False self . do_delete = False self . field_text = \"\" def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . import_statement : self . rewriter . insertAfterToken ( token = ctx . stop , text = self . import_statement , program_name = self . rewriter . DEFAULT_PROGRAM_NAME ) self . import_statement = None def enterMemberDeclaration2 ( self , ctx : JavaParserLabeled . MemberDeclaration2Context ): self . is_member = True def exitMemberDeclaration2 ( self , ctx : JavaParserLabeled . MemberDeclaration2Context ): self . is_member = False def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): if self . is_member and ctx . IDENTIFIER () . getText () == self . field_name : self . do_delete = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . do_delete : self . field_text = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) if self . is_static : replace_text = f \"public static { self . class_name } { self . instance_name } = new { self . class_name } ();\" else : replace_text = f \"public { self . class_name } { self . instance_name } = new { self . class_name } ();\" self . rewriter . replace ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex , text = replace_text ) self . do_delete = False __init__ ( self , class_name , instance_name , field_name , is_static , import_statement , rewriter ) special Source code in codart\\refactorings\\move_field.py def __init__ ( self , class_name : str , instance_name : str , field_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . field_name = field_name self . is_static = is_static self . import_statement = import_statement self . rewriter = rewriter self . instance_name = instance_name self . instance_name = class_name . lower () + \"ByCodArt\" self . is_member = False self . do_delete = False self . field_text = \"\" main ( source_class , source_package , target_class , target_package , field_name , udb_path , * args , ** kwargs ) Move filed main API Source code in codart\\refactorings\\move_field.py def main ( source_class : str , source_package : str , target_class : str , target_package : str , field_name : str , udb_path : str , * args , ** kwargs ): \"\"\" Move filed main API \"\"\" import_statement = None if source_package != target_package : import_statement = f \" \\n import { target_package } . { target_class } ;\" instance_name = target_class . lower () + \"ByCodArt\" db = und . open ( udb_path ) # Check if field is static field_ent = db . lookup ( f \" { source_package } . { source_class } . { field_name } \" , \"Variable\" ) if len ( field_ent ) == 0 : logger . error ( f \"Entity not found with query: { source_package } . { source_class } . { field_name } .\" ) db . close () return False if source_package == target_package and source_class == target_class : logger . error ( \"Can not move to self.\" ) db . close () return False field_ent = field_ent [ 0 ] is_static = field_ent . kindname () == STATIC if is_static : logger . warning ( \"Field is static!\" ) # Find usages usages = {} for ref in field_ent . refs ( \"Setby, Useby\" ): file = ref . file () . longname () if file in usages : usages [ file ] . append ( ref . line ()) else : usages [ file ] = [ ref . line (), ] try : src_class_file = db . lookup ( f \" { source_package } . { source_class } .java\" )[ 0 ] . longname () target_class_file = db . lookup ( f \" { target_package } . { target_class } .java\" )[ 0 ] . longname () except IndexError : logger . error ( \"This is a nested class.\" ) logger . info ( f \" { source_package } . { source_class } .java\" ) logger . info ( f \" { target_package } . { target_class } .java\" ) db . close () return False db . close () # Check if there is an cycle listener = parse_and_walk ( file_path = target_class_file , listener_class = CheckCycleListener , class_name = source_class , ) if not listener . is_valid : logger . error ( f \"Can not move field because there is a cycle between { source_class } , { target_class } \" ) # db.close() return False # Propagate Changes for file in usages . keys (): parse_and_walk ( file_path = file , listener_class = PropagateListener , has_write = True , field_name = field_name , new_name = f \" { instance_name } . { field_name } \" , lines = usages [ file ], ) # Do the cut and paste! # Cut listener = parse_and_walk ( file_path = src_class_file , listener_class = CutFieldListener , has_write = True , class_name = target_class , instance_name = instance_name , field_name = field_name , is_static = is_static , import_statement = import_statement ) field_text = listener . field_text # Paste parse_and_walk ( file_path = target_class_file , listener_class = PasteFieldListener , has_write = True , field_text = field_text , ) # db.close() return True","title":"Mode field"},{"location":"refactorings/move_field/#move-field","text":"","title":"Move field"},{"location":"refactorings/move_field/#codart.refactorings.move_field--introduction","text":"The module implements Move Field refactoring operation","title":"Introduction"},{"location":"refactorings/move_field/#codart.refactorings.move_field--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/move_field/#codart.refactorings.move_field--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/move_field/#codart.refactorings.move_field--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/move_field/#codart.refactorings.move_field.CutFieldListener","text":"Source code in codart\\refactorings\\move_field.py class CutFieldListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , class_name : str , instance_name : str , field_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . field_name = field_name self . is_static = is_static self . import_statement = import_statement self . rewriter = rewriter self . instance_name = instance_name self . instance_name = class_name . lower () + \"ByCodArt\" self . is_member = False self . do_delete = False self . field_text = \"\" def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . import_statement : self . rewriter . insertAfterToken ( token = ctx . stop , text = self . import_statement , program_name = self . rewriter . DEFAULT_PROGRAM_NAME ) self . import_statement = None def enterMemberDeclaration2 ( self , ctx : JavaParserLabeled . MemberDeclaration2Context ): self . is_member = True def exitMemberDeclaration2 ( self , ctx : JavaParserLabeled . MemberDeclaration2Context ): self . is_member = False def enterVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): if self . is_member and ctx . IDENTIFIER () . getText () == self . field_name : self . do_delete = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . do_delete : self . field_text = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) if self . is_static : replace_text = f \"public static { self . class_name } { self . instance_name } = new { self . class_name } ();\" else : replace_text = f \"public { self . class_name } { self . instance_name } = new { self . class_name } ();\" self . rewriter . replace ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex , text = replace_text ) self . do_delete = False","title":"CutFieldListener"},{"location":"refactorings/move_field/#codart.refactorings.move_field.CutFieldListener.__init__","text":"Source code in codart\\refactorings\\move_field.py def __init__ ( self , class_name : str , instance_name : str , field_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . field_name = field_name self . is_static = is_static self . import_statement = import_statement self . rewriter = rewriter self . instance_name = instance_name self . instance_name = class_name . lower () + \"ByCodArt\" self . is_member = False self . do_delete = False self . field_text = \"\"","title":"__init__()"},{"location":"refactorings/move_field/#codart.refactorings.move_field.main","text":"Move filed main API Source code in codart\\refactorings\\move_field.py def main ( source_class : str , source_package : str , target_class : str , target_package : str , field_name : str , udb_path : str , * args , ** kwargs ): \"\"\" Move filed main API \"\"\" import_statement = None if source_package != target_package : import_statement = f \" \\n import { target_package } . { target_class } ;\" instance_name = target_class . lower () + \"ByCodArt\" db = und . open ( udb_path ) # Check if field is static field_ent = db . lookup ( f \" { source_package } . { source_class } . { field_name } \" , \"Variable\" ) if len ( field_ent ) == 0 : logger . error ( f \"Entity not found with query: { source_package } . { source_class } . { field_name } .\" ) db . close () return False if source_package == target_package and source_class == target_class : logger . error ( \"Can not move to self.\" ) db . close () return False field_ent = field_ent [ 0 ] is_static = field_ent . kindname () == STATIC if is_static : logger . warning ( \"Field is static!\" ) # Find usages usages = {} for ref in field_ent . refs ( \"Setby, Useby\" ): file = ref . file () . longname () if file in usages : usages [ file ] . append ( ref . line ()) else : usages [ file ] = [ ref . line (), ] try : src_class_file = db . lookup ( f \" { source_package } . { source_class } .java\" )[ 0 ] . longname () target_class_file = db . lookup ( f \" { target_package } . { target_class } .java\" )[ 0 ] . longname () except IndexError : logger . error ( \"This is a nested class.\" ) logger . info ( f \" { source_package } . { source_class } .java\" ) logger . info ( f \" { target_package } . { target_class } .java\" ) db . close () return False db . close () # Check if there is an cycle listener = parse_and_walk ( file_path = target_class_file , listener_class = CheckCycleListener , class_name = source_class , ) if not listener . is_valid : logger . error ( f \"Can not move field because there is a cycle between { source_class } , { target_class } \" ) # db.close() return False # Propagate Changes for file in usages . keys (): parse_and_walk ( file_path = file , listener_class = PropagateListener , has_write = True , field_name = field_name , new_name = f \" { instance_name } . { field_name } \" , lines = usages [ file ], ) # Do the cut and paste! # Cut listener = parse_and_walk ( file_path = src_class_file , listener_class = CutFieldListener , has_write = True , class_name = target_class , instance_name = instance_name , field_name = field_name , is_static = is_static , import_statement = import_statement ) field_text = listener . field_text # Paste parse_and_walk ( file_path = target_class_file , listener_class = PasteFieldListener , has_write = True , field_text = field_text , ) # db.close() return True","title":"main()"},{"location":"refactorings/move_method/","text":"Move method Introduction The module implements Move Method refactoring operation Pre and post-conditions Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions CutMethodListener ( JavaParserLabeledListener ) Source code in codart\\refactorings\\move_method.py class CutMethodListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , class_name : str , instance_name : str , method_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . method_name = method_name self . is_static = is_static self . rewriter = rewriter self . import_statement = import_statement self . instance_name = instance_name self . is_member = False self . do_delete = False self . method_text = \"\" self . imports = \"\" def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): self . imports += self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) + \" \\n \" def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . import_statement : self . rewriter . insertAfterToken ( token = ctx . stop , text = self . import_statement , program_name = self . rewriter . DEFAULT_PROGRAM_NAME ) self . import_statement = None def enterMemberDeclaration0 ( self , ctx : JavaParserLabeled . MemberDeclaration0Context ): self . is_member = True def exitMemberDeclaration0 ( self , ctx : JavaParserLabeled . MemberDeclaration0Context ): self . is_member = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_member and ctx . IDENTIFIER () . getText () == self . method_name : self . do_delete = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . do_delete : self . method_text = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) if self . is_static : replace_text = f \"public static { self . class_name } { self . instance_name } = new { self . class_name } ();\" else : replace_text = f \"public { self . class_name } { self . instance_name } = new { self . class_name } ();\" self . rewriter . replace ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex , text = replace_text ) self . do_delete = False __init__ ( self , class_name , instance_name , method_name , is_static , import_statement , rewriter ) special Source code in codart\\refactorings\\move_method.py def __init__ ( self , class_name : str , instance_name : str , method_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . method_name = method_name self . is_static = is_static self . rewriter = rewriter self . import_statement = import_statement self . instance_name = instance_name self . is_member = False self . do_delete = False self . method_text = \"\" self . imports = \"\" main ( source_class , source_package , target_class , target_package , method_name , udb_path , * args , ** kwargs ) Source code in codart\\refactorings\\move_method.py def main ( source_class : str , source_package : str , target_class : str , target_package : str , method_name : str , udb_path : str , * args , ** kwargs ): \"\"\" \"\"\" import_statement = None if source_package != target_package : import_statement = f \" \\n import { target_package } . { target_class } ;\" instance_name = target_class . lower () + \"ByCodArt\" db = und . open ( udb_path ) method_map , class_ent = get_source_class_map ( db , source_class ) if class_ent is None : logger . error ( \"Class entity is None\" ) return False # Strong overlay precondition # if class_ent.refs(\"Extend ~Implicit, ExtendBy, Implement\"): # logger.error(\"Class is in inheritance or implements an interface.\") # db.close() # return False # Check if method is static method_ent = db . lookup ( f \" { source_package } . { source_class } . { method_name } \" , \"Method\" ) if len ( method_ent ) >= 1 : method_ent = method_ent [ 0 ] else : logger . error ( \"Entity not found.\" ) db . close () return False if method_ent . simplename () != method_name : logger . error ( \"Can not move method duo to duplicated entities.\" ) logger . info ( f \" { method_ent } , { method_ent . kindname () } \" ) db . close () return False if source_package == target_package and source_class == target_class : logger . error ( \"Can not move to self.\" ) db . close () return False is_static = STATIC in method_ent . kindname () # Find usages usages = {} for ref in method_ent . refs ( \"Callby\" ): file = ref . file () . longname () if file in usages : usages [ file ] . append ( ref . line ()) else : usages [ file ] = [ ref . line (), ] try : src_class_file = db . lookup ( f \" { source_package } . { source_class } .java\" , \"File\" )[ 0 ] . longname () target_class_file = db . lookup ( f \" { target_package } . { target_class } .java\" , \"File\" )[ 0 ] . longname () except IndexError : logger . error ( \"This is a nested method.\" ) logger . info ( f \" { source_package } . { source_class } .java\" ) logger . info ( f \" { target_package } . { target_class } .java\" ) db . close () return False db . close () # Check if there is an cycle listener = parse_and_walk ( file_path = target_class_file , listener_class = CheckCycleListener , class_name = source_class ) if not listener . is_valid : logger . error ( f \"Can not move method because there is a cycle between { source_class } , { target_class } \" ) # db.close() return False # Propagate Changes for file in usages . keys (): public_class_name = os . path . basename ( file ) . split ( \".\" )[ 0 ] is_in_target_class = public_class_name == target_class parse_and_walk ( file_path = file , listener_class = PropagateListener , has_write = True , method_name = method_name , new_name = f \" { instance_name } . { method_name } \" , lines = usages [ file ], is_in_target_class = is_in_target_class , method_map = method_map , ) # exit(-1) # Do the cut and paste! # Cut listener = parse_and_walk ( file_path = src_class_file , listener_class = CutMethodListener , has_write = True , class_name = target_class , instance_name = instance_name , method_name = method_name , is_static = is_static , import_statement = import_statement , ) method_text = listener . method_text # Paste listener = parse_and_walk ( file_path = target_class_file , listener_class = PasteMethodListener , has_write = True , method_text = method_text , source_class = source_class , method_map = method_map , imports = listener . imports , ) # Post-Paste: Reference Injection parse_and_walk ( file_path = target_class_file , listener_class = ReferenceInjectorAndConstructorListener , has_write = True , method_text = method_text , source_class = source_class , method_map = method_map , imports = None , has_empty_cons = listener . has_empty_cons , ) # db.close() return True","title":"Move method"},{"location":"refactorings/move_method/#move-method","text":"","title":"Move method"},{"location":"refactorings/move_method/#codart.refactorings.move_method--introduction","text":"The module implements Move Method refactoring operation","title":"Introduction"},{"location":"refactorings/move_method/#codart.refactorings.move_method--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/move_method/#codart.refactorings.move_method--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/move_method/#codart.refactorings.move_method--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/move_method/#codart.refactorings.move_method.CutMethodListener","text":"Source code in codart\\refactorings\\move_method.py class CutMethodListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , class_name : str , instance_name : str , method_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . method_name = method_name self . is_static = is_static self . rewriter = rewriter self . import_statement = import_statement self . instance_name = instance_name self . is_member = False self . do_delete = False self . method_text = \"\" self . imports = \"\" def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): self . imports += self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) + \" \\n \" def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . import_statement : self . rewriter . insertAfterToken ( token = ctx . stop , text = self . import_statement , program_name = self . rewriter . DEFAULT_PROGRAM_NAME ) self . import_statement = None def enterMemberDeclaration0 ( self , ctx : JavaParserLabeled . MemberDeclaration0Context ): self . is_member = True def exitMemberDeclaration0 ( self , ctx : JavaParserLabeled . MemberDeclaration0Context ): self . is_member = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_member and ctx . IDENTIFIER () . getText () == self . method_name : self . do_delete = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . do_delete : self . method_text = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) if self . is_static : replace_text = f \"public static { self . class_name } { self . instance_name } = new { self . class_name } ();\" else : replace_text = f \"public { self . class_name } { self . instance_name } = new { self . class_name } ();\" self . rewriter . replace ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex , text = replace_text ) self . do_delete = False","title":"CutMethodListener"},{"location":"refactorings/move_method/#codart.refactorings.move_method.CutMethodListener.__init__","text":"Source code in codart\\refactorings\\move_method.py def __init__ ( self , class_name : str , instance_name : str , method_name : str , is_static : bool , import_statement : str , rewriter : TokenStreamRewriter ): \"\"\" \"\"\" self . class_name = class_name self . method_name = method_name self . is_static = is_static self . rewriter = rewriter self . import_statement = import_statement self . instance_name = instance_name self . is_member = False self . do_delete = False self . method_text = \"\" self . imports = \"\"","title":"__init__()"},{"location":"refactorings/move_method/#codart.refactorings.move_method.main","text":"Source code in codart\\refactorings\\move_method.py def main ( source_class : str , source_package : str , target_class : str , target_package : str , method_name : str , udb_path : str , * args , ** kwargs ): \"\"\" \"\"\" import_statement = None if source_package != target_package : import_statement = f \" \\n import { target_package } . { target_class } ;\" instance_name = target_class . lower () + \"ByCodArt\" db = und . open ( udb_path ) method_map , class_ent = get_source_class_map ( db , source_class ) if class_ent is None : logger . error ( \"Class entity is None\" ) return False # Strong overlay precondition # if class_ent.refs(\"Extend ~Implicit, ExtendBy, Implement\"): # logger.error(\"Class is in inheritance or implements an interface.\") # db.close() # return False # Check if method is static method_ent = db . lookup ( f \" { source_package } . { source_class } . { method_name } \" , \"Method\" ) if len ( method_ent ) >= 1 : method_ent = method_ent [ 0 ] else : logger . error ( \"Entity not found.\" ) db . close () return False if method_ent . simplename () != method_name : logger . error ( \"Can not move method duo to duplicated entities.\" ) logger . info ( f \" { method_ent } , { method_ent . kindname () } \" ) db . close () return False if source_package == target_package and source_class == target_class : logger . error ( \"Can not move to self.\" ) db . close () return False is_static = STATIC in method_ent . kindname () # Find usages usages = {} for ref in method_ent . refs ( \"Callby\" ): file = ref . file () . longname () if file in usages : usages [ file ] . append ( ref . line ()) else : usages [ file ] = [ ref . line (), ] try : src_class_file = db . lookup ( f \" { source_package } . { source_class } .java\" , \"File\" )[ 0 ] . longname () target_class_file = db . lookup ( f \" { target_package } . { target_class } .java\" , \"File\" )[ 0 ] . longname () except IndexError : logger . error ( \"This is a nested method.\" ) logger . info ( f \" { source_package } . { source_class } .java\" ) logger . info ( f \" { target_package } . { target_class } .java\" ) db . close () return False db . close () # Check if there is an cycle listener = parse_and_walk ( file_path = target_class_file , listener_class = CheckCycleListener , class_name = source_class ) if not listener . is_valid : logger . error ( f \"Can not move method because there is a cycle between { source_class } , { target_class } \" ) # db.close() return False # Propagate Changes for file in usages . keys (): public_class_name = os . path . basename ( file ) . split ( \".\" )[ 0 ] is_in_target_class = public_class_name == target_class parse_and_walk ( file_path = file , listener_class = PropagateListener , has_write = True , method_name = method_name , new_name = f \" { instance_name } . { method_name } \" , lines = usages [ file ], is_in_target_class = is_in_target_class , method_map = method_map , ) # exit(-1) # Do the cut and paste! # Cut listener = parse_and_walk ( file_path = src_class_file , listener_class = CutMethodListener , has_write = True , class_name = target_class , instance_name = instance_name , method_name = method_name , is_static = is_static , import_statement = import_statement , ) method_text = listener . method_text # Paste listener = parse_and_walk ( file_path = target_class_file , listener_class = PasteMethodListener , has_write = True , method_text = method_text , source_class = source_class , method_map = method_map , imports = listener . imports , ) # Post-Paste: Reference Injection parse_and_walk ( file_path = target_class_file , listener_class = ReferenceInjectorAndConstructorListener , has_write = True , method_text = method_text , source_class = source_class , method_map = method_map , imports = None , has_empty_cons = listener . has_empty_cons , ) # db.close() return True","title":"main()"},{"location":"refactorings/pull_up_constructor/","text":"Pull-up constructor Introduction When subclasses grow and get developed separately, your code may have constructors that perform similar work. Pull up constructor refactoring removes the repetitive method from subclasses and moves it to a superclass. Pre and post-conditions Pre-conditions: The source package, class and constructor should exist. The order of the params in the constructor should be equal in the child classes. empty package name is addressable using \"\". Post Conditions: No specific post-condition PullUpConstructorListener ( JavaParserLabeledListener ) Source code in codart\\refactorings\\pullup_constructor.py class PullUpConstructorListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , rewriter : TokenStreamRewriter , is_father : bool , class_name : str , has_father_con : bool , common_sets : [], params : str ): \"\"\" \"\"\" self . rewriter = rewriter self . is_father = is_father self . has_father_con = has_father_con self . class_name = class_name self . common_sets = common_sets self . params = params self . in_con = False self . delete = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_father : code = \"\" for var in self . common_sets : code += f \"this. { var } = { var } ; \\n \" if self . has_father_con : pass else : self . rewriter . insertBeforeToken ( token = ctx . stop , text = f \"public { self . class_name } ( { self . params } )\" + \"{ \\n \" + code + \"}\" ) def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if not self . is_father : self . in_con = True def exitConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): is_valid = False for i in self . common_sets : if i in ctx . getText (): is_valid = True break if self . is_father and self . has_father_con and is_valid : code = \"\" for var in self . common_sets : code += f \"this. { var } = { var } ; \\n \" self . rewriter . insertBeforeToken ( token = ctx . stop , text = code ) self . in_con = False def enterExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): if self . in_con : identifier = str ( ctx . IDENTIFIER ()) if identifier in self . common_sets : self . delete = True def exitExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . delete : self . rewriter . delete ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex + 1 ) self . delete = False __init__ ( self , rewriter , is_father , class_name , has_father_con , common_sets , params ) special Source code in codart\\refactorings\\pullup_constructor.py def __init__ ( self , rewriter : TokenStreamRewriter , is_father : bool , class_name : str , has_father_con : bool , common_sets : [], params : str ): \"\"\" \"\"\" self . rewriter = rewriter self . is_father = is_father self . has_father_con = has_father_con self . class_name = class_name self . common_sets = common_sets self . params = params self . in_con = False self . delete = False get_cons ( program , packagename , superclassname , class_name ) A function to complete the Pull-up constructor refactoring by finding all the classes with similar constructors. Source code in codart\\refactorings\\pullup_constructor.py def get_cons ( program : Program , packagename : str , superclassname : str , class_name : str ): \"\"\" A function to complete the Pull-up constructor refactoring by finding all the classes with similar constructors. \"\"\" extendedclass = [] removemethods = {} removemethods1 = [] removemethods3 = {} mets = program . packages [ packagename ] . classes [ class_name ] . methods met = [] methodkey = \"\" for methodName , method in mets . items (): if method . is_constructor : met = method methodkey = methodName break body_text_method = met . body_text parammethod = met . parameters for package_name in program . packages : package = program . packages [ package_name ] for class_ in package . classes : _class = package . classes [ class_ ] if _class . superclass_name == superclassname : extendedclass . append ( _class ) i = 0 for d in extendedclass : class_ = extendedclass [ i ] i = i + 1 for mk in class_ . methods : m_ = class_ . methods [ mk ] m = mk [: mk . find ( '(' )] if m_ . body_text == body_text_method and m_ . parameters == parammethod and m_ . is_constructor : if class_ . name not in removemethods : removemethods [ class_ . name ] = [ methodkey ] else : removemethods [ class_ . name ] . append ( methodkey ) elif m_ . is_constructor : listBody_text = body_text_method . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . split ( \";\" ) listm_body = m_ . body_text . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . split ( \";\" ) s1 = set ( listBody_text ) s2 = set ( listm_body ) if s2 . issubset ( s1 ): removemethods1 . append ( diff_lists ( listBody_text , listm_body )) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) elif s1 . issubset ( s2 ): removemethods1 . append ( diff_lists ( listm_body , listBody_text )) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) else : a = diff_lists ( listBody_text , listm_body ) if class_ . name not in removemethods3 : removemethods3 [ class_ . name ] = [ a ] else : removemethods3 [ class_ . name ] . append ( a ) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) removemethods [ class_name ] = [ methodkey ] return removemethods , removemethods1 main ( udb_path , source_package , target_class , class_names , * args , ** kwargs ) Source code in codart\\refactorings\\pullup_constructor.py def main ( udb_path , source_package , target_class , class_names : list , * args , ** kwargs ): \"\"\" \"\"\" if len ( class_names ) < 2 : logger . error ( \"class_names is empty.\" ) return False db = und . open ( udb_path ) parent_cons = [] # Check children parent = db . lookup ( f \" { target_class } \" , \"Public Class\" ) if len ( parent ) != 1 : logger . error ( \"Count of target class is not 1.\" ) db . close () return False parent = parent [ 0 ] parent_file = db . lookup ( f \" { target_class } .java\" , \"File\" )[ 0 ] . longname () for i in parent . ents ( \"Define\" , \"Constructor\" ): parent_cons . append ( i . parameters ()) # Find constructor entities group by signature constructors = {} for child in class_names : cons = db . lookup ( f \" { child } . { child } \" , \"Constructor\" ) for con in cons : if con . parent () is not None : if source_package not in con . parent () . longname (): logger . error ( \"Source package does not match.\" ) db . close () return False parameters = con . parameters () if parameters in constructors : constructors [ parameters ] . append ( con ) else : constructors [ parameters ] = [ con ] # Find common statements for k in constructors : meta_data = { parent_file : { 'is_father' : True , 'has_father_con' : k in parent_cons , 'class_name' : parent . simplename ()}, } con = constructors [ k ][ 0 ] ents = [] for ref in con . refs ( \"Set\" ): data = { 'is_father' : False , 'has_father_con' : k in parent_cons , 'class_name' : con . parent () . simplename ()} if ref . file () . longname () not in meta_data . keys (): meta_data [ ref . file () . longname ()] = data if target_class in ref . ent () . longname (): ents . append ( ref . ent () . simplename ()) for i in range ( 1 , len ( constructors [ k ])): con2 = constructors [ k ][ i ] for ref in con2 . refs ( \"Set\" ): data = { 'is_father' : False , 'has_father_con' : k in parent_cons , 'class_name' : con2 . parent () . simplename () } if ref . file () . longname () not in meta_data . keys (): meta_data [ ref . file () . longname ()] = data if target_class in ref . ent () . longname (): ents . append ( ref . ent () . simplename ()) ents = [ item for item , count in collections . Counter ( ents ) . items () if count > 1 ] if len ( meta_data . keys ()) > 1 : for file_name in meta_data : data = meta_data [ file_name ] parse_and_walk ( file_name , PullUpConstructorListener , has_write = True , is_father = data [ 'is_father' ], has_father_con = data [ 'has_father_con' ], common_sets = ents , class_name = data [ 'class_name' ], params = k ) db . close () return True","title":"Pull-up constructor"},{"location":"refactorings/pull_up_constructor/#pull-up-constructor","text":"","title":"Pull-up constructor"},{"location":"refactorings/pull_up_constructor/#codart.refactorings.pullup_constructor--introduction","text":"When subclasses grow and get developed separately, your code may have constructors that perform similar work. Pull up constructor refactoring removes the repetitive method from subclasses and moves it to a superclass.","title":"Introduction"},{"location":"refactorings/pull_up_constructor/#codart.refactorings.pullup_constructor--pre-and-post-conditions","text":"","title":"Pre and post-conditions"},{"location":"refactorings/pull_up_constructor/#codart.refactorings.pullup_constructor--pre-conditions","text":"The source package, class and constructor should exist. The order of the params in the constructor should be equal in the child classes. empty package name is addressable using \"\".","title":"Pre-conditions:"},{"location":"refactorings/pull_up_constructor/#codart.refactorings.pullup_constructor--post-conditions","text":"No specific post-condition","title":"Post Conditions:"},{"location":"refactorings/pull_up_constructor/#codart.refactorings.pullup_constructor.PullUpConstructorListener","text":"Source code in codart\\refactorings\\pullup_constructor.py class PullUpConstructorListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , rewriter : TokenStreamRewriter , is_father : bool , class_name : str , has_father_con : bool , common_sets : [], params : str ): \"\"\" \"\"\" self . rewriter = rewriter self . is_father = is_father self . has_father_con = has_father_con self . class_name = class_name self . common_sets = common_sets self . params = params self . in_con = False self . delete = False def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_father : code = \"\" for var in self . common_sets : code += f \"this. { var } = { var } ; \\n \" if self . has_father_con : pass else : self . rewriter . insertBeforeToken ( token = ctx . stop , text = f \"public { self . class_name } ( { self . params } )\" + \"{ \\n \" + code + \"}\" ) def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if not self . is_father : self . in_con = True def exitConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): is_valid = False for i in self . common_sets : if i in ctx . getText (): is_valid = True break if self . is_father and self . has_father_con and is_valid : code = \"\" for var in self . common_sets : code += f \"this. { var } = { var } ; \\n \" self . rewriter . insertBeforeToken ( token = ctx . stop , text = code ) self . in_con = False def enterExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): if self . in_con : identifier = str ( ctx . IDENTIFIER ()) if identifier in self . common_sets : self . delete = True def exitExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . delete : self . rewriter . delete ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex + 1 ) self . delete = False","title":"PullUpConstructorListener"},{"location":"refactorings/pull_up_constructor/#codart.refactorings.pullup_constructor.PullUpConstructorListener.__init__","text":"Source code in codart\\refactorings\\pullup_constructor.py def __init__ ( self , rewriter : TokenStreamRewriter , is_father : bool , class_name : str , has_father_con : bool , common_sets : [], params : str ): \"\"\" \"\"\" self . rewriter = rewriter self . is_father = is_father self . has_father_con = has_father_con self . class_name = class_name self . common_sets = common_sets self . params = params self . in_con = False self . delete = False","title":"__init__()"},{"location":"refactorings/pull_up_constructor/#codart.refactorings.pullup_constructor.get_cons","text":"A function to complete the Pull-up constructor refactoring by finding all the classes with similar constructors. Source code in codart\\refactorings\\pullup_constructor.py def get_cons ( program : Program , packagename : str , superclassname : str , class_name : str ): \"\"\" A function to complete the Pull-up constructor refactoring by finding all the classes with similar constructors. \"\"\" extendedclass = [] removemethods = {} removemethods1 = [] removemethods3 = {} mets = program . packages [ packagename ] . classes [ class_name ] . methods met = [] methodkey = \"\" for methodName , method in mets . items (): if method . is_constructor : met = method methodkey = methodName break body_text_method = met . body_text parammethod = met . parameters for package_name in program . packages : package = program . packages [ package_name ] for class_ in package . classes : _class = package . classes [ class_ ] if _class . superclass_name == superclassname : extendedclass . append ( _class ) i = 0 for d in extendedclass : class_ = extendedclass [ i ] i = i + 1 for mk in class_ . methods : m_ = class_ . methods [ mk ] m = mk [: mk . find ( '(' )] if m_ . body_text == body_text_method and m_ . parameters == parammethod and m_ . is_constructor : if class_ . name not in removemethods : removemethods [ class_ . name ] = [ methodkey ] else : removemethods [ class_ . name ] . append ( methodkey ) elif m_ . is_constructor : listBody_text = body_text_method . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . split ( \";\" ) listm_body = m_ . body_text . replace ( \"{\" , \"\" ) . replace ( \"}\" , \"\" ) . split ( \";\" ) s1 = set ( listBody_text ) s2 = set ( listm_body ) if s2 . issubset ( s1 ): removemethods1 . append ( diff_lists ( listBody_text , listm_body )) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) elif s1 . issubset ( s2 ): removemethods1 . append ( diff_lists ( listm_body , listBody_text )) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) else : a = diff_lists ( listBody_text , listm_body ) if class_ . name not in removemethods3 : removemethods3 [ class_ . name ] = [ a ] else : removemethods3 [ class_ . name ] . append ( a ) if class_ . name not in removemethods : removemethods [ class_ . name ] = [ mk ] else : removemethods [ class_ . name ] . append ( mk ) removemethods [ class_name ] = [ methodkey ] return removemethods , removemethods1","title":"get_cons()"},{"location":"refactorings/pull_up_constructor/#codart.refactorings.pullup_constructor.main","text":"Source code in codart\\refactorings\\pullup_constructor.py def main ( udb_path , source_package , target_class , class_names : list , * args , ** kwargs ): \"\"\" \"\"\" if len ( class_names ) < 2 : logger . error ( \"class_names is empty.\" ) return False db = und . open ( udb_path ) parent_cons = [] # Check children parent = db . lookup ( f \" { target_class } \" , \"Public Class\" ) if len ( parent ) != 1 : logger . error ( \"Count of target class is not 1.\" ) db . close () return False parent = parent [ 0 ] parent_file = db . lookup ( f \" { target_class } .java\" , \"File\" )[ 0 ] . longname () for i in parent . ents ( \"Define\" , \"Constructor\" ): parent_cons . append ( i . parameters ()) # Find constructor entities group by signature constructors = {} for child in class_names : cons = db . lookup ( f \" { child } . { child } \" , \"Constructor\" ) for con in cons : if con . parent () is not None : if source_package not in con . parent () . longname (): logger . error ( \"Source package does not match.\" ) db . close () return False parameters = con . parameters () if parameters in constructors : constructors [ parameters ] . append ( con ) else : constructors [ parameters ] = [ con ] # Find common statements for k in constructors : meta_data = { parent_file : { 'is_father' : True , 'has_father_con' : k in parent_cons , 'class_name' : parent . simplename ()}, } con = constructors [ k ][ 0 ] ents = [] for ref in con . refs ( \"Set\" ): data = { 'is_father' : False , 'has_father_con' : k in parent_cons , 'class_name' : con . parent () . simplename ()} if ref . file () . longname () not in meta_data . keys (): meta_data [ ref . file () . longname ()] = data if target_class in ref . ent () . longname (): ents . append ( ref . ent () . simplename ()) for i in range ( 1 , len ( constructors [ k ])): con2 = constructors [ k ][ i ] for ref in con2 . refs ( \"Set\" ): data = { 'is_father' : False , 'has_father_con' : k in parent_cons , 'class_name' : con2 . parent () . simplename () } if ref . file () . longname () not in meta_data . keys (): meta_data [ ref . file () . longname ()] = data if target_class in ref . ent () . longname (): ents . append ( ref . ent () . simplename ()) ents = [ item for item , count in collections . Counter ( ents ) . items () if count > 1 ] if len ( meta_data . keys ()) > 1 : for file_name in meta_data : data = meta_data [ file_name ] parse_and_walk ( file_name , PullUpConstructorListener , has_write = True , is_father = data [ 'is_father' ], has_father_con = data [ 'has_father_con' ], common_sets = ents , class_name = data [ 'class_name' ], params = k ) db . close () return True","title":"main()"},{"location":"refactorings/pull_up_field/","text":"Pull-up field Introduction When subclasses grow and get developed separately, identical (or nearly identical) fields and methods appear. Pull up field refactoring removes the repetitive field from subclasses and moves it to a superclass. Pre and Post Conditions Pre Conditions: There should exist a corresponding child and parent in the project. The field that should be pulled up must be valid. The user must enter the package's name, class's name and the fields that need to be removed. Post Conditions: The changed field's usages and callings will also change respectively. There will be children and parents having their desired fields added or removed. Check for multilevel inheritance. PullUpFieldRefactoring The class that does the process of pull up field refactoring. Removes the repetitive fields from the subclasses, creates the superclass, and moves the fields to the superclass. Source code in codart\\refactorings\\pullup_field.py class PullUpFieldRefactoring : \"\"\" The class that does the process of pull up field refactoring. Removes the repetitive fields from the subclasses, creates the superclass, and moves the fields to the superclass. \"\"\" def __init__ ( self , source_filenames : list , package_name : str , class_name : str , field_name : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the classes/superclasses) class_name (str): Name of the class that the field is pulled up from field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PullUpFieldRefactoring): An instance of PullUpFieldRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_name = class_name self . field_name = field_name self . filename_mapping = filename_mapping def do_refactor ( self ): program = symbol_table . get_program ( self . source_filenames , print_status = False ) # print(program.packages) if ( self . package_name not in program . packages or self . class_name not in program . packages [ self . package_name ] . classes or self . field_name not in program . packages [ self . package_name ] . classes [ self . class_name ] . fields ): logger . error ( \"One or more inputs are not valid.\" ) return False _class : symbol_table . Class = program . packages [ self . package_name ] . classes [ self . class_name ] if _class . superclass_name is None : logger . error ( \"Super class is none.\" ) return False superclass_name = _class . superclass_name if not program . packages [ self . package_name ] . classes . get ( superclass_name ): logger . error ( \"Super class package is none!\" ) return False superclass : symbol_table . Class = program . packages [ self . package_name ] . classes [ superclass_name ] superclass_body_start = symbol_table . TokensInfo ( superclass . parser_context . classBody ()) superclass_body_start . stop = superclass_body_start . start # Start and stop both point to the '{' if self . field_name in superclass . fields : logger . error ( \"Field is in superclass fields.\" ) return False datatype = _class . fields [ self . field_name ] . datatype fields_to_remove = [] for pn in program . packages : p : symbol_table . Package = program . packages [ pn ] for cn in p . classes : c : symbol_table . Class = p . classes [ cn ] if ( ( ( c . superclass_name == superclass_name and c . file_info . has_imported_class ( self . package_name , superclass_name ) ) or ( self . package_name is not None and c . superclass_name == superclass_name ) ) and self . field_name in c . fields and c . fields [ self . field_name ] . datatype == datatype ): fields_to_remove . append ( c . fields [ self . field_name ]) if len ( fields_to_remove ) == 0 : logger . error ( \"No fields to remove.\" ) return False is_public = False is_protected = True for field in fields_to_remove : field : symbol_table . Field = field is_public = is_public or \"public\" in field . modifiers is_protected = is_protected and ( \"protected\" in field . modifiers or \"private\" in field . modifiers ) rewriter = symbol_table . Rewriter ( program , self . filename_mapping ) rewriter . insert_after ( superclass_body_start , \" \\n\\t \" + ( \"public \" if is_public else ( \"protected \" if is_protected else \"\" )) + datatype + \" \" + self . field_name + \";\" ) for field in fields_to_remove : if len ( field . neighbor_names ) == 0 : rewriter . replace ( field . get_tokens_info (), \"\" ) # Have to remove the modifiers too, because of the new grammar. for mod_ctx in field . modifiers_parser_contexts : rewriter . replace ( symbol_table . TokensInfo ( mod_ctx ), \"\" ) else : i = field . index_in_variable_declarators var_ctxs = field . all_variable_declarator_contexts if i == 0 : to_remove = symbol_table . TokensInfo ( var_ctxs [ i ]) to_remove . stop = symbol_table . TokensInfo ( var_ctxs [ i + 1 ]) . start - 1 # Include the ',' after it rewriter . replace ( to_remove , \"\" ) else : to_remove = symbol_table . TokensInfo ( var_ctxs [ i ]) to_remove . start = symbol_table . TokensInfo ( var_ctxs [ i - 1 ]) . stop + 1 # Include the ',' before it rewriter . replace ( to_remove , \"\" ) # Add initializer to class constructor if initializer exists in field declaration if field . initializer is not None : _class : symbol_table . Class = program . packages [ field . package_name ] . classes [ field . class_name ] initializer_statement = ( field . name + \" = \" + ( \"new \" + field . datatype + \" \" if field . initializer . startswith ( '{' ) else \"\" ) + field . initializer + \";\" ) # Todo: Requires better handling if 'new' in initializer_statement and '()' in initializer_statement : initializer_statement = initializer_statement . replace ( 'new' , 'new ' ) has_contructor = False for class_body_decl in _class . parser_context . classBody () . getChildren (): if class_body_decl . getText () in [ '{' , '}' ]: continue member_decl = class_body_decl . memberDeclaration () if member_decl is not None : constructor = member_decl . constructorDeclaration () if constructor is not None : body = constructor . constructorBody # Start token = '{' body_start = symbol_table . TokensInfo ( body ) body_start . stop = body_start . start # Start and stop both point to the '{' rewriter . insert_after ( body_start , \" \\n\\t \" + initializer_statement ) has_contructor = True if not has_contructor : body = _class . parser_context . classBody () body_start = symbol_table . TokensInfo ( body ) body_start . stop = body_start . start # Start and stop both point to the '{' rewriter . insert_after ( body_start , \" \\n\\t \" + _class . modifiers [ 0 ] + \" \" + _class . name + \"() { \" + initializer_statement + \" }\" ) rewriter . apply () # Todo: check for multilevel inheritance recursively. # if _class.superclass_name is not None: # PullUpFieldRefactoring(self.source_filenames, self.package_name, _class.superclass_name, \"id\").do_refactor() return True __init__ ( self , source_filenames , package_name , class_name , field_name , filename_mapping =< function PullUpFieldRefactoring .< lambda > at 0x000001616DE3B3A0 > ) special Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the classes/superclasses) required class_name str Name of the class that the field is pulled up from required field_name str Name of the field that has to be refactored required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function PullUpFieldRefactoring.<lambda> at 0x000001616DE3B3A0> Returns: Type Description object (PullUpFieldRefactoring) An instance of PullUpFieldRefactoring class Source code in codart\\refactorings\\pullup_field.py def __init__ ( self , source_filenames : list , package_name : str , class_name : str , field_name : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the classes/superclasses) class_name (str): Name of the class that the field is pulled up from field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PullUpFieldRefactoring): An instance of PullUpFieldRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_name = class_name self . field_name = field_name self . filename_mapping = filename_mapping main ( project_dir , package_name , children_class , field_name , * args , ** kwargs ) Source code in codart\\refactorings\\pullup_field.py def main ( project_dir : str , package_name : str , children_class : str , field_name : str , * args , ** kwargs ): \"\"\" \"\"\" # print(\"Pull-up field\") result = PullUpFieldRefactoring ( symbol_table . get_filenames_in_dir ( project_dir ), package_name , children_class , field_name # lambda x: \"tests/pullup_field_ant/\" + x[len(ant_dir):] ) . do_refactor () # print(f\"Success pull-up field {field_name}\" if result else f\"Cannot pull-up field {field_name}\") return result","title":"Pull-up field"},{"location":"refactorings/pull_up_field/#pull-up-field","text":"","title":"Pull-up field"},{"location":"refactorings/pull_up_field/#codart.refactorings.pullup_field--introduction","text":"When subclasses grow and get developed separately, identical (or nearly identical) fields and methods appear. Pull up field refactoring removes the repetitive field from subclasses and moves it to a superclass.","title":"Introduction"},{"location":"refactorings/pull_up_field/#codart.refactorings.pullup_field--pre-and-post-conditions","text":"","title":"Pre and Post Conditions"},{"location":"refactorings/pull_up_field/#codart.refactorings.pullup_field--pre-conditions","text":"There should exist a corresponding child and parent in the project. The field that should be pulled up must be valid. The user must enter the package's name, class's name and the fields that need to be removed.","title":"Pre Conditions:"},{"location":"refactorings/pull_up_field/#codart.refactorings.pullup_field--post-conditions","text":"The changed field's usages and callings will also change respectively. There will be children and parents having their desired fields added or removed. Check for multilevel inheritance.","title":"Post Conditions:"},{"location":"refactorings/pull_up_field/#codart.refactorings.pullup_field.PullUpFieldRefactoring","text":"The class that does the process of pull up field refactoring. Removes the repetitive fields from the subclasses, creates the superclass, and moves the fields to the superclass. Source code in codart\\refactorings\\pullup_field.py class PullUpFieldRefactoring : \"\"\" The class that does the process of pull up field refactoring. Removes the repetitive fields from the subclasses, creates the superclass, and moves the fields to the superclass. \"\"\" def __init__ ( self , source_filenames : list , package_name : str , class_name : str , field_name : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the classes/superclasses) class_name (str): Name of the class that the field is pulled up from field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PullUpFieldRefactoring): An instance of PullUpFieldRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_name = class_name self . field_name = field_name self . filename_mapping = filename_mapping def do_refactor ( self ): program = symbol_table . get_program ( self . source_filenames , print_status = False ) # print(program.packages) if ( self . package_name not in program . packages or self . class_name not in program . packages [ self . package_name ] . classes or self . field_name not in program . packages [ self . package_name ] . classes [ self . class_name ] . fields ): logger . error ( \"One or more inputs are not valid.\" ) return False _class : symbol_table . Class = program . packages [ self . package_name ] . classes [ self . class_name ] if _class . superclass_name is None : logger . error ( \"Super class is none.\" ) return False superclass_name = _class . superclass_name if not program . packages [ self . package_name ] . classes . get ( superclass_name ): logger . error ( \"Super class package is none!\" ) return False superclass : symbol_table . Class = program . packages [ self . package_name ] . classes [ superclass_name ] superclass_body_start = symbol_table . TokensInfo ( superclass . parser_context . classBody ()) superclass_body_start . stop = superclass_body_start . start # Start and stop both point to the '{' if self . field_name in superclass . fields : logger . error ( \"Field is in superclass fields.\" ) return False datatype = _class . fields [ self . field_name ] . datatype fields_to_remove = [] for pn in program . packages : p : symbol_table . Package = program . packages [ pn ] for cn in p . classes : c : symbol_table . Class = p . classes [ cn ] if ( ( ( c . superclass_name == superclass_name and c . file_info . has_imported_class ( self . package_name , superclass_name ) ) or ( self . package_name is not None and c . superclass_name == superclass_name ) ) and self . field_name in c . fields and c . fields [ self . field_name ] . datatype == datatype ): fields_to_remove . append ( c . fields [ self . field_name ]) if len ( fields_to_remove ) == 0 : logger . error ( \"No fields to remove.\" ) return False is_public = False is_protected = True for field in fields_to_remove : field : symbol_table . Field = field is_public = is_public or \"public\" in field . modifiers is_protected = is_protected and ( \"protected\" in field . modifiers or \"private\" in field . modifiers ) rewriter = symbol_table . Rewriter ( program , self . filename_mapping ) rewriter . insert_after ( superclass_body_start , \" \\n\\t \" + ( \"public \" if is_public else ( \"protected \" if is_protected else \"\" )) + datatype + \" \" + self . field_name + \";\" ) for field in fields_to_remove : if len ( field . neighbor_names ) == 0 : rewriter . replace ( field . get_tokens_info (), \"\" ) # Have to remove the modifiers too, because of the new grammar. for mod_ctx in field . modifiers_parser_contexts : rewriter . replace ( symbol_table . TokensInfo ( mod_ctx ), \"\" ) else : i = field . index_in_variable_declarators var_ctxs = field . all_variable_declarator_contexts if i == 0 : to_remove = symbol_table . TokensInfo ( var_ctxs [ i ]) to_remove . stop = symbol_table . TokensInfo ( var_ctxs [ i + 1 ]) . start - 1 # Include the ',' after it rewriter . replace ( to_remove , \"\" ) else : to_remove = symbol_table . TokensInfo ( var_ctxs [ i ]) to_remove . start = symbol_table . TokensInfo ( var_ctxs [ i - 1 ]) . stop + 1 # Include the ',' before it rewriter . replace ( to_remove , \"\" ) # Add initializer to class constructor if initializer exists in field declaration if field . initializer is not None : _class : symbol_table . Class = program . packages [ field . package_name ] . classes [ field . class_name ] initializer_statement = ( field . name + \" = \" + ( \"new \" + field . datatype + \" \" if field . initializer . startswith ( '{' ) else \"\" ) + field . initializer + \";\" ) # Todo: Requires better handling if 'new' in initializer_statement and '()' in initializer_statement : initializer_statement = initializer_statement . replace ( 'new' , 'new ' ) has_contructor = False for class_body_decl in _class . parser_context . classBody () . getChildren (): if class_body_decl . getText () in [ '{' , '}' ]: continue member_decl = class_body_decl . memberDeclaration () if member_decl is not None : constructor = member_decl . constructorDeclaration () if constructor is not None : body = constructor . constructorBody # Start token = '{' body_start = symbol_table . TokensInfo ( body ) body_start . stop = body_start . start # Start and stop both point to the '{' rewriter . insert_after ( body_start , \" \\n\\t \" + initializer_statement ) has_contructor = True if not has_contructor : body = _class . parser_context . classBody () body_start = symbol_table . TokensInfo ( body ) body_start . stop = body_start . start # Start and stop both point to the '{' rewriter . insert_after ( body_start , \" \\n\\t \" + _class . modifiers [ 0 ] + \" \" + _class . name + \"() { \" + initializer_statement + \" }\" ) rewriter . apply () # Todo: check for multilevel inheritance recursively. # if _class.superclass_name is not None: # PullUpFieldRefactoring(self.source_filenames, self.package_name, _class.superclass_name, \"id\").do_refactor() return True","title":"PullUpFieldRefactoring"},{"location":"refactorings/pull_up_field/#codart.refactorings.pullup_field.PullUpFieldRefactoring.__init__","text":"Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the classes/superclasses) required class_name str Name of the class that the field is pulled up from required field_name str Name of the field that has to be refactored required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function PullUpFieldRefactoring.<lambda> at 0x000001616DE3B3A0> Returns: Type Description object (PullUpFieldRefactoring) An instance of PullUpFieldRefactoring class Source code in codart\\refactorings\\pullup_field.py def __init__ ( self , source_filenames : list , package_name : str , class_name : str , field_name : str , filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the classes/superclasses) class_name (str): Name of the class that the field is pulled up from field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PullUpFieldRefactoring): An instance of PullUpFieldRefactoring class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . class_name = class_name self . field_name = field_name self . filename_mapping = filename_mapping","title":"__init__()"},{"location":"refactorings/pull_up_field/#codart.refactorings.pullup_field.main","text":"Source code in codart\\refactorings\\pullup_field.py def main ( project_dir : str , package_name : str , children_class : str , field_name : str , * args , ** kwargs ): \"\"\" \"\"\" # print(\"Pull-up field\") result = PullUpFieldRefactoring ( symbol_table . get_filenames_in_dir ( project_dir ), package_name , children_class , field_name # lambda x: \"tests/pullup_field_ant/\" + x[len(ant_dir):] ) . do_refactor () # print(f\"Success pull-up field {field_name}\" if result else f\"Cannot pull-up field {field_name}\") return result","title":"main()"},{"location":"refactorings/pull_up_method/","text":"Pull-up method Introduction The module implements pull-up method refactoring operation. Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions PullUpMethodRefactoringListener ( JavaParserLabeledListener ) To implement pull-up method refactoring based on its actors. Source code in codart\\refactorings\\pullup_method.py class PullUpMethodRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement pull-up method refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , destination_class : str = None , children_class : list = None , moved_methods = None , method_text : str = None ): \"\"\" \"\"\" if method_text is None : self . mothod_text = [] else : self . method_text = method_text if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if children_class is None : self . children_class = [] else : self . children_class = children_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if destination_class is None : raise ValueError ( \"source_class is None\" ) else : self . destination_class = destination_class self . is_children_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . tempdeclarationcode = \"\" def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_children_class : method_identifier = ctx . IDENTIFIER () . getText () if self . moved_methods == method_identifier : methodDefctx = ctx . parentCtx . parentCtx start_index = methodDefctx . start . tokenIndex stop_index = methodDefctx . stop . tokenIndex self . method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = methodDefctx . start . tokenIndex , to_idx = methodDefctx . stop . tokenIndex ) else : return None def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier in self . children_class : self . is_children_class = True else : # Enter another class self . is_children_class = False def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): classDecctx = ctx . parentCtx if hasattr ( classDecctx , \"IDENTIFIER\" ): class_identifier = classDecctx . IDENTIFIER () . getText () if class_identifier in self . destination_class : self . token_stream_rewriter . replaceRange ( from_idx = ctx . start . tokenIndex + 1 , to_idx = ctx . start . tokenIndex + 1 , text = \" \\n \" + self . method_text + \" \\n \" ) def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_children_class : self . is_children_class = False def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): self . token_stream_rewriter . insertAfter ( index = ctx . stop . tokenIndex , text = self . code ) __init__ ( self , common_token_stream = None , destination_class = None , children_class = None , moved_methods = None , method_text = None ) special Source code in codart\\refactorings\\pullup_method.py def __init__ ( self , common_token_stream : CommonTokenStream = None , destination_class : str = None , children_class : list = None , moved_methods = None , method_text : str = None ): \"\"\" \"\"\" if method_text is None : self . mothod_text = [] else : self . method_text = method_text if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if children_class is None : self . children_class = [] else : self . children_class = children_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if destination_class is None : raise ValueError ( \"source_class is None\" ) else : self . destination_class = destination_class self . is_children_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . tempdeclarationcode = \"\" main ( udb_path , children_classes , method_name , * args , ** kwargs ) Source code in codart\\refactorings\\pullup_method.py def main ( udb_path : str , children_classes : list , method_name : str , * args , ** kwargs ): \"\"\" \"\"\" if len ( children_classes ) <= 1 : logger . error ( \"len(children_classes) should be gte 2\" ) return False # Initialize with understand destination_class = \"\" fileslist_to_be_rafeactored = set () fileslist_to_be_propagate = set () propagation_classes = set () db = und . open ( udb_path ) try : method_ents = [ db . lookup ( i + \".\" + method_name , \"method\" )[ 0 ] for i in children_classes ] except IndexError : # print([db.lookup(i + \".\" + method_name, \"method\") for i in children_classes]) logger . error ( f \"Method { method_name } does not exists in all children_classes.\" ) db . close () return False # Get method text method_text = method_ents [ 0 ] . contents () . strip () for method_ent in method_ents : if method_ent . contents () . strip () != method_text : logger . error ( \"Method content is different.\" ) db . close () return False for ref in method_ent . refs ( \"Use,Call\" ): if ref . ent () . parent () is not None : if ref . ent () . parent () . simplename () in children_classes : logger . error ( \"Method has internal dependencies.\" ) db . close () return False for mth in db . ents ( \"Java Method\" ): for child in children_classes : if mth . longname () . endswith ( child + \".\" + method_name ): fileslist_to_be_rafeactored . add ( mth . parent () . parent () . longname ()) for fth in mth . parent () . refs ( \"Extend\" ): destination_class = fth . ent () . longname () fileslist_to_be_rafeactored . add ( fth . ent () . parent () . longname ()) for ref in mth . refs ( \"Java Callby\" ): propagation_classes . add ( ref . ent () . parent () . longname ()) fileslist_to_be_propagate . add ( ref . ent () . parent () . parent () . longname ()) db . close () # print(\"=========================================\") # print(\"fileslist_to_be_propagate :\", fileslist_to_be_propagate) # print(\"propagation_classes : \", propagation_classes) # print(\"fileslist_to_be_rafeactored :\", fileslist_to_be_rafeactored) # print(\"father class :\", destination_class) fileslist_to_be_rafeactored = list ( fileslist_to_be_rafeactored ) fileslist_to_be_propagate = list ( fileslist_to_be_propagate ) propagation_class = list ( propagation_classes ) # refactored start for file in fileslist_to_be_rafeactored : try : stream = FileStream ( file , encoding = 'utf-8' , errors = 'ignore' ) except : continue lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener_refactor = PullUpMethodRefactoringListener ( common_token_stream = token_stream , destination_class = destination_class , children_class = children_classes , moved_methods = method_name , method_text = method_text ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener_refactor ) with open ( file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener_refactor . token_stream_rewriter . getDefaultText ()) # end refactoring # beginning of propagate for file in fileslist_to_be_propagate : if not os . path . exists ( file ): continue stream = FileStream ( file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener_propagate = PropagationPullUpMethodRefactoringListener ( token_stream_rewriter = token_stream , old_class_name = children_classes , new_class_name = destination_class , propagated_class_name = propagation_class ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener_propagate ) with open ( file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener_propagate . token_stream_rewriter . getDefaultText ()) # end of propagate return True","title":"Pull-up method"},{"location":"refactorings/pull_up_method/#pull-up-method","text":"","title":"Pull-up method"},{"location":"refactorings/pull_up_method/#codart.refactorings.pullup_method--introduction","text":"The module implements pull-up method refactoring operation.","title":"Introduction"},{"location":"refactorings/pull_up_method/#codart.refactorings.pullup_method--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/pull_up_method/#codart.refactorings.pullup_method--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/pull_up_method/#codart.refactorings.pullup_method.PullUpMethodRefactoringListener","text":"To implement pull-up method refactoring based on its actors. Source code in codart\\refactorings\\pullup_method.py class PullUpMethodRefactoringListener ( JavaParserLabeledListener ): \"\"\" To implement pull-up method refactoring based on its actors. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , destination_class : str = None , children_class : list = None , moved_methods = None , method_text : str = None ): \"\"\" \"\"\" if method_text is None : self . mothod_text = [] else : self . method_text = method_text if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if children_class is None : self . children_class = [] else : self . children_class = children_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if destination_class is None : raise ValueError ( \"source_class is None\" ) else : self . destination_class = destination_class self . is_children_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . tempdeclarationcode = \"\" def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_children_class : method_identifier = ctx . IDENTIFIER () . getText () if self . moved_methods == method_identifier : methodDefctx = ctx . parentCtx . parentCtx start_index = methodDefctx . start . tokenIndex stop_index = methodDefctx . stop . tokenIndex self . method_text = self . token_stream_rewriter . getText ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , start = start_index , stop = stop_index ) self . token_stream_rewriter . delete ( program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME , from_idx = methodDefctx . start . tokenIndex , to_idx = methodDefctx . stop . tokenIndex ) else : return None def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_identifier = ctx . IDENTIFIER () . getText () if class_identifier in self . children_class : self . is_children_class = True else : # Enter another class self . is_children_class = False def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): classDecctx = ctx . parentCtx if hasattr ( classDecctx , \"IDENTIFIER\" ): class_identifier = classDecctx . IDENTIFIER () . getText () if class_identifier in self . destination_class : self . token_stream_rewriter . replaceRange ( from_idx = ctx . start . tokenIndex + 1 , to_idx = ctx . start . tokenIndex + 1 , text = \" \\n \" + self . method_text + \" \\n \" ) def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_children_class : self . is_children_class = False def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): self . token_stream_rewriter . insertAfter ( index = ctx . stop . tokenIndex , text = self . code )","title":"PullUpMethodRefactoringListener"},{"location":"refactorings/pull_up_method/#codart.refactorings.pullup_method.PullUpMethodRefactoringListener.__init__","text":"Source code in codart\\refactorings\\pullup_method.py def __init__ ( self , common_token_stream : CommonTokenStream = None , destination_class : str = None , children_class : list = None , moved_methods = None , method_text : str = None ): \"\"\" \"\"\" if method_text is None : self . mothod_text = [] else : self . method_text = method_text if moved_methods is None : self . moved_methods = [] else : self . moved_methods = moved_methods if children_class is None : self . children_class = [] else : self . children_class = children_class if common_token_stream is None : raise ValueError ( 'common_token_stream is None' ) else : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) if destination_class is None : raise ValueError ( \"source_class is None\" ) else : self . destination_class = destination_class self . is_children_class = False self . detected_field = None self . detected_method = None self . TAB = \" \\t \" self . NEW_LINE = \" \\n \" self . code = \"\" self . tempdeclarationcode = \"\"","title":"__init__()"},{"location":"refactorings/pull_up_method/#codart.refactorings.pullup_method.main","text":"Source code in codart\\refactorings\\pullup_method.py def main ( udb_path : str , children_classes : list , method_name : str , * args , ** kwargs ): \"\"\" \"\"\" if len ( children_classes ) <= 1 : logger . error ( \"len(children_classes) should be gte 2\" ) return False # Initialize with understand destination_class = \"\" fileslist_to_be_rafeactored = set () fileslist_to_be_propagate = set () propagation_classes = set () db = und . open ( udb_path ) try : method_ents = [ db . lookup ( i + \".\" + method_name , \"method\" )[ 0 ] for i in children_classes ] except IndexError : # print([db.lookup(i + \".\" + method_name, \"method\") for i in children_classes]) logger . error ( f \"Method { method_name } does not exists in all children_classes.\" ) db . close () return False # Get method text method_text = method_ents [ 0 ] . contents () . strip () for method_ent in method_ents : if method_ent . contents () . strip () != method_text : logger . error ( \"Method content is different.\" ) db . close () return False for ref in method_ent . refs ( \"Use,Call\" ): if ref . ent () . parent () is not None : if ref . ent () . parent () . simplename () in children_classes : logger . error ( \"Method has internal dependencies.\" ) db . close () return False for mth in db . ents ( \"Java Method\" ): for child in children_classes : if mth . longname () . endswith ( child + \".\" + method_name ): fileslist_to_be_rafeactored . add ( mth . parent () . parent () . longname ()) for fth in mth . parent () . refs ( \"Extend\" ): destination_class = fth . ent () . longname () fileslist_to_be_rafeactored . add ( fth . ent () . parent () . longname ()) for ref in mth . refs ( \"Java Callby\" ): propagation_classes . add ( ref . ent () . parent () . longname ()) fileslist_to_be_propagate . add ( ref . ent () . parent () . parent () . longname ()) db . close () # print(\"=========================================\") # print(\"fileslist_to_be_propagate :\", fileslist_to_be_propagate) # print(\"propagation_classes : \", propagation_classes) # print(\"fileslist_to_be_rafeactored :\", fileslist_to_be_rafeactored) # print(\"father class :\", destination_class) fileslist_to_be_rafeactored = list ( fileslist_to_be_rafeactored ) fileslist_to_be_propagate = list ( fileslist_to_be_propagate ) propagation_class = list ( propagation_classes ) # refactored start for file in fileslist_to_be_rafeactored : try : stream = FileStream ( file , encoding = 'utf-8' , errors = 'ignore' ) except : continue lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener_refactor = PullUpMethodRefactoringListener ( common_token_stream = token_stream , destination_class = destination_class , children_class = children_classes , moved_methods = method_name , method_text = method_text ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener_refactor ) with open ( file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener_refactor . token_stream_rewriter . getDefaultText ()) # end refactoring # beginning of propagate for file in fileslist_to_be_propagate : if not os . path . exists ( file ): continue stream = FileStream ( file , encoding = 'utf-8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener_propagate = PropagationPullUpMethodRefactoringListener ( token_stream_rewriter = token_stream , old_class_name = children_classes , new_class_name = destination_class , propagated_class_name = propagation_class ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener_propagate ) with open ( file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener_propagate . token_stream_rewriter . getDefaultText ()) # end of propagate return True","title":"main()"},{"location":"refactorings/push_down_field/","text":"Push-down field Introduction Although it was planned to use a field universally for all classes, in reality the field is used only in some subclasses. This situation can occur when planned features fail to pan out, for example. because of this, we push down the field from the superclass into its related subclass. Pre and Post Conditions Pre Conditions: There should exist a corresponding child and parent in the project. The field that should be pushed down must be valid. The user must enter the package's name, class's name and the fields that need to be added. Post Conditions: The changed field's usages and callings will also change respectively. There will be children and parents having their desired fields added or removed. PushDownField The main function that does the process of pull up field refactoring. Adds the necessary fields to the subclasses and removes them from the superclass. Source code in codart\\refactorings\\pushdown_field.py class PushDownField : \"\"\" The main function that does the process of pull up field refactoring. Adds the necessary fields to the subclasses and removes them from the superclass. \"\"\" def __init__ ( self , source_filenames : list , package_name : str , superclass_name : str , field_name : str , class_names : list = [], filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the superclass) superclass_name (str): The name of the needed superclass class_names (list): Name of the classes in which the refactoring has to be done \\ (the classes to push down field from) field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PushDownField): An instance of PushDownField class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . superclass_name = superclass_name self . field_name = field_name self . class_names = class_names self . filename_mapping = filename_mapping def pre_condition_check ( self , program , superclass ): if self . package_name not in program . packages \\ or self . superclass_name not in program . packages [ self . package_name ] . classes \\ or self . field_name not in program . packages [ self . package_name ] . classes [ self . superclass_name ] . fields : return False for m in superclass . methods : method : symbol_table . Method = superclass . methods [ m ] for item in method . body_local_vars_and_expr_names : if isinstance ( item , symbol_table . ExpressionName ): if (( len ( item . dot_separated_identifiers ) == 1 and item . dot_separated_identifiers [ 0 ] == self . field_name ) or ( len ( item . dot_separated_identifiers ) == 2 and item . dot_separated_identifiers [ 0 ] == \"this\" and item . dot_separated_identifiers [ 1 ] == self . field_name )): return False return True def do_refactor ( self ): program = symbol_table . get_program ( self . source_filenames , print_status = False ) superclass : symbol_table . Class = program . packages [ self . package_name ] . classes [ self . superclass_name ] if not self . pre_condition_check ( program , superclass ): print ( f \"Cannot push-down field from { superclass . name } \" ) return False other_derived_classes = [] classes_to_add_to = [] for pn in program . packages : p : symbol_table . Package = program . packages [ pn ] for cn in p . classes : c : symbol_table . Class = p . classes [ cn ] if (( c . superclass_name == self . superclass_name and c . file_info . has_imported_class ( self . package_name , self . superclass_name )) or ( self . package_name is not None and c . superclass_name == self . package_name + '.' + self . superclass_name )): # all_derived_classes.append(c) if len ( self . class_names ) == 0 or cn in self . class_names : if self . field_name in c . fields : print ( \"some classes have same variable\" ) return False else : classes_to_add_to . append ( c ) else : other_derived_classes . append ( c ) # Check if the field is used from the superclass or other derived classes for pn in program . packages : p : symbol_table . Package = program . packages [ pn ] for cn in p . classes : c : symbol_table . Class = p . classes [ cn ] has_imported_superclass = c . file_info . has_imported_class ( self . package_name , self . superclass_name ) fields_of_superclass_type_or_others = [] for fn in c . fields : f : symbol_table . Field = c . fields [ fn ] if ( f . name == self . field_name and has_imported_superclass ) \\ or ( self . package_name is not None and f . name == ( self . package_name + '.' + self . superclass_name )): fields_of_superclass_type_or_others . append ( f . name ) if any (( c . file_info . has_imported_class ( o . package_name , o . name ) and f . datatype == o . name ) or f . datatype == ( o . package_name + '.' + o . name ) for o in other_derived_classes ): fields_of_superclass_type_or_others . append ( f . name ) for mk in c . methods : m : symbol_table . Method = c . methods [ mk ] local_vars_of_superclass_type_or_others = [] for item in m . body_local_vars_and_expr_names : if isinstance ( item , symbol_table . LocalVariable ): if ( item . datatype == self . superclass_name and has_imported_superclass ) \\ or item . datatype == ( self . package_name + '.' + self . superclass_name ): local_vars_of_superclass_type_or_others . append ( item . identifier ) if any (( c . file_info . has_imported_class ( o . package_name , o . name ) and item . datatype == o . name ) or item . datatype == ( o . package_name + '.' + o . name ) for o in other_derived_classes ): local_vars_of_superclass_type_or_others . append ( item . identifier ) elif isinstance ( item , symbol_table . ExpressionName ): if item . dot_separated_identifiers [ - 1 ] == self . field_name \\ and ( ( len ( item . dot_separated_identifiers ) == 2 ) or ( len ( item . dot_separated_identifiers ) == 3 and item . dot_separated_identifiers [ 0 ] == \"this\" ) ) and ( ( item . dot_separated_identifiers [ - 2 ] in local_vars_of_superclass_type_or_others and len ( item . dot_separated_identifiers ) == 2 ) or item . dot_separated_identifiers [ - 2 ] in fields_of_superclass_type_or_others ): return False rewriter = symbol_table . Rewriter ( program , self . filename_mapping ) field = superclass . fields [ self . field_name ] if len ( field . neighbor_names ) == 0 : rewriter . replace ( field . get_tokens_info (), \"\" ) # Have to remove the modifiers too, because of the new grammar. for mod_ctx in field . modifiers_parser_contexts : rewriter . replace ( symbol_table . TokensInfo ( mod_ctx ), \"\" ) else : i = field . index_in_variable_declarators var_ctxs = field . all_variable_declarator_contexts if i == 0 : to_remove = symbol_table . TokensInfo ( var_ctxs [ i ]) to_remove . stop = symbol_table . TokensInfo ( var_ctxs [ i + 1 ]) . start - 1 # Include the ',' after it rewriter . replace ( to_remove , \"\" ) else : to_remove = symbol_table . TokensInfo ( var_ctxs [ i ]) to_remove . start = symbol_table . TokensInfo ( var_ctxs [ i - 1 ]) . stop + 1 # Include the ',' before it rewriter . replace ( to_remove , \"\" ) is_public = \"public\" in field . modifiers is_protected = \"protected\" in field . modifiers modifier = ( \"public \" if is_public else ( \"protected \" if is_protected else \"\" )) for c in classes_to_add_to : c_body_start = symbol_table . TokensInfo ( c . parser_context . classBody ()) c_body_start . stop = c_body_start . start # Start and stop both point to the '{' rewriter . insert_after ( c_body_start , ( \" \\n \" + modifier + field . datatype + \" \" + self . field_name + (( \" = \" + field . initializer ) if field . initializer is not None else \"\" ) + \";\" ) ) rewriter . apply () return True __init__ ( self , source_filenames , package_name , superclass_name , field_name , class_names = [], filename_mapping =< function PushDownField .< lambda > at 0x000001616E4A4700 > ) special Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the superclass) required superclass_name str The name of the needed superclass required class_names list Name of the classes in which the refactoring has to be done (the classes to push down field from) [] field_name str Name of the field that has to be refactored required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function PushDownField.<lambda> at 0x000001616E4A4700> Returns: Type Description object (PushDownField) An instance of PushDownField class Source code in codart\\refactorings\\pushdown_field.py def __init__ ( self , source_filenames : list , package_name : str , superclass_name : str , field_name : str , class_names : list = [], filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the superclass) superclass_name (str): The name of the needed superclass class_names (list): Name of the classes in which the refactoring has to be done \\ (the classes to push down field from) field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PushDownField): An instance of PushDownField class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . superclass_name = superclass_name self . field_name = field_name self . class_names = class_names self . filename_mapping = filename_mapping main ( project_dir , source_package , source_class , field_name , target_classes , * args , ** kwargs ) Source code in codart\\refactorings\\pushdown_field.py def main ( project_dir , source_package , source_class , field_name , target_classes : list , * args , ** kwargs ): \"\"\" \"\"\" res = PushDownField ( symbol_table . get_filenames_in_dir ( project_dir ), package_name = source_package , superclass_name = source_class , field_name = field_name , class_names = target_classes , ) . do_refactor () if not res : logger . error ( \"Cannot push-down field\" ) return False return True Push-down field 2 Introduction The module implements a light-weight version of push-down field refactoring described in pushdown_field.py . Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions CutFieldListener ( JavaParserLabeledListener ) Removes the field declaration from the parent class. Source code in codart\\refactorings\\pushdown_field2.py class CutFieldListener ( JavaParserLabeledListener ): \"\"\" Removes the field declaration from the parent class. \"\"\" def __init__ ( self , source_class : str , field_name : str , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. field_name: (str) Field's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutFieldListener): The full string of field declaration \"\"\" self . source_class = source_class self . field_name = field_name self . rewriter = rewriter self . field_content = \"\" self . import_statements = \"\" self . detected_field = False self . is_source_class = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if class_name == self . source_class : self . is_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if self . is_source_class and class_name == self . source_class : self . is_source_class = False def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): statement = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . import_statements += statement + \" \\n \" def exitVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): variable_name = ctx . IDENTIFIER () . getText () if self . is_source_class : if variable_name == self . field_name : self . detected_field = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_field and self . is_source_class : self . field_content = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . rewriter . delete ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex ) self . detected_field = False __init__ ( self , source_class , field_name , rewriter ) special Parameters: Name Type Description Default source_class str (str) Parent's class name. required field_name str (str) Field's name. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description field_content (CutFieldListener) The full string of field declaration Source code in codart\\refactorings\\pushdown_field2.py def __init__ ( self , source_class : str , field_name : str , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. field_name: (str) Field's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutFieldListener): The full string of field declaration \"\"\" self . source_class = source_class self . field_name = field_name self . rewriter = rewriter self . field_content = \"\" self . import_statements = \"\" self . detected_field = False self . is_source_class = False PasteFieldListener ( JavaParserLabeledListener ) Inserts field declaration to children classes. Source code in codart\\refactorings\\pushdown_field2.py class PasteFieldListener ( JavaParserLabeledListener ): \"\"\" Inserts field declaration to children classes. \"\"\" def __init__ ( self , source_class , field_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: Child class name. field_content: Full string of the field declaration. rewriter: Antlr's token stream rewriter. Returns: object (PasteFieldListener): An instance of PasteFieldListener class \"\"\" self . source_class = source_class self . rewriter = rewriter self . field_content = field_content self . import_statements = import_statements self . is_source_class = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if class_name == self . source_class : self . is_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if self . is_source_class and class_name == self . source_class : self . is_source_class = False def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . rewriter . insertAfter ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , index = ctx . stop . tokenIndex , text = \" \\n \" + self . import_statements ) def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_source_class : self . rewriter . insertAfter ( index = ctx . start . tokenIndex , text = \" \\n\\t \" + self . field_content ) __init__ ( self , source_class , field_content , import_statements , rewriter ) special Parameters: Name Type Description Default source_class Child class name. required field_content Full string of the field declaration. required rewriter TokenStreamRewriter Antlr's token stream rewriter. required Returns: Type Description object (PasteFieldListener) An instance of PasteFieldListener class Source code in codart\\refactorings\\pushdown_field2.py def __init__ ( self , source_class , field_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: Child class name. field_content: Full string of the field declaration. rewriter: Antlr's token stream rewriter. Returns: object (PasteFieldListener): An instance of PasteFieldListener class \"\"\" self . source_class = source_class self . rewriter = rewriter self . field_content = field_content self . import_statements = import_statements self . is_source_class = False main ( udb_path = None , source_package = None , source_class = None , field_name = None , target_classes = None , * args , ** kwargs ) The main API for push-down field refactoring Source code in codart\\refactorings\\pushdown_field2.py def main ( udb_path = None , source_package = None , source_class = None , field_name = None , target_classes : list = None , * args , ** kwargs ): \"\"\" The main API for push-down field refactoring \"\"\" if udb_path is None : db = und . open ( codart . config . UDB_PATH ) else : db = und . open ( udb_path ) source_class_ent = None source_class_ents = db . lookup ( f \" { source_package } . { source_class } \" , \"Class\" ) if len ( source_class_ents ) == 0 : logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False else : for ent in source_class_ents : if ent . simplename () == source_class : source_class_ent = ent break if source_class_ent is None : logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False fields = db . lookup ( f \" { source_package } . { source_class } . { field_name } \" , \"Variable\" ) if fields is None or len ( fields ) == 0 : logger . error ( f \"Cannot find field to pushdown: { field_name } \" ) db . close () return False else : field_ent = fields [ 0 ] target_class_ents_files = [] target_class_ents_simplenames = [] for ref in source_class_ent . refs ( \"Extendby\" ): if ref . ent () . simplename () not in target_classes : logger . error ( \"Target classes are not children classes\" ) db . close () return False target_class_ents_files . append ( ref . ent () . parent () . longname ()) target_class_ents_simplenames . append ( ref . ent () . simplename ()) for ref in field_ent . refs ( \"Useby, Setby\" ): if ref . file () . simplename () . split ( \".\" )[ 0 ] in target_classes : continue else : logger . error ( \"Field has dependencies.\" ) db . close () return False source_class_file = source_class_ent . parent () . longname () db . close () # Remove field from source class listener = parse_and_walk ( file_path = source_class_file , listener_class = CutFieldListener , has_write = True , source_class = source_class , field_name = field_name , debug = False ) # Insert field in children classes for i , target_class_file in enumerate ( target_class_ents_files ): parse_and_walk ( file_path = target_class_file , listener_class = PasteFieldListener , has_write = True , source_class = target_class_ents_simplenames [ i ], field_content = listener . field_content , import_statements = listener . import_statements , debug = False ) # db.close() return True","title":"Push-down field"},{"location":"refactorings/push_down_field/#push-down-field","text":"","title":"Push-down field"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field--introduction","text":"Although it was planned to use a field universally for all classes, in reality the field is used only in some subclasses. This situation can occur when planned features fail to pan out, for example. because of this, we push down the field from the superclass into its related subclass.","title":"Introduction"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field--pre-and-post-conditions","text":"","title":"Pre and Post Conditions"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field--pre-conditions","text":"There should exist a corresponding child and parent in the project. The field that should be pushed down must be valid. The user must enter the package's name, class's name and the fields that need to be added.","title":"Pre Conditions:"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field--post-conditions","text":"The changed field's usages and callings will also change respectively. There will be children and parents having their desired fields added or removed.","title":"Post Conditions:"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field.PushDownField","text":"The main function that does the process of pull up field refactoring. Adds the necessary fields to the subclasses and removes them from the superclass. Source code in codart\\refactorings\\pushdown_field.py class PushDownField : \"\"\" The main function that does the process of pull up field refactoring. Adds the necessary fields to the subclasses and removes them from the superclass. \"\"\" def __init__ ( self , source_filenames : list , package_name : str , superclass_name : str , field_name : str , class_names : list = [], filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the superclass) superclass_name (str): The name of the needed superclass class_names (list): Name of the classes in which the refactoring has to be done \\ (the classes to push down field from) field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PushDownField): An instance of PushDownField class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . superclass_name = superclass_name self . field_name = field_name self . class_names = class_names self . filename_mapping = filename_mapping def pre_condition_check ( self , program , superclass ): if self . package_name not in program . packages \\ or self . superclass_name not in program . packages [ self . package_name ] . classes \\ or self . field_name not in program . packages [ self . package_name ] . classes [ self . superclass_name ] . fields : return False for m in superclass . methods : method : symbol_table . Method = superclass . methods [ m ] for item in method . body_local_vars_and_expr_names : if isinstance ( item , symbol_table . ExpressionName ): if (( len ( item . dot_separated_identifiers ) == 1 and item . dot_separated_identifiers [ 0 ] == self . field_name ) or ( len ( item . dot_separated_identifiers ) == 2 and item . dot_separated_identifiers [ 0 ] == \"this\" and item . dot_separated_identifiers [ 1 ] == self . field_name )): return False return True def do_refactor ( self ): program = symbol_table . get_program ( self . source_filenames , print_status = False ) superclass : symbol_table . Class = program . packages [ self . package_name ] . classes [ self . superclass_name ] if not self . pre_condition_check ( program , superclass ): print ( f \"Cannot push-down field from { superclass . name } \" ) return False other_derived_classes = [] classes_to_add_to = [] for pn in program . packages : p : symbol_table . Package = program . packages [ pn ] for cn in p . classes : c : symbol_table . Class = p . classes [ cn ] if (( c . superclass_name == self . superclass_name and c . file_info . has_imported_class ( self . package_name , self . superclass_name )) or ( self . package_name is not None and c . superclass_name == self . package_name + '.' + self . superclass_name )): # all_derived_classes.append(c) if len ( self . class_names ) == 0 or cn in self . class_names : if self . field_name in c . fields : print ( \"some classes have same variable\" ) return False else : classes_to_add_to . append ( c ) else : other_derived_classes . append ( c ) # Check if the field is used from the superclass or other derived classes for pn in program . packages : p : symbol_table . Package = program . packages [ pn ] for cn in p . classes : c : symbol_table . Class = p . classes [ cn ] has_imported_superclass = c . file_info . has_imported_class ( self . package_name , self . superclass_name ) fields_of_superclass_type_or_others = [] for fn in c . fields : f : symbol_table . Field = c . fields [ fn ] if ( f . name == self . field_name and has_imported_superclass ) \\ or ( self . package_name is not None and f . name == ( self . package_name + '.' + self . superclass_name )): fields_of_superclass_type_or_others . append ( f . name ) if any (( c . file_info . has_imported_class ( o . package_name , o . name ) and f . datatype == o . name ) or f . datatype == ( o . package_name + '.' + o . name ) for o in other_derived_classes ): fields_of_superclass_type_or_others . append ( f . name ) for mk in c . methods : m : symbol_table . Method = c . methods [ mk ] local_vars_of_superclass_type_or_others = [] for item in m . body_local_vars_and_expr_names : if isinstance ( item , symbol_table . LocalVariable ): if ( item . datatype == self . superclass_name and has_imported_superclass ) \\ or item . datatype == ( self . package_name + '.' + self . superclass_name ): local_vars_of_superclass_type_or_others . append ( item . identifier ) if any (( c . file_info . has_imported_class ( o . package_name , o . name ) and item . datatype == o . name ) or item . datatype == ( o . package_name + '.' + o . name ) for o in other_derived_classes ): local_vars_of_superclass_type_or_others . append ( item . identifier ) elif isinstance ( item , symbol_table . ExpressionName ): if item . dot_separated_identifiers [ - 1 ] == self . field_name \\ and ( ( len ( item . dot_separated_identifiers ) == 2 ) or ( len ( item . dot_separated_identifiers ) == 3 and item . dot_separated_identifiers [ 0 ] == \"this\" ) ) and ( ( item . dot_separated_identifiers [ - 2 ] in local_vars_of_superclass_type_or_others and len ( item . dot_separated_identifiers ) == 2 ) or item . dot_separated_identifiers [ - 2 ] in fields_of_superclass_type_or_others ): return False rewriter = symbol_table . Rewriter ( program , self . filename_mapping ) field = superclass . fields [ self . field_name ] if len ( field . neighbor_names ) == 0 : rewriter . replace ( field . get_tokens_info (), \"\" ) # Have to remove the modifiers too, because of the new grammar. for mod_ctx in field . modifiers_parser_contexts : rewriter . replace ( symbol_table . TokensInfo ( mod_ctx ), \"\" ) else : i = field . index_in_variable_declarators var_ctxs = field . all_variable_declarator_contexts if i == 0 : to_remove = symbol_table . TokensInfo ( var_ctxs [ i ]) to_remove . stop = symbol_table . TokensInfo ( var_ctxs [ i + 1 ]) . start - 1 # Include the ',' after it rewriter . replace ( to_remove , \"\" ) else : to_remove = symbol_table . TokensInfo ( var_ctxs [ i ]) to_remove . start = symbol_table . TokensInfo ( var_ctxs [ i - 1 ]) . stop + 1 # Include the ',' before it rewriter . replace ( to_remove , \"\" ) is_public = \"public\" in field . modifiers is_protected = \"protected\" in field . modifiers modifier = ( \"public \" if is_public else ( \"protected \" if is_protected else \"\" )) for c in classes_to_add_to : c_body_start = symbol_table . TokensInfo ( c . parser_context . classBody ()) c_body_start . stop = c_body_start . start # Start and stop both point to the '{' rewriter . insert_after ( c_body_start , ( \" \\n \" + modifier + field . datatype + \" \" + self . field_name + (( \" = \" + field . initializer ) if field . initializer is not None else \"\" ) + \";\" ) ) rewriter . apply () return True","title":"PushDownField"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field.PushDownField.__init__","text":"Parameters: Name Type Description Default source_filenames list A list of file names to be processed required package_name str The name of the package in which the refactoring has to be done (contains the superclass) required superclass_name str The name of the needed superclass required class_names list Name of the classes in which the refactoring has to be done (the classes to push down field from) [] field_name str Name of the field that has to be refactored required filename_mapping str Mapping the file's name to the correct format so that it can be processed <function PushDownField.<lambda> at 0x000001616E4A4700> Returns: Type Description object (PushDownField) An instance of PushDownField class Source code in codart\\refactorings\\pushdown_field.py def __init__ ( self , source_filenames : list , package_name : str , superclass_name : str , field_name : str , class_names : list = [], filename_mapping = lambda x : ( x [: - 5 ] if x . endswith ( \".java\" ) else x ) + \".java\" ): \"\"\" Args: source_filenames (list): A list of file names to be processed package_name (str): The name of the package in which the refactoring has to be done \\ (contains the superclass) superclass_name (str): The name of the needed superclass class_names (list): Name of the classes in which the refactoring has to be done \\ (the classes to push down field from) field_name (str): Name of the field that has to be refactored filename_mapping (str): Mapping the file's name to the correct format so that it can be processed Returns: object (PushDownField): An instance of PushDownField class \"\"\" self . source_filenames = source_filenames self . package_name = package_name self . superclass_name = superclass_name self . field_name = field_name self . class_names = class_names self . filename_mapping = filename_mapping","title":"__init__()"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field.main","text":"Source code in codart\\refactorings\\pushdown_field.py def main ( project_dir , source_package , source_class , field_name , target_classes : list , * args , ** kwargs ): \"\"\" \"\"\" res = PushDownField ( symbol_table . get_filenames_in_dir ( project_dir ), package_name = source_package , superclass_name = source_class , field_name = field_name , class_names = target_classes , ) . do_refactor () if not res : logger . error ( \"Cannot push-down field\" ) return False return True","title":"main()"},{"location":"refactorings/push_down_field/#push-down-field-2","text":"","title":"Push-down field 2"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field2--introduction","text":"The module implements a light-weight version of push-down field refactoring described in pushdown_field.py .","title":"Introduction"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field2.CutFieldListener","text":"Removes the field declaration from the parent class. Source code in codart\\refactorings\\pushdown_field2.py class CutFieldListener ( JavaParserLabeledListener ): \"\"\" Removes the field declaration from the parent class. \"\"\" def __init__ ( self , source_class : str , field_name : str , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. field_name: (str) Field's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutFieldListener): The full string of field declaration \"\"\" self . source_class = source_class self . field_name = field_name self . rewriter = rewriter self . field_content = \"\" self . import_statements = \"\" self . detected_field = False self . is_source_class = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if class_name == self . source_class : self . is_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if self . is_source_class and class_name == self . source_class : self . is_source_class = False def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): statement = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . import_statements += statement + \" \\n \" def exitVariableDeclaratorId ( self , ctx : JavaParserLabeled . VariableDeclaratorIdContext ): variable_name = ctx . IDENTIFIER () . getText () if self . is_source_class : if variable_name == self . field_name : self . detected_field = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_field and self . is_source_class : self . field_content = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . rewriter . delete ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex ) self . detected_field = False","title":"CutFieldListener"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field2.CutFieldListener.__init__","text":"Parameters: Name Type Description Default source_class str (str) Parent's class name. required field_name str (str) Field's name. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description field_content (CutFieldListener) The full string of field declaration Source code in codart\\refactorings\\pushdown_field2.py def __init__ ( self , source_class : str , field_name : str , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. field_name: (str) Field's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutFieldListener): The full string of field declaration \"\"\" self . source_class = source_class self . field_name = field_name self . rewriter = rewriter self . field_content = \"\" self . import_statements = \"\" self . detected_field = False self . is_source_class = False","title":"__init__()"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field2.PasteFieldListener","text":"Inserts field declaration to children classes. Source code in codart\\refactorings\\pushdown_field2.py class PasteFieldListener ( JavaParserLabeledListener ): \"\"\" Inserts field declaration to children classes. \"\"\" def __init__ ( self , source_class , field_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: Child class name. field_content: Full string of the field declaration. rewriter: Antlr's token stream rewriter. Returns: object (PasteFieldListener): An instance of PasteFieldListener class \"\"\" self . source_class = source_class self . rewriter = rewriter self . field_content = field_content self . import_statements = import_statements self . is_source_class = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if class_name == self . source_class : self . is_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if self . is_source_class and class_name == self . source_class : self . is_source_class = False def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . rewriter . insertAfter ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , index = ctx . stop . tokenIndex , text = \" \\n \" + self . import_statements ) def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_source_class : self . rewriter . insertAfter ( index = ctx . start . tokenIndex , text = \" \\n\\t \" + self . field_content )","title":"PasteFieldListener"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field2.PasteFieldListener.__init__","text":"Parameters: Name Type Description Default source_class Child class name. required field_content Full string of the field declaration. required rewriter TokenStreamRewriter Antlr's token stream rewriter. required Returns: Type Description object (PasteFieldListener) An instance of PasteFieldListener class Source code in codart\\refactorings\\pushdown_field2.py def __init__ ( self , source_class , field_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: Child class name. field_content: Full string of the field declaration. rewriter: Antlr's token stream rewriter. Returns: object (PasteFieldListener): An instance of PasteFieldListener class \"\"\" self . source_class = source_class self . rewriter = rewriter self . field_content = field_content self . import_statements = import_statements self . is_source_class = False","title":"__init__()"},{"location":"refactorings/push_down_field/#codart.refactorings.pushdown_field2.main","text":"The main API for push-down field refactoring Source code in codart\\refactorings\\pushdown_field2.py def main ( udb_path = None , source_package = None , source_class = None , field_name = None , target_classes : list = None , * args , ** kwargs ): \"\"\" The main API for push-down field refactoring \"\"\" if udb_path is None : db = und . open ( codart . config . UDB_PATH ) else : db = und . open ( udb_path ) source_class_ent = None source_class_ents = db . lookup ( f \" { source_package } . { source_class } \" , \"Class\" ) if len ( source_class_ents ) == 0 : logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False else : for ent in source_class_ents : if ent . simplename () == source_class : source_class_ent = ent break if source_class_ent is None : logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False fields = db . lookup ( f \" { source_package } . { source_class } . { field_name } \" , \"Variable\" ) if fields is None or len ( fields ) == 0 : logger . error ( f \"Cannot find field to pushdown: { field_name } \" ) db . close () return False else : field_ent = fields [ 0 ] target_class_ents_files = [] target_class_ents_simplenames = [] for ref in source_class_ent . refs ( \"Extendby\" ): if ref . ent () . simplename () not in target_classes : logger . error ( \"Target classes are not children classes\" ) db . close () return False target_class_ents_files . append ( ref . ent () . parent () . longname ()) target_class_ents_simplenames . append ( ref . ent () . simplename ()) for ref in field_ent . refs ( \"Useby, Setby\" ): if ref . file () . simplename () . split ( \".\" )[ 0 ] in target_classes : continue else : logger . error ( \"Field has dependencies.\" ) db . close () return False source_class_file = source_class_ent . parent () . longname () db . close () # Remove field from source class listener = parse_and_walk ( file_path = source_class_file , listener_class = CutFieldListener , has_write = True , source_class = source_class , field_name = field_name , debug = False ) # Insert field in children classes for i , target_class_file in enumerate ( target_class_ents_files ): parse_and_walk ( file_path = target_class_file , listener_class = PasteFieldListener , has_write = True , source_class = target_class_ents_simplenames [ i ], field_content = listener . field_content , import_statements = listener . import_statements , debug = False ) # db.close() return True","title":"main()"},{"location":"refactorings/push_down_method/","text":"Push-down method Introduction The module implements push-down method refactoring Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions DeleteSourceListener ( JavaParserLabeledListener ) Source code in codart\\refactorings\\pushdown_method.py class DeleteSourceListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream , source_method : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_method = source_method def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . source_method == ctx . IDENTIFIER () . getText (): self . token_stream_rewriter . replaceRange ( from_idx = ctx . parentCtx . parentCtx . start . tokenIndex , to_idx = ctx . parentCtx . parentCtx . stop . tokenIndex , text = \"\" ) __init__ ( self , common_token_stream , source_method ) special Source code in codart\\refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_method : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_method = source_method PropagationListener ( JavaParserLabeledListener ) Source code in codart\\refactorings\\pushdown_method.py class PropagationListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , child_class : str , class_name : str , method_name : str , ref_line : int , target_package : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_class = source_class self . child_class = child_class self . class_name = class_name self . method_name = method_name self . ref_line = ref_line self . target_package = target_package self . start = None self . stop = None self . is_safe = False self . need_cast = False self . variable = None self . detected_class = False self . detected_package = False self . import_end = None def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . is_safe = ctx . IDENTIFIER () . getText () == self . class_name def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . is_safe = not self . is_safe def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . target_package in ctx . getText (): self . detected_package = True self . import_end = ctx . stop def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if f \" { self . target_package } . { self . child_class } \" in ctx . getText (): self . detected_package = True self . import_end = ctx . stop def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): if not self . detected_package and self . import_end is not None : self . token_stream_rewriter . insertAfterToken ( token = self . import_end , text = f \" \\n import { self . target_package } . { self . child_class } ; \\n \" , program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME ) __init__ ( self , common_token_stream , source_class , child_class , class_name , method_name , ref_line , target_package ) special Source code in codart\\refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , child_class : str , class_name : str , method_name : str , ref_line : int , target_package : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_class = source_class self . child_class = child_class self . class_name = class_name self . method_name = method_name self . ref_line = ref_line self . target_package = target_package self . start = None self . stop = None self . is_safe = False self . need_cast = False self . variable = None self . detected_class = False self . detected_package = False self . import_end = None PropagationNonStaticListener ( PropagationListener ) Source code in codart\\refactorings\\pushdown_method.py class PropagationNonStaticListener ( PropagationListener ): \"\"\" \"\"\" def exitCreatedName0 ( self , ctx : JavaParserLabeled . CreatedName0Context ): if ctx . IDENTIFIER ( 0 ) . getText () == self . source_class and self . is_safe : self . detected_class = True self . start = ctx . start self . stop = ctx . stop def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if ctx . IDENTIFIER () . getText () == self . method_name and self . is_safe and self . detected_class : # Change Name if ctx . start . line == self . ref_line : self . token_stream_rewriter . replaceRange ( from_idx = self . start . tokenIndex , to_idx = self . stop . tokenIndex , text = self . child_class ) self . detected_class = False def exitVariableDeclarator ( self , ctx : JavaParserLabeled . VariableDeclaratorContext ): if self . detected_class and self . is_safe : self . variable = ctx . variableDeclaratorId () . IDENTIFIER () . getText () self . detected_class = False def enterExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if ctx . start . line == self . ref_line and self . is_safe : self . need_cast = True def exitExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if ctx . start . line == self . ref_line and self . is_safe : self . need_cast = False def enterExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): self . enterExpression21 ( ctx ) def exitExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): if self . is_safe and self . need_cast and self . variable is not None : # Type casting child = ctx . getChild ( 0 ) . getChild ( 0 ) self . token_stream_rewriter . replaceRange ( from_idx = child . start . tokenIndex , to_idx = child . stop . tokenIndex , text = f \"(( { self . child_class } ) { self . variable } )\" ) self . need_cast = False PropagationStaticListener ( PropagationListener ) Source code in codart\\refactorings\\pushdown_method.py class PropagationStaticListener ( PropagationListener ): \"\"\" \"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\" \"\"\" super ( PropagationStaticListener , self ) . __init__ ( * args , ** kwargs ) self . detected_method = False def enterPrimary4 ( self , ctx : JavaParserLabeled . Primary4Context ): if self . is_safe : self . start = ctx . start self . stop = ctx . stop self . detected_class = True def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): method_name = ctx . IDENTIFIER () . getText () if method_name == self . method_name and self . is_safe : self . detected_method = True def exitMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if self . detected_method and self . detected_class : self . detected_class = False self . detected_method = False self . token_stream_rewriter . replaceRange ( from_idx = self . start . tokenIndex , to_idx = self . stop . tokenIndex , text = f \" { self . child_class } \" ) PushDownMethodRefactoringListener ( JavaParserLabeledListener ) Source code in codart\\refactorings\\pushdown_method.py class PushDownMethodRefactoringListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , source_method_text : str ): \"\"\" \"\"\" self . source_method_text = source_method_text self . source_class = source_class self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_safe = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . is_safe = ctx . IDENTIFIER () . getText () == self . source_class def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . is_safe = not self . is_safe def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_safe : self . token_stream_rewriter . insertBefore ( index = ctx . stop . tokenIndex , text = self . source_method_text + \" \\n \" , program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME ) __init__ ( self , common_token_stream , source_class , source_method_text ) special Source code in codart\\refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , source_method_text : str ): \"\"\" \"\"\" self . source_method_text = source_method_text self . source_class = source_class self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_safe = False main ( udb_path , source_package , source_class , method_name , target_classes , * args , ** kwargs ) The main API for the push-down method refactoring operation Source code in codart\\refactorings\\pushdown_method.py def main ( udb_path , source_package , source_class , method_name , target_classes : list , * args , ** kwargs ): \"\"\" The main API for the push-down method refactoring operation \"\"\" target_package = source_package source_method = method_name main_file = None source_method_entity = None is_static = False propagation_files = [] propagation_classes = [] propagation_lines = [] children_classes = [] children_files = [] # Initialize with understand db = und . open ( udb_path ) methods = db . ents ( \"Java Method\" ) for mth in methods : if mth . longname () == source_package + \".\" + source_class + \".\" + source_method : source_method_entity = mth for child_ref in mth . parent () . refs ( \"Extendby\" ): child_ref = child_ref . ent () if child_ref . simplename () in target_classes : children_classes . append ( child_ref . simplename ()) children_files . append ( child_ref . parent () . longname ()) # print(\"mainfile : \", mth.parent().parent().longname()) is_static = mth . kind () . check ( \"static\" ) main_file = mth . parent () . parent () . longname () for ref in mth . refs ( \"Callby\" ): propagation_files . append ( ref . ent () . parent () . parent () . longname ()) propagation_classes . append ( ref . ent () . parent () . simplename ()) propagation_lines . append ( ref . line ()) # Check pre-condition if not len ( target_classes ) == 1 : logger . error ( f \"len(target_classes) is not 1.\" ) db . close () return False if not len ( children_classes ) == 1 : logger . error ( f \"len(children_classes) is not 1.\" ) db . close () return False if not len ( children_files ) == 1 : logger . error ( f \"len(children_files) is not 1.\" ) db . close () return False for mth in methods : if mth . simplename () == source_method : if mth . parent () . simplename () in target_classes : if mth . type () == source_method_entity . type (): if mth . kind () == source_method_entity . kind (): if mth . parameters () == source_method_entity . parameters (): logger . error ( \"Duplicated method\" ) db . close () return False for ref in source_method_entity . refs ( \"use, call\" ): ref_ent = ref . ent () is_public = ref_ent . kind () . check ( \"public\" ) if not is_public : logger . error ( \"Has internal dependencies.\" ) db . close () return False # get text method_text = source_method_entity . contents () db . close () # Delete source method stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = DeleteSourceListener ( common_token_stream = token_stream , source_method = source_method ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( main_file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # Do the push down for child_file , child_class in zip ( children_files , children_classes ): stream = FileStream ( child_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = PushDownMethodRefactoringListener ( common_token_stream = token_stream , source_class = child_class , source_method_text = method_text ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( child_file , mode = 'w' , encoding = 'utf8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # Propagation for file , _class , line in zip ( propagation_files , propagation_classes , propagation_lines ): stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () if is_static : my_listener = PropagationStaticListener ( common_token_stream = token_stream , source_class = source_class , child_class = children_classes [ 0 ], class_name = _class , method_name = source_method , ref_line = line , target_package = target_package ) else : my_listener = PropagationNonStaticListener ( common_token_stream = token_stream , source_class = source_class , child_class = children_classes [ 0 ], class_name = _class , method_name = source_method , ref_line = line , target_package = target_package ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True Push-down method 2 Introduction The module implements a light-weight version of the push-down method refactoring described in pushdown_method.py Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions CutMethodListener ( JavaParserLabeledListener ) Removes the method declaration from the parent class. Source code in codart\\refactorings\\pushdown_method2.py class CutMethodListener ( JavaParserLabeledListener ): \"\"\" Removes the method declaration from the parent class. \"\"\" def __init__ ( self , source_class , method_name , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. method_name: (str) Method's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutMethodListener): The full string of method declaration \"\"\" self . source_class = source_class self . method_name = method_name self . rewriter = rewriter self . method_content = \"\" self . import_statements = \"\" self . detected_method = False self . is_source_class = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if class_name == self . source_class : self . is_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if self . is_source_class and class_name == self . source_class : self . is_source_class = False def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): statement = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . import_statements += statement + \" \\n \" def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_source_class and ctx . IDENTIFIER () . getText () == self . method_name : self . detected_method = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_method : self . method_content = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . rewriter . delete ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex ) self . detected_method = False __init__ ( self , source_class , method_name , rewriter ) special Parameters: Name Type Description Default source_class (str) Parent's class name. required method_name (str) Method's name. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description field_content (CutMethodListener) The full string of method declaration Source code in codart\\refactorings\\pushdown_method2.py def __init__ ( self , source_class , method_name , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. method_name: (str) Method's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutMethodListener): The full string of method declaration \"\"\" self . source_class = source_class self . method_name = method_name self . rewriter = rewriter self . method_content = \"\" self . import_statements = \"\" self . detected_method = False self . is_source_class = False PasteMethodListener ( JavaParserLabeledListener ) Inserts method declaration to children classes. Source code in codart\\refactorings\\pushdown_method2.py class PasteMethodListener ( JavaParserLabeledListener ): \"\"\" Inserts method declaration to children classes. \"\"\" def __init__ ( self , source_class , method_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Child class name. method_content (str): Full string of the method declaration. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: object (PasteMethodListener): An instance of PasteMethodListener class. \"\"\" self . source_class = source_class self . rewriter = rewriter self . method_content = method_content self . import_statements = import_statements self . is_source_class = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if class_name == self . source_class : self . is_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if self . is_source_class and class_name == self . source_class : self . is_source_class = False def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . rewriter . insertAfter ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , index = ctx . stop . tokenIndex , text = \" \\n \" + self . import_statements ) def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_source_class : self . rewriter . insertBefore ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , index = ctx . stop . tokenIndex , text = \" \\n\\t \" + self . method_content + \" \\n \" ) __init__ ( self , source_class , method_content , import_statements , rewriter ) special Parameters: Name Type Description Default source_class str Child class name. required method_content str Full string of the method declaration. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description object (PasteMethodListener) An instance of PasteMethodListener class. Source code in codart\\refactorings\\pushdown_method2.py def __init__ ( self , source_class , method_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Child class name. method_content (str): Full string of the method declaration. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: object (PasteMethodListener): An instance of PasteMethodListener class. \"\"\" self . source_class = source_class self . rewriter = rewriter self . method_content = method_content self . import_statements = import_statements self . is_source_class = False main ( udb_path , source_package , source_class , method_name , target_classes , * args , ** kwargs ) The main API for the push-down method refactoring (version 2) Source code in codart\\refactorings\\pushdown_method2.py def main ( udb_path , source_package , source_class , method_name , target_classes : list , * args , ** kwargs ): \"\"\" The main API for the push-down method refactoring (version 2) \"\"\" db = und . open ( udb_path ) source_class_ents = db . lookup ( f \" { source_package } . { source_class } \" , \"Class\" ) target_class_ents = [] source_class_ent = None if len ( source_class_ents ) == 0 : config . logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False else : for ent in source_class_ents : if ent . simplename () == source_class : source_class_ent = ent break if source_class_ent is None : config . logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False method_ent = db . lookup ( f \" { source_package } . { source_class } . { method_name } \" , \"Method\" ) if len ( method_ent ) == 0 : config . logger . error ( f \"Cannot find method to pushdown: { method_name } \" ) db . close () return False else : method_ent = method_ent [ 0 ] for ref in source_class_ent . refs ( \"extendBy\" ): if ref . ent () . simplename () not in target_classes : config . logger . error ( \"Target classes are not children classes\" ) db . close () return False target_class_ents . append ( ref . ent ()) for ref in method_ent . refs ( \"callBy\" ): if ref . file () . simplename () . split ( \".\" )[ 0 ] in target_classes : continue else : config . logger . error ( \"Method has dependencies.\" ) db . close () return False # Remove field from source class listener = parse_and_walk ( file_path = source_class_ent . parent () . longname (), listener_class = CutMethodListener , has_write = True , source_class = source_class , method_name = method_name , debug = False ) # Insert field in children classes for target_class in target_class_ents : parse_and_walk ( file_path = target_class . parent () . longname (), listener_class = PasteMethodListener , has_write = True , source_class = target_class . simplename (), method_content = listener . method_content , import_statements = listener . import_statements , debug = False ) db . close ()","title":"Push-down method"},{"location":"refactorings/push_down_method/#push-down-method","text":"","title":"Push-down method"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method--introduction","text":"The module implements push-down method refactoring","title":"Introduction"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.DeleteSourceListener","text":"Source code in codart\\refactorings\\pushdown_method.py class DeleteSourceListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream , source_method : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_method = source_method def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . source_method == ctx . IDENTIFIER () . getText (): self . token_stream_rewriter . replaceRange ( from_idx = ctx . parentCtx . parentCtx . start . tokenIndex , to_idx = ctx . parentCtx . parentCtx . stop . tokenIndex , text = \"\" )","title":"DeleteSourceListener"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.DeleteSourceListener.__init__","text":"Source code in codart\\refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_method : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_method = source_method","title":"__init__()"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.PropagationListener","text":"Source code in codart\\refactorings\\pushdown_method.py class PropagationListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , child_class : str , class_name : str , method_name : str , ref_line : int , target_package : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_class = source_class self . child_class = child_class self . class_name = class_name self . method_name = method_name self . ref_line = ref_line self . target_package = target_package self . start = None self . stop = None self . is_safe = False self . need_cast = False self . variable = None self . detected_class = False self . detected_package = False self . import_end = None def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . is_safe = ctx . IDENTIFIER () . getText () == self . class_name def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . is_safe = not self . is_safe def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . target_package in ctx . getText (): self . detected_package = True self . import_end = ctx . stop def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if f \" { self . target_package } . { self . child_class } \" in ctx . getText (): self . detected_package = True self . import_end = ctx . stop def exitCompilationUnit ( self , ctx : JavaParserLabeled . CompilationUnitContext ): if not self . detected_package and self . import_end is not None : self . token_stream_rewriter . insertAfterToken ( token = self . import_end , text = f \" \\n import { self . target_package } . { self . child_class } ; \\n \" , program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME )","title":"PropagationListener"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.PropagationListener.__init__","text":"Source code in codart\\refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , child_class : str , class_name : str , method_name : str , ref_line : int , target_package : str ): \"\"\" \"\"\" self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . source_class = source_class self . child_class = child_class self . class_name = class_name self . method_name = method_name self . ref_line = ref_line self . target_package = target_package self . start = None self . stop = None self . is_safe = False self . need_cast = False self . variable = None self . detected_class = False self . detected_package = False self . import_end = None","title":"__init__()"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.PropagationNonStaticListener","text":"Source code in codart\\refactorings\\pushdown_method.py class PropagationNonStaticListener ( PropagationListener ): \"\"\" \"\"\" def exitCreatedName0 ( self , ctx : JavaParserLabeled . CreatedName0Context ): if ctx . IDENTIFIER ( 0 ) . getText () == self . source_class and self . is_safe : self . detected_class = True self . start = ctx . start self . stop = ctx . stop def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if ctx . IDENTIFIER () . getText () == self . method_name and self . is_safe and self . detected_class : # Change Name if ctx . start . line == self . ref_line : self . token_stream_rewriter . replaceRange ( from_idx = self . start . tokenIndex , to_idx = self . stop . tokenIndex , text = self . child_class ) self . detected_class = False def exitVariableDeclarator ( self , ctx : JavaParserLabeled . VariableDeclaratorContext ): if self . detected_class and self . is_safe : self . variable = ctx . variableDeclaratorId () . IDENTIFIER () . getText () self . detected_class = False def enterExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if ctx . start . line == self . ref_line and self . is_safe : self . need_cast = True def exitExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if ctx . start . line == self . ref_line and self . is_safe : self . need_cast = False def enterExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): self . enterExpression21 ( ctx ) def exitExpression1 ( self , ctx : JavaParserLabeled . Expression1Context ): if self . is_safe and self . need_cast and self . variable is not None : # Type casting child = ctx . getChild ( 0 ) . getChild ( 0 ) self . token_stream_rewriter . replaceRange ( from_idx = child . start . tokenIndex , to_idx = child . stop . tokenIndex , text = f \"(( { self . child_class } ) { self . variable } )\" ) self . need_cast = False","title":"PropagationNonStaticListener"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.PropagationStaticListener","text":"Source code in codart\\refactorings\\pushdown_method.py class PropagationStaticListener ( PropagationListener ): \"\"\" \"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\" \"\"\" super ( PropagationStaticListener , self ) . __init__ ( * args , ** kwargs ) self . detected_method = False def enterPrimary4 ( self , ctx : JavaParserLabeled . Primary4Context ): if self . is_safe : self . start = ctx . start self . stop = ctx . stop self . detected_class = True def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): method_name = ctx . IDENTIFIER () . getText () if method_name == self . method_name and self . is_safe : self . detected_method = True def exitMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if self . detected_method and self . detected_class : self . detected_class = False self . detected_method = False self . token_stream_rewriter . replaceRange ( from_idx = self . start . tokenIndex , to_idx = self . stop . tokenIndex , text = f \" { self . child_class } \" )","title":"PropagationStaticListener"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.PushDownMethodRefactoringListener","text":"Source code in codart\\refactorings\\pushdown_method.py class PushDownMethodRefactoringListener ( JavaParserLabeledListener ): \"\"\" \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , source_method_text : str ): \"\"\" \"\"\" self . source_method_text = source_method_text self . source_class = source_class self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_safe = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . is_safe = ctx . IDENTIFIER () . getText () == self . source_class def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): self . is_safe = not self . is_safe def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_safe : self . token_stream_rewriter . insertBefore ( index = ctx . stop . tokenIndex , text = self . source_method_text + \" \\n \" , program_name = self . token_stream_rewriter . DEFAULT_PROGRAM_NAME )","title":"PushDownMethodRefactoringListener"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.PushDownMethodRefactoringListener.__init__","text":"Source code in codart\\refactorings\\pushdown_method.py def __init__ ( self , common_token_stream : CommonTokenStream , source_class : str , source_method_text : str ): \"\"\" \"\"\" self . source_method_text = source_method_text self . source_class = source_class self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . is_safe = False","title":"__init__()"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method.main","text":"The main API for the push-down method refactoring operation Source code in codart\\refactorings\\pushdown_method.py def main ( udb_path , source_package , source_class , method_name , target_classes : list , * args , ** kwargs ): \"\"\" The main API for the push-down method refactoring operation \"\"\" target_package = source_package source_method = method_name main_file = None source_method_entity = None is_static = False propagation_files = [] propagation_classes = [] propagation_lines = [] children_classes = [] children_files = [] # Initialize with understand db = und . open ( udb_path ) methods = db . ents ( \"Java Method\" ) for mth in methods : if mth . longname () == source_package + \".\" + source_class + \".\" + source_method : source_method_entity = mth for child_ref in mth . parent () . refs ( \"Extendby\" ): child_ref = child_ref . ent () if child_ref . simplename () in target_classes : children_classes . append ( child_ref . simplename ()) children_files . append ( child_ref . parent () . longname ()) # print(\"mainfile : \", mth.parent().parent().longname()) is_static = mth . kind () . check ( \"static\" ) main_file = mth . parent () . parent () . longname () for ref in mth . refs ( \"Callby\" ): propagation_files . append ( ref . ent () . parent () . parent () . longname ()) propagation_classes . append ( ref . ent () . parent () . simplename ()) propagation_lines . append ( ref . line ()) # Check pre-condition if not len ( target_classes ) == 1 : logger . error ( f \"len(target_classes) is not 1.\" ) db . close () return False if not len ( children_classes ) == 1 : logger . error ( f \"len(children_classes) is not 1.\" ) db . close () return False if not len ( children_files ) == 1 : logger . error ( f \"len(children_files) is not 1.\" ) db . close () return False for mth in methods : if mth . simplename () == source_method : if mth . parent () . simplename () in target_classes : if mth . type () == source_method_entity . type (): if mth . kind () == source_method_entity . kind (): if mth . parameters () == source_method_entity . parameters (): logger . error ( \"Duplicated method\" ) db . close () return False for ref in source_method_entity . refs ( \"use, call\" ): ref_ent = ref . ent () is_public = ref_ent . kind () . check ( \"public\" ) if not is_public : logger . error ( \"Has internal dependencies.\" ) db . close () return False # get text method_text = source_method_entity . contents () db . close () # Delete source method stream = FileStream ( main_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = DeleteSourceListener ( common_token_stream = token_stream , source_method = source_method ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( main_file , mode = 'w' , encoding = 'utf-8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # Do the push down for child_file , child_class in zip ( children_files , children_classes ): stream = FileStream ( child_file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () my_listener = PushDownMethodRefactoringListener ( common_token_stream = token_stream , source_class = child_class , source_method_text = method_text ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( child_file , mode = 'w' , encoding = 'utf8' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) # Propagation for file , _class , line in zip ( propagation_files , propagation_classes , propagation_lines ): stream = FileStream ( file , encoding = 'utf8' , errors = 'ignore' ) lexer = JavaLexer ( stream ) token_stream = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( token_stream ) parser . getTokenStream () parse_tree = parser . compilationUnit () if is_static : my_listener = PropagationStaticListener ( common_token_stream = token_stream , source_class = source_class , child_class = children_classes [ 0 ], class_name = _class , method_name = source_method , ref_line = line , target_package = target_package ) else : my_listener = PropagationNonStaticListener ( common_token_stream = token_stream , source_class = source_class , child_class = children_classes [ 0 ], class_name = _class , method_name = source_method , ref_line = line , target_package = target_package ) walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) # print(my_listener.token_stream_rewriter.getDefaultText()) with open ( file , mode = 'w' , encoding = 'utf8' , errors = 'ignore' , newline = '' ) as f : f . write ( my_listener . token_stream_rewriter . getDefaultText ()) return True","title":"main()"},{"location":"refactorings/push_down_method/#push-down-method-2","text":"","title":"Push-down method 2"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method2--introduction","text":"The module implements a light-weight version of the push-down method refactoring described in pushdown_method.py","title":"Introduction"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method2.CutMethodListener","text":"Removes the method declaration from the parent class. Source code in codart\\refactorings\\pushdown_method2.py class CutMethodListener ( JavaParserLabeledListener ): \"\"\" Removes the method declaration from the parent class. \"\"\" def __init__ ( self , source_class , method_name , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. method_name: (str) Method's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutMethodListener): The full string of method declaration \"\"\" self . source_class = source_class self . method_name = method_name self . rewriter = rewriter self . method_content = \"\" self . import_statements = \"\" self . detected_method = False self . is_source_class = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if class_name == self . source_class : self . is_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if self . is_source_class and class_name == self . source_class : self . is_source_class = False def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): statement = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . import_statements += statement + \" \\n \" def exitMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_source_class and ctx . IDENTIFIER () . getText () == self . method_name : self . detected_method = True def exitClassBodyDeclaration2 ( self , ctx : JavaParserLabeled . ClassBodyDeclaration2Context ): if self . detected_method : self . method_content = self . rewriter . getText ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , start = ctx . start . tokenIndex , stop = ctx . stop . tokenIndex ) self . rewriter . delete ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , from_idx = ctx . start . tokenIndex , to_idx = ctx . stop . tokenIndex ) self . detected_method = False","title":"CutMethodListener"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method2.CutMethodListener.__init__","text":"Parameters: Name Type Description Default source_class (str) Parent's class name. required method_name (str) Method's name. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description field_content (CutMethodListener) The full string of method declaration Source code in codart\\refactorings\\pushdown_method2.py def __init__ ( self , source_class , method_name , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class: (str) Parent's class name. method_name: (str) Method's name. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: field_content (CutMethodListener): The full string of method declaration \"\"\" self . source_class = source_class self . method_name = method_name self . rewriter = rewriter self . method_content = \"\" self . import_statements = \"\" self . detected_method = False self . is_source_class = False","title":"__init__()"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method2.PasteMethodListener","text":"Inserts method declaration to children classes. Source code in codart\\refactorings\\pushdown_method2.py class PasteMethodListener ( JavaParserLabeledListener ): \"\"\" Inserts method declaration to children classes. \"\"\" def __init__ ( self , source_class , method_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Child class name. method_content (str): Full string of the method declaration. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: object (PasteMethodListener): An instance of PasteMethodListener class. \"\"\" self . source_class = source_class self . rewriter = rewriter self . method_content = method_content self . import_statements = import_statements self . is_source_class = False def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if class_name == self . source_class : self . is_source_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): class_name = ctx . IDENTIFIER () . getText () if self . is_source_class and class_name == self . source_class : self . is_source_class = False def exitPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . rewriter . insertAfter ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , index = ctx . stop . tokenIndex , text = \" \\n \" + self . import_statements ) def enterClassBody ( self , ctx : JavaParserLabeled . ClassBodyContext ): if self . is_source_class : self . rewriter . insertBefore ( program_name = self . rewriter . DEFAULT_PROGRAM_NAME , index = ctx . stop . tokenIndex , text = \" \\n\\t \" + self . method_content + \" \\n \" )","title":"PasteMethodListener"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method2.PasteMethodListener.__init__","text":"Parameters: Name Type Description Default source_class str Child class name. required method_content str Full string of the method declaration. required rewriter TokenStreamRewriter ANTLR's token stream rewriter. required Returns: Type Description object (PasteMethodListener) An instance of PasteMethodListener class. Source code in codart\\refactorings\\pushdown_method2.py def __init__ ( self , source_class , method_content , import_statements , rewriter : TokenStreamRewriter ): \"\"\" Args: source_class (str): Child class name. method_content (str): Full string of the method declaration. rewriter (TokenStreamRewriter): ANTLR's token stream rewriter. Returns: object (PasteMethodListener): An instance of PasteMethodListener class. \"\"\" self . source_class = source_class self . rewriter = rewriter self . method_content = method_content self . import_statements = import_statements self . is_source_class = False","title":"__init__()"},{"location":"refactorings/push_down_method/#codart.refactorings.pushdown_method2.main","text":"The main API for the push-down method refactoring (version 2) Source code in codart\\refactorings\\pushdown_method2.py def main ( udb_path , source_package , source_class , method_name , target_classes : list , * args , ** kwargs ): \"\"\" The main API for the push-down method refactoring (version 2) \"\"\" db = und . open ( udb_path ) source_class_ents = db . lookup ( f \" { source_package } . { source_class } \" , \"Class\" ) target_class_ents = [] source_class_ent = None if len ( source_class_ents ) == 0 : config . logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False else : for ent in source_class_ents : if ent . simplename () == source_class : source_class_ent = ent break if source_class_ent is None : config . logger . error ( f \"Cannot find source class: { source_class } \" ) db . close () return False method_ent = db . lookup ( f \" { source_package } . { source_class } . { method_name } \" , \"Method\" ) if len ( method_ent ) == 0 : config . logger . error ( f \"Cannot find method to pushdown: { method_name } \" ) db . close () return False else : method_ent = method_ent [ 0 ] for ref in source_class_ent . refs ( \"extendBy\" ): if ref . ent () . simplename () not in target_classes : config . logger . error ( \"Target classes are not children classes\" ) db . close () return False target_class_ents . append ( ref . ent ()) for ref in method_ent . refs ( \"callBy\" ): if ref . file () . simplename () . split ( \".\" )[ 0 ] in target_classes : continue else : config . logger . error ( \"Method has dependencies.\" ) db . close () return False # Remove field from source class listener = parse_and_walk ( file_path = source_class_ent . parent () . longname (), listener_class = CutMethodListener , has_write = True , source_class = source_class , method_name = method_name , debug = False ) # Insert field in children classes for target_class in target_class_ents : parse_and_walk ( file_path = target_class . parent () . longname (), listener_class = PasteMethodListener , has_write = True , source_class = target_class . simplename (), method_content = listener . method_content , import_statements = listener . import_statements , debug = False ) db . close ()","title":"main()"},{"location":"refactorings/rename_class/","text":"Rename class Implementation 1 Introduction When the name of a class does not explain what the class does (class's functionality), it needs to be changed. Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions RenameClassRefactoringListener ( JavaParserLabeledListener ) The class performs Rename Class refactoring. The main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Source code in codart\\refactorings\\rename_class.py class RenameClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class performs Rename Class refactoring. The main listener which parses the file based on the provided information, \\ using ANTLR parser generator and tokenization methods \"\"\" def __init__ ( self , java_file_path , common_token_stream : CommonTokenStream = None , class_new_name : str = None , class_identifier : str = None , package_identifier : str = None ): \"\"\" Initializer of rename class refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class class_new_name(str): The new name of the refactored class class_identifier(str): Name of the class in which the refactoring has to be done package_identifier(str): Name of the package in which the refactoring has to be done Returns: RenameMethodListener: An instance of RenameClassRefactoringListener class \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . class_new_name = class_new_name self . class_identifier = class_identifier self . package_identifier = package_identifier self . in_class = False self . changed = False self . declared_objects_names = [] self . is_package_imported = False self . in_selected_package = False self . in_selected_class = False self . in_some_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . in_some_package = True if self . package_identifier is not None : print ( ctx . qualifiedName ()) print ( ctx . getText ()) if self . package_identifier == ctx . qualifiedName () . getText (): self . in_selected_package = True print ( \"Package Found\" ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . package_identifier is None \\ and not self . in_some_package \\ or self . package_identifier is not None \\ and self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : print ( \"Class Found\" ) self . in_selected_class = True self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex + 2 , text = self . class_new_name ) self . changed = True def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if self . package_identifier is not None : if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \".*\" + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \";\" : self . is_package_imported = True if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" : self . token_stream_rewriter . replaceIndex ( index = ctx . qualifiedName () . start . tokenIndex + 2 * len ( ctx . qualifiedName () . IDENTIFIER ()) - 2 , text = self . class_new_name ) self . changed = True def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . in_selected_package and ctx . IDENTIFIER () . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) self . changed = True def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . package_identifier is None \\ or self . package_identifier is not None \\ and self . is_package_imported : if ctx . typeType () . getText () == self . class_identifier : # change the name class; (we find right class then change the name class) self . token_stream_rewriter . replaceIndex ( index = ctx . typeType () . start . tokenIndex , text = self . class_new_name ) self . changed = True print ( \"class name has change to new_class_name\" ) # def enterExpressionName2(self, ctx:Java9_v2Parser.ExpressionName1Context): # if self.is_package_imported \\ # or self.package_identifier is None \\ # or self.in_selected_package: # if ctx.getText() == self.class_identifier: # self.token_stream_rewriter.replaceIndex( # index=ctx.start.tokenIndex, # text=self.class_identifier) # def exitPrimary4 ( self , ctx : JavaParserLabeled . Primary4Context ): if self . is_package_imported \\ or self . package_identifier is None \\ or self . in_selected_package : if ctx . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) self . changed = True def enterCreatedName0 ( self , ctx : JavaParserLabeled . CreatedName0Context ): if self . is_package_imported \\ or self . package_identifier is None \\ or self . in_selected_package : if ctx . getText () == self . class_identifier : print ( \"ClassInstanceCreationExpression_lfno_primary1\" ) self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) self . changed = True __init__ ( self , java_file_path , common_token_stream = None , class_new_name = None , class_identifier = None , package_identifier = None ) special Initializer of rename class refactoring listener Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required common_token_stream CommonTokenStream An instance of ANTLR4 CommonTokenStream class None class_new_name(str) The new name of the refactored class required class_identifier(str) Name of the class in which the refactoring has to be done required package_identifier(str) Name of the package in which the refactoring has to be done required Returns: Type Description RenameMethodListener An instance of RenameClassRefactoringListener class Source code in codart\\refactorings\\rename_class.py def __init__ ( self , java_file_path , common_token_stream : CommonTokenStream = None , class_new_name : str = None , class_identifier : str = None , package_identifier : str = None ): \"\"\" Initializer of rename class refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class class_new_name(str): The new name of the refactored class class_identifier(str): Name of the class in which the refactoring has to be done package_identifier(str): Name of the package in which the refactoring has to be done Returns: RenameMethodListener: An instance of RenameClassRefactoringListener class \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . class_new_name = class_new_name self . class_identifier = class_identifier self . package_identifier = package_identifier self . in_class = False self . changed = False self . declared_objects_names = [] self . is_package_imported = False self . in_selected_package = False self . in_selected_class = False self . in_some_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) rename_class ( java_file_path , package_identifier , class_identifier , class_new_name , reference = None ) Main Entry Point to the Listener and Tree Walker Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required scope_class_name(str) Name of the class in which the refactoring has to be done required target_method_name(str) Name of the method in which the refactoring has to be done required new_name(str) The new name of the refactored method required reference(str) Keeping track for all of the method references in the project scope required Returns: Type Description No Returns Source code in codart\\refactorings\\rename_class.py def rename_class ( java_file_path , package_identifier , class_identifier , class_new_name , reference = None ): \"\"\"Main Entry Point to the Listener and Tree Walker Args: java_file_path(str): Address path to the test/source file scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method reference(str): Keeping track for all of the method references in the project scope Returns: No Returns \"\"\" stream = FileStream ( java_file_path ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = RenameClassRefactoringListener ( java_file_path = java_file_path , common_token_stream = tokens , class_new_name = class_new_name , class_identifier = class_identifier , package_identifier = package_identifier ) walker = ParseTreeWalker () walker . walk ( listener , tree ) if listener . changed : # print(java_file_path) new_file = open ( file = java_file_path , mode = 'w' ) new_file . write ( listener . token_stream_rewriter . getDefaultText () . replace ( ' \\r ' , '' )) # def enterTypeName1(self, ctx:Java9_v2Parser.TypeName1Context): # if self.is_package_imported \\ # or self.package_identifier is None \\ # or self.in_selected_package: # if ctx.identifier().getText() == self.class_identifier: # print(\" type name 1\") # self.token_stream_rewriter.replaceIndex( # index=ctx.identifier().start.tokenIndex, # text=self.class_new_name) # # # def enterCompilationUnit1(self, ctx: Java9_v2Parser.CompilationUnit1Context): # hidden = self.token_stream.getHiddenTokensToLeft(ctx.start.tokenIndex) # self.token_stream_rewriter.replaceRange(from_idx=hidden[0].tokenIndex, # to_idx=hidden[-1].tokenIndex, # text='/*After refactoring (Refactored version)*/\\n') Implementation 2 Introduction When the name of a class does not explain what the class does (class's functionality), it needs to be changed. The module implements a light-weight version of Rename Class refactoring described in rename_class.py Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions RenameClassRefactoringListener ( JavaParserLabeledListener ) The class implements rename class refactoring Source code in codart\\refactorings\\rename_class2.py class RenameClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class implements rename class refactoring \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , class_identifier : str = None , class_new_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done class_identifier(str): Name of the class in which the refactoring has to be done class_new_name(str): The new name of the refactored class Returns: RenameMethodListener: An instance of RenameClassRefactoringListener class \"\"\" self . token_stream = common_token_stream self . class_new_name = class_new_name self . class_identifier = class_identifier self . package_identifier = package_name self . is_package_imported = False self . in_selected_package = False self . in_selected_class = False self . in_some_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . in_some_package = True if self . package_identifier == ctx . qualifiedName () . getText (): self . in_selected_package = True print ( \"Package \" + self . package_identifier + \" Found\" ) def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \".*\" + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \";\" : self . is_package_imported = True print ( \"package \" + self . package_identifier + \" imported\" ) if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" : self . token_stream_rewriter . replaceIndex ( index = ctx . qualifiedName () . start . tokenIndex + 2 * len ( ctx . qualifiedName () . IDENTIFIER ()) - 2 , text = self . class_new_name ) print ( \"class name in package changed\" ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex + 2 , text = self . class_new_name ) change_file_name ( self . class_identifier , self . class_new_name ) print ( \"class name : \" + self . class_identifier + \" in class declaration changed \" ) def enterCreatedName0 ( self , ctx : JavaParserLabeled . CreatedName0Context ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER ( 0 ) . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) print ( \"class name in creator changed\" ) def enterClassOrInterfaceType ( self , ctx : JavaParserLabeled . ClassOrInterfaceTypeContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER ( 0 ) . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) print ( \"class type changed\" ) def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) print ( \"constructor name changed !\" ) __init__ ( self , common_token_stream = None , package_name = None , class_identifier = None , class_new_name = None ) special Parameters: Name Type Description Default common_token_stream CommonTokenStream An instance of ANTLR4 CommonTokenStream class None package_name(str) Name of the package in which the refactoring has to be done required class_identifier(str) Name of the class in which the refactoring has to be done required class_new_name(str) The new name of the refactored class required Returns: Type Description RenameMethodListener An instance of RenameClassRefactoringListener class Source code in codart\\refactorings\\rename_class2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , class_identifier : str = None , class_new_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done class_identifier(str): Name of the class in which the refactoring has to be done class_new_name(str): The new name of the refactored class Returns: RenameMethodListener: An instance of RenameClassRefactoringListener class \"\"\" self . token_stream = common_token_stream self . class_new_name = class_new_name self . class_identifier = class_identifier self . package_identifier = package_name self . is_package_imported = False self . in_selected_package = False self . in_selected_class = False self . in_some_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"Rename class"},{"location":"refactorings/rename_class/#rename-class","text":"","title":"Rename class"},{"location":"refactorings/rename_class/#implementation-1","text":"","title":"Implementation 1"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class--introduction","text":"When the name of a class does not explain what the class does (class's functionality), it needs to be changed.","title":"Introduction"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class.RenameClassRefactoringListener","text":"The class performs Rename Class refactoring. The main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Source code in codart\\refactorings\\rename_class.py class RenameClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class performs Rename Class refactoring. The main listener which parses the file based on the provided information, \\ using ANTLR parser generator and tokenization methods \"\"\" def __init__ ( self , java_file_path , common_token_stream : CommonTokenStream = None , class_new_name : str = None , class_identifier : str = None , package_identifier : str = None ): \"\"\" Initializer of rename class refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class class_new_name(str): The new name of the refactored class class_identifier(str): Name of the class in which the refactoring has to be done package_identifier(str): Name of the package in which the refactoring has to be done Returns: RenameMethodListener: An instance of RenameClassRefactoringListener class \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . class_new_name = class_new_name self . class_identifier = class_identifier self . package_identifier = package_identifier self . in_class = False self . changed = False self . declared_objects_names = [] self . is_package_imported = False self . in_selected_package = False self . in_selected_class = False self . in_some_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . in_some_package = True if self . package_identifier is not None : print ( ctx . qualifiedName ()) print ( ctx . getText ()) if self . package_identifier == ctx . qualifiedName () . getText (): self . in_selected_package = True print ( \"Package Found\" ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . package_identifier is None \\ and not self . in_some_package \\ or self . package_identifier is not None \\ and self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : print ( \"Class Found\" ) self . in_selected_class = True self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex + 2 , text = self . class_new_name ) self . changed = True def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if self . package_identifier is not None : if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \".*\" + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \";\" : self . is_package_imported = True if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" : self . token_stream_rewriter . replaceIndex ( index = ctx . qualifiedName () . start . tokenIndex + 2 * len ( ctx . qualifiedName () . IDENTIFIER ()) - 2 , text = self . class_new_name ) self . changed = True def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . in_selected_package and ctx . IDENTIFIER () . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) self . changed = True def exitFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . package_identifier is None \\ or self . package_identifier is not None \\ and self . is_package_imported : if ctx . typeType () . getText () == self . class_identifier : # change the name class; (we find right class then change the name class) self . token_stream_rewriter . replaceIndex ( index = ctx . typeType () . start . tokenIndex , text = self . class_new_name ) self . changed = True print ( \"class name has change to new_class_name\" ) # def enterExpressionName2(self, ctx:Java9_v2Parser.ExpressionName1Context): # if self.is_package_imported \\ # or self.package_identifier is None \\ # or self.in_selected_package: # if ctx.getText() == self.class_identifier: # self.token_stream_rewriter.replaceIndex( # index=ctx.start.tokenIndex, # text=self.class_identifier) # def exitPrimary4 ( self , ctx : JavaParserLabeled . Primary4Context ): if self . is_package_imported \\ or self . package_identifier is None \\ or self . in_selected_package : if ctx . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) self . changed = True def enterCreatedName0 ( self , ctx : JavaParserLabeled . CreatedName0Context ): if self . is_package_imported \\ or self . package_identifier is None \\ or self . in_selected_package : if ctx . getText () == self . class_identifier : print ( \"ClassInstanceCreationExpression_lfno_primary1\" ) self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) self . changed = True","title":"RenameClassRefactoringListener"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class.RenameClassRefactoringListener.__init__","text":"Initializer of rename class refactoring listener Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required common_token_stream CommonTokenStream An instance of ANTLR4 CommonTokenStream class None class_new_name(str) The new name of the refactored class required class_identifier(str) Name of the class in which the refactoring has to be done required package_identifier(str) Name of the package in which the refactoring has to be done required Returns: Type Description RenameMethodListener An instance of RenameClassRefactoringListener class Source code in codart\\refactorings\\rename_class.py def __init__ ( self , java_file_path , common_token_stream : CommonTokenStream = None , class_new_name : str = None , class_identifier : str = None , package_identifier : str = None ): \"\"\" Initializer of rename class refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class class_new_name(str): The new name of the refactored class class_identifier(str): Name of the class in which the refactoring has to be done package_identifier(str): Name of the package in which the refactoring has to be done Returns: RenameMethodListener: An instance of RenameClassRefactoringListener class \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . class_new_name = class_new_name self . class_identifier = class_identifier self . package_identifier = package_identifier self . in_class = False self . changed = False self . declared_objects_names = [] self . is_package_imported = False self . in_selected_package = False self . in_selected_class = False self . in_some_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class.rename_class","text":"Main Entry Point to the Listener and Tree Walker Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required scope_class_name(str) Name of the class in which the refactoring has to be done required target_method_name(str) Name of the method in which the refactoring has to be done required new_name(str) The new name of the refactored method required reference(str) Keeping track for all of the method references in the project scope required Returns: Type Description No Returns Source code in codart\\refactorings\\rename_class.py def rename_class ( java_file_path , package_identifier , class_identifier , class_new_name , reference = None ): \"\"\"Main Entry Point to the Listener and Tree Walker Args: java_file_path(str): Address path to the test/source file scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method reference(str): Keeping track for all of the method references in the project scope Returns: No Returns \"\"\" stream = FileStream ( java_file_path ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = RenameClassRefactoringListener ( java_file_path = java_file_path , common_token_stream = tokens , class_new_name = class_new_name , class_identifier = class_identifier , package_identifier = package_identifier ) walker = ParseTreeWalker () walker . walk ( listener , tree ) if listener . changed : # print(java_file_path) new_file = open ( file = java_file_path , mode = 'w' ) new_file . write ( listener . token_stream_rewriter . getDefaultText () . replace ( ' \\r ' , '' )) # def enterTypeName1(self, ctx:Java9_v2Parser.TypeName1Context): # if self.is_package_imported \\ # or self.package_identifier is None \\ # or self.in_selected_package: # if ctx.identifier().getText() == self.class_identifier: # print(\" type name 1\") # self.token_stream_rewriter.replaceIndex( # index=ctx.identifier().start.tokenIndex, # text=self.class_new_name) # # # def enterCompilationUnit1(self, ctx: Java9_v2Parser.CompilationUnit1Context): # hidden = self.token_stream.getHiddenTokensToLeft(ctx.start.tokenIndex) # self.token_stream_rewriter.replaceRange(from_idx=hidden[0].tokenIndex, # to_idx=hidden[-1].tokenIndex, # text='/*After refactoring (Refactored version)*/\\n')","title":"rename_class()"},{"location":"refactorings/rename_class/#implementation-2","text":"","title":"Implementation 2"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class2--introduction","text":"When the name of a class does not explain what the class does (class's functionality), it needs to be changed. The module implements a light-weight version of Rename Class refactoring described in rename_class.py","title":"Introduction"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class2.RenameClassRefactoringListener","text":"The class implements rename class refactoring Source code in codart\\refactorings\\rename_class2.py class RenameClassRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class implements rename class refactoring \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , class_identifier : str = None , class_new_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done class_identifier(str): Name of the class in which the refactoring has to be done class_new_name(str): The new name of the refactored class Returns: RenameMethodListener: An instance of RenameClassRefactoringListener class \"\"\" self . token_stream = common_token_stream self . class_new_name = class_new_name self . class_identifier = class_identifier self . package_identifier = package_name self . is_package_imported = False self . in_selected_package = False self . in_selected_class = False self . in_some_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): self . in_some_package = True if self . package_identifier == ctx . qualifiedName () . getText (): self . in_selected_package = True print ( \"Package \" + self . package_identifier + \" Found\" ) def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \".*\" + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \";\" : self . is_package_imported = True print ( \"package \" + self . package_identifier + \" imported\" ) if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" : self . token_stream_rewriter . replaceIndex ( index = ctx . qualifiedName () . start . tokenIndex + 2 * len ( ctx . qualifiedName () . IDENTIFIER ()) - 2 , text = self . class_new_name ) print ( \"class name in package changed\" ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex + 2 , text = self . class_new_name ) change_file_name ( self . class_identifier , self . class_new_name ) print ( \"class name : \" + self . class_identifier + \" in class declaration changed \" ) def enterCreatedName0 ( self , ctx : JavaParserLabeled . CreatedName0Context ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER ( 0 ) . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) print ( \"class name in creator changed\" ) def enterClassOrInterfaceType ( self , ctx : JavaParserLabeled . ClassOrInterfaceTypeContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER ( 0 ) . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) print ( \"class type changed\" ) def enterConstructorDeclaration ( self , ctx : JavaParserLabeled . ConstructorDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . class_new_name ) print ( \"constructor name changed !\" )","title":"RenameClassRefactoringListener"},{"location":"refactorings/rename_class/#codart.refactorings.rename_class2.RenameClassRefactoringListener.__init__","text":"Parameters: Name Type Description Default common_token_stream CommonTokenStream An instance of ANTLR4 CommonTokenStream class None package_name(str) Name of the package in which the refactoring has to be done required class_identifier(str) Name of the class in which the refactoring has to be done required class_new_name(str) The new name of the refactored class required Returns: Type Description RenameMethodListener An instance of RenameClassRefactoringListener class Source code in codart\\refactorings\\rename_class2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , class_identifier : str = None , class_new_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done class_identifier(str): Name of the class in which the refactoring has to be done class_new_name(str): The new name of the refactored class Returns: RenameMethodListener: An instance of RenameClassRefactoringListener class \"\"\" self . token_stream = common_token_stream self . class_new_name = class_new_name self . class_identifier = class_identifier self . package_identifier = package_name self . is_package_imported = False self . in_selected_package = False self . in_selected_class = False self . in_some_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"refactorings/rename_field/","text":"Rename field When the name of a class field does not explain what the field hold, it needs to be changed. Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions RenameFieldRefactoringListener ( JavaParserLabeledListener ) The class performs Rename Field Refactoring Source code in codart\\refactorings\\rename_field.py class RenameFieldRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class performs Rename Field Refactoring \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , scope_class_name : str = None , field_identifier : str = None , field_new_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the packages in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done field_identifier(str): Name of the package in which the refactoring has to be done field_new_name(str): The new name of the refactored method Returns: RenameFieldListener: An instance of RenameFieldListener class \"\"\" self . token_stream = common_token_stream self . class_identifier = scope_class_name self . field_identifier = field_identifier self . field_new_name = field_new_name self . package_identifier = package_name self . is_package_imported = False self . in_class = False self . in_selected_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . package_identifier == ctx . qualifiedName () . getText (): self . in_selected_package = True print ( \"Package \" + self . package_identifier + \" Found\" ) def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \".*\" + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \";\" : self . is_package_imported = True print ( \"package \" + self . package_identifier + \" imported\" ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . in_class = False def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . in_class : if ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . getText () == self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . start . tokenIndex , text = self . field_new_name ) print ( \"field name changed !\" ) def enterExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . in_class : if ctx . expression ( 0 ) . getText () == self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression ( 0 ) . start . tokenIndex , text = self . field_new_name ) print ( \"expression21 changed! \" ) elif ctx . expression ( 0 ) . getText () == \"this.\" + self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression ( 0 ) . start . tokenIndex + 2 , text = self . field_new_name ) # print(\"expression21 \", ctx.expression(0).getText(), \" changed to: \", \"this.\", self.field_new_name) print ( \"expression21 changed! \" ) if ctx . expression ( 1 ) . getText () == self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression ( 1 ) . start . tokenIndex , text = self . field_new_name ) # print(\"expression21 \", ctx.expression(1).getText(), \" changed to: \", self.field_new_name) print ( \"expression21 changed! \" ) elif ctx . expression ( 1 ) . getText () == \"this.\" + self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression ( 1 ) . start . tokenIndex + 2 , text = self . field_new_name ) # print(\"expression21 \", ctx.expression(1).getText(), \" changed to: \", \"this.\", self.field_new_name) print ( \"expression21 changed! \" ) # def enterVariableDeclarator(self, ctx: JavaParserLabeled.VariableDeclaratorContext): # print(\"8888888888888888888888888888888888888888888888888888888888888888888888888888888888\") # x = JavaParserLabeled.VariableInitializer1Context(ctx.variableInitializer(),ctx.) # y = JavaParserLabeled.Expression1Context(x.expression(), ctx) # print(y.IDENTIFIER()) # # if self.is_in_scope: # # if ctx.variableInitializer().expression().IDENTIFIER().getText() == self.field_identifier: # # self.token_stream_rewriter.replaceIndex( # # index=ctx.expression().start.tokenIndex, # # text=self.field_new_name) # # print(\"8888888888888888888888888888888888888888888888888888888888888888888888888888888888\") def enterVariableInitializer1 ( self , ctx : JavaParserLabeled . VariableInitializer1Context ): if self . in_class : if ctx . expression () . getText () == self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression () . start . tokenIndex , text = self . field_new_name ) print ( \"variable initializer changed\" ) elif ctx . expression () . getText () == \"this.\" + self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression () . start . tokenIndex + 2 , text = self . field_new_name ) print ( \"variable initializer changed\" ) # # def enterMethodCall0(self, ctx: JavaParserLabeled.MethodCall0Context): # print(ctx.expressionList()) __init__ ( self , common_token_stream = None , package_name = None , scope_class_name = None , field_identifier = None , field_new_name = None ) special Parameters: Name Type Description Default common_token_stream CommonTokenStream An instance of ANTLR4 CommonTokenStream class None package_name(str) Name of the packages in which the refactoring has to be done required scope_class_name(str) Name of the class in which the refactoring has to be done required field_identifier(str) Name of the package in which the refactoring has to be done required field_new_name(str) The new name of the refactored method required Returns: Type Description RenameFieldListener An instance of RenameFieldListener class Source code in codart\\refactorings\\rename_field.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , scope_class_name : str = None , field_identifier : str = None , field_new_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the packages in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done field_identifier(str): Name of the package in which the refactoring has to be done field_new_name(str): The new name of the refactored method Returns: RenameFieldListener: An instance of RenameFieldListener class \"\"\" self . token_stream = common_token_stream self . class_identifier = scope_class_name self . field_identifier = field_identifier self . field_new_name = field_new_name self . package_identifier = package_name self . is_package_imported = False self . in_class = False self . in_selected_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"Rename field"},{"location":"refactorings/rename_field/#rename-field","text":"When the name of a class field does not explain what the field hold, it needs to be changed.","title":"Rename field"},{"location":"refactorings/rename_field/#codart.refactorings.rename_field--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/rename_field/#codart.refactorings.rename_field--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/rename_field/#codart.refactorings.rename_field.RenameFieldRefactoringListener","text":"The class performs Rename Field Refactoring Source code in codart\\refactorings\\rename_field.py class RenameFieldRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class performs Rename Field Refactoring \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , scope_class_name : str = None , field_identifier : str = None , field_new_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the packages in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done field_identifier(str): Name of the package in which the refactoring has to be done field_new_name(str): The new name of the refactored method Returns: RenameFieldListener: An instance of RenameFieldListener class \"\"\" self . token_stream = common_token_stream self . class_identifier = scope_class_name self . field_identifier = field_identifier self . field_new_name = field_new_name self . package_identifier = package_name self . is_package_imported = False self . in_class = False self . in_selected_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . package_identifier == ctx . qualifiedName () . getText (): self . in_selected_package = True print ( \"Package \" + self . package_identifier + \" Found\" ) def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \".*\" + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \";\" : self . is_package_imported = True print ( \"package \" + self . package_identifier + \" imported\" ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . in_class = False def enterFieldDeclaration ( self , ctx : JavaParserLabeled . FieldDeclarationContext ): if self . in_class : if ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . getText () == self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . variableDeclarators () . variableDeclarator ( 0 ) . variableDeclaratorId () . start . tokenIndex , text = self . field_new_name ) print ( \"field name changed !\" ) def enterExpression21 ( self , ctx : JavaParserLabeled . Expression21Context ): if self . in_class : if ctx . expression ( 0 ) . getText () == self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression ( 0 ) . start . tokenIndex , text = self . field_new_name ) print ( \"expression21 changed! \" ) elif ctx . expression ( 0 ) . getText () == \"this.\" + self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression ( 0 ) . start . tokenIndex + 2 , text = self . field_new_name ) # print(\"expression21 \", ctx.expression(0).getText(), \" changed to: \", \"this.\", self.field_new_name) print ( \"expression21 changed! \" ) if ctx . expression ( 1 ) . getText () == self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression ( 1 ) . start . tokenIndex , text = self . field_new_name ) # print(\"expression21 \", ctx.expression(1).getText(), \" changed to: \", self.field_new_name) print ( \"expression21 changed! \" ) elif ctx . expression ( 1 ) . getText () == \"this.\" + self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression ( 1 ) . start . tokenIndex + 2 , text = self . field_new_name ) # print(\"expression21 \", ctx.expression(1).getText(), \" changed to: \", \"this.\", self.field_new_name) print ( \"expression21 changed! \" ) # def enterVariableDeclarator(self, ctx: JavaParserLabeled.VariableDeclaratorContext): # print(\"8888888888888888888888888888888888888888888888888888888888888888888888888888888888\") # x = JavaParserLabeled.VariableInitializer1Context(ctx.variableInitializer(),ctx.) # y = JavaParserLabeled.Expression1Context(x.expression(), ctx) # print(y.IDENTIFIER()) # # if self.is_in_scope: # # if ctx.variableInitializer().expression().IDENTIFIER().getText() == self.field_identifier: # # self.token_stream_rewriter.replaceIndex( # # index=ctx.expression().start.tokenIndex, # # text=self.field_new_name) # # print(\"8888888888888888888888888888888888888888888888888888888888888888888888888888888888\") def enterVariableInitializer1 ( self , ctx : JavaParserLabeled . VariableInitializer1Context ): if self . in_class : if ctx . expression () . getText () == self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression () . start . tokenIndex , text = self . field_new_name ) print ( \"variable initializer changed\" ) elif ctx . expression () . getText () == \"this.\" + self . field_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . expression () . start . tokenIndex + 2 , text = self . field_new_name ) print ( \"variable initializer changed\" ) # # def enterMethodCall0(self, ctx: JavaParserLabeled.MethodCall0Context): # print(ctx.expressionList())","title":"RenameFieldRefactoringListener"},{"location":"refactorings/rename_field/#codart.refactorings.rename_field.RenameFieldRefactoringListener.__init__","text":"Parameters: Name Type Description Default common_token_stream CommonTokenStream An instance of ANTLR4 CommonTokenStream class None package_name(str) Name of the packages in which the refactoring has to be done required scope_class_name(str) Name of the class in which the refactoring has to be done required field_identifier(str) Name of the package in which the refactoring has to be done required field_new_name(str) The new name of the refactored method required Returns: Type Description RenameFieldListener An instance of RenameFieldListener class Source code in codart\\refactorings\\rename_field.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , scope_class_name : str = None , field_identifier : str = None , field_new_name : str = None ): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the packages in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done field_identifier(str): Name of the package in which the refactoring has to be done field_new_name(str): The new name of the refactored method Returns: RenameFieldListener: An instance of RenameFieldListener class \"\"\" self . token_stream = common_token_stream self . class_identifier = scope_class_name self . field_identifier = field_identifier self . field_new_name = field_new_name self . package_identifier = package_name self . is_package_imported = False self . in_class = False self . in_selected_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"refactorings/rename_method/","text":"Rename method Implementation 1 Introduction When the name of a method does not explain what the method does (method's functionality), it needs to be changed. Pre and post conditions Pre-conditions: User must enter the existing method's name, The source class's name for the refactoring, and the new method name in order to rename. Check if the method exist, then rename it. Post-conditions: After refactoring, all the old method names in the project should be changed. See whether the method is defined in a superclass or subclass. If so, you must repeat all steps in these classes too. The next method is important for maintaining the functionality of the program during the refactoring process. Create a new method with a new name. Copy the code of the old method to it. Delete all the code in the old method and, instead of it, insert a call for the new method. Find all references to the old method and replace them with references to the new one. Delete the old method. If the old method is part of a public interface, don\u2019t perform this step. Instead, mark the old method as deprecated. RenameMethodListener ( JavaParserLabeledListener ) The class implements Rename Method refactoring. The Main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Source code in codart\\refactorings\\rename_method.py class RenameMethodListener ( JavaParserLabeledListener ): \"\"\" The class implements Rename Method refactoring. The Main listener which parses the file based on the provided information, \\ using ANTLR parser generator and tokenization methods \"\"\" def __init__ ( self , java_file_path , common_token_stream , scope_class_name , target_method_name , new_name , reference = None ): \"\"\" Initializer of rename method refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . class_name = scope_class_name self . method_name = target_method_name self . new_method_name = new_name self . in_class = False self . changed = False self . reference = reference def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): name = ctx . IDENTIFIER () . getText () if name == self . class_name : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): name = ctx . IDENTIFIER () . getText () if name == self . class_name : self . in_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . in_class : name = ctx . IDENTIFIER () if name . getText () == self . method_name : node = name . getSymbol () self . token_stream_rewriter . replaceIndex ( node . tokenIndex , self . new_method_name ) self . changed = True def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if self . in_class and self . reference : name = ctx . IDENTIFIER () if name . getText () == self . method_name : node = name . getSymbol () if node . line == self . reference [ \"line\" ]: self . token_stream_rewriter . replaceIndex ( node . tokenIndex , self . new_method_name ) self . changed = True def enterMethodCall1 ( self , ctx : JavaParserLabeled . MethodCall1Context ): if self . in_class and self . reference : name = ctx . IDENTIFIER () if name . getText () == self . method_name : node = name . getSymbol () if node . line == self . reference [ \"line\" ]: self . token_stream_rewriter . replaceIndex ( node . tokenIndex , self . new_method_name ) self . changed = True __init__ ( self , java_file_path , common_token_stream , scope_class_name , target_method_name , new_name , reference = None ) special Initializer of rename method refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class Source code in codart\\refactorings\\rename_method.py def __init__ ( self , java_file_path , common_token_stream , scope_class_name , target_method_name , new_name , reference = None ): \"\"\" Initializer of rename method refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . class_name = scope_class_name self . method_name = target_method_name self . new_method_name = new_name self . in_class = False self . changed = False self . reference = reference get_method_calls ( udb_path , scope_class_name , new_name ) Finds all of the refactored method calls in the database file and returns all of the correct references !!! args udb_path (str): Address path to the database file scope_class_name (str): Name of the class in which the refactoring has to be done new_name (str): The new name of the refactored method !!! returns References Source code in codart\\refactorings\\rename_method.py def get_method_calls ( udb_path , scope_class_name , new_name ): # Open Database \"\"\"Finds all of the refactored method calls in the database file and returns all of the correct references Args: udb_path (str): Address path to the database file scope_class_name (str): Name of the class in which the refactoring has to be done new_name (str): The new name of the refactored method Returns: References \"\"\" if not os . path . exists ( path = udb_path ): raise ValueError ( \"Database file does not exist!\" ) db = und . open ( udb_path ) method_scope = scope_class_name + \".\" + new_name references = [] # Find All Method Calls for ent in sorted ( db . ents (), key = lambda ent : ent . name ()): for ref in ent . refs ( refkindstring = \"Call\" ): scope = str ( ref . ent ()) if scope == method_scope : references . append ({ \"scope\" : str ( ref . scope ()), \"file_name\" : str ( ref . file ()), \"file_path\" : str ( ref . file () . longname ()), \"line\" : ref . line (), \"column\" : ref . column () }) db . close () return references rename_method ( java_file_path , scope_class_name , target_method_name , new_name , reference = None ) Main Entry Point to the Listener and Tree Walker Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required scope_class_name(str) Name of the class in which the refactoring has to be done required target_method_name(str) Name of the method in which the refactoring has to be done required new_name(str) The new name of the refactored method required reference(str) Keeping track for all of the method references in the project scope required Returns: Type Description No Returns Source code in codart\\refactorings\\rename_method.py def rename_method ( java_file_path , scope_class_name , target_method_name , new_name , reference = None ): \"\"\"Main Entry Point to the Listener and Tree Walker Args: java_file_path(str): Address path to the test/source file scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method reference(str): Keeping track for all of the method references in the project scope Returns: No Returns \"\"\" stream = FileStream ( java_file_path ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = RenameMethodListener ( java_file_path = java_file_path , common_token_stream = tokens , scope_class_name = scope_class_name , target_method_name = target_method_name , new_name = new_name , reference = reference ) walker = ParseTreeWalker () walker . walk ( listener , tree ) if listener . changed : # print(java_file_path) new_file = open ( file = java_file_path , mode = 'w' ) new_file . write ( listener . token_stream_rewriter . getDefaultText () . replace ( ' \\r ' , '' )) Implementation 2 Introduction When the name of a method does not explain what the method does (method's functionality), it needs to be changed. The module implements a light-weight version of Rename Method refactoring described in rename_method.py Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions RenameMethodRefactoringListener ( JavaParserLabeledListener ) The class implements Rename Method refactoring. The Main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Source code in codart\\refactorings\\rename_method2.py class RenameMethodRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class implements Rename Method refactoring. The Main listener which parses the file based on the provided information, \\ using ANTLR parser generator and tokenization methods \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , scope_class_name : str = None , method_identifier : str = None , method_new_name : str = None ): \"\"\" Initializer of rename method refactoring listener Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done method_identifier(str): Name of the method in which the refactoring has to be done method_new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class \"\"\" self . token_stream = common_token_stream self . class_identifier = scope_class_name self . method_identifier = method_identifier self . method_new_name = method_new_name self . package_identifier = package_name self . is_package_imported = False self . in_class = False self . in_selected_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . package_identifier == ctx . qualifiedName () . getText (): self . in_selected_package = True print ( \"Package \" + self . package_identifier + \" Found\" ) def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \".*\" + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \";\" : self . is_package_imported = True print ( \"package \" + self . package_identifier + \" imported\" ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . in_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_package_imported or self . in_selected_package : if self . in_class : if ctx . IDENTIFIER () . getText () == self . method_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex + 2 , text = self . method_new_name ) print ( \"method name changed !\" ) def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if self . is_package_imported or self . in_selected_package : if self . in_class : if ctx . IDENTIFIER () . getText () == self . method_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . method_new_name ) print ( \"method call name changed !\" ) __init__ ( self , common_token_stream = None , package_name = None , scope_class_name = None , method_identifier = None , method_new_name = None ) special Initializer of rename method refactoring listener Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done method_identifier(str): Name of the method in which the refactoring has to be done method_new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class Source code in codart\\refactorings\\rename_method2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , scope_class_name : str = None , method_identifier : str = None , method_new_name : str = None ): \"\"\" Initializer of rename method refactoring listener Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done method_identifier(str): Name of the method in which the refactoring has to be done method_new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class \"\"\" self . token_stream = common_token_stream self . class_identifier = scope_class_name self . method_identifier = method_identifier self . method_new_name = method_new_name self . package_identifier = package_name self . is_package_imported = False self . in_class = False self . in_selected_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"Rename method"},{"location":"refactorings/rename_method/#rename-method","text":"","title":"Rename method"},{"location":"refactorings/rename_method/#implementation-1","text":"","title":"Implementation 1"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method--introduction","text":"When the name of a method does not explain what the method does (method's functionality), it needs to be changed.","title":"Introduction"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method--pre-and-post-conditions","text":"","title":"Pre and post conditions"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method--pre-conditions","text":"User must enter the existing method's name, The source class's name for the refactoring, and the new method name in order to rename. Check if the method exist, then rename it.","title":"Pre-conditions:"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method--post-conditions","text":"After refactoring, all the old method names in the project should be changed. See whether the method is defined in a superclass or subclass. If so, you must repeat all steps in these classes too. The next method is important for maintaining the functionality of the program during the refactoring process. Create a new method with a new name. Copy the code of the old method to it. Delete all the code in the old method and, instead of it, insert a call for the new method. Find all references to the old method and replace them with references to the new one. Delete the old method. If the old method is part of a public interface, don\u2019t perform this step. Instead, mark the old method as deprecated.","title":"Post-conditions:"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method.RenameMethodListener","text":"The class implements Rename Method refactoring. The Main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Source code in codart\\refactorings\\rename_method.py class RenameMethodListener ( JavaParserLabeledListener ): \"\"\" The class implements Rename Method refactoring. The Main listener which parses the file based on the provided information, \\ using ANTLR parser generator and tokenization methods \"\"\" def __init__ ( self , java_file_path , common_token_stream , scope_class_name , target_method_name , new_name , reference = None ): \"\"\" Initializer of rename method refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . class_name = scope_class_name self . method_name = target_method_name self . new_method_name = new_name self . in_class = False self . changed = False self . reference = reference def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): name = ctx . IDENTIFIER () . getText () if name == self . class_name : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): name = ctx . IDENTIFIER () . getText () if name == self . class_name : self . in_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . in_class : name = ctx . IDENTIFIER () if name . getText () == self . method_name : node = name . getSymbol () self . token_stream_rewriter . replaceIndex ( node . tokenIndex , self . new_method_name ) self . changed = True def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if self . in_class and self . reference : name = ctx . IDENTIFIER () if name . getText () == self . method_name : node = name . getSymbol () if node . line == self . reference [ \"line\" ]: self . token_stream_rewriter . replaceIndex ( node . tokenIndex , self . new_method_name ) self . changed = True def enterMethodCall1 ( self , ctx : JavaParserLabeled . MethodCall1Context ): if self . in_class and self . reference : name = ctx . IDENTIFIER () if name . getText () == self . method_name : node = name . getSymbol () if node . line == self . reference [ \"line\" ]: self . token_stream_rewriter . replaceIndex ( node . tokenIndex , self . new_method_name ) self . changed = True","title":"RenameMethodListener"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method.RenameMethodListener.__init__","text":"Initializer of rename method refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class Source code in codart\\refactorings\\rename_method.py def __init__ ( self , java_file_path , common_token_stream , scope_class_name , target_method_name , new_name , reference = None ): \"\"\" Initializer of rename method refactoring listener Args: java_file_path(str): Address path to the test/source file common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class \"\"\" self . file_path = java_file_path self . token_stream = common_token_stream self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) self . class_name = scope_class_name self . method_name = target_method_name self . new_method_name = new_name self . in_class = False self . changed = False self . reference = reference","title":"__init__()"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method.get_method_calls","text":"Finds all of the refactored method calls in the database file and returns all of the correct references !!! args udb_path (str): Address path to the database file scope_class_name (str): Name of the class in which the refactoring has to be done new_name (str): The new name of the refactored method !!! returns References Source code in codart\\refactorings\\rename_method.py def get_method_calls ( udb_path , scope_class_name , new_name ): # Open Database \"\"\"Finds all of the refactored method calls in the database file and returns all of the correct references Args: udb_path (str): Address path to the database file scope_class_name (str): Name of the class in which the refactoring has to be done new_name (str): The new name of the refactored method Returns: References \"\"\" if not os . path . exists ( path = udb_path ): raise ValueError ( \"Database file does not exist!\" ) db = und . open ( udb_path ) method_scope = scope_class_name + \".\" + new_name references = [] # Find All Method Calls for ent in sorted ( db . ents (), key = lambda ent : ent . name ()): for ref in ent . refs ( refkindstring = \"Call\" ): scope = str ( ref . ent ()) if scope == method_scope : references . append ({ \"scope\" : str ( ref . scope ()), \"file_name\" : str ( ref . file ()), \"file_path\" : str ( ref . file () . longname ()), \"line\" : ref . line (), \"column\" : ref . column () }) db . close () return references","title":"get_method_calls()"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method.rename_method","text":"Main Entry Point to the Listener and Tree Walker Parameters: Name Type Description Default java_file_path(str) Address path to the test/source file required scope_class_name(str) Name of the class in which the refactoring has to be done required target_method_name(str) Name of the method in which the refactoring has to be done required new_name(str) The new name of the refactored method required reference(str) Keeping track for all of the method references in the project scope required Returns: Type Description No Returns Source code in codart\\refactorings\\rename_method.py def rename_method ( java_file_path , scope_class_name , target_method_name , new_name , reference = None ): \"\"\"Main Entry Point to the Listener and Tree Walker Args: java_file_path(str): Address path to the test/source file scope_class_name(str): Name of the class in which the refactoring has to be done target_method_name(str): Name of the method in which the refactoring has to be done new_name(str): The new name of the refactored method reference(str): Keeping track for all of the method references in the project scope Returns: No Returns \"\"\" stream = FileStream ( java_file_path ) lexer = JavaLexer ( stream ) tokens = CommonTokenStream ( lexer ) parser = JavaParserLabeled ( tokens ) tree = parser . compilationUnit () listener = RenameMethodListener ( java_file_path = java_file_path , common_token_stream = tokens , scope_class_name = scope_class_name , target_method_name = target_method_name , new_name = new_name , reference = reference ) walker = ParseTreeWalker () walker . walk ( listener , tree ) if listener . changed : # print(java_file_path) new_file = open ( file = java_file_path , mode = 'w' ) new_file . write ( listener . token_stream_rewriter . getDefaultText () . replace ( ' \\r ' , '' ))","title":"rename_method()"},{"location":"refactorings/rename_method/#implementation-2","text":"","title":"Implementation 2"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method2--introduction","text":"When the name of a method does not explain what the method does (method's functionality), it needs to be changed. The module implements a light-weight version of Rename Method refactoring described in rename_method.py","title":"Introduction"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method2--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method2--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method2.RenameMethodRefactoringListener","text":"The class implements Rename Method refactoring. The Main listener which parses the file based on the provided information, using ANTLR parser generator and tokenization methods Source code in codart\\refactorings\\rename_method2.py class RenameMethodRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class implements Rename Method refactoring. The Main listener which parses the file based on the provided information, \\ using ANTLR parser generator and tokenization methods \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , scope_class_name : str = None , method_identifier : str = None , method_new_name : str = None ): \"\"\" Initializer of rename method refactoring listener Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done method_identifier(str): Name of the method in which the refactoring has to be done method_new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class \"\"\" self . token_stream = common_token_stream self . class_identifier = scope_class_name self . method_identifier = method_identifier self . method_new_name = method_new_name self . package_identifier = package_name self . is_package_imported = False self . in_class = False self . in_selected_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . package_identifier == ctx . qualifiedName () . getText (): self . in_selected_package = True print ( \"Package \" + self . package_identifier + \" Found\" ) def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if ctx . getText () == \"import\" + self . package_identifier + \".\" + self . class_identifier + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \".*\" + \";\" \\ or ctx . getText () == \"import\" + self . package_identifier + \";\" : self . is_package_imported = True print ( \"package \" + self . package_identifier + \" imported\" ) def enterClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . in_class = True def exitClassDeclaration ( self , ctx : JavaParserLabeled . ClassDeclarationContext ): if self . is_package_imported or self . in_selected_package : if ctx . IDENTIFIER () . getText () == self . class_identifier : self . in_class = False def enterMethodDeclaration ( self , ctx : JavaParserLabeled . MethodDeclarationContext ): if self . is_package_imported or self . in_selected_package : if self . in_class : if ctx . IDENTIFIER () . getText () == self . method_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex + 2 , text = self . method_new_name ) print ( \"method name changed !\" ) def enterMethodCall0 ( self , ctx : JavaParserLabeled . MethodCall0Context ): if self . is_package_imported or self . in_selected_package : if self . in_class : if ctx . IDENTIFIER () . getText () == self . method_identifier : self . token_stream_rewriter . replaceIndex ( index = ctx . start . tokenIndex , text = self . method_new_name ) print ( \"method call name changed !\" )","title":"RenameMethodRefactoringListener"},{"location":"refactorings/rename_method/#codart.refactorings.rename_method2.RenameMethodRefactoringListener.__init__","text":"Initializer of rename method refactoring listener Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done method_identifier(str): Name of the method in which the refactoring has to be done method_new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class Source code in codart\\refactorings\\rename_method2.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_name : str = None , scope_class_name : str = None , method_identifier : str = None , method_new_name : str = None ): \"\"\" Initializer of rename method refactoring listener Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_name(str): Name of the package in which the refactoring has to be done scope_class_name(str): Name of the class in which the refactoring has to be done method_identifier(str): Name of the method in which the refactoring has to be done method_new_name(str): The new name of the refactored method Returns: RenameMethodListener: An instance of RenameMethodListener class \"\"\" self . token_stream = common_token_stream self . class_identifier = scope_class_name self . method_identifier = method_identifier self . method_new_name = method_new_name self . package_identifier = package_name self . is_package_imported = False self . in_class = False self . in_selected_package = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"refactorings/rename_package/","text":"Rename package When the name of a package does not explain what the class does (package's functionality), it needs to be changed. Pre-conditions: Todo: Add pre-conditions Post-conditions: Todo: Add post-conditions FindPackages ( JavaParserLabeledListener ) The class find packages Source code in codart\\refactorings\\rename_package.py class FindPackages ( JavaParserLabeledListener ): \"\"\" The class find packages \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None ): \"\"\" \"\"\" self . token_stream = common_token_stream # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText () not in packages : packages . append ( ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText ()) print ( \"package\" , ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText (), \"added to list\" ) __init__ ( self , common_token_stream = None ) special Source code in codart\\refactorings\\rename_package.py def __init__ ( self , common_token_stream : CommonTokenStream = None ): \"\"\" \"\"\" self . token_stream = common_token_stream # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) RenamePackageRefactoringListener ( JavaParserLabeledListener ) The class implements Rename Package refactoring. Source code in codart\\refactorings\\rename_package.py class RenamePackageRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class implements Rename Package refactoring. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_identifier : str = None , package_new_name : str = None , packages_name : list = []): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_identifier(str): Name of the package in which the refactoring has to be done package_new_name(str): The new name of the refactored method packages_name(str): Name of the packages in which the refactoring has to be done Returns: RenamePackageRefactoringListener: An instance of RenamePackageRefactoringListener class \"\"\" self . token_stream = common_token_stream self . package_identifier = package_identifier self . package_new_name = package_new_name self . packages_name = packages_name self . is_in_scope = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . package_identifier == ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText (): if self . package_new_name not in self . packages_name : self . token_stream_rewriter . replaceIndex ( index = ctx . qualifiedName () . start . tokenIndex + ( 2 * len ( ctx . qualifiedName () . IDENTIFIER ()) - 2 ), text = self . package_new_name ) print ( \"package changed\" ) def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText () == self . package_identifier : if self . package_new_name not in self . packages_name : self . token_stream_rewriter . replaceIndex ( index = ctx . qualifiedName () . start . tokenIndex + ( 2 * len ( ctx . qualifiedName () . IDENTIFIER ()) - 2 ), text = self . package_new_name ) print ( \"package name in import changed\" ) __init__ ( self , common_token_stream = None , package_identifier = None , package_new_name = None , packages_name = []) special Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_identifier(str): Name of the package in which the refactoring has to be done package_new_name(str): The new name of the refactored method packages_name(str): Name of the packages in which the refactoring has to be done Returns: Type Description RenamePackageRefactoringListener An instance of RenamePackageRefactoringListener class Source code in codart\\refactorings\\rename_package.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_identifier : str = None , package_new_name : str = None , packages_name : list = []): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_identifier(str): Name of the package in which the refactoring has to be done package_new_name(str): The new name of the refactored method packages_name(str): Name of the packages in which the refactoring has to be done Returns: RenamePackageRefactoringListener: An instance of RenamePackageRefactoringListener class \"\"\" self . token_stream = common_token_stream self . package_identifier = package_identifier self . package_new_name = package_new_name self . packages_name = packages_name self . is_in_scope = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"Rename package"},{"location":"refactorings/rename_package/#rename-package","text":"When the name of a package does not explain what the class does (package's functionality), it needs to be changed.","title":"Rename package"},{"location":"refactorings/rename_package/#codart.refactorings.rename_package--pre-conditions","text":"Todo: Add pre-conditions","title":"Pre-conditions:"},{"location":"refactorings/rename_package/#codart.refactorings.rename_package--post-conditions","text":"Todo: Add post-conditions","title":"Post-conditions:"},{"location":"refactorings/rename_package/#codart.refactorings.rename_package.FindPackages","text":"The class find packages Source code in codart\\refactorings\\rename_package.py class FindPackages ( JavaParserLabeledListener ): \"\"\" The class find packages \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None ): \"\"\" \"\"\" self . token_stream = common_token_stream # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText () not in packages : packages . append ( ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText ()) print ( \"package\" , ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText (), \"added to list\" )","title":"FindPackages"},{"location":"refactorings/rename_package/#codart.refactorings.rename_package.FindPackages.__init__","text":"Source code in codart\\refactorings\\rename_package.py def __init__ ( self , common_token_stream : CommonTokenStream = None ): \"\"\" \"\"\" self . token_stream = common_token_stream # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"refactorings/rename_package/#codart.refactorings.rename_package.RenamePackageRefactoringListener","text":"The class implements Rename Package refactoring. Source code in codart\\refactorings\\rename_package.py class RenamePackageRefactoringListener ( JavaParserLabeledListener ): \"\"\" The class implements Rename Package refactoring. \"\"\" def __init__ ( self , common_token_stream : CommonTokenStream = None , package_identifier : str = None , package_new_name : str = None , packages_name : list = []): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_identifier(str): Name of the package in which the refactoring has to be done package_new_name(str): The new name of the refactored method packages_name(str): Name of the packages in which the refactoring has to be done Returns: RenamePackageRefactoringListener: An instance of RenamePackageRefactoringListener class \"\"\" self . token_stream = common_token_stream self . package_identifier = package_identifier self . package_new_name = package_new_name self . packages_name = packages_name self . is_in_scope = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) def enterPackageDeclaration ( self , ctx : JavaParserLabeled . PackageDeclarationContext ): if self . package_identifier == ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText (): if self . package_new_name not in self . packages_name : self . token_stream_rewriter . replaceIndex ( index = ctx . qualifiedName () . start . tokenIndex + ( 2 * len ( ctx . qualifiedName () . IDENTIFIER ()) - 2 ), text = self . package_new_name ) print ( \"package changed\" ) def enterImportDeclaration ( self , ctx : JavaParserLabeled . ImportDeclarationContext ): if ctx . qualifiedName () . IDENTIFIER ()[ - 1 ] . getText () == self . package_identifier : if self . package_new_name not in self . packages_name : self . token_stream_rewriter . replaceIndex ( index = ctx . qualifiedName () . start . tokenIndex + ( 2 * len ( ctx . qualifiedName () . IDENTIFIER ()) - 2 ), text = self . package_new_name ) print ( \"package name in import changed\" )","title":"RenamePackageRefactoringListener"},{"location":"refactorings/rename_package/#codart.refactorings.rename_package.RenamePackageRefactoringListener.__init__","text":"Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_identifier(str): Name of the package in which the refactoring has to be done package_new_name(str): The new name of the refactored method packages_name(str): Name of the packages in which the refactoring has to be done Returns: Type Description RenamePackageRefactoringListener An instance of RenamePackageRefactoringListener class Source code in codart\\refactorings\\rename_package.py def __init__ ( self , common_token_stream : CommonTokenStream = None , package_identifier : str = None , package_new_name : str = None , packages_name : list = []): \"\"\" Args: common_token_stream (CommonTokenStream): An instance of ANTLR4 CommonTokenStream class package_identifier(str): Name of the package in which the refactoring has to be done package_new_name(str): The new name of the refactored method packages_name(str): Name of the packages in which the refactoring has to be done Returns: RenamePackageRefactoringListener: An instance of RenamePackageRefactoringListener class \"\"\" self . token_stream = common_token_stream self . package_identifier = package_identifier self . package_new_name = package_new_name self . packages_name = packages_name self . is_in_scope = False # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"tutorials/antlr_advanced/","text":"ANTLR advanced tutorials By: Morteza Zakeri Last update: April 30, 2022 Compiler background We first define some terms used in compiler literature when analyzing the program based on the ANTLR vocabulary. Compiler pass. Each time that the walk method of ParseTreeWalker class is called, it visits all nodes of the parse tree. In compiler literature, we called this process a pass. The ANTLR pass can be annotated with listener classes to perform specific analysis or transformation. An analysis pass refers to the pass in which some information is obtained from the source code, but the source code is not changed, or no new code is generated. A transformation pass refers to the pass in which the program source code is modified or new codes are generated. As we discussed in the next sections, refactoring automation consists of both the analysis and transformation passes. Single v.s. multiple pass. Often to perform specific analyses or transformations, the program should be visited multiple times. Indeed, such tasks required multiple passes. For instance, if a class attribute is defined after it is used in a method, which is possible in Java programming language, to find the definition of the field and then modify its usage, we should visit the program twice. The reason is that the program tokens are read from left to right, and then when traversing the parse tree, the node only is visited once in the order they appear in the program text. For a given task, if we visit a node and require the information obtained from the next nodes, we cannot complete the task in one pass. In such a case, a pass is required to obtain the necessary information from the next nodes, and another pass is required to use this information for the current node. Most refactoring operations we described in this chapter require multiple passes to complete the refactoring process. For each pass, we develop a separate listener class and pass it to ParseTreeWalker class.","title":"ANTLR advanced"},{"location":"tutorials/antlr_advanced/#antlr-advanced-tutorials","text":"By: Morteza Zakeri Last update: April 30, 2022","title":"ANTLR advanced tutorials"},{"location":"tutorials/antlr_advanced/#compiler-background","text":"We first define some terms used in compiler literature when analyzing the program based on the ANTLR vocabulary. Compiler pass. Each time that the walk method of ParseTreeWalker class is called, it visits all nodes of the parse tree. In compiler literature, we called this process a pass. The ANTLR pass can be annotated with listener classes to perform specific analysis or transformation. An analysis pass refers to the pass in which some information is obtained from the source code, but the source code is not changed, or no new code is generated. A transformation pass refers to the pass in which the program source code is modified or new codes are generated. As we discussed in the next sections, refactoring automation consists of both the analysis and transformation passes. Single v.s. multiple pass. Often to perform specific analyses or transformations, the program should be visited multiple times. Indeed, such tasks required multiple passes. For instance, if a class attribute is defined after it is used in a method, which is possible in Java programming language, to find the definition of the field and then modify its usage, we should visit the program twice. The reason is that the program tokens are read from left to right, and then when traversing the parse tree, the node only is visited once in the order they appear in the program text. For a given task, if we visit a node and require the information obtained from the next nodes, we cannot complete the task in one pass. In such a case, a pass is required to obtain the necessary information from the next nodes, and another pass is required to use this information for the current node. Most refactoring operations we described in this chapter require multiple passes to complete the refactoring process. For each pass, we develop a separate listener class and pass it to ParseTreeWalker class.","title":"Compiler background"},{"location":"tutorials/antlr_basics/","text":"ANTLR basic tutorials By: Morteza Zakeri Last update: April 30, 2022 Introduction The ANTLR tool generates a top-down parser from the grammar rules defined with the ANTLR meta-grammar (Parr and Fisher 2011). The initial version of ANTLR generated the target parser source code in Java. In the current version (version 4), the parser source code can be generated in a wide range of programming languages listed on the ANTLR official website (Parr 2022a). For simplicity, we generate the parser in Python 3, which provides us to run the tool on every platform having Python 3 installed on it. Another reason to use Python is that we can integrate the developed program easily with other libraries available in Python, such as machine learning and optimization libraries. Finally, I found that there is no comprehensive tutorial on using ANTLR with the Python backend. To use ANTLR in other programming languages, specifically Java and C#, refer to the ANTLR slides I created before this tutorial. The ANTLR tool is a small \u201c.jar\u201d file that must be run from the command line to generate the parser codes. The ANTLR tool jar file can be downloaded from here . Generating parser As mentioned, to generate a parser for a programming language, the grammar specification described with ANTLR meta-grammar is required. ANTLR grammar files are named with the \u201c.g4\u201d suffix. We obtain the grammar of Java 8 to build our parser for the Java programming language. The grammar can be downloaded from ANTLR 4 grammar repository on GitHub: https://github.com/antlr/grammars-v4 . Once the ANTLR tool and required grammar files are prepared, we can generate the parser for that with the following command: > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -o . JavaLexer.g4 > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -visitor -listener -o . JavaLabeledParser.g4 The first command generates the lexer from the JavaLexer.g4 description file and the second command generates the parser from the JavaLabeledParser.g4 description file. It is worth noting that the lexer and parser can be written in one file. In such a case, a single command generates all required codes in one step. The grammar files used in the above command are also available in grammars directory of the CodART repository. You may see that I have made some modifications to the Parser rules. In the above commands, the antlr-4.9.3-complete.jar is the ANTLR tool that requires Java to be executed. -Dlanguage denotes the destination language that the ANTLR parser (and lexer) source code is generated in which. In our case, we set it to Python3. After executing the ANTLR parser generation commands, eight files, including parser source code and other required information, are generated. Figure 1 shows the generated files. The \u201c.py\u201d contains lexer and parser source code that can parse any Java input file. The -visitor -listener switches in the second command result in generating two separate source files, JavaLabledParserListener.py and JavaLabledParserVistor.py , which provide interfaces to implement the required codes for a specific language application. Our application is source code refactoring which uses the listener mechanism to implement necessary actions transforming the program to the refactored version. The parse tree structure in and listener mechanism are discussed in the next sections. Figure 1. Generated files by ANTLR. It should be noted that to use the generated classes in Figure 1, for developing a specific program, we need to install the appropriate ANTLR runtime library. For creating ANTLR-based programs in Python, the command pip install antlr-python3-runtime can be used. It installed all runtime dependencies required to program using the ANTLR library. ANTLR parse tree The generated parser by ANTLR is responsible for parsing every Java source code file and generating the parse tree or designating the syntax errors in the input file. The parse tree for real-world programs with thousands of lines of code has a non-trivial structure. ANTLR developers have provided some IDE plugins that can visualize the parse tree to better understand the structure of the parse tree generated by ANTLR. We use Pycharm IDE developed by Jetbrains to work with Python code. Figure 2 shows how we can install the ANTLR plugin in PyCharm. The plugin source code is available on the GitHub repo . When the plugin is installed, the ANTLR preview widow is applied at the bottom of the PyCharm IDE. In addition, the IDE can be recognized as \u201c.g4\u201d files and some other options added to the IDE. The main option is the ability to test a grammar rule and visualize the corresponding parse tree to that rule. Figure 2. Installing the ANTLR plugin in the PyCharm IDE. In order to use the ANTLR preview tab, the ANTLR grammar should be opened in the PyCharm IDE. We then select a rule (typically the start rule) of our grammar, right-click on the rule, and select the \u201cTest Rule rule_name \u201d option from the opened menu, shown in Figure 3. We now write our sample input program in the left panel of the ANTLR preview, and the parse tree is shown in the right panel. Figure 3. Test the grammar rule in the ANTLR PyCharm plugin. Figure 4 shows a simple Java class and the corresponding parse tree generated by the ANTLR. The leaves of the parse tree are program tokens, while the intermediate nodes are grammar rules that the evaluating program is derived from them. Also, the root of the tree is the grammar rule, which we selected to start parsing. It means that we can select and test every rule independently. However, a complete Java program can only parse from the start rule of the given grammar, i.e., the compilaionUnit rule. Figure 4. Test the grammar rule in the ANTLR PyCharm plugin. It should be mentioned that the ANTLR Preview window is based on a grammar interpreter, not on the actual generated parser described in the previous section. It means that grammar attributes such as actions and predicates will not be evaluated during live preview because the interpreter is language agnostic. For the same reasons, if the generated parser and/or lexer classes extend a custom implementation of the base parser/lexer classes, the custom code will not be run during the live preview. In addition to the parse tree visualization, the ANTLR plugin provides facilities such as profiling, code generation, etc., described in here (Parr 2022b). For example, the profile tab shows the execution time of each rule in the parser for a given input string. I want to emphasize that visualizing the parse tree with the ANTLR plugin is really helpful when developing code and fixing bugs described in the next section of this tutorial. Traversing the parse tree programmatically ANTLR is not a simple parser generator. It provides a depth-first parse tree visiting and a callback mechanism called listener to implement the required program analysis or transformation passes. The depth-first search is performed by instantiating an object from the ANTLR ParseTreeWalker class and calling the walk method, which takes an instance of ParseTree as an input argument and traverses it. Obviously, if we visit the parse tree with the depth-first search algorithm, all program tokens are visited in the same order that they appeared in the source code file. However, the depth-first search contains additional information about when a node in the tree is visited and when the visiting all nodes in its subtree is finished. Therefore, we can add the required actions when visiting a node to perform a special task. For example, according to Figure 4, for counting the number of classes in a code snippet, we can define a counter variable, initialize it to zero, and increase it whenever the walker visits the \u201cclassDeclartion\u201d node. ANTLR provides two callback functions for each node in the parse tree. One is called by the walker when it is entered into a node, i.e., visit the node, but the children are not visited yet. Another is called when all nodes in the subtree of the visited node have been visited, and the walker is exiting the node. These callback functions are available in the listener class generated by the ANTLR for every rule in a given grammar. In our example for counting the number of classes, we implement all required logic in the body of enterClassDeclartion method of the JavaLabledParserListener class. We called these logic codes grammar\u2019s actions since, indeed, they are bunded to a grammar rule. It is worth noting that we can add these actions codes in the grammar file ( .g4 file) to form an attributed grammar. Embedding actions in grammar increase the efficiency of the analyzing process. However, when we need many complex actions, the listener mechanism provides a better way to implement them. Indeed, ANTLR 4 emphasizes separating the language applications from the language grammar by using the listener mechanism. Listing 1 shows the implementation program for counting the number of classes using the ANTLR listener mechanism. The DesignMetrics class inherits from JavaLabeledParserListener class which is the default listener class generated by ANTLR. We only implement the enterClassDeclartion method, which increases the value of the __dsc counter each time the walker visits a Java class. # module: JavaLabledParserListener.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * if __name__ is not None and \".\" in __name__: from .JavaLabeledParser import JavaLabeledParser else: from JavaLabeledParser import JavaLabeledParser class JavaLabeledParserListener(ParseTreeListener): # \u2026 def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): pass # \u2026 class DesignMetrics(JavaLabeledParserListener): def __init__(self): self.__dsc:int = 0 # Keep design size in classes @property def get_design_size(self): return self.__dsc def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): self.__dsc += 1 Listing 1: Programs that count the number of classes in a Java source code. Wiring the modules To complete our simple analysis task, first, the parse tree for a given input should be constructed. Then, the DesignMetrics class should be instantiated and passed to an object of ParseTreeWalker class. We created a driver module in Python beside the generated code by ANTLR to connect different parts of our program and complete our task. Listing 2 shows the implementation of the main driver for a program that counts the number of classes in Java source codes. # Module: main_driver.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * from JavaLabledLexer import JavaLabledLexer from JavaLeabledParser import JavaLabledParser from JavaLabledParserListener import DesignMetrics def main(args): # Step 1: Load input source into the stream object stream = FileStream(args.file, encoding='utf8') # Step 2: Create an instance of AssignmentStLexer lexer = JavaLabledLexer(stream) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream(lexer) # Step 4: Create an instance of the AssignmentStParser parser = JavaLabledParser(token_stream) # Step 5: Create parse tree parse_tree = parser.compilationUnit() # Step 6: Create an instance of DesignMetrics listener class my_listener = DesignMetrics() # Step 7: Create a walker to traverse the parse tree and callback our listener walker = ParseTreeWalker() walker.walk(t=parse_tree, listener=my_listener) # Step 8: Getting the results print(f'DSC={my_listener.get_design_size}') Listing 2: Main driver module for the program in Listing 1 Conclusion and remarks In this tutorial, we described the basic concepts regarding using the ANTLR tool to generate and walk phase three and implement custom program analysis applications with the help of the ANTLR listener mechanism. The most important point is that we used the real-world programming languages grammars to show the parsing and analyzing process. The discussed topics form the underlying concepts of our approach for automated refactoring used in CodART. Check out the ANTLR advanced tutorial to find out how we can use ANTLR for reliable and efficient program transformation. References Parr T ANTLR (ANother Tool for Language Recognition). https://www.antlr.org. Accessed 10 Jan 2022a Parr T IntelliJ Idea Plugin for ANTLR v4. https://github.com/antlr/intellij-plugin-v4. Accessed 10 Jan 2022b Parr T, Fisher K (2011) LL(*): the foundation of the ANTLR parser generator. Proc 32nd ACM SIGPLAN Conf Program Lang Des Implement 425\u2013436. https://doi.org/http://doi.acm.org/10.1145/1993498.1993548","title":"ANTLR basics"},{"location":"tutorials/antlr_basics/#antlr-basic-tutorials","text":"By: Morteza Zakeri Last update: April 30, 2022","title":"ANTLR basic tutorials"},{"location":"tutorials/antlr_basics/#introduction","text":"The ANTLR tool generates a top-down parser from the grammar rules defined with the ANTLR meta-grammar (Parr and Fisher 2011). The initial version of ANTLR generated the target parser source code in Java. In the current version (version 4), the parser source code can be generated in a wide range of programming languages listed on the ANTLR official website (Parr 2022a). For simplicity, we generate the parser in Python 3, which provides us to run the tool on every platform having Python 3 installed on it. Another reason to use Python is that we can integrate the developed program easily with other libraries available in Python, such as machine learning and optimization libraries. Finally, I found that there is no comprehensive tutorial on using ANTLR with the Python backend. To use ANTLR in other programming languages, specifically Java and C#, refer to the ANTLR slides I created before this tutorial. The ANTLR tool is a small \u201c.jar\u201d file that must be run from the command line to generate the parser codes. The ANTLR tool jar file can be downloaded from here .","title":"Introduction"},{"location":"tutorials/antlr_basics/#generating-parser","text":"As mentioned, to generate a parser for a programming language, the grammar specification described with ANTLR meta-grammar is required. ANTLR grammar files are named with the \u201c.g4\u201d suffix. We obtain the grammar of Java 8 to build our parser for the Java programming language. The grammar can be downloaded from ANTLR 4 grammar repository on GitHub: https://github.com/antlr/grammars-v4 . Once the ANTLR tool and required grammar files are prepared, we can generate the parser for that with the following command: > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -o . JavaLexer.g4 > java -Xmx500M -cp antlr-4.9.3-complete.jar org.antlr.v4.Tool -Dlanguage=Python3 -visitor -listener -o . JavaLabeledParser.g4 The first command generates the lexer from the JavaLexer.g4 description file and the second command generates the parser from the JavaLabeledParser.g4 description file. It is worth noting that the lexer and parser can be written in one file. In such a case, a single command generates all required codes in one step. The grammar files used in the above command are also available in grammars directory of the CodART repository. You may see that I have made some modifications to the Parser rules. In the above commands, the antlr-4.9.3-complete.jar is the ANTLR tool that requires Java to be executed. -Dlanguage denotes the destination language that the ANTLR parser (and lexer) source code is generated in which. In our case, we set it to Python3. After executing the ANTLR parser generation commands, eight files, including parser source code and other required information, are generated. Figure 1 shows the generated files. The \u201c.py\u201d contains lexer and parser source code that can parse any Java input file. The -visitor -listener switches in the second command result in generating two separate source files, JavaLabledParserListener.py and JavaLabledParserVistor.py , which provide interfaces to implement the required codes for a specific language application. Our application is source code refactoring which uses the listener mechanism to implement necessary actions transforming the program to the refactored version. The parse tree structure in and listener mechanism are discussed in the next sections. Figure 1. Generated files by ANTLR. It should be noted that to use the generated classes in Figure 1, for developing a specific program, we need to install the appropriate ANTLR runtime library. For creating ANTLR-based programs in Python, the command pip install antlr-python3-runtime can be used. It installed all runtime dependencies required to program using the ANTLR library.","title":"Generating parser"},{"location":"tutorials/antlr_basics/#antlr-parse-tree","text":"The generated parser by ANTLR is responsible for parsing every Java source code file and generating the parse tree or designating the syntax errors in the input file. The parse tree for real-world programs with thousands of lines of code has a non-trivial structure. ANTLR developers have provided some IDE plugins that can visualize the parse tree to better understand the structure of the parse tree generated by ANTLR. We use Pycharm IDE developed by Jetbrains to work with Python code. Figure 2 shows how we can install the ANTLR plugin in PyCharm. The plugin source code is available on the GitHub repo . When the plugin is installed, the ANTLR preview widow is applied at the bottom of the PyCharm IDE. In addition, the IDE can be recognized as \u201c.g4\u201d files and some other options added to the IDE. The main option is the ability to test a grammar rule and visualize the corresponding parse tree to that rule. Figure 2. Installing the ANTLR plugin in the PyCharm IDE. In order to use the ANTLR preview tab, the ANTLR grammar should be opened in the PyCharm IDE. We then select a rule (typically the start rule) of our grammar, right-click on the rule, and select the \u201cTest Rule rule_name \u201d option from the opened menu, shown in Figure 3. We now write our sample input program in the left panel of the ANTLR preview, and the parse tree is shown in the right panel. Figure 3. Test the grammar rule in the ANTLR PyCharm plugin. Figure 4 shows a simple Java class and the corresponding parse tree generated by the ANTLR. The leaves of the parse tree are program tokens, while the intermediate nodes are grammar rules that the evaluating program is derived from them. Also, the root of the tree is the grammar rule, which we selected to start parsing. It means that we can select and test every rule independently. However, a complete Java program can only parse from the start rule of the given grammar, i.e., the compilaionUnit rule. Figure 4. Test the grammar rule in the ANTLR PyCharm plugin. It should be mentioned that the ANTLR Preview window is based on a grammar interpreter, not on the actual generated parser described in the previous section. It means that grammar attributes such as actions and predicates will not be evaluated during live preview because the interpreter is language agnostic. For the same reasons, if the generated parser and/or lexer classes extend a custom implementation of the base parser/lexer classes, the custom code will not be run during the live preview. In addition to the parse tree visualization, the ANTLR plugin provides facilities such as profiling, code generation, etc., described in here (Parr 2022b). For example, the profile tab shows the execution time of each rule in the parser for a given input string. I want to emphasize that visualizing the parse tree with the ANTLR plugin is really helpful when developing code and fixing bugs described in the next section of this tutorial.","title":"ANTLR parse tree"},{"location":"tutorials/antlr_basics/#traversing-the-parse-tree-programmatically","text":"ANTLR is not a simple parser generator. It provides a depth-first parse tree visiting and a callback mechanism called listener to implement the required program analysis or transformation passes. The depth-first search is performed by instantiating an object from the ANTLR ParseTreeWalker class and calling the walk method, which takes an instance of ParseTree as an input argument and traverses it. Obviously, if we visit the parse tree with the depth-first search algorithm, all program tokens are visited in the same order that they appeared in the source code file. However, the depth-first search contains additional information about when a node in the tree is visited and when the visiting all nodes in its subtree is finished. Therefore, we can add the required actions when visiting a node to perform a special task. For example, according to Figure 4, for counting the number of classes in a code snippet, we can define a counter variable, initialize it to zero, and increase it whenever the walker visits the \u201cclassDeclartion\u201d node. ANTLR provides two callback functions for each node in the parse tree. One is called by the walker when it is entered into a node, i.e., visit the node, but the children are not visited yet. Another is called when all nodes in the subtree of the visited node have been visited, and the walker is exiting the node. These callback functions are available in the listener class generated by the ANTLR for every rule in a given grammar. In our example for counting the number of classes, we implement all required logic in the body of enterClassDeclartion method of the JavaLabledParserListener class. We called these logic codes grammar\u2019s actions since, indeed, they are bunded to a grammar rule. It is worth noting that we can add these actions codes in the grammar file ( .g4 file) to form an attributed grammar. Embedding actions in grammar increase the efficiency of the analyzing process. However, when we need many complex actions, the listener mechanism provides a better way to implement them. Indeed, ANTLR 4 emphasizes separating the language applications from the language grammar by using the listener mechanism. Listing 1 shows the implementation program for counting the number of classes using the ANTLR listener mechanism. The DesignMetrics class inherits from JavaLabeledParserListener class which is the default listener class generated by ANTLR. We only implement the enterClassDeclartion method, which increases the value of the __dsc counter each time the walker visits a Java class. # module: JavaLabledParserListener.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * if __name__ is not None and \".\" in __name__: from .JavaLabeledParser import JavaLabeledParser else: from JavaLabeledParser import JavaLabeledParser class JavaLabeledParserListener(ParseTreeListener): # \u2026 def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): pass # \u2026 class DesignMetrics(JavaLabeledParserListener): def __init__(self): self.__dsc:int = 0 # Keep design size in classes @property def get_design_size(self): return self.__dsc def enterClassDeclaration(self, ctx:JavaLabeledParser.ClassDeclarationContext): self.__dsc += 1 Listing 1: Programs that count the number of classes in a Java source code.","title":"Traversing the parse tree programmatically"},{"location":"tutorials/antlr_basics/#wiring-the-modules","text":"To complete our simple analysis task, first, the parse tree for a given input should be constructed. Then, the DesignMetrics class should be instantiated and passed to an object of ParseTreeWalker class. We created a driver module in Python beside the generated code by ANTLR to connect different parts of our program and complete our task. Listing 2 shows the implementation of the main driver for a program that counts the number of classes in Java source codes. # Module: main_driver.py __version__ = \"0.1.0\" __author__ = \"Morteza\" from antlr4 import * from JavaLabledLexer import JavaLabledLexer from JavaLeabledParser import JavaLabledParser from JavaLabledParserListener import DesignMetrics def main(args): # Step 1: Load input source into the stream object stream = FileStream(args.file, encoding='utf8') # Step 2: Create an instance of AssignmentStLexer lexer = JavaLabledLexer(stream) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream(lexer) # Step 4: Create an instance of the AssignmentStParser parser = JavaLabledParser(token_stream) # Step 5: Create parse tree parse_tree = parser.compilationUnit() # Step 6: Create an instance of DesignMetrics listener class my_listener = DesignMetrics() # Step 7: Create a walker to traverse the parse tree and callback our listener walker = ParseTreeWalker() walker.walk(t=parse_tree, listener=my_listener) # Step 8: Getting the results print(f'DSC={my_listener.get_design_size}') Listing 2: Main driver module for the program in Listing 1","title":"Wiring the modules"},{"location":"tutorials/antlr_basics/#conclusion-and-remarks","text":"In this tutorial, we described the basic concepts regarding using the ANTLR tool to generate and walk phase three and implement custom program analysis applications with the help of the ANTLR listener mechanism. The most important point is that we used the real-world programming languages grammars to show the parsing and analyzing process. The discussed topics form the underlying concepts of our approach for automated refactoring used in CodART. Check out the ANTLR advanced tutorial to find out how we can use ANTLR for reliable and efficient program transformation.","title":"Conclusion and remarks"},{"location":"tutorials/antlr_basics/#references","text":"Parr T ANTLR (ANother Tool for Language Recognition). https://www.antlr.org. Accessed 10 Jan 2022a Parr T IntelliJ Idea Plugin for ANTLR v4. https://github.com/antlr/intellij-plugin-v4. Accessed 10 Jan 2022b Parr T, Fisher K (2011) LL(*): the foundation of the ANTLR parser generator. Proc 32nd ACM SIGPLAN Conf Program Lang Des Implement 425\u2013436. https://doi.org/http://doi.acm.org/10.1145/1993498.1993548","title":"References"},{"location":"tutorials/antlr_slides/","text":"ANTLR slides Introduction to ANTLR: Part I Antlr part1 introduction from Morteza Zakeri Introduction to ANTLR: Part II Antlr part2 getting_started_in_java from Morteza Zakeri Introduction to ANTLR: Part III Antlr part3 getting_started_in_c_sharp from Morteza Zakeri","title":"ANTLR slides"},{"location":"tutorials/antlr_slides/#antlr-slides","text":"","title":"ANTLR slides"},{"location":"tutorials/antlr_slides/#introduction-to-antlr-part-i","text":"Antlr part1 introduction from Morteza Zakeri","title":"Introduction to ANTLR: Part I"},{"location":"tutorials/antlr_slides/#introduction-to-antlr-part-ii","text":"Antlr part2 getting_started_in_java from Morteza Zakeri","title":"Introduction to ANTLR: Part II"},{"location":"tutorials/antlr_slides/#introduction-to-antlr-part-iii","text":"Antlr part3 getting_started_in_c_sharp from Morteza Zakeri","title":"Introduction to ANTLR: Part III"},{"location":"tutorials/refactorings_basics/","text":"Refactoring basic tutorials Please refer to a related blog post Automated Refactoring of the Java Codes using ANTLR in Python .","title":"Refactoring basics"},{"location":"tutorials/refactorings_basics/#refactoring-basic-tutorials","text":"Please refer to a related blog post Automated Refactoring of the Java Codes using ANTLR in Python .","title":"Refactoring basic tutorials"},{"location":"utilities/project_utils/","text":"Project utils Directory utils Utilities related to project directory. create_understand_database ( project_dir = None , db_dir = None ) This function creates understand database for the given project directory. Parameters: Name Type Description Default project_dir str The absolute path of project's directory. None db_dir str The absolute directory path to save Understand database (.udb or .und binary file) None Returns: Type Description str Understand database path Source code in codart\\utility\\directory_utils.py def create_understand_database ( project_dir : str = None , db_dir : str = None ): \"\"\" This function creates understand database for the given project directory. Args: project_dir (str): The absolute path of project's directory. db_dir (str): The absolute directory path to save Understand database (.udb or .und binary file) Returns: str: Understand database path \"\"\" assert os . path . isdir ( project_dir ) db_name = os . path . basename ( os . path . normpath ( project_dir )) + \".und\" db_path = os . path . join ( db_dir , db_name ) # print(project_dir, db_name, db_path) # quit() if os . path . exists ( db_path ): return db_path # An example of command-line is: # und create -languages c++ add @myFiles.txt analyze -all myDb.udb understand_5_cmd = [ 'und' , 'create' , '-languages' , 'Java' , 'add' , project_dir , 'analyze' , '-all' , db_path ] understand_6_cmd = [ 'und' , 'create' , '-db' , db_path , '-languages' , 'java' ] result = subprocess . run ( understand_6_cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) if result . returncode != 0 : error_ = result . stderr . decode ( 'utf-8' ) config . logger . debug ( f 'return code: { result . returncode } msg: { error_ } ' ) else : config . logger . debug ( f 'Understand project was created successfully!' ) return db_path export_understand_dependencies_csv ( csv_path , db_path ) Exports understand dependencies into a csv file. :param csv_path: The absolute address of csv file to generate. :param db_path: The absolute address of project path. :return: None Source code in codart\\utility\\directory_utils.py def export_understand_dependencies_csv ( csv_path : str , db_path : str ): \"\"\" Exports understand dependencies into a csv file. :param csv_path: The absolute address of csv file to generate. :param db_path: The absolute address of project path. :return: None \"\"\" command = [ 'und' , 'export' , '-format' , 'long' , '-dependencies' , 'class' , 'csv' , csv_path , db_path ] result = subprocess . run ( command , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) trials = 0 while result . returncode != 0 : result = subprocess . run ( command , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) error_ = result . stderr . decode ( 'utf-8' ) config . logger . debug ( f 'return code: { result . returncode } msg: { error_ } ' ) trials += 1 if trials > 5 : break config . logger . debug ( \"Modular dependency graph (MDG.csv) was exported.\" ) # Try to close und.exe process if it has not been killed automatically result = subprocess . run ([ 'taskkill' , '/f' , '/im' , 'und.exe' ], stdout = subprocess . PIPE , stderr = subprocess . PIPE ) if result . returncode != 0 : config . logger . debug ( 'The und.exe process is not running' ) else : config . logger . debug ( 'The und.exe process killed manually' ) export_understand_dependencies_csv2 ( csv_path , db_path ) Exports understand dependencies into a csv file. :param csv_path: The absolute address of csv file to generate. :param db_path: The absolute address of project path. :return: None Source code in codart\\utility\\directory_utils.py def export_understand_dependencies_csv2 ( csv_path : str , db_path : str ): \"\"\" Exports understand dependencies into a csv file. :param csv_path: The absolute address of csv file to generate. :param db_path: The absolute address of project path. :return: None \"\"\" command = [ 'und' , 'export' , '-format' , 'long' , '-dependencies' , 'class' , 'csv' , csv_path , db_path ] subprocess . Popen ( command , stdout = open ( os . devnull , 'wb' ) ) . wait () config . logger . debug ( \"Modular dependency graph (MDG.csv) was exported.\" ) git_restore ( project_dir ) This function returns a git supported project back to the initial commit Parameters: Name Type Description Default project_dir str The absolute path of project's directory. required Returns: Type Description None Source code in codart\\utility\\directory_utils.py def git_restore ( project_dir ): \"\"\" This function returns a git supported project back to the initial commit Args: project_dir (str): The absolute path of project's directory. Returns: None \"\"\" assert os . path . isdir ( project_dir ) assert os . path . isdir ( os . path . join ( project_dir , '.git' )) subprocess . Popen ([ \"git\" , \"restore\" , \".\" ], cwd = project_dir , stdout = open ( os . devnull , 'wb' )) . wait () subprocess . Popen ([ \"git\" , \"clean\" , \"-f\" , \"-d\" ], cwd = project_dir , stdout = open ( os . devnull , 'wb' )) . wait () update_understand_database ( udb_path ) This function updates database due to file changes. If any error, such as database is locked or read only, occurred it tries again and again to update db. Arges: udb_path (str): The absolute path of understand database. Returns: Type Description None Source code in codart\\utility\\directory_utils.py def update_understand_database ( udb_path ): \"\"\" This function updates database due to file changes. If any error, such as database is locked or read only, occurred it tries again and again to update db. Arges: udb_path (str): The absolute path of understand database. Return: None \"\"\" understand_5_cmd = [ 'und' , 'analyze' , '-rescan' , '-changed' , udb_path ] understand_6_cmd = [ 'und' , 'analyze' , '-changed' , udb_path ] # -rescan option is not required for understand >= 6.0 result = subprocess . run ( understand_6_cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) # info_ = result.stdout.decode('utf-8') # error_ = result.stderr.decode('utf-8') # print(info_[:85]) # print(f'return code: {result.returncode} --- error: {error_}') trials = 0 while result . returncode != 0 : try : db : und . Db = und . open ( config . UDB_PATH ) db . close () except : pass finally : result = subprocess . run ( understand_6_cmd , # stdout = subprocess . PIPE , stderr = subprocess . PIPE ) # info_ = result.stdout.decode('utf-8') error_ = result . stderr . decode ( 'utf-8' ) # print(info_[:85]) config . logger . debug ( f 'return code: { result . returncode } msg: { error_ } ' ) trials += 1 if trials > 5 : break # Try to close und.exe process if it has not been killed automatically result = subprocess . run ([ 'taskkill' , '/f' , '/im' , 'und.exe' ], stdout = subprocess . PIPE , stderr = subprocess . PIPE ) if result . returncode != 0 : config . logger . debug ( 'The und.exe process is not running' ) else : config . logger . debug ( 'The und.exe process killed manually' ) update_understand_database2 ( udb_path ) This function updates database due to file changes. Error message raised by understand 6.x: Error: The Analysis cannot be performed because the database is locked or read only Arges: udb_path (str): The absolute path of understand database. Returns: Type Description None Source code in codart\\utility\\directory_utils.py def update_understand_database2 ( udb_path ): \"\"\" This function updates database due to file changes. Error message raised by understand 6.x: Error: The Analysis cannot be performed because the database is locked or read only Arges: udb_path (str): The absolute path of understand database. Return: None \"\"\" understand_5_cmd = [ 'und' , 'analyze' , '-rescan' , '-changed' , udb_path ] understand_6_cmd = [ 'und' , 'analyze' , '-changed' , udb_path ] # -rescan option is not required for understand >= 6.0 subprocess . Popen ( understand_6_cmd , stdout = open ( os . devnull , 'wb' ) ) . wait () Performance meter ProjectParseUsage Source code in codart\\utility\\cpu_ram_usage.py class ProjectParseUsage : def __init__ ( self , project_dir ): \"\"\" This by calling this class you can measure: - Total consumed memory for keeping all parse trees - Total consumed time for parsing in seconds \"\"\" self . project_root = project_dir self . parse_trees = [] self . counter = 0 @staticmethod def java_explorer ( path ): result = list ( Path ( path ) . rglob ( \"*.java\" )) for file_path in result : yield file_path . absolute () @staticmethod def generate_tree ( file_path ): # Step 1: Load input source into stream stream = FileStream ( file_path , encoding = 'utf8' , errors = 'ignore' ) # Step 2: Create an instance of AssignmentStLexer lexer = JavaLexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = JavaParser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . compilationUnit () return parse_tree def run ( self ): print ( \"Parsing...\" ) total_time = 0 generator = self . java_explorer ( self . project_root ) for file_path in generator : self . counter += 1 print ( f \"Parsing { self . counter } : { file_path } \" ) start = time . time () tree = self . generate_tree ( file_path ) end = time . time () self . parse_trees . append ( tree ) total_time += end - start print ( f \"Execute time is { total_time } seconds.\" ) print ( f \"Memory used for all trees is { sys . getsizeof ( self . parse_trees ) / 1000 } KB\" ) __init__ ( self , project_dir ) special This by calling this class you can measure: - Total consumed memory for keeping all parse trees - Total consumed time for parsing in seconds Source code in codart\\utility\\cpu_ram_usage.py def __init__ ( self , project_dir ): \"\"\" This by calling this class you can measure: - Total consumed memory for keeping all parse trees - Total consumed time for parsing in seconds \"\"\" self . project_root = project_dir self . parse_trees = [] self . counter = 0","title":"Project utilities"},{"location":"utilities/project_utils/#project-utils","text":"","title":"Project utils"},{"location":"utilities/project_utils/#directory-utils","text":"Utilities related to project directory.","title":"Directory utils"},{"location":"utilities/project_utils/#codart.utility.directory_utils.create_understand_database","text":"This function creates understand database for the given project directory. Parameters: Name Type Description Default project_dir str The absolute path of project's directory. None db_dir str The absolute directory path to save Understand database (.udb or .und binary file) None Returns: Type Description str Understand database path Source code in codart\\utility\\directory_utils.py def create_understand_database ( project_dir : str = None , db_dir : str = None ): \"\"\" This function creates understand database for the given project directory. Args: project_dir (str): The absolute path of project's directory. db_dir (str): The absolute directory path to save Understand database (.udb or .und binary file) Returns: str: Understand database path \"\"\" assert os . path . isdir ( project_dir ) db_name = os . path . basename ( os . path . normpath ( project_dir )) + \".und\" db_path = os . path . join ( db_dir , db_name ) # print(project_dir, db_name, db_path) # quit() if os . path . exists ( db_path ): return db_path # An example of command-line is: # und create -languages c++ add @myFiles.txt analyze -all myDb.udb understand_5_cmd = [ 'und' , 'create' , '-languages' , 'Java' , 'add' , project_dir , 'analyze' , '-all' , db_path ] understand_6_cmd = [ 'und' , 'create' , '-db' , db_path , '-languages' , 'java' ] result = subprocess . run ( understand_6_cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) if result . returncode != 0 : error_ = result . stderr . decode ( 'utf-8' ) config . logger . debug ( f 'return code: { result . returncode } msg: { error_ } ' ) else : config . logger . debug ( f 'Understand project was created successfully!' ) return db_path","title":"create_understand_database()"},{"location":"utilities/project_utils/#codart.utility.directory_utils.export_understand_dependencies_csv","text":"Exports understand dependencies into a csv file. :param csv_path: The absolute address of csv file to generate. :param db_path: The absolute address of project path. :return: None Source code in codart\\utility\\directory_utils.py def export_understand_dependencies_csv ( csv_path : str , db_path : str ): \"\"\" Exports understand dependencies into a csv file. :param csv_path: The absolute address of csv file to generate. :param db_path: The absolute address of project path. :return: None \"\"\" command = [ 'und' , 'export' , '-format' , 'long' , '-dependencies' , 'class' , 'csv' , csv_path , db_path ] result = subprocess . run ( command , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) trials = 0 while result . returncode != 0 : result = subprocess . run ( command , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) error_ = result . stderr . decode ( 'utf-8' ) config . logger . debug ( f 'return code: { result . returncode } msg: { error_ } ' ) trials += 1 if trials > 5 : break config . logger . debug ( \"Modular dependency graph (MDG.csv) was exported.\" ) # Try to close und.exe process if it has not been killed automatically result = subprocess . run ([ 'taskkill' , '/f' , '/im' , 'und.exe' ], stdout = subprocess . PIPE , stderr = subprocess . PIPE ) if result . returncode != 0 : config . logger . debug ( 'The und.exe process is not running' ) else : config . logger . debug ( 'The und.exe process killed manually' )","title":"export_understand_dependencies_csv()"},{"location":"utilities/project_utils/#codart.utility.directory_utils.export_understand_dependencies_csv2","text":"Exports understand dependencies into a csv file. :param csv_path: The absolute address of csv file to generate. :param db_path: The absolute address of project path. :return: None Source code in codart\\utility\\directory_utils.py def export_understand_dependencies_csv2 ( csv_path : str , db_path : str ): \"\"\" Exports understand dependencies into a csv file. :param csv_path: The absolute address of csv file to generate. :param db_path: The absolute address of project path. :return: None \"\"\" command = [ 'und' , 'export' , '-format' , 'long' , '-dependencies' , 'class' , 'csv' , csv_path , db_path ] subprocess . Popen ( command , stdout = open ( os . devnull , 'wb' ) ) . wait () config . logger . debug ( \"Modular dependency graph (MDG.csv) was exported.\" )","title":"export_understand_dependencies_csv2()"},{"location":"utilities/project_utils/#codart.utility.directory_utils.git_restore","text":"This function returns a git supported project back to the initial commit Parameters: Name Type Description Default project_dir str The absolute path of project's directory. required Returns: Type Description None Source code in codart\\utility\\directory_utils.py def git_restore ( project_dir ): \"\"\" This function returns a git supported project back to the initial commit Args: project_dir (str): The absolute path of project's directory. Returns: None \"\"\" assert os . path . isdir ( project_dir ) assert os . path . isdir ( os . path . join ( project_dir , '.git' )) subprocess . Popen ([ \"git\" , \"restore\" , \".\" ], cwd = project_dir , stdout = open ( os . devnull , 'wb' )) . wait () subprocess . Popen ([ \"git\" , \"clean\" , \"-f\" , \"-d\" ], cwd = project_dir , stdout = open ( os . devnull , 'wb' )) . wait ()","title":"git_restore()"},{"location":"utilities/project_utils/#codart.utility.directory_utils.update_understand_database","text":"This function updates database due to file changes. If any error, such as database is locked or read only, occurred it tries again and again to update db. Arges: udb_path (str): The absolute path of understand database. Returns: Type Description None Source code in codart\\utility\\directory_utils.py def update_understand_database ( udb_path ): \"\"\" This function updates database due to file changes. If any error, such as database is locked or read only, occurred it tries again and again to update db. Arges: udb_path (str): The absolute path of understand database. Return: None \"\"\" understand_5_cmd = [ 'und' , 'analyze' , '-rescan' , '-changed' , udb_path ] understand_6_cmd = [ 'und' , 'analyze' , '-changed' , udb_path ] # -rescan option is not required for understand >= 6.0 result = subprocess . run ( understand_6_cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) # info_ = result.stdout.decode('utf-8') # error_ = result.stderr.decode('utf-8') # print(info_[:85]) # print(f'return code: {result.returncode} --- error: {error_}') trials = 0 while result . returncode != 0 : try : db : und . Db = und . open ( config . UDB_PATH ) db . close () except : pass finally : result = subprocess . run ( understand_6_cmd , # stdout = subprocess . PIPE , stderr = subprocess . PIPE ) # info_ = result.stdout.decode('utf-8') error_ = result . stderr . decode ( 'utf-8' ) # print(info_[:85]) config . logger . debug ( f 'return code: { result . returncode } msg: { error_ } ' ) trials += 1 if trials > 5 : break # Try to close und.exe process if it has not been killed automatically result = subprocess . run ([ 'taskkill' , '/f' , '/im' , 'und.exe' ], stdout = subprocess . PIPE , stderr = subprocess . PIPE ) if result . returncode != 0 : config . logger . debug ( 'The und.exe process is not running' ) else : config . logger . debug ( 'The und.exe process killed manually' )","title":"update_understand_database()"},{"location":"utilities/project_utils/#codart.utility.directory_utils.update_understand_database2","text":"This function updates database due to file changes. Error message raised by understand 6.x: Error: The Analysis cannot be performed because the database is locked or read only Arges: udb_path (str): The absolute path of understand database. Returns: Type Description None Source code in codart\\utility\\directory_utils.py def update_understand_database2 ( udb_path ): \"\"\" This function updates database due to file changes. Error message raised by understand 6.x: Error: The Analysis cannot be performed because the database is locked or read only Arges: udb_path (str): The absolute path of understand database. Return: None \"\"\" understand_5_cmd = [ 'und' , 'analyze' , '-rescan' , '-changed' , udb_path ] understand_6_cmd = [ 'und' , 'analyze' , '-changed' , udb_path ] # -rescan option is not required for understand >= 6.0 subprocess . Popen ( understand_6_cmd , stdout = open ( os . devnull , 'wb' ) ) . wait ()","title":"update_understand_database2()"},{"location":"utilities/project_utils/#performance-meter","text":"","title":"Performance meter"},{"location":"utilities/project_utils/#codart.utility.cpu_ram_usage.ProjectParseUsage","text":"Source code in codart\\utility\\cpu_ram_usage.py class ProjectParseUsage : def __init__ ( self , project_dir ): \"\"\" This by calling this class you can measure: - Total consumed memory for keeping all parse trees - Total consumed time for parsing in seconds \"\"\" self . project_root = project_dir self . parse_trees = [] self . counter = 0 @staticmethod def java_explorer ( path ): result = list ( Path ( path ) . rglob ( \"*.java\" )) for file_path in result : yield file_path . absolute () @staticmethod def generate_tree ( file_path ): # Step 1: Load input source into stream stream = FileStream ( file_path , encoding = 'utf8' , errors = 'ignore' ) # Step 2: Create an instance of AssignmentStLexer lexer = JavaLexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = JavaParser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . compilationUnit () return parse_tree def run ( self ): print ( \"Parsing...\" ) total_time = 0 generator = self . java_explorer ( self . project_root ) for file_path in generator : self . counter += 1 print ( f \"Parsing { self . counter } : { file_path } \" ) start = time . time () tree = self . generate_tree ( file_path ) end = time . time () self . parse_trees . append ( tree ) total_time += end - start print ( f \"Execute time is { total_time } seconds.\" ) print ( f \"Memory used for all trees is { sys . getsizeof ( self . parse_trees ) / 1000 } KB\" )","title":"ProjectParseUsage"},{"location":"utilities/project_utils/#codart.utility.cpu_ram_usage.ProjectParseUsage.__init__","text":"This by calling this class you can measure: - Total consumed memory for keeping all parse trees - Total consumed time for parsing in seconds Source code in codart\\utility\\cpu_ram_usage.py def __init__ ( self , project_dir ): \"\"\" This by calling this class you can measure: - Total consumed memory for keeping all parse trees - Total consumed time for parsing in seconds \"\"\" self . project_root = project_dir self . parse_trees = [] self . counter = 0","title":"__init__()"}]}